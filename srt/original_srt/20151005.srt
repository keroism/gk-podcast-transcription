1
00:00:08,860 --> 00:00:10,588
Speaker 1: It's Monday, October 5th, 2015.

2
00:00:10,588 --> 00:00:10,890
Speaker 1: I'm Rym.

3
00:00:13,623 --> 00:00:14,440
Speaker 0: I am Scott.

4
00:00:14,640 --> 00:00:21,340
Speaker 1: And this is Geek Nights, back after a surprisingly long hiatus, here to talk about For The People.

5
00:00:22,220 --> 00:00:25,140
Speaker 1: Rating people on the internet, like y'all.

6
00:00:25,140 --> 00:00:27,500
Speaker 0: Not Ra-ding, like Oakland.

7
00:00:27,740 --> 00:00:31,554
Speaker 1: Ra-ting, with a T. Let's do this.

8
00:00:32,640 --> 00:00:42,780
Speaker 1: So, I'm not gonna tell like every story from, you know, me traveling all around the world, but the small stories I will tell now is one, I flew to Asia business class because fuck all y'all.

9
00:00:43,660 --> 00:00:44,680
Speaker 0: Someone else paid for it.

10
00:00:44,982 --> 00:00:46,679
Speaker 1: No, someone else did not pay for it.

11
00:00:46,760 --> 00:00:48,439
Speaker 0: You used your own monies to pay for that ticket?

12
00:00:48,940 --> 00:00:54,520
Speaker 1: So, normally I fly coach, but I can get premium economy if there's a reason.

13
00:00:54,800 --> 00:01:07,880
Speaker 1: Like, if I'm flying overnight or something, or like I'm gonna land somewhere and I have a meeting, like the next day or like something real quick, then yeah, I'll go like premium economy, which like on Turkish air, that's better than most business class in the US.

14
00:01:08,140 --> 00:01:09,999
Speaker 1: Like, that is pretty nice by itself.

15
00:01:10,681 --> 00:01:18,931
Speaker 1: But I will usually try to sweet talk people who work for the airlines into, "Can I just slip into that business class?

16
00:01:18,971 --> 00:01:20,157
Speaker 1: I know there's no one sitting up there right

17
00:01:20,197 --> 00:01:20,338
Speaker 1: now.".

18
00:01:21,023 --> 00:01:22,159
Speaker 1: Like, I'll try to pull shit.

19
00:01:22,561 --> 00:01:23,797
Speaker 1: It very rarely works out.

20
00:01:24,500 --> 00:01:47,559
Speaker 1: But I booked premium economy all the way to Asia and one thing led to another and one of my legs, because I booked it through one of those dodgy sites that like gets your stuff for you, I don't know what happened on their end, but they ended up giving me premium economy on a very, like a little leg in one section of the, because I had a layover, because there aren't a lot of direct flights that far, even from New York.

21
00:01:48,400 --> 00:01:54,200
Speaker 1: So, because my big leg was business class, it made the whole trip count as business class.

22
00:01:54,581 --> 00:02:01,439
Speaker 1: So, I got to fly in one of those little cubicles that has a full flat lay down bed and like a little shield I can put up, just like a tiny room.

23
00:02:02,542 --> 00:02:15,159
Speaker 1: And I got to stop at my layover and go into a tiny apartment and take a shower and take a nap in an actual bed and eat a bunch of free food and drink a whole bunch of wine and then get on my premium economy flight the rest of the way.

24
00:02:16,240 --> 00:02:24,880
Speaker 1: Let me tell you, I would never in my life pay that much money, even if I was rich, to fly like that, because it is so much money, it is stupid.

25
00:02:25,160 --> 00:02:26,499
Speaker 0: But what if I'm so much rich?

26
00:02:26,841 --> 00:02:33,800
Speaker 1: But the sheer classist hierarchy of it, it's so weird to fly like that, because you do not-.

27
00:02:33,800 --> 00:02:39,660
Speaker 0: But the thing is, I don't understand who is rich enough to afford that, yet not rich enough to afford the private jet.

28
00:02:40,520 --> 00:02:48,820
Speaker 1: So, actually, the private jet's kind of a pain in a lot of ways, because they can't get, like private jets can't go to Australia from New York easily.

29
00:02:49,102 --> 00:02:49,498
Speaker 0: Why not?

30
00:02:49,781 --> 00:02:51,060
Speaker 1: They don't have that much range.

31
00:02:51,762 --> 00:02:53,552
Speaker 1: You're not going to get a 737 as your private jet.

32
00:02:55,146 --> 00:02:55,520
Speaker 1: Why not?

33
00:02:56,060 --> 00:02:56,326
Speaker 1: Why not?

34
00:02:57,743 --> 00:02:58,338
Speaker 1: You just don't.

35
00:02:58,600 --> 00:02:58,957
Speaker 0: Why not?

36
00:02:59,424 --> 00:02:59,900
Speaker 0: Google has one.

37
00:03:00,100 --> 00:03:00,460
Speaker 1: That's too much.

38
00:03:00,680 --> 00:03:01,100
Speaker 1: Yeah, Google.

39
00:03:01,380 --> 00:03:03,300
Speaker 1: Not Sergei, but Google.

40
00:03:03,522 --> 00:03:03,605
Speaker 1: Sure.

41
00:03:04,240 --> 00:03:05,139
Speaker 1: Sergei doesn't have his own.

42
00:03:06,242 --> 00:03:07,618
Speaker 0: If he wants to go, he's going to go.

43
00:03:08,660 --> 00:03:19,120
Speaker 1: But, so, basically, the weirdest thing is that all that crazy luxury I experienced on this trip is a pale comparison to first class.

44
00:03:19,861 --> 00:03:21,460
Speaker 0: The people- Business class is not first class?

45
00:03:21,700 --> 00:03:28,559
Speaker 0: No, first class- If business class is a little cabin with a lay down bed, is first class like there's a mansion in the front of the plane?

46
00:03:29,001 --> 00:03:40,397
Speaker 1: I linked to an article a long time ago of a guy who flew 25 hours first class, like across the Pacific, and he had a room about half the size of the studio we're sitting in right now.

47
00:03:40,500 --> 00:03:41,219
Speaker 0: So it's not that big.

48
00:03:41,480 --> 00:03:59,398
Speaker 1: Yeah, but with a full bed in it, a butler to take care of him, custom menu, you're driven to- the airport picks you up, if you don't have your own driver, and you don't even interact- You go to a separate area of the airport and are checked in manually by people who take care of everything for you.

49
00:03:59,980 --> 00:04:01,799
Speaker 1: Private security screening, right there.

50
00:04:02,822 --> 00:04:05,380
Speaker 1: You never interact with any of the plebes in the airport.

51
00:04:06,341 --> 00:04:08,300
Speaker 1: Like you're taken out of the plane separately.

52
00:04:09,000 --> 00:04:16,139
Speaker 1: Sometimes by a different ramp, sometimes they drive a little car and let you walk up the ramp on the other side of the plane that no one else even knows they put there.

53
00:04:17,401 --> 00:04:21,700
Speaker 1: A chef deals with your meal arrangements for the entire trip, including at the airport.

54
00:04:23,281 --> 00:04:24,476
Speaker 1: Yeah, it's messed up.

55
00:04:25,321 --> 00:04:27,500
Speaker 1: But I got that, and it was great.

56
00:04:28,141 --> 00:04:31,259
Speaker 1: The other story I'll tell is how I almost died out in the bush.

57
00:04:32,340 --> 00:04:33,798
Speaker 0: Doing things I told you not to do.

58
00:04:34,320 --> 00:04:39,495
Speaker 1: So I went up to Lura in the Blue Mountains, and I did a whole bunch of mountain biking- How many lives you got left there, Mr.

59
00:04:39,515 --> 00:04:39,636
Speaker 0: Kent?

60
00:04:41,002 --> 00:04:43,040
Speaker 1: I've burned through maybe three or four.

61
00:04:43,301 --> 00:04:44,259
Speaker 0: It's not looking too good.

62
00:04:44,640 --> 00:04:48,680
Speaker 1: So this one's- this is a great- I'm very proud of this thing that happened.

63
00:04:48,761 --> 00:04:50,640
Speaker 0: You're so proud, you're all gonna die.

64
00:04:50,764 --> 00:04:51,200
Speaker 1: I'm hiking.

65
00:04:51,521 --> 00:04:55,520
Speaker 1: The first day, all these warnings, everyone's like, "The Australian bush will fucking kill

66
00:04:55,603 --> 00:04:55,706
Speaker 1: you."

67
00:04:56,328 --> 00:04:56,580
Speaker 1: Yeah.

68
00:04:57,080 --> 00:05:07,800
Speaker 1: And even when I get there, I hike on this little trail, and I go down- so the Blue Mountains, there's this valley, and there's like a kilometer-ish tall sheer cliff surrounding it.

69
00:05:08,120 --> 00:05:13,059
Speaker 1: So you go down into the valley, which is already a pretty substantial hike, and then down there- How do you get back out?

70
00:05:13,802 --> 00:05:14,500
Speaker 1: Fucking climb.

71
00:05:14,661 --> 00:05:15,660
Speaker 1: It's real hard.

72
00:05:16,600 --> 00:05:25,039
Speaker 1: There's three or four points, at least where I was, where there's a stairway- I'm making finger quotes- bolted into the side of the mountain so you can get up.

73
00:05:25,860 --> 00:05:30,620
Speaker 1: But the stairway is half stairway, half ladder, half rough cliff edges.

74
00:05:31,522 --> 00:05:33,819
Speaker 1: There's a little train you can take in one point.

75
00:05:34,380 --> 00:05:34,878
Speaker 0: Oh, okay.

76
00:05:35,040 --> 00:05:35,479
Speaker 0: That sounds good.

77
00:05:35,640 --> 00:05:43,139
Speaker 1: Yeah, there is a train, and basically, everywhere near that train is where all the people who- Who aren't gonna die.

78
00:05:43,660 --> 00:05:44,940
Speaker 1: Yeah, who can't hike.

79
00:05:45,081 --> 00:05:49,560
Speaker 1: There were people wearing flippy floppies, little kids, families.

80
00:05:49,840 --> 00:05:52,339
Speaker 0: They did not have a brush with death in the brush.

81
00:05:53,140 --> 00:06:03,464
Speaker 1: So the one thing I learned real quick was that all the signs and all the stuff everywhere, because there's all these signs that are like, "If you were behind this sign, well, you might just

82
00:06:03,505 --> 00:06:03,790
Speaker 1: die.".

83
00:06:04,460 --> 00:06:05,198
Speaker 0: They're not lying.

84
00:06:06,900 --> 00:06:12,960
Speaker 1: So what's behind those signs is not that deadly, assuming a couple things.

85
00:06:13,120 --> 00:06:14,179
Speaker 0: Not that deadly.

86
00:06:14,240 --> 00:06:16,620
Speaker 0: So it's- Assuming you are Superman.

87
00:06:16,640 --> 00:06:28,300
Speaker 1: It is no more deadly than the trails I hike in upstate New York, because basically, all those signs, they're trying to scare away tourists, because a lot of tourists go there.

88
00:06:29,381 --> 00:06:39,320
Speaker 1: People who go to the Appalachian, the mountain areas, and climb in the US, very few people go to those places, except White Mountain, that you can drive up to the top of, unless they know how to deal.

89
00:06:39,701 --> 00:06:40,620
Speaker 1: They know orienteering.

90
00:06:40,720 --> 00:06:41,239
Speaker 1: They know hiking.

91
00:06:41,320 --> 00:06:41,996
Speaker 1: They know this stuff.

92
00:06:42,800 --> 00:06:48,139
Speaker 1: But the Blue Mountains in Australia, a lot of tourists go up there- Sure, there wasn't a poisonous animal there that was too small to see.

93
00:06:48,800 --> 00:06:49,399
Speaker 1: Nah, not really.

94
00:06:49,681 --> 00:06:49,980
Speaker 0: Some spiders.

95
00:06:50,583 --> 00:06:55,140
Speaker 1: So the only special warning I got- When I went mountain biking is a guy's like, "Oh, wait, you're from the States.

96
00:06:55,941 --> 00:06:57,156
Speaker 1: Do you know about Australian

97
00:06:57,196 --> 00:06:57,480
Speaker 1: snakes?".

98
00:06:57,844 --> 00:06:58,978
Speaker 1: And I was like, "Don't fuck with

99
00:06:58,998 --> 00:06:59,100
Speaker 1: them.".

100
00:06:59,120 --> 00:07:00,134
Speaker 1: And he's like, "Yeah, don't fuck with

101
00:07:00,155 --> 00:07:00,236
Speaker 1: them.".

102
00:07:01,041 --> 00:07:02,460
Speaker 1: And that was literally the extent.

103
00:07:02,640 --> 00:07:05,400
Speaker 1: He wanted to make sure I knew not to fuck with snakes in Australia.

104
00:07:05,600 --> 00:07:07,920
Speaker 0: Who was gonna- I'm sure he's had tourists fuck with snakes.

105
00:07:08,003 --> 00:07:08,418
Speaker 0: I guess.

106
00:07:08,901 --> 00:07:09,520
Speaker 0: Like, "Ooh, a snake.

107
00:07:09,580 --> 00:07:10,249
Speaker 0: Let's fuck with

108
00:07:10,351 --> 00:07:10,391
Speaker 0: it.".

109
00:07:11,143 --> 00:07:12,060
Speaker 0: "Ooh, an alligator.

110
00:07:12,121 --> 00:07:12,810
Speaker 0: I'll poke it with a

111
00:07:12,851 --> 00:07:13,135
Speaker 0: stick.".

112
00:07:13,520 --> 00:07:17,820
Speaker 1: Well, you know, people who live in the US, there's a lot of places where the average snake you run into is pretty harmless.

113
00:07:17,960 --> 00:07:21,340
Speaker 1: Like a lot of kids will catch garter snakes, but anyway.

114
00:07:22,620 --> 00:07:27,617
Speaker 1: So all those warnings basically say if you don't fucking know what you're doing, it's dangerous back here.

115
00:07:28,461 --> 00:07:31,199
Speaker 1: So if you know what you're doing, it's actually not dangerous.

116
00:07:32,440 --> 00:07:34,097
Speaker 0: So- Except for the one time it is.

117
00:07:34,702 --> 00:07:37,280
Speaker 1: So what I did is I hiked on Federal Pass.

118
00:07:37,625 --> 00:07:38,660
Speaker 1: I did a bunch of other hiking.

119
00:07:38,760 --> 00:07:40,419
Speaker 1: I was in the Valley all goddamn day.

120
00:07:41,000 --> 00:07:48,999
Speaker 1: So I took this little trail out through Federal Pass, through all these, like this old coal mine, through an area- Oh, that's not dangerous at all.

121
00:07:49,241 --> 00:07:51,459
Speaker 1: Not in the coal mine, like through the area where the coal mine was.

122
00:07:52,421 --> 00:07:57,920
Speaker 1: Over an old land slip, so this giant landslide, you kind of skirt the edge of the ruins.

123
00:07:57,960 --> 00:07:58,960
Speaker 0: That's not dangerous whatsoever.

124
00:07:59,602 --> 00:08:07,360
Speaker 0: And way out there- I just walked across the pit of lava, and up the mountain of doom, and over the jagged rocks of death.

125
00:08:07,860 --> 00:08:11,440
Speaker 1: So I'd been hiking all day, and I was real tired.

126
00:08:11,600 --> 00:08:13,099
Speaker 1: I'd gone a long way.

127
00:08:13,900 --> 00:08:23,520
Speaker 1: And I still had plenty of provisions, like I was pretty good on water, and I had a little bit of emergency food left, and all my, it's like my Mylar blanket, and my life straw, and my compass, and all the stuff I would need.

128
00:08:23,621 --> 00:08:24,614
Speaker 0: Going through Tombstone Gulch.

129
00:08:28,342 --> 00:08:37,672
Speaker 1: So I'm going to leave, and then I say, "Oh, I'd read this trail map that said, 'Ruined Castle Rock is a really cool thing to see,' and Mount Solitary, which is further out from that, is amazing.

130
00:08:38,740 --> 00:08:42,980
Speaker 1: But all the things I read said it's real hard and dangerous to get to these places.

131
00:08:43,960 --> 00:08:47,840
Speaker 1: But then I get to- Does Ruined Castle Rock have an actual ruined castle?

132
00:08:48,241 --> 00:08:52,800
Speaker 1: It has a giant rock formation that, from a distance, really looks like a medieval castle.

133
00:08:53,843 --> 00:08:56,140
Speaker 1: It looks like a medieval castle that fell into disrepair.

134
00:08:56,520 --> 00:08:57,811
Speaker 1: But then you get up to it, it's like, "No, it's just

135
00:08:57,851 --> 00:08:58,133
Speaker 1: rocks.".

136
00:08:58,960 --> 00:08:59,760
Speaker 0: But- Quite a disappointment.

137
00:09:00,441 --> 00:09:00,940
Speaker 1: But yeah.

138
00:09:01,380 --> 00:09:04,300
Speaker 1: But still, from a distance, it really looks like a castle.

139
00:09:04,380 --> 00:09:05,740
Speaker 0: I'll look on Google Image Search and all that.

140
00:09:05,740 --> 00:09:12,600
Speaker 1: From what I read, early people who got to that area, white people who were colonizing and disrupting, they saw it in the distance, they were like, "Uh-oh.

141
00:09:13,022 --> 00:09:13,900
Speaker 1: Is there civilization?

142
00:09:15,102 --> 00:09:15,473
Speaker 1: Uh-oh.".

143
00:09:15,982 --> 00:09:17,956
Speaker 1: But then they got out, they're like, "Oh, it's just a rock

144
00:09:17,976 --> 00:09:18,399
Speaker 1: formation.".

145
00:09:18,663 --> 00:09:19,478
Speaker 0: Arty har har.

146
00:09:20,841 --> 00:09:23,894
Speaker 1: So I see a sign, and the sign's like, "Ruined Castle, 3.6

147
00:09:23,894 --> 00:09:24,135
Speaker 1: kilometers."

148
00:09:25,540 --> 00:09:26,138
Speaker 1: That's not far.

149
00:09:26,360 --> 00:09:26,451
Speaker 0: Yeah.

150
00:09:26,701 --> 00:09:28,940
Speaker 1: I'm like, "Even over rough terrain-".

151
00:09:28,940 --> 00:09:32,040
Speaker 0: Of course, you have to cross over Tombstone Valley.

152
00:09:32,620 --> 00:09:35,139
Speaker 1: Even over rough terrain, that is not a hard hike.

153
00:09:35,961 --> 00:09:41,755
Speaker 1: So I look at my maps, and the trail gets dodgy in a few places, but not that bad, so I figure I'll go for it.

154
00:09:42,120 --> 00:09:45,436
Speaker 1: And I actually ran there, because I run five k's, they're like, "It's no big

155
00:09:45,456 --> 00:09:45,657
Speaker 1: deal.".

156
00:09:46,300 --> 00:09:51,400
Speaker 1: So I get there, and it's basically these three pillars of rock, hundreds of feet tall.

157
00:09:52,185 --> 00:09:53,060
Speaker 1: And it's amazing.

158
00:09:53,540 --> 00:09:55,280
Speaker 0: You knocked one down, and it fell on you.

159
00:09:55,280 --> 00:09:56,919
Speaker 1: So I climbed up on top of the tallest one.

160
00:09:57,082 --> 00:09:57,839
Speaker 0: That's a bad idea.

161
00:09:57,940 --> 00:09:59,580
Speaker 1: Because I know how to climb, it's not that dangerous.

162
00:09:59,641 --> 00:10:04,380
Speaker 1: Like Emily and I, either one of us- You knocked down the historic castle rock.

163
00:10:04,800 --> 00:10:10,140
Speaker 1: It is trivial to climb this thing if you have even basic bouldering skills.

164
00:10:10,800 --> 00:10:14,220
Speaker 1: Luke Burrage apparently also climbed the exact same rock, he's been on that same spot.

165
00:10:14,420 --> 00:10:17,320
Speaker 1: You destroyed the historic castle rock.

166
00:10:17,440 --> 00:10:20,220
Speaker 1: No, no, the story's about how I almost died, not how I knocked down Stonehenge.

167
00:10:20,400 --> 00:10:23,400
Speaker 0: And you fell off of it with the rocks that ripped off.

168
00:10:23,400 --> 00:10:30,828
Speaker 1: So, I'm standing on the top, there is zero wind, there is nothing higher than me in any direction, except way off.

169
00:10:30,848 --> 00:10:35,118
Speaker 1: in the distance is the cliff wall of the valley surrounding me on all sides.

170
00:10:36,180 --> 00:10:41,980
Speaker 1: And then in one direction, the one side other than that, is Mount Solitary, which is another four kilometers.

171
00:10:42,422 --> 00:10:45,999
Speaker 1: But apparently there's no tracked trail, you've got a straight up orient to it.

172
00:10:46,781 --> 00:10:53,558
Speaker 1: And I actually didn't have enough water to make it to Mount Solitary, and back to Castle Rock, and back to Civilization.

173
00:10:54,083 --> 00:10:55,600
Speaker 1: So I decided not to go to Mount Solitary.

174
00:10:56,240 --> 00:10:57,460
Speaker 1: In retrospect, I kind of wish I did.

175
00:10:57,500 --> 00:10:58,420
Speaker 0: Is Mount Solitary?

176
00:10:59,721 --> 00:11:02,720
Speaker 1: I would have had to hike back in the dark, which I was prepared for.

177
00:11:02,920 --> 00:11:04,158
Speaker 0: It's not because Superman lives there.

178
00:11:05,921 --> 00:11:10,900
Speaker 1: I was not, I could have hiked back in the dark, but I did not want to.

179
00:11:11,440 --> 00:11:13,099
Speaker 1: I did enough night hiking the night before.

180
00:11:14,380 --> 00:11:15,360
Speaker 0: Almost dying once is good.

181
00:11:15,500 --> 00:11:16,279
Speaker 0: Actually dying.

182
00:11:16,700 --> 00:11:19,780
Speaker 1: Night hiking was pretty easy because of the super moon, actually, believe it or not.

183
00:11:19,920 --> 00:11:24,240
Speaker 1: Because I had to go up the cliff face at the end, but the moon was at my back so I could see everything great.

184
00:11:24,340 --> 00:11:28,219
Speaker 1: I didn't even need the flashlight until I got over the top of the valley and had to hike the rest of the way to the car.

185
00:11:29,120 --> 00:11:30,460
Speaker 1: So I'm on top of this thing.

186
00:11:30,683 --> 00:11:31,160
Speaker 1: It's amazing.

187
00:11:31,340 --> 00:11:31,980
Speaker 1: It's breathtaking.

188
00:11:32,380 --> 00:11:33,900
Speaker 1: I see Mount Solitary in the distance.

189
00:11:34,121 --> 00:11:37,900
Speaker 1: I'm standing there on a pillar of rock that's about a meter in diameter.

190
00:11:40,661 --> 00:11:44,539
Speaker 1: And suddenly a giant bug hits me in the face.

191
00:11:45,602 --> 00:11:48,320
Speaker 1: And I instinctually go, ah, to swat it out of my face.

192
00:11:48,801 --> 00:11:52,840
Speaker 1: And I was wearing my fancy sunglasses that stick out further than my normal glasses.

193
00:11:53,221 --> 00:11:58,380
Speaker 1: And I literally hit my glasses, knocked them off my face, and they were gone.

194
00:11:59,183 --> 00:11:59,659
Speaker 1: And you know me.

195
00:11:59,760 --> 00:12:00,499
Speaker 1: I can't see for shit.

196
00:12:02,402 --> 00:12:07,739
Speaker 1: I probably could have climbed down the thing, but I don't think I could have made it back to civilization without my glasses.

197
00:12:08,684 --> 00:12:10,299
Speaker 1: I would have had to call the Rangers for help.

198
00:12:11,140 --> 00:12:13,160
Speaker 1: I would have been in a lot of fucking trouble.

199
00:12:13,280 --> 00:12:17,660
Speaker 1: And in fact, climbing down the thing would have been doable, but not optimal.

200
00:12:18,181 --> 00:12:23,400
Speaker 1: I would have had to make a lot of very serious decisions in a hurry without my glasses.

201
00:12:23,580 --> 00:12:24,679
Speaker 0: There happened to be someone there?

202
00:12:25,160 --> 00:12:28,180
Speaker 1: No, I did not see a human being anywhere in that valley.

203
00:12:29,964 --> 00:12:31,880
Speaker 1: It was easily a 5K hike to any humans.

204
00:12:32,120 --> 00:12:33,100
Speaker 0: Called someone on your phone?

205
00:12:33,580 --> 00:12:35,258
Speaker 1: So I did have cell service, which was good.

206
00:12:36,581 --> 00:12:37,478
Speaker 0: Where was the cell tower?

207
00:12:38,080 --> 00:12:39,260
Speaker 1: The whole, because it's in a valley.

208
00:12:39,540 --> 00:12:42,020
Speaker 1: So the whole valley actually has cell service, which is great.

209
00:12:43,160 --> 00:12:45,160
Speaker 0: So the valley with no people in it, but cell service.

210
00:12:45,460 --> 00:12:46,800
Speaker 1: Because a lot of hikers are back there.

211
00:12:46,940 --> 00:12:55,020
Speaker 1: So actually for safety, like that's the cost to run that cell tower is probably way cheaper than the cost of Rangers looking for people who are dying on a regular basis.

212
00:12:56,281 --> 00:12:58,260
Speaker 1: So it was a Samurai Jack moment.

213
00:12:58,400 --> 00:13:02,340
Speaker 1: My glasses are flying off and I just freeze and close my eyes immediately.

214
00:13:02,801 --> 00:13:09,717
Speaker 1: And I listen and I hear a little, and it was too soon to have been the glasses falling all the way down.

215
00:13:10,084 --> 00:13:10,899
Speaker 1: Also too loud.

216
00:13:11,563 --> 00:13:14,000
Speaker 1: And it didn't sound like they hit rock and bounced.

217
00:13:14,640 --> 00:13:23,798
Speaker 1: So based on where the sound was, I creep over to the edge of this pillar and I look over and there's a bush sticking out of the side and there's a couple other bushes a little bit further down.

218
00:13:24,320 --> 00:13:27,960
Speaker 1: And I think I see, it looks like my glasses might be hanging from that first Bush.

219
00:13:28,821 --> 00:13:37,239
Speaker 1: So I very carefully climbed down the side and they're not in the first Bush there's, but they are in the second Bush, the second Bush.

220
00:13:37,761 --> 00:13:45,076
Speaker 1: So I put them back on and I climbed back up to the top because it was too dangerous to climb down there and I wait for my adrenaline to stop pumping.

221
00:13:45,237 --> 00:13:46,720
Speaker 1: and then I enjoyed the rest of my day and it was great.

222
00:13:46,880 --> 00:13:51,379
Speaker 0: Why don't you get the thing that A. attaches less to your face, B. contact lenses, C. new eyeballs.

223
00:13:51,980 --> 00:13:52,940
Speaker 1: So I have the thing.

224
00:13:53,160 --> 00:13:53,201
Speaker 1: D.

225
00:13:53,241 --> 00:13:54,580
Speaker 0: don't do anything where you could die.

226
00:13:54,700 --> 00:13:55,660
Speaker 1: To hold the glasses to my face.

227
00:13:55,741 --> 00:13:56,299
Speaker 1: I have a croaky.

228
00:13:56,700 --> 00:13:57,440
Speaker 1: It's in my ski stuff.

229
00:13:57,541 --> 00:13:59,560
Speaker 1: I didn't think I would need it hiking.

230
00:14:00,101 --> 00:14:02,159
Speaker 1: I did not think I would punch myself in the face.

231
00:14:02,480 --> 00:14:06,125
Speaker 0: You did not think you would die, but it's going to happen if you keep doing crazy stupid shit.

232
00:14:06,880 --> 00:14:17,640
Speaker 1: So I highly recommend if any of you are ever in the blue mountains, uh, if you know how to hike and camp and all that shit, seriously, ignore the warnings, hike to at least ruin castle.

233
00:14:17,861 --> 00:14:18,900
Speaker 1: It is breathtaking.

234
00:14:19,240 --> 00:14:22,619
Speaker 0: I recommend bringing more, more than zero people with you.

235
00:14:23,265 --> 00:14:24,020
Speaker 1: Uh, yeah.

236
00:14:24,320 --> 00:14:26,300
Speaker 0: Make that solitary mountain not so solitary.

237
00:14:26,540 --> 00:14:30,760
Speaker 1: So Mount solitary, they do recommend having at least three people and one skilled orientarian.

238
00:14:30,880 --> 00:14:32,060
Speaker 0: Bring some equipments with you.

239
00:14:32,200 --> 00:14:34,098
Speaker 1: Maybe I had a lot of equipment with me.

240
00:14:34,760 --> 00:14:41,129
Speaker 1: So I had multiple layers of sports gear, so I was actually equipped for very cold weather if need be.

241
00:14:42,264 --> 00:14:43,397
Speaker 0: I had melting when it's hot out.

242
00:14:43,940 --> 00:14:47,560
Speaker 1: Uh, no, I wasn't because it's fancy sports gear.

243
00:14:47,800 --> 00:14:49,220
Speaker 1: I could shift layers and open.

244
00:14:49,621 --> 00:14:50,739
Speaker 0: So rich people only.

245
00:14:51,111 --> 00:14:51,298
Speaker 1: Yeah.

246
00:14:51,780 --> 00:14:51,994
Speaker 1: Yeah.

247
00:14:52,441 --> 00:14:56,300
Speaker 1: Actually I had a life straw so I could actually drink water if I needed to.

248
00:14:56,360 --> 00:14:57,639
Speaker 1: I could forge for water safely.

249
00:14:58,760 --> 00:15:01,580
Speaker 1: I had a mylar to mylar Cape safety blanket.

250
00:15:01,660 --> 00:15:11,240
Speaker 1: So if I like broke my leg and was stuck there dangerously, I could wrap myself up in a mylar cocoon to stave off, uh, exposure death long enough for someone to find me.

251
00:15:11,703 --> 00:15:13,480
Speaker 1: I had a real compass, like a sighting compass.

252
00:15:13,945 --> 00:15:14,979
Speaker 1: I had a topographic map.

253
00:15:15,322 --> 00:15:18,200
Speaker 1: I was at my cell phone and I had maps and everything in there.

254
00:15:18,461 --> 00:15:24,659
Speaker 1: I was tracking my GPS positions the whole way and I had registered my hike and my estimated return with the ranger's office.

255
00:15:25,561 --> 00:15:30,619
Speaker 1: So if I didn't come back, someone would have eventually gone and looked for me and I had enough equipment to survive.

256
00:15:31,080 --> 00:15:31,755
Speaker 0: Or would they?

257
00:15:32,202 --> 00:15:32,820
Speaker 1: Yeah, they would have.

258
00:15:32,840 --> 00:15:33,640
Speaker 1: They take that shit seriously.

259
00:15:33,740 --> 00:15:36,773
Speaker 1: In fact, I could have taken out tracking beacon with me.

260
00:15:36,813 --> 00:15:41,199
Speaker 1: if I wanted that I could hit a button on it as a, Oh shit, Rangers, come find me.

261
00:15:41,661 --> 00:15:44,600
Speaker 1: But I decided I was not doing anything dangerous enough to warrant that.

262
00:15:44,864 --> 00:15:45,600
Speaker 0: That was wrong.

263
00:15:46,020 --> 00:15:51,478
Speaker 1: Uh, I wasn't, I didn't need that beacon for where I was, whatever your glasses were not in the bush.

264
00:15:52,162 --> 00:15:54,380
Speaker 1: Uh, then I would have climbed down and decided what to do.

265
00:15:54,540 --> 00:16:01,079
Speaker 1: Either I would have called triple zero or, uh, to, you know, and just basically nine one one and waited for Rangers to find me.

266
00:16:02,141 --> 00:16:14,040
Speaker 1: Or I would have slowly made my way down the trail that I had taken towards civilization and gone as far as I could safely get without seeing and hope to run into someone.

267
00:16:14,322 --> 00:16:16,119
Speaker 0: And then you don't see the snake.

268
00:16:17,002 --> 00:16:21,359
Speaker 1: Uh, that would have been a danger except it was evening and actually, cause I couldn't see any way snakes.

269
00:16:21,701 --> 00:16:27,059
Speaker 1: So snakes really would only be on the trail during like bright, bright sunlight resting cause snakes avoid people.

270
00:16:27,881 --> 00:16:29,471
Speaker 1: So I would have made noise people living snakes.

271
00:16:30,940 --> 00:16:35,818
Speaker 1: So get this, if it was dark, I wouldn't have been any worse off and the snakes wouldn't be out.

272
00:16:35,920 --> 00:16:44,236
Speaker 1: So actually walking back in the dark without my glasses would have been a way easier time for the poison bats and spiders, poisonous bats, owls.

273
00:16:45,701 --> 00:16:50,218
Speaker 1: Uh, the biggest danger might've been a cockatoo fucking with me because they like to fuck with people.

274
00:16:50,387 --> 00:16:50,600
Speaker 1: Yeah.

275
00:16:50,720 --> 00:16:51,260
Speaker 0: Eat your eyeballs.

276
00:16:51,400 --> 00:16:52,159
Speaker 0: Not protected now.

277
00:16:52,360 --> 00:16:53,279
Speaker 1: But anyway, we're back.

278
00:16:53,860 --> 00:16:54,619
Speaker 1: Geek Knights is back.

279
00:16:55,280 --> 00:16:57,560
Speaker 1: We're hopefully going to be mostly uninterrupted like normal.

280
00:16:58,067 --> 00:16:58,560
Speaker 0: Be prepared.

281
00:16:58,700 --> 00:17:00,580
Speaker 0: The last episode of unique nights is coming soon.

282
00:17:00,740 --> 00:17:02,117
Speaker 0: Next time rim goes on a deadly trip.

283
00:17:03,221 --> 00:17:04,877
Speaker 1: You wouldn't continue the show without me.

284
00:17:05,339 --> 00:17:05,679
Speaker 0: Okay.

285
00:17:05,859 --> 00:17:06,103
Speaker 0: I'll get.

286
00:17:06,144 --> 00:17:07,378
Speaker 1: Emily knows how to use a Mackie.

287
00:17:07,480 --> 00:17:08,480
Speaker 1: She could keep the show going.

288
00:17:08,786 --> 00:17:08,934
Speaker 0: Okay.

289
00:17:09,119 --> 00:17:10,438
Speaker 0: We'll make the last geeky.

290
00:17:10,641 --> 00:17:11,118
Speaker 0: Nice with rim.

291
00:17:11,280 --> 00:17:12,059
Speaker 0: Enjoy it while you can.

292
00:17:12,988 --> 00:17:13,200
Speaker 1: Actually.

293
00:17:13,280 --> 00:17:15,898
Speaker 1: October 31st is going to be our 10th anniversary of geek nights.

294
00:17:16,180 --> 00:17:20,240
Speaker 1: Exciting for real arbitrary numbers, but anyway, that's all.

295
00:17:20,260 --> 00:17:20,900
Speaker 1: At a moment stuff.

296
00:17:21,020 --> 00:17:24,220
Speaker 1: I got an announcement for them at a moment, but uh, yeah, it's Monday.

297
00:17:24,359 --> 00:17:26,240
Speaker 1: It's tech news day and there's so much tech news.

298
00:17:26,400 --> 00:17:29,240
Speaker 0: We've got to focus on a show and so long there's news and bits for everything.

299
00:17:29,300 --> 00:17:34,420
Speaker 1: There's a lot of things I want to talk about that we're going to skip because there's bigger things that happened more recently.

300
00:17:35,442 --> 00:17:37,940
Speaker 1: So I guess your news is probably the most interesting.

301
00:17:38,667 --> 00:17:39,319
Speaker 1: I guess mine is.

302
00:17:39,480 --> 00:17:45,386
Speaker 1: So yeah, Volkswagen is probably the biggest news in terms of like actual impact of the world.

303
00:17:46,363 --> 00:17:51,000
Speaker 1: Volkswagen is a horrible fucking company and Jews never buy Volkswagens.

304
00:17:51,720 --> 00:17:59,380
Speaker 1: I like how John Oliver basically was like, remember the member, the Nazis trusted Volkswagen and he had all these spots.

305
00:17:59,500 --> 00:18:04,116
Speaker 1: He was, he was very fairly unfair to Volkswagen.

306
00:18:04,136 --> 00:18:05,160
Speaker 0: Jews don't buy Volkswagen.

307
00:18:05,660 --> 00:18:14,159
Speaker 1: So Volkswagen independent of their interactions with the Nazis in world war II because you know, IBM, a lot of companies interacted with the Nazis in world war II IBM at least.

308
00:18:14,219 --> 00:18:20,200
Speaker 1: it's interesting how Germany is basically the model for a modern democratic socialist state.

309
00:18:20,780 --> 00:18:24,420
Speaker 1: Like for real actual social, like Germany's a pretty great place governmentally.

310
00:18:24,880 --> 00:18:38,500
Speaker 1: Germany's taken in more problems, but so does everybody, but they're taking in more refugees than everyone, which is kind of interesting in light of their, but Volkswagen was always seen as a like fair, well run company globally.

311
00:18:39,280 --> 00:18:43,837
Speaker 1: Like Volkswagen would be given the benefit of the doubt by a lot of countries and a lot of people.

312
00:18:44,760 --> 00:18:53,020
Speaker 1: And they had a reputation for making diesel cars that were super fuel efficient, super non-polluting, super green, like the best cars.

313
00:18:53,140 --> 00:18:57,799
Speaker 1: Like if you care about the environment and you want to save money on gas, like these are the best cars.

314
00:18:58,163 --> 00:18:58,840
Speaker 0: I don't know about that.

315
00:18:58,900 --> 00:19:03,692
Speaker 0: We went to the Volkswagen dealer, that lady was giving us the hard sell and I listen to that.

316
00:19:03,960 --> 00:19:05,769
Speaker 1: She closed the door repeatedly.

317
00:19:05,789 --> 00:19:13,559
Speaker 0: and make us listen to how great the thing that really made me realize we shouldn't buy any cars there, you know, because at first, you know, at first, obviously Jews don't buy Volkswagens.

318
00:19:13,760 --> 00:19:16,280
Speaker 0: It's like, all right, you know, I buy an IBM computer, right?

319
00:19:16,320 --> 00:19:16,839
Speaker 0: It's like, whatever.

320
00:19:17,501 --> 00:19:18,029
Speaker 0: It's not like.

321
00:19:18,192 --> 00:19:18,679
Speaker 0: I went there.

322
00:19:18,847 --> 00:19:19,038
Speaker 0: Yeah.

323
00:19:19,241 --> 00:19:21,800
Speaker 0: I saw the big lineup at the service center.

324
00:19:21,880 --> 00:19:23,600
Speaker 0: The other car dealers did not have.

325
00:19:23,660 --> 00:19:24,576
Speaker 0: And I'm like, uh-huh.

326
00:19:24,842 --> 00:19:24,928
Speaker 0: Yeah.

327
00:19:25,261 --> 00:19:25,471
Speaker 0: Uh-huh.

328
00:19:25,764 --> 00:19:26,240
Speaker 0: And you know what?

329
00:19:26,280 --> 00:19:26,980
Speaker 0: That's actually true.

330
00:19:27,100 --> 00:19:28,479
Speaker 0: Volkswagens are super unreliable.

331
00:19:29,161 --> 00:19:34,080
Speaker 0: So the long story short, because I realized it wasn't just an anecdote like that Volkswagen had a big lineup that day.

332
00:19:34,080 --> 00:19:38,160
Speaker 0: It's like, no, they're actually statistically not reliable cars relative to other cars.

333
00:19:38,582 --> 00:19:42,138
Speaker 1: So if you haven't been following the story, I'm going to summarize it really succinctly.

334
00:19:42,840 --> 00:19:48,380
Speaker 1: Volkswagen has been cheating on their emissions tests for a long time.

335
00:19:48,780 --> 00:19:54,819
Speaker 0: So the software in the car was written such to detect when the car was being given an emissions test.

336
00:19:54,960 --> 00:20:02,480
Speaker 0: And when a car was being given an emissions test, the engine changed function to have lower output so that it would pass the emissions test.

337
00:20:02,660 --> 00:20:07,094
Speaker 1: And other things too, like basically it turned on all the emission controls that the cars said they have.

338
00:20:07,861 --> 00:20:10,440
Speaker 1: Like it did what the car is expected to do all the time.

339
00:20:11,040 --> 00:20:13,060
Speaker 0: Like, you know, it turned the air conditioning off, right?

340
00:20:13,220 --> 00:20:16,259
Speaker 0: It turned all these things off, you know, to make sure that you were getting, you know.

341
00:20:16,760 --> 00:20:18,838
Speaker 1: But it's a little worse than that.

342
00:20:20,521 --> 00:20:28,540
Speaker 1: The controls, like the actual, like not just air conditioning, like basic stuff like that, but like the actual pollution control systems themselves were all on.

343
00:20:29,662 --> 00:20:35,460
Speaker 1: If the car was reasonably sure that it was being driven on the road by a normal person, it turned everything off.

344
00:20:35,802 --> 00:20:38,080
Speaker 1: It spewed ridiculous amounts of pollution.

345
00:20:38,540 --> 00:20:41,360
Speaker 1: We're not talking like one percent more pollution.

346
00:20:41,942 --> 00:20:45,040
Speaker 1: We're talking like 40 times the amount of pollution.

347
00:20:45,287 --> 00:20:45,375
Speaker 0: Yeah.

348
00:20:45,580 --> 00:20:46,540
Speaker 0: This is interesting.

349
00:20:47,160 --> 00:20:50,140
Speaker 0: People think they're like, oh, industrial pollution is really the big problem.

350
00:20:50,240 --> 00:20:56,660
Speaker 0: And yeah, it is, you know, but all the cars added up is a tremendous problem equal to, you know, whatever.

351
00:20:56,860 --> 00:20:56,971
Speaker 0: Right.

352
00:20:57,300 --> 00:21:10,120
Speaker 0: And the thing is, people don't realize if you take just five percent of all the cars, the five percent of cars that are really, really bad, that have awful emissions, put out like ninety five percent of all the air pollution.

353
00:21:10,320 --> 00:21:14,000
Speaker 0: If all the cars on the road were like super nice and even though they're gas powered.

354
00:21:14,680 --> 00:21:14,810
Speaker 0: Right.

355
00:21:15,080 --> 00:21:20,861
Speaker 0: You're not even hybrid cars, just efficient, well maintained, not broken, truly passing emissions.

356
00:21:20,881 --> 00:21:22,347
Speaker 0: test cars like.

357
00:21:22,447 --> 00:21:26,100
Speaker 0: total air pollution from cars goes down by ninety five percent.

358
00:21:26,200 --> 00:21:26,337
Speaker 0: Yeah.

359
00:21:26,561 --> 00:21:34,260
Speaker 1: That's one reason why like hybrids and electric cars are such a big deal for pollution, because yeah, they're using the same energy, arguably more because of transmission losses.

360
00:21:34,641 --> 00:21:43,320
Speaker 1: But instead of having five, you know, millions of poorly maintained, I mean, I did not maintain that purple car I had at RIT very well.

361
00:21:43,520 --> 00:21:55,039
Speaker 0: But I mean, even just a normal, non hybrid, non electric car that actually has, you know, regular good, you know, good efficiency and is, you know, proper pollution controls is perfectly fine.

362
00:21:55,460 --> 00:21:57,540
Speaker 0: You know, at least is ninety five percent better than a Volkswagen.

363
00:21:57,821 --> 00:22:03,200
Speaker 1: But I'm saying on that other argument, the electric manufacturing can have an economy of scale.

364
00:22:03,340 --> 00:22:09,040
Speaker 1: If you can put pollution controls on a giant smokestack that you can't put on millions and millions of tiny little smokestacks.

365
00:22:11,484 --> 00:22:16,315
Speaker 1: But the the the moral of this is that this isn't just like they cheated a little bit or they cheated a ton.

366
00:22:17,060 --> 00:22:29,340
Speaker 1: They cheated, biggest cheating openly, blatantly, hugely to the point that like the article I'm going to link to here talks about how this would have had to have been a gigantic institutional conspiracy.

367
00:22:29,760 --> 00:22:29,861
Speaker 0: Right.

368
00:22:29,882 --> 00:22:31,300
Speaker 0: Because you have to you have the software.

369
00:22:31,460 --> 00:22:34,039
Speaker 0: So obviously the engineers who wrote the software have to know.

370
00:22:34,321 --> 00:22:34,503
Speaker 0: Yeah.

371
00:22:34,686 --> 00:22:35,920
Speaker 1: So, hey, Scott, Broadway dot com.

372
00:22:36,080 --> 00:22:39,100
Speaker 0: We need someone told you an engineer is just not going to think to do that.

373
00:22:39,320 --> 00:22:40,398
Speaker 0: Someone told them to do it.

374
00:22:40,500 --> 00:22:44,060
Speaker 1: Scott, we need you to put a backdoor in the site personally.

375
00:22:44,200 --> 00:22:47,657
Speaker 1: Now, don't tell any of your other teammates about this, but put a backdoor here.

376
00:22:48,881 --> 00:22:53,619
Speaker 0: So it could have been just a small number of people, but it had to be like the QA.

377
00:22:53,639 --> 00:22:54,930
Speaker 0: people are checking this code.

378
00:22:54,970 --> 00:22:56,039
Speaker 0: People are testing this.

379
00:22:56,220 --> 00:22:56,502
Speaker 0: Right.

380
00:22:56,602 --> 00:23:02,459
Speaker 0: It's like, you know, there's a lot of people who would have had to been in on this who didn't blow the whistle.

381
00:23:02,922 --> 00:23:03,566
Speaker 0: It might not have been.

382
00:23:03,606 --> 00:23:05,800
Speaker 0: everyone like the CEO might not have known about it.

383
00:23:05,961 --> 00:23:06,773
Speaker 0: You know, it's possible.

384
00:23:07,138 --> 00:23:07,280
Speaker 0: Right.

385
00:23:07,420 --> 00:23:11,498
Speaker 0: But a lot of people at the company had to know about it and not say anything.

386
00:23:12,100 --> 00:23:14,780
Speaker 1: And even worse, low level people wouldn't do this on their own.

387
00:23:14,861 --> 00:23:15,674
Speaker 1: Like, that's crazy.

388
00:23:15,695 --> 00:23:16,040
Speaker 0: Yeah.

389
00:23:16,081 --> 00:23:17,219
Speaker 0: Why would they think to do that?

390
00:23:17,360 --> 00:23:17,441
Speaker 0: Yeah.

391
00:23:17,461 --> 00:23:21,580
Speaker 0: And even if they thought to do it, it has someone had to order someone to do this.

392
00:23:21,740 --> 00:23:31,758
Speaker 0: I mean, no, no one who's just like a software engineer is going to write this into the softwares of their own unless like they'd have to be like a genius who wanted to really get the company bad.

393
00:23:32,481 --> 00:23:33,604
Speaker 1: Yeah.

394
00:23:33,625 --> 00:23:49,054
Speaker 1: So beyond that, the reason it wasn't caught for so long is partly because Volkswagen had such a good reputation that the EPA and all the testing that just happens both in the US and other countries, they didn't give Volkswagen a pass, but they had bigger fish to fry.

395
00:23:49,620 --> 00:23:57,980
Speaker 1: So they didn't give them deep scrutiny because they had a good reputation and they were mostly going after big diesel trucks lately because those are the real problems.

396
00:23:58,200 --> 00:23:58,802
Speaker 0: They're real bad.

397
00:23:59,264 --> 00:24:03,264
Speaker 1: And two, they're underfunded because of Republicans and politics in the US.

398
00:24:03,305 --> 00:24:04,120
Speaker 0: Everything's underfunded.

399
00:24:04,540 --> 00:24:04,620
Speaker 1: Yeah.

400
00:24:04,641 --> 00:24:08,360
Speaker 1: Like this would have been caught immediately if the EPA had been funded.

401
00:24:10,122 --> 00:24:14,610
Speaker 1: So and also, you know, there are a lot of states that don't have emissions testing like in Michigan.

402
00:24:14,631 --> 00:24:14,876
Speaker 1: Yeah.

403
00:24:15,440 --> 00:24:22,045
Speaker 1: My I drove a car that would not have been street legal in New York or California when I was a kid.

404
00:24:22,410 --> 00:24:23,280
Speaker 1: That's just how it went.

405
00:24:24,460 --> 00:24:31,139
Speaker 1: But the testing now, basically, from what I can see, there's a big move to where the people are responsible for this testing.

406
00:24:31,780 --> 00:24:36,155
Speaker 1: One, this is such a big deal that there's talk of criminal charges like.

407
00:24:36,416 --> 00:24:38,500
Speaker 1: I hope that people go to jail.

408
00:24:38,740 --> 00:24:44,660
Speaker 1: I hope that the US extradites executives from Volkswagen and Germany better not say no.

409
00:24:44,800 --> 00:24:45,960
Speaker 0: Why don't they just put them in German jail?

410
00:24:46,120 --> 00:24:47,260
Speaker 0: Why do we got to be always doing that?

411
00:24:47,360 --> 00:24:48,579
Speaker 0: We're always cleaning up their messes.

412
00:24:48,620 --> 00:24:58,480
Speaker 0: It's like, yeah, you know, and then when they try to come after our companies, Google alone, you fuckers, it's like you could go after Google if they did something this bad and I would be like, OK, go for it.

413
00:24:59,023 --> 00:25:00,177
Speaker 0: But they didn't do anything.

414
00:25:01,900 --> 00:25:02,864
Speaker 1: I mean, yeah, it was on.

415
00:25:03,185 --> 00:25:08,699
Speaker 1: if anyone Amazon's doing bad stuff right now by deciding to not sell streaming devices except theirs.

416
00:25:09,742 --> 00:25:12,436
Speaker 0: If you're a store, you're allowed to sell whatever you want to.

417
00:25:12,456 --> 00:25:16,880
Speaker 0: a grocery store is only selling Chiquita bananas now to a point and not Bonita banana to a point.

418
00:25:17,081 --> 00:25:20,151
Speaker 1: Amazon is such market share that they.

419
00:25:20,171 --> 00:25:26,200
Speaker 1: it's arguable that in a class, we're in a class where another division of Amazon competes streaming devices.

420
00:25:26,741 --> 00:25:32,003
Speaker 1: They probably shouldn't be allowed to ban competitors products from their store using yours.

421
00:25:32,023 --> 00:25:32,510
Speaker 0: That's true.

422
00:25:32,530 --> 00:25:32,611
Speaker 0: Yeah.

423
00:25:33,380 --> 00:25:35,519
Speaker 0: Also, I mean, antitrust is so weak lately.

424
00:25:35,680 --> 00:25:36,404
Speaker 0: I know I know.

425
00:25:36,464 --> 00:25:40,398
Speaker 0: Antitrust is what it should be, but all of these companies would be in like one hundred pieces.

426
00:25:40,640 --> 00:25:45,740
Speaker 1: But I'm saying Europe's going after Google for the things they're going after Google for and get this Amazon shit.

427
00:25:45,920 --> 00:25:48,740
Speaker 1: OK, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no.

428
00:25:48,740 --> 00:25:51,861
Speaker 0: Because, you know, there's an Amazon dot code at whatever country and they're happy with that.

429
00:25:51,881 --> 00:26:06,040
Speaker 1: But based on the existing law, Volkswagen basically would be fined a certain amount per vehicle, which, because this is such a huge conspiracy, could be twenty, thirty billion dollars, never mind.

430
00:26:06,360 --> 00:26:07,699
Speaker 1: And that's just the statutory fee.

431
00:26:07,861 --> 00:26:10,420
Speaker 1: That's not punitive and criminal charges on top.

432
00:26:10,680 --> 00:26:15,740
Speaker 0: We should basically just own their company like Volkswagen is not property of the US government.

433
00:26:15,800 --> 00:26:16,605
Speaker 1: It would be like.

434
00:26:16,867 --> 00:26:18,960
Speaker 1: these are the things that couldn't easily happen.

435
00:26:19,101 --> 00:26:23,742
Speaker 1: But if this were a manga like Eagle, you could see the president being in Congress being like.

436
00:26:24,124 --> 00:26:26,899
Speaker 1: Volkswagen is banned from selling in the United States.

437
00:26:27,201 --> 00:26:28,620
Speaker 0: I know it'd be like Volkswagen.

438
00:26:28,700 --> 00:26:31,980
Speaker 0: The company is now a subsidiary of the United States of America.

439
00:26:32,081 --> 00:26:35,000
Speaker 0: We are selling all of it and taking all the money or eminent domain.

440
00:26:35,341 --> 00:26:37,820
Speaker 1: Every unsold Volkswagen car in the US.

441
00:26:38,020 --> 00:26:38,282
Speaker 0: Oh, yeah.

442
00:26:38,362 --> 00:26:41,080
Speaker 0: Every Volkswagen car in the US is also owned by the US government.

443
00:26:41,100 --> 00:26:45,726
Speaker 1: Well, no, although if a consumer owns one, the government should at least pay you the unsold ones.

444
00:26:45,847 --> 00:26:47,260
Speaker 0: Yeah, I think dealers.

445
00:26:47,520 --> 00:26:52,889
Speaker 1: I think every everyone who owns one of these Volkswagens should basically be given a new car by Volkswagen.

446
00:26:52,949 --> 00:26:54,560
Speaker 1: because because here's the thing.

447
00:26:54,580 --> 00:26:58,200
Speaker 1: They bought a car that had emissions ratings and performance ratings.

448
00:26:58,701 --> 00:27:02,200
Speaker 1: The recall will fix the emissions problems by ruining the performance.

449
00:27:02,482 --> 00:27:02,867
Speaker 0: That's true.

450
00:27:02,887 --> 00:27:03,879
Speaker 1: You didn't get what you paid for.

451
00:27:04,060 --> 00:27:04,550
Speaker 0: That's right.

452
00:27:04,693 --> 00:27:04,979
Speaker 1: Yeah.

453
00:27:05,960 --> 00:27:06,787
Speaker 1: Fuck Volkswagen.

454
00:27:07,109 --> 00:27:08,239
Speaker 1: That's what I got to say about this.

455
00:27:08,882 --> 00:27:23,599
Speaker 1: And every other car company, there's hints from the EPA and a lot of other regulators that basically, guys, if you're cheating, might be good to tell us now because you think we're not going to test every goddamn car ever from now.

456
00:27:24,061 --> 00:27:29,300
Speaker 0: And also, even if you like you stop cheating now, your old cars are on the road now.

457
00:27:29,400 --> 00:27:35,306
Speaker 0: You can't go and get your Toyota Camry from 2010 and like bring it back and fix it before the EPA finds.

458
00:27:35,446 --> 00:27:37,279
Speaker 0: Yeah, that code is there.

459
00:27:37,600 --> 00:27:38,282
Speaker 0: They're going to.

460
00:27:39,005 --> 00:27:44,726
Speaker 0: this is also, you know, you should be forced to have open source software in your car.

461
00:27:44,746 --> 00:27:46,340
Speaker 0: Yeah, you shouldn't be allowed to have that.

462
00:27:46,440 --> 00:27:47,243
Speaker 0: Should be closed source.

463
00:27:47,604 --> 00:27:57,940
Speaker 1: So this gets into a wider problem of the fact that corporations can have such control over these things like car firmware and car emissions.

464
00:27:58,861 --> 00:28:06,460
Speaker 1: And yet, you know, people who are against tighter regulation of technology, which I'm for in a lot of cases like Internet, like I want more regulation.

465
00:28:06,600 --> 00:28:08,909
Speaker 1: I want a neutrality as a lot of technologists do.

466
00:28:09,773 --> 00:28:33,780
Speaker 1: the fact, you know, people say we don't need regulation, but a trustworthy or at least until now trustworthy, respected global company that generally people had a very high opinion of engaged in massive global, cripplingly damaging to the environment, fraud and conspiracy to commit fraud pretty much says you need regulation.

467
00:28:34,080 --> 00:28:43,980
Speaker 0: Well, someone said something very clever, which is that regulation is built on the idea right that you can't trust people to not lie, but you can trust things to not lie.

468
00:28:44,340 --> 00:28:46,780
Speaker 0: But this is a case where things lied.

469
00:28:47,381 --> 00:28:54,090
Speaker 0: And the only way to make things not lie is if it's not any proprietary, closed source software, then, you know, things aren't lying.

470
00:28:54,110 --> 00:28:59,260
Speaker 1: because if you have code, you can hook up unit tests all around that code and ask the code.

471
00:28:59,320 --> 00:29:00,349
Speaker 1: Hey, what do you do?

472
00:29:01,014 --> 00:29:01,740
Speaker 1: You can ask the car.

473
00:29:01,922 --> 00:29:03,240
Speaker 0: Everyone should be able to read the code.

474
00:29:03,420 --> 00:29:11,200
Speaker 0: If I own the car, I should be, you know, by law, I should be able to have, you know, the full diagram plans for everything in the car, including all the software.

475
00:29:12,681 --> 00:29:17,449
Speaker 0: For any device you buy, all that stuff should be given to you, even the OS that runs on the device.

476
00:29:17,572 --> 00:29:17,818
Speaker 1: Yes.

477
00:29:18,900 --> 00:29:19,166
Speaker 0: Fuck you.

478
00:29:19,187 --> 00:29:19,760
Speaker 0: All right.

479
00:29:20,422 --> 00:29:22,293
Speaker 1: I take a radical stance, but I don't.

480
00:29:22,655 --> 00:29:23,420
Speaker 1: I don't want to go that far.

481
00:29:23,541 --> 00:29:26,780
Speaker 1: I would be happy with a little bit of that.

482
00:29:27,081 --> 00:29:27,443
Speaker 0: Why not?

483
00:29:27,563 --> 00:29:30,660
Speaker 0: I'm paying you any amount of money for this thing.

484
00:29:30,902 --> 00:29:32,860
Speaker 0: And especially a car where your life is on the line.

485
00:29:32,900 --> 00:29:33,206
Speaker 1: That's good.

486
00:29:33,268 --> 00:29:33,798
Speaker 1: I agree with you.

487
00:29:34,261 --> 00:29:34,984
Speaker 1: I agree with you.

488
00:29:35,004 --> 00:29:39,320
Speaker 1: I disagree in the sense that politically we can't get anything done.

489
00:29:39,521 --> 00:29:45,132
Speaker 0: No, but that's, you know, let's not talk about anything else except the fact that governments are corrupt because there's.

490
00:29:45,152 --> 00:29:45,999
Speaker 0: no we can't get anything done.

491
00:29:46,200 --> 00:29:49,680
Speaker 0: Paging Lauren's lesson is not talk about anything else because there's no point.

492
00:29:50,120 --> 00:29:50,817
Speaker 1: You got any other news?

493
00:29:51,560 --> 00:29:52,970
Speaker 0: Yeah, so it's a tiny news.

494
00:29:53,030 --> 00:29:54,420
Speaker 0: Adobe had a big thing today.

495
00:29:54,541 --> 00:29:56,819
Speaker 0: They made a bunch of announcements and updates to their stuff.

496
00:29:57,902 --> 00:30:05,940
Speaker 0: The one that probably matters to people listening here, if you care, is they update a lot of the mobile apps for the Android and the iPhone.

497
00:30:07,383 --> 00:30:09,439
Speaker 0: Well, I mean, the iPhone and the Android even.

498
00:30:10,560 --> 00:30:10,682
Speaker 1: Yeah.

499
00:30:10,764 --> 00:30:11,395
Speaker 1: Correct order there.

500
00:30:11,477 --> 00:30:11,620
Speaker 0: Yeah.

501
00:30:13,025 --> 00:30:15,620
Speaker 0: So the big update is Lightroom Mobile's way improved.

502
00:30:15,800 --> 00:30:17,005
Speaker 0: And I think it's even.

503
00:30:17,025 --> 00:30:20,280
Speaker 0: it says in the update, I think it's some somewhat free.

504
00:30:20,762 --> 00:30:24,643
Speaker 0: Like if you'd even if you're on Creative Cloud, I think Lightroom Mobile is somewhat free.

505
00:30:25,287 --> 00:30:27,160
Speaker 0: And some of these other apps might be partially free.

506
00:30:27,480 --> 00:30:31,515
Speaker 1: I noticed that because some of the apps I installed, like they did stuff before I authenticated my creative.

507
00:30:31,575 --> 00:30:31,900
Speaker 1: Yeah.

508
00:30:32,041 --> 00:30:35,240
Speaker 0: And I mean, there's apps that do the same thing that are also free.

509
00:30:35,341 --> 00:30:36,209
Speaker 0: So it's kind of stupid.

510
00:30:36,229 --> 00:30:36,330
Speaker 0: Right.

511
00:30:37,600 --> 00:30:39,059
Speaker 0: Like you can get VCO cam for free.

512
00:30:40,422 --> 00:30:50,318
Speaker 0: But anyway, the big one they did is there are four apps, brush, hue, color and shape, and they combine them into one, which is Adobe capture.

513
00:30:50,921 --> 00:30:54,040
Speaker 0: And it's like, yes, I don't have four stupid icons on my screen.

514
00:30:54,101 --> 00:30:55,535
Speaker 0: Now I only have one icon.

515
00:30:55,576 --> 00:30:55,960
Speaker 0: Yeah.

516
00:30:56,260 --> 00:30:56,808
Speaker 0: Yeah.

517
00:30:56,828 --> 00:30:57,579
Speaker 0: That's the best news.

518
00:30:58,780 --> 00:31:01,720
Speaker 1: Meanwhile, Google split wallet into wallet and Android pays.

519
00:31:01,840 --> 00:31:03,339
Speaker 1: And I got two icons instead of one.

520
00:31:04,963 --> 00:31:14,949
Speaker 1: And also, and I'll talk about this on another show in the future, but last tiny news, the much awaited successor to the Nexus five, the Nexus five X. Like it's out.

521
00:31:15,212 --> 00:31:15,859
Speaker 1: The specs are out.

522
00:31:16,161 --> 00:31:16,843
Speaker 1: It's garbage.

523
00:31:17,886 --> 00:31:24,200
Speaker 1: It's not materially better than the existing Nexus five, except it has a working camera as opposed to a garbage camera.

524
00:31:24,340 --> 00:31:25,240
Speaker 0: How about some iPhone action?

525
00:31:26,504 --> 00:31:27,479
Speaker 1: We'll see what I do now.

526
00:31:27,980 --> 00:31:31,330
Speaker 1: My last hope would have been the Xperia Z five.

527
00:31:32,233 --> 00:31:34,921
Speaker 1: if one, these overheating problems aren't true.

528
00:31:34,942 --> 00:31:43,659
Speaker 1: And two, I hold in my hand someone else's Z five compact that they have gotten Sanogen mod working on and they tell me how they did it.

529
00:31:44,803 --> 00:31:46,860
Speaker 1: Those are the only two ways I'll ever buy a Sony phone.

530
00:31:47,703 --> 00:31:49,660
Speaker 1: And the Nexus five X is garbage.

531
00:31:49,860 --> 00:31:51,339
Speaker 1: It's bigger than the Nexus five.

532
00:31:52,223 --> 00:31:54,220
Speaker 1: It's not that much faster or more powerful.

533
00:31:54,840 --> 00:31:55,939
Speaker 1: And it has a bigger bezel.

534
00:31:56,240 --> 00:31:58,600
Speaker 1: The screen's higher resolution, but the screen's not actually bigger.

535
00:31:58,700 --> 00:31:59,680
Speaker 1: Just the bezels bigger.

536
00:32:00,500 --> 00:32:03,320
Speaker 1: Well, I don't know why they made this phone because they're not good enough.

537
00:32:03,763 --> 00:32:05,259
Speaker 0: They're trying to do good, but they suck.

538
00:32:05,480 --> 00:32:10,926
Speaker 1: Yeah, but like the Nexus five X is just like it's a shittier version of all the other big phones.

539
00:32:10,987 --> 00:32:11,998
Speaker 0: They're not good at it.

540
00:32:12,280 --> 00:32:12,502
Speaker 1: Yeah.

541
00:32:13,431 --> 00:32:14,420
Speaker 1: So we'll see.

542
00:32:15,962 --> 00:32:22,780
Speaker 1: I'll continue to use my Nexus five, which is still the best Android phone on the market, even though it has a bad camera.

543
00:32:23,180 --> 00:32:25,320
Speaker 1: I know, Conrad, you keep telling me it has a bad camera.

544
00:32:25,440 --> 00:32:25,825
Speaker 1: You know what?

545
00:32:25,845 --> 00:32:26,999
Speaker 0: How many pictures you take him with it?

546
00:32:27,540 --> 00:32:28,043
Speaker 0: I take a lot.

547
00:32:28,123 --> 00:32:30,920
Speaker 1: I take a lot of crappy pictures with it because it's phone.

548
00:32:31,080 --> 00:32:32,699
Speaker 1: I have a real camera to buy a camera.

549
00:32:33,060 --> 00:32:33,180
Speaker 1: Yeah.

550
00:32:39,036 --> 00:32:40,580
Speaker 1: Things of the day.

551
00:32:41,121 --> 00:32:43,660
Speaker 1: NASA has released a little flicker gallery.

552
00:32:44,342 --> 00:32:47,702
Speaker 1: All the pictures they took on the moon, not just the good ones like they'd released before.

553
00:32:47,722 --> 00:32:55,233
Speaker 1: It's kind of like if you go to my place like because think about it, even a crappy picture of the moon in 1969 from the moon is a picture of the moon.

554
00:32:57,360 --> 00:33:06,100
Speaker 0: Well, the 1969 reason these pictures look good is because if you look up the kind of cameras they brought when they went into space, they brought like these Hasselblad cameras that are like incredible.

555
00:33:06,361 --> 00:33:10,040
Speaker 0: So that's why all the pictures of space from those days look incredible.

556
00:33:10,301 --> 00:33:18,258
Speaker 0: But it's really interesting to see this because you can even you can even get the manual on how to use that camera that they gave to the astronauts because not like they were photographers or anything.

557
00:33:18,380 --> 00:33:18,603
Speaker 0: Yeah.

558
00:33:18,947 --> 00:33:20,000
Speaker 1: But I mean, just think about that.

559
00:33:20,321 --> 00:33:21,767
Speaker 1: We can see the full.

560
00:33:21,827 --> 00:33:26,200
Speaker 1: it's like looking at my flicker photo stream like, yeah, that's all the pictures I took, not just the good ones.

561
00:33:26,280 --> 00:33:32,200
Speaker 1: Like there's six pictures of Scott doing something weird and they're all like from different angles and like they tell a little story by themselves.

562
00:33:32,300 --> 00:33:35,437
Speaker 1: That's not interesting enough to feature, but kind of neat to see.

563
00:33:37,021 --> 00:33:37,302
Speaker 0: Anyway.

564
00:33:37,483 --> 00:33:38,526
Speaker 0: Yeah.

565
00:33:38,727 --> 00:33:44,600
Speaker 0: So there's this group of kids called the Louisville, obviously from Louisville, Kentucky, leopards, percussionists.

566
00:33:44,781 --> 00:33:45,002
Speaker 0: Right.

567
00:33:45,042 --> 00:33:48,220
Speaker 0: So it's like this is after school program where.

568
00:33:49,203 --> 00:33:51,420
Speaker 0: You don't have it doesn't cost a lot of money or no money.

569
00:33:51,761 --> 00:34:00,120
Speaker 0: And the kids can go and they practice percussion, drums, cymbals, marimbas, remember, xylophones, xylophones.

570
00:34:00,421 --> 00:34:08,760
Speaker 0: And when they get these kids together, they make them play the highest quality tunes for your enjoyment.

571
00:34:09,242 --> 00:34:12,964
Speaker 1: So if you search for them on YouTube, this already looks like a high quality group of kids here.

572
00:34:13,126 --> 00:34:14,360
Speaker 0: If you search for them on YouTube.

573
00:34:14,981 --> 00:34:15,243
Speaker 0: Right.

574
00:34:15,304 --> 00:34:17,540
Speaker 0: There are many, many songs that they are playing.

575
00:34:17,639 --> 00:34:24,820
Speaker 0: If you look in the sidebar there, I saw one where they're playing like I see a lot of Zeppelin hanging out in some war, some low rider.

576
00:34:25,501 --> 00:34:25,882
Speaker 1: Yeah.

577
00:34:25,962 --> 00:34:32,659
Speaker 0: So, you know, here's that we're linking to a little Zeppelin here, but you can make a little YouTube playlist and enjoy.

578
00:34:35,803 --> 00:34:42,500
Speaker 0: Also, you should be like very sad that these little kids are way better than you playing music in the moment.

579
00:34:42,679 --> 00:34:45,400
Speaker 1: The book, the book was the Wheel of Time book one.

580
00:34:45,521 --> 00:34:47,699
Speaker 1: You can get reviews up like it's done that episode.

581
00:34:48,224 --> 00:34:49,418
Speaker 1: And Scott and I just kept reading them.

582
00:34:49,801 --> 00:34:51,040
Speaker 1: So Scott's on book five.

583
00:34:51,199 --> 00:34:52,614
Speaker 0: I'm almost on book five.

584
00:34:52,634 --> 00:34:53,199
Speaker 0: I'm getting close.

585
00:34:53,360 --> 00:34:54,559
Speaker 0: I'm almost done with book four.

586
00:34:54,880 --> 00:34:56,159
Speaker 1: I'm about halfway through book four.

587
00:34:56,460 --> 00:34:58,099
Speaker 0: So I'm on like 90 percent book four.

588
00:34:58,501 --> 00:35:09,419
Speaker 1: So I'm not going to announce the new booklet book because we might just keep talking about the Wheel of Time a little bit because we're burning through them and they continue to plot at the same level of quality and pace.

589
00:35:10,184 --> 00:35:11,180
Speaker 0: It's just plodding along.

590
00:35:11,360 --> 00:35:12,263
Speaker 1: Yeah.

591
00:35:12,865 --> 00:35:18,064
Speaker 0: The only thing I can travel to tell her on Riyadh in the early book, in the early high.

592
00:35:18,085 --> 00:35:19,320
Speaker 1: I know a lot about that place now.

593
00:35:19,380 --> 00:35:20,175
Speaker 1: I know about wolves now.

594
00:35:22,840 --> 00:35:27,124
Speaker 1: So in book one, I wanted all three kids to shut up because Maureen and Land are the only people who know.

595
00:35:27,204 --> 00:35:29,580
Speaker 1: And Tom were smart and the kids were stupid.

596
00:35:29,800 --> 00:35:30,403
Speaker 0: Tom is still the best.

597
00:35:30,464 --> 00:35:33,981
Speaker 1: In book two, the Perrin was the only one I liked other than the adults.

598
00:35:34,904 --> 00:35:37,273
Speaker 1: Book three, all three of those kids are OK now.

599
00:35:37,714 --> 00:35:41,178
Speaker 1: and the girls who want to be teenagers, they need to shut up.

600
00:35:42,000 --> 00:35:44,679
Speaker 0: They need to just ram so sexist on the ladies to show up.

601
00:35:44,900 --> 00:35:52,320
Speaker 1: Seriously, half the problems in that book stem from one of them said something they shouldn't have because they are kids and they don't know what they're doing.

602
00:35:52,500 --> 00:35:54,899
Speaker 0: Well, the one who's not a kid is like so angry all the time.

603
00:35:55,324 --> 00:35:56,599
Speaker 1: She is the worst of them.

604
00:35:57,122 --> 00:35:59,020
Speaker 1: Just cool it seriously.

605
00:35:59,360 --> 00:36:00,598
Speaker 1: Ninna vinna ninna wee.

606
00:36:01,161 --> 00:36:03,440
Speaker 0: Oh, by the way, the pronunciations, if you look in the glass.

607
00:36:03,901 --> 00:36:05,347
Speaker 0: Yeah, I like them.

608
00:36:05,467 --> 00:36:08,580
Speaker 1: I was right on about 30 percent of them way wrong on the rest.

609
00:36:08,661 --> 00:36:09,737
Speaker 1: Like I got more rain.

610
00:36:09,778 --> 00:36:09,920
Speaker 1: Right.

611
00:36:10,040 --> 00:36:10,565
Speaker 1: I got land.

612
00:36:10,626 --> 00:36:10,949
Speaker 1: Right.

613
00:36:11,292 --> 00:36:12,059
Speaker 0: Oh, man, that's hard.

614
00:36:12,621 --> 00:36:12,742
Speaker 1: Yeah.

615
00:36:12,782 --> 00:36:15,456
Speaker 1: It could have been a long land party, long land party.

616
00:36:17,343 --> 00:36:18,860
Speaker 1: It's a grain, I guess, not a grain.

617
00:36:19,441 --> 00:36:23,679
Speaker 1: Oh, well, I thought it was a boy's name because I don't know how that stuff works.

618
00:36:24,040 --> 00:36:24,810
Speaker 0: This is going.

619
00:36:24,830 --> 00:36:24,911
Speaker 0: Yeah.

620
00:36:26,566 --> 00:36:27,030
Speaker 1: Go away.

621
00:36:27,413 --> 00:36:28,099
Speaker 1: Go in those two.

622
00:36:28,541 --> 00:36:29,226
Speaker 1: Those two guys.

623
00:36:29,690 --> 00:36:30,880
Speaker 1: I still can't tell them apart.

624
00:36:30,920 --> 00:36:32,500
Speaker 1: I forget which one's which on text.

625
00:36:32,680 --> 00:36:37,319
Speaker 1: But the thing is, every time they're mentioned, the context tells you which one it is because no one knows their names.

626
00:36:37,561 --> 00:36:39,950
Speaker 0: Yeah, they're just one of.

627
00:36:39,990 --> 00:36:42,400
Speaker 0: the one is who's too good that he's bad.

628
00:36:42,822 --> 00:36:44,700
Speaker 0: And the other one is the prince.

629
00:36:44,942 --> 00:36:45,186
Speaker 1: Yeah.

630
00:36:45,409 --> 00:36:45,613
Speaker 1: Yeah.

631
00:36:45,836 --> 00:36:45,999
Speaker 1: Yep.

632
00:36:46,701 --> 00:36:48,659
Speaker 0: Anyway, generic prince guy.

633
00:36:49,221 --> 00:36:52,979
Speaker 1: So, yeah, we're going to keep reading the Wheel of Time and goes round and round.

634
00:36:53,301 --> 00:36:53,503
Speaker 1: Yep.

635
00:36:53,806 --> 00:36:55,260
Speaker 1: No counts for a while till Magfest.

636
00:36:55,380 --> 00:36:55,766
Speaker 1: We'll be talking.

637
00:36:55,786 --> 00:36:56,640
Speaker 1: We're going to be at Magfest.

638
00:36:56,741 --> 00:37:01,159
Speaker 0: We're doing a bunch of panels and I go to the New York Comic Con, but we're not going to the New York real soon.

639
00:37:01,280 --> 00:37:01,978
Speaker 0: You can go if you want.

640
00:37:02,503 --> 00:37:03,920
Speaker 1: We're doing things around the New York Comic Con.

641
00:37:03,980 --> 00:37:10,260
Speaker 1: But we're not actually going to the New York Comic Con, which seriously, guys, unless you already live here, the New York Comic Con sucks.

642
00:37:10,341 --> 00:37:12,079
Speaker 1: Like, I'm not even going to front like it.

643
00:37:12,421 --> 00:37:13,879
Speaker 0: Every nerdy person I meet is going.

644
00:37:14,060 --> 00:37:14,787
Speaker 0: And I'm like, why?

645
00:37:15,292 --> 00:37:16,039
Speaker 0: Yeah, they like that.

646
00:37:16,561 --> 00:37:20,680
Speaker 1: I have a free badge and the subway goes to the Javits.

647
00:37:20,820 --> 00:37:22,780
Speaker 0: Now and now the subway goes directly there.

648
00:37:23,001 --> 00:37:28,740
Speaker 1: I can get in a subway that I can see from my window and get out at the New York Comic Con with a free badge.

649
00:37:28,840 --> 00:37:29,600
Speaker 1: I'm still not going.

650
00:37:30,062 --> 00:37:30,605
Speaker 1: That's how much.

651
00:37:30,787 --> 00:37:32,640
Speaker 1: I really don't like the New York Comic Con.

652
00:37:32,720 --> 00:37:43,960
Speaker 0: You just want to buy comic books and wait in line, wait in line to see things that have someone to have someone announce something or see a famous person that I don't give a shit about, who's in like some TV show.

653
00:37:44,260 --> 00:37:44,344
Speaker 1: Yeah.

654
00:37:44,365 --> 00:37:44,720
Speaker 1: And you know what?

655
00:37:44,760 --> 00:37:47,940
Speaker 1: They're all famous people that you can usually see at smaller cons.

656
00:37:48,622 --> 00:37:52,960
Speaker 0: Well, you can see the big famous people are on TV, but I don't watch garbage TV like you people.

657
00:37:53,120 --> 00:37:53,221
Speaker 1: Yeah.

658
00:37:53,402 --> 00:37:55,980
Speaker 1: And all the people I would want to see, they're not coming.

659
00:37:56,602 --> 00:37:58,998
Speaker 1: Or if they're coming, they're at a bunch of other cons, too.

660
00:37:59,622 --> 00:38:00,580
Speaker 1: So I'm not going to your comic.

661
00:38:00,701 --> 00:38:02,759
Speaker 1: I'll see him in some smaller kind of what I actually care about.

662
00:38:03,442 --> 00:38:03,684
Speaker 1: Yeah.

663
00:38:03,744 --> 00:38:05,415
Speaker 1: Like some of those people will be like mocha.

664
00:38:05,456 --> 00:38:06,060
Speaker 0: So sure.

665
00:38:07,582 --> 00:38:08,217
Speaker 1: So, yeah.

666
00:38:08,922 --> 00:38:11,200
Speaker 1: And we're going to start off the Patreon we're talking about soon.

667
00:38:11,300 --> 00:38:16,559
Speaker 1: But I realized there's something real I can offer through that Patreon to interest you kids.

668
00:38:17,841 --> 00:38:22,200
Speaker 1: You know, we did beta geek nights for a long time before we did real geek nights.

669
00:38:22,400 --> 00:38:24,499
Speaker 0: Anyone who signs of the Patreon gets the beta geek nights.

670
00:38:25,040 --> 00:38:26,125
Speaker 1: I will prop.

671
00:38:26,226 --> 00:38:35,160
Speaker 1: the one of the rewards I will give is I will periodically in Patreon only put up one of the pre geek nights beta episodes.

672
00:38:35,400 --> 00:38:36,228
Speaker 0: Do you even know where they are?

673
00:38:36,410 --> 00:38:37,460
Speaker 1: Yeah, of course I know where they are.

674
00:38:37,540 --> 00:38:40,340
Speaker 1: I check every few months to see if they're still downloadable.

675
00:38:41,443 --> 00:38:42,398
Speaker 0: But you're not going to give them the URL.

676
00:38:42,641 --> 00:38:44,819
Speaker 0: You're going to upload them in a different place to put them up.

677
00:38:45,040 --> 00:38:47,980
Speaker 0: But of course, once one person gets them, they can share them with everybody.

678
00:38:48,262 --> 00:38:48,930
Speaker 1: Yeah, they could.

679
00:38:49,072 --> 00:38:49,619
Speaker 1: And you know what?

680
00:38:50,240 --> 00:38:52,980
Speaker 1: I stand by my idea that DRM free.

681
00:38:53,121 --> 00:38:59,260
Speaker 1: So if you say if you pay us a dollar on Patreon, steal these and make a torrent and post a link in the forum.

682
00:38:59,943 --> 00:39:00,938
Speaker 1: I'm not going to stop you.

683
00:39:01,824 --> 00:39:02,559
Speaker 1: You're a dick.

684
00:39:03,021 --> 00:39:06,720
Speaker 1: But at the same time, I'm going to practice what I preach about DRM.

685
00:39:06,881 --> 00:39:09,960
Speaker 0: Why don't we just make geek nights episodes that are only in there?

686
00:39:10,601 --> 00:39:18,480
Speaker 1: There's going to be Patreon exclusive content, but it's going to take me a long time to spin that up because you can't even make regular content.

687
00:39:19,000 --> 00:39:27,524
Speaker 1: Do you realize the majority of the messages I get through YouTube are yo dawg, why, you know, geek nights presents utenna 14.

688
00:39:27,524 --> 00:39:29,479
Speaker 1: That is the majority of the of the messages I get.

689
00:39:30,621 --> 00:39:31,939
Speaker 1: So Patreon is coming soon.

690
00:39:32,720 --> 00:39:40,001
Speaker 1: And if enough people sign up for it, we will commit to going to PAX Australia 2016.

691
00:39:40,001 --> 00:39:44,440
Speaker 1: So for the people dot com is down and that saga came to an end.

692
00:39:44,700 --> 00:39:47,300
Speaker 0: So if you don't know what the saga might not be over yet.

693
00:39:47,600 --> 00:39:48,400
Speaker 1: But saga is wonderful.

694
00:39:48,701 --> 00:39:49,719
Speaker 0: But we had to talk about this.

695
00:39:49,841 --> 00:39:51,760
Speaker 0: So there's something we've wanted for a long time.

696
00:39:51,901 --> 00:39:55,394
Speaker 0: And suddenly this thing came out called People PEPLE.

697
00:39:55,876 --> 00:40:03,117
Speaker 0: that was going to do exact all sort of exactly the thing that we thought about and knew was coming, which is Yelp for human beings.

698
00:40:03,379 --> 00:40:03,560
Speaker 0: Right.

699
00:40:03,900 --> 00:40:07,060
Speaker 0: There would be a page for people and you would rate people.

700
00:40:07,503 --> 00:40:09,660
Speaker 1: I've wanted that along with like Google Glass.

701
00:40:09,800 --> 00:40:20,780
Speaker 1: My dream of augmented reality is to go to a room party at a convention and the that guys are rated and flagged as that guys by people I trust.

702
00:40:21,082 --> 00:40:29,459
Speaker 0: As you look around and you see people and then you get information about those people just by looking at them like, oh, this guy's internet runner is a chill dude.

703
00:40:30,061 --> 00:40:31,039
Speaker 1: This is a that guy.

704
00:40:31,621 --> 00:40:38,038
Speaker 1: This gentleman actually was flagged by three of your friends as being a straight up creeper pickup artist.

705
00:40:38,139 --> 00:40:38,340
Speaker 0: Right.

706
00:40:38,661 --> 00:40:44,600
Speaker 0: So right now we have the Facebooks and stuff, which is you make a profile about yourself and you put your own stuff up on your own page.

707
00:40:44,800 --> 00:40:45,540
Speaker 0: This would be the opposite.

708
00:40:45,700 --> 00:40:49,878
Speaker 0: You put a there's a profile about you and other people put the content there about you.

709
00:40:50,342 --> 00:40:52,760
Speaker 1: Now, there are two sides of that coin and a conceptual level.

710
00:40:53,163 --> 00:40:54,100
Speaker 1: It's so obvious.

711
00:40:55,161 --> 00:40:55,797
Speaker 0: Yeah, Captain Obvious.

712
00:40:56,220 --> 00:40:57,259
Speaker 1: Before we even talk about people.

713
00:40:57,841 --> 00:41:00,600
Speaker 1: So, yeah, my use cases are great.

714
00:41:01,142 --> 00:41:04,696
Speaker 1: But at the same time, you saw what happened with gamer gate and Twitter and all that nonsense.

715
00:41:04,716 --> 00:41:05,000
Speaker 1: Right.

716
00:41:05,520 --> 00:41:09,020
Speaker 0: Oh, you know, I need to say that Sarkeesian's page is going to be so great.

717
00:41:09,120 --> 00:41:11,078
Speaker 0: She's going to have such great reviews that are all true.

718
00:41:12,123 --> 00:41:15,499
Speaker 0: And that's going to be a totally helpful profile to visit when you want to learn about her.

719
00:41:15,880 --> 00:41:18,599
Speaker 1: So there were actually what's cool is like my sarcasm.

720
00:41:18,760 --> 00:41:24,480
Speaker 1: The tech is totally working now when Scott and I came up with this idea and we still want to make this happen.

721
00:41:25,623 --> 00:41:28,219
Speaker 1: Our idea was to use augmented reality and face recognition, all that.

722
00:41:28,581 --> 00:41:30,900
Speaker 1: But it's not a public database of reviews.

723
00:41:31,382 --> 00:41:34,000
Speaker 1: You subscribe to friend networks of individual people.

724
00:41:34,281 --> 00:41:38,920
Speaker 1: So like my personal friends all share data about people we've reviewed.

725
00:41:39,622 --> 00:41:41,079
Speaker 1: No one else gets that data.

726
00:41:41,642 --> 00:41:44,280
Speaker 1: So I flag a dude is bad to my friends.

727
00:41:44,561 --> 00:41:49,172
Speaker 1: So it's the same as me pulling you aside and saying, yo, see that guy over there in the fedora?

728
00:41:49,494 --> 00:41:50,139
Speaker 1: Don't talk to him.

729
00:41:51,360 --> 00:41:54,320
Speaker 1: So I think that gets around like 90 percent of those problems.

730
00:41:54,641 --> 00:41:56,660
Speaker 1: Yeah, but people had another interesting way.

731
00:41:57,182 --> 00:41:59,920
Speaker 1: And none of the reporting about people actually talked about this.

732
00:42:00,040 --> 00:42:03,480
Speaker 1: The way people worked was everyone has a profile.

733
00:42:04,502 --> 00:42:06,720
Speaker 1: Only positive reviews go up ever.

734
00:42:07,180 --> 00:42:13,260
Speaker 1: Negative reviews never appear unless that person themselves has an active people account.

735
00:42:14,003 --> 00:42:18,048
Speaker 1: So you can't negatively review someone who's checking all of these.

736
00:42:18,410 --> 00:42:20,019
Speaker 1: Well, you have to give star ratings and stuff.

737
00:42:20,381 --> 00:42:24,940
Speaker 0: Yeah, but who's checking to make sure there's negative, what's negative and what's positive that I'm curious about?

738
00:42:25,060 --> 00:42:26,979
Speaker 0: Actually, it's a manually check all this.

739
00:42:27,681 --> 00:42:27,982
Speaker 0: Maybe.

740
00:42:28,002 --> 00:42:32,860
Speaker 1: I mean, maybe I didn't read all the details because people's gone.

741
00:42:33,381 --> 00:42:33,743
Speaker 1: Yeah.

742
00:42:34,427 --> 00:42:34,649
Speaker 0: There was.

743
00:42:34,689 --> 00:42:38,400
Speaker 0: so it was such a controversial idea that they just shied away and disappeared.

744
00:42:39,560 --> 00:42:45,260
Speaker 1: Supposedly, any negative review, even if you had an account, would go into a holding area and you get a notification.

745
00:42:45,300 --> 00:42:46,540
Speaker 0: How would they know reviews negative?

746
00:42:47,061 --> 00:42:49,079
Speaker 1: And I'm skipping that part, supposedly.

747
00:42:49,340 --> 00:42:50,378
Speaker 1: That's why I keep saying supposedly.

748
00:42:51,002 --> 00:42:54,580
Speaker 1: And you'd have 48 hours to contest it or flag it or whatever.

749
00:42:55,742 --> 00:42:59,440
Speaker 0: And checking every 48 hours, you got to keep it in there for a long time.

750
00:42:59,861 --> 00:43:04,959
Speaker 1: I guess the kind of people who would use the system like this, because honestly, I would not have signed up for people.

751
00:43:05,503 --> 00:43:06,311
Speaker 0: No, I would not.

752
00:43:06,351 --> 00:43:07,119
Speaker 0: What do I need it for?

753
00:43:08,161 --> 00:43:11,758
Speaker 1: Yeah, because I want I'm going to rate people around me like like Yelp.

754
00:43:13,322 --> 00:43:16,240
Speaker 1: I would rate the dude who sat next to me on the flight home from Australia.

755
00:43:16,400 --> 00:43:17,107
Speaker 0: Jesus, God.

756
00:43:17,330 --> 00:43:18,178
Speaker 0: Yeah, that guy.

757
00:43:18,823 --> 00:43:19,710
Speaker 1: Oh, blessed be.

758
00:43:19,751 --> 00:43:20,538
Speaker 0: That's what it's lasted.

759
00:43:21,080 --> 00:43:22,140
Speaker 0: Be that's what it's for.

760
00:43:22,320 --> 00:43:24,020
Speaker 1: He wheezed through his fedora.

761
00:43:24,280 --> 00:43:24,742
Speaker 1: Oh, my God.

762
00:43:24,762 --> 00:43:26,850
Speaker 1: Anyway, that guy was.

763
00:43:26,930 --> 00:43:32,380
Speaker 1: this was I can imagine I could write the review of that guy right now and just posted anonymously on Craigslist.

764
00:43:32,540 --> 00:43:33,084
Speaker 1: That would be funny.

765
00:43:33,104 --> 00:43:35,440
Speaker 0: But that's what it's for.

766
00:43:35,580 --> 00:43:35,782
Speaker 0: That's it.

767
00:43:35,822 --> 00:43:36,003
Speaker 0: Right.

768
00:43:36,044 --> 00:43:38,220
Speaker 0: So I think we should just make people.

769
00:43:38,300 --> 00:43:41,200
Speaker 0: They were too chicken to make it or at least it appears that you're going to make it.

770
00:43:41,240 --> 00:43:43,720
Speaker 0: Well, let's just fuck while the iron's hot, let's just fucking strike.

771
00:43:43,840 --> 00:43:44,223
Speaker 0: We'll make it.

772
00:43:44,244 --> 00:43:46,120
Speaker 0: And here's how my version of people is going to work.

773
00:43:46,261 --> 00:43:46,482
Speaker 0: Right.

774
00:43:47,147 --> 00:43:48,799
Speaker 0: It's going to be just like Yelp for people.

775
00:43:49,020 --> 00:43:49,161
Speaker 1: Yeah.

776
00:43:49,606 --> 00:43:51,039
Speaker 0: All profiles will be public.

777
00:43:51,401 --> 00:43:53,700
Speaker 0: There's nothing private on the site whatsoever.

778
00:43:54,320 --> 00:43:56,980
Speaker 0: However, we're not just going to make a profile for everyone.

779
00:43:57,201 --> 00:44:00,924
Speaker 0: We're going to start only by making profiles for famous people because it's very clever.

780
00:44:01,065 --> 00:44:03,760
Speaker 0: It's legally open season on famous people.

781
00:44:04,120 --> 00:44:06,460
Speaker 1: In fact, if they're dead, you can basically do anything.

782
00:44:06,540 --> 00:44:06,804
Speaker 0: Oh, yeah.

783
00:44:06,844 --> 00:44:07,919
Speaker 0: Van Gogh's going up first.

784
00:44:08,482 --> 00:44:08,724
Speaker 0: Right.

785
00:44:08,744 --> 00:44:09,127
Speaker 0: We can learn.

786
00:44:09,168 --> 00:44:10,500
Speaker 0: We can rat on Van Gogh all we want.

787
00:44:10,601 --> 00:44:12,979
Speaker 1: We start with old dead celebrities and work our way down.

788
00:44:13,901 --> 00:44:14,263
Speaker 0: Right.

789
00:44:14,283 --> 00:44:20,000
Speaker 0: Then if you want one, a profile on there for a not famous person, we got to figure out where the line is on famous.

790
00:44:20,141 --> 00:44:20,281
Speaker 0: Right.

791
00:44:20,301 --> 00:44:24,259
Speaker 0: But we'll probably just start with the epically famous only like, you know, president level.

792
00:44:24,661 --> 00:44:24,802
Speaker 0: Yeah.

793
00:44:24,862 --> 00:44:28,920
Speaker 1: And probably avoid known litigious actors like leave Tom Cruise off for a little while.

794
00:44:29,180 --> 00:44:29,341
Speaker 1: Yeah.

795
00:44:29,361 --> 00:44:29,743
Speaker 0: Who knows?

796
00:44:29,863 --> 00:44:33,520
Speaker 0: Anyway, and then working our way down.

797
00:44:34,122 --> 00:44:37,380
Speaker 0: But the way it's going to work is let's say I want to have a profile for me, but I'm not famous.

798
00:44:38,162 --> 00:44:40,519
Speaker 0: The profile of me can only exist if I make it.

799
00:44:41,081 --> 00:44:43,760
Speaker 0: Well, how do we know that someone else will just make a Scott Rubin profile?

800
00:44:44,040 --> 00:44:53,540
Speaker 0: Well, because anyone who wants to make one, they have to call us themselves and we'll check and super check to make sure they're actually the person they say they are.

801
00:44:54,041 --> 00:44:59,240
Speaker 0: And we'll make the profile for them after being super sure that they're them and they wanted the profile up.

802
00:44:59,300 --> 00:45:02,260
Speaker 0: But once they do, there's no change in your mind.

803
00:45:02,962 --> 00:45:03,285
Speaker 0: Right.

804
00:45:03,305 --> 00:45:04,599
Speaker 0: Which is why we made super sure.

805
00:45:05,262 --> 00:45:10,940
Speaker 0: And then once you have a profile, not only do you have a profile, but you can now review other people.

806
00:45:11,080 --> 00:45:14,300
Speaker 0: You can't review other people unless you're putting yourself up to be reviewed.

807
00:45:15,021 --> 00:45:15,241
Speaker 0: Right.

808
00:45:15,682 --> 00:45:22,480
Speaker 0: So if you want to go up and, you know, get an account, you know, to go on to Scott Rubin's page and say how much of a jerk I am.

809
00:45:22,840 --> 00:45:29,059
Speaker 0: Well, you better be ready for me to go on your page and say, well, this guy's just a random person who hates me.

810
00:45:29,341 --> 00:45:32,139
Speaker 0: And that's the reason he hates me is because of this and this and this.

811
00:45:32,280 --> 00:45:34,139
Speaker 0: And here's the horrible things I'm going to reveal about him.

812
00:45:34,340 --> 00:45:40,540
Speaker 1: And that way, slander, libel, all that stuff pass through just like Google with the copyright stuff.

813
00:45:40,660 --> 00:45:41,699
Speaker 1: Yeah, it's through led law.

814
00:45:42,000 --> 00:45:51,800
Speaker 0: I guarantee that the person who posts this is actually this real person, because not the person who was commented on and the person commenting both verified with us that those accounts belong to the people they say.

815
00:45:52,224 --> 00:45:53,439
Speaker 0: Oh, and those accounts cost money.

816
00:45:53,982 --> 00:45:54,244
Speaker 1: Yep.

817
00:45:55,132 --> 00:45:55,939
Speaker 0: And that's how it should work.

818
00:45:56,380 --> 00:45:56,641
Speaker 1: Yep.

819
00:45:57,021 --> 00:46:10,360
Speaker 1: Now, the meta level, because people is pretty obviously one of those like startup people, startup, startup people had some money and an idea and they were getting other people to work for equity or whatever.

820
00:46:10,480 --> 00:46:13,160
Speaker 0: Probably like this is going to exist whether you like it or not.

821
00:46:13,280 --> 00:46:13,461
Speaker 0: Right.

822
00:46:13,501 --> 00:46:19,320
Speaker 0: We don't, you know, just like this is, you know, we talked about this on a privacy show many, many times.

823
00:46:19,441 --> 00:46:20,560
Speaker 0: I think we had a whole show about it.

824
00:46:20,640 --> 00:46:26,360
Speaker 1: A lot of people were so mad about people like guys, the people will exist.

825
00:46:26,640 --> 00:46:26,742
Speaker 0: Right.

826
00:46:26,762 --> 00:46:27,859
Speaker 0: I just want to reiterate this.

827
00:46:28,060 --> 00:46:36,580
Speaker 0: It's like because so many privacy advocates out there and the thing that's the funniest to me are the people who are like they're anti copyright and pro privacy.

828
00:46:36,820 --> 00:46:37,839
Speaker 0: It's like they're the same issue.

829
00:46:38,420 --> 00:46:49,320
Speaker 0: The issue is whether you agree that it should be this way or not, it is impossible to stop the transfer of information that can be digitized as long as the Internet exists.

830
00:46:49,563 --> 00:46:50,939
Speaker 0: There is nothing you can do about it.

831
00:46:51,121 --> 00:46:53,279
Speaker 0: There is no legislation you can make that will stop it.

832
00:46:53,501 --> 00:46:55,900
Speaker 0: There is no technological measure you can make that will stop it.

833
00:46:56,200 --> 00:47:02,760
Speaker 0: It is a law of the universe, just like you can't, no matter how much you don't like gravity or the law of conservation of energy, you cannot stop them.

834
00:47:03,220 --> 00:47:13,100
Speaker 0: Therefore, you just even though it sucks and I agree, it might be better in many or some ways if it wasn't this way, just like the world would be a lot better without the law of conservation of energy.

835
00:47:13,800 --> 00:47:16,719
Speaker 0: But you just have to deal with it rather than try to fight it.

836
00:47:17,162 --> 00:47:20,980
Speaker 1: Preventing something like people from existing in any form is impossible.

837
00:47:21,240 --> 00:47:31,600
Speaker 1: It's like preventing me from telling Scott that some guy I met on an airplane flying back from Australia was a really horrifying person and personally annoyed me.

838
00:47:32,120 --> 00:47:32,180
Speaker 0: Yes.

839
00:47:32,841 --> 00:47:44,140
Speaker 0: Therefore, we have to instead of trying to stop people from making a thing like people and should figure out a way for you to live in a world where people is an inevitability.

840
00:47:44,801 --> 00:47:48,920
Speaker 1: Because it is an inevitability like I am shocked.

841
00:47:49,100 --> 00:47:59,940
Speaker 1: Well, I'm not shocked, but it is interesting to see the ridiculous, immediate and such widespread, voluminous hate toward and anger about this platform.

842
00:48:00,120 --> 00:48:08,700
Speaker 1: Like I get the impression that they expected a moderate amount of pushback and what they got was the Hoover Dam exploding like.

843
00:48:09,442 --> 00:48:12,860
Speaker 1: And I suspect that's mostly because of all the nonsense that happened recently.

844
00:48:12,961 --> 00:48:16,139
Speaker 1: Like this is a real problematic issue right now because U.N.

845
00:48:16,400 --> 00:48:17,263
Speaker 0: play God.

846
00:48:17,423 --> 00:48:23,240
Speaker 1: Well, it means that the people who made people have no idea what's going on on the Internet.

847
00:48:23,280 --> 00:48:24,820
Speaker 0: Well, they're definitely they're out of touch for sure.

848
00:48:25,140 --> 00:48:25,301
Speaker 1: Yeah.

849
00:48:25,341 --> 00:48:32,200
Speaker 1: Like this had to launch a specific incident, though, if this had launched two years ago, it would have made billions and been sold.

850
00:48:32,400 --> 00:48:32,681
Speaker 1: Maybe.

851
00:48:33,002 --> 00:48:41,399
Speaker 1: But now it's hard to sell it as it is this kind of idea, because people are really mad about people and things like people.

852
00:48:42,502 --> 00:48:45,100
Speaker 0: That means is a strike while the iron's hot, like I said.

853
00:48:45,480 --> 00:48:54,100
Speaker 1: Yeah, but I mean, most of the complaints were that people are afraid that they will get raided poorly and slanderous.

854
00:48:54,400 --> 00:48:54,801
Speaker 0: All right.

855
00:48:54,821 --> 00:48:55,904
Speaker 0: So let's imagine a world.

856
00:48:55,964 --> 00:49:03,180
Speaker 0: let's say I could put up a site tomorrow and on the site, anyone can make a profile for anyone, upload any picture they want and write any comment they want.

857
00:49:04,362 --> 00:49:08,520
Speaker 0: And all the URLs are like, you know, Scott's people dot com slash name.

858
00:49:09,261 --> 00:49:12,920
Speaker 1: Now, the things like what would happen is the Internet actually did kind of exist.

859
00:49:13,160 --> 00:49:13,261
Speaker 0: Right.

860
00:49:13,282 --> 00:49:14,357
Speaker 0: What would happen if I did that?

861
00:49:15,741 --> 00:49:21,140
Speaker 1: There'd be a bunch of dicks and defamation and slander and libel and nonsense on there all over the place.

862
00:49:21,300 --> 00:49:21,841
Speaker 0: That's true.

863
00:49:21,982 --> 00:49:30,420
Speaker 1: And the people are on that side of you super mad at you and try to make you take it down for making a database with a Web interface that had upload picture, write name.

864
00:49:30,821 --> 00:49:31,021
Speaker 1: Yep.

865
00:49:31,362 --> 00:49:39,640
Speaker 1: I mean, remember, Web blogs or when people would sign the guest book on a Web site, those basically had that same kind of content.

866
00:49:40,020 --> 00:49:49,080
Speaker 1: Pretty much the day normal people get access to the Internet as opposed to just researchers, every one of those things was filled with spam and slander.

867
00:49:50,560 --> 00:49:54,374
Speaker 0: You should just make a Web site and be like, just like that, be like, let it be spam, just like.

868
00:49:54,474 --> 00:49:56,000
Speaker 0: just let it go, see what happens.

869
00:49:56,320 --> 00:50:07,280
Speaker 1: I mean, I feel like harassment is something that has to be dealt with specifically and it cannot be dealt with with the blanket idea that you can't have other people.

870
00:50:07,700 --> 00:50:09,800
Speaker 1: Third parties cannot talk about you on the Internet.

871
00:50:10,520 --> 00:50:18,160
Speaker 1: You cannot prevent third parties from talking about you on the Internet, but you can deal with harassment in some fashion.

872
00:50:18,321 --> 00:50:20,320
Speaker 1: And that is way beyond the scope of this episode.

873
00:50:20,560 --> 00:50:23,940
Speaker 0: How to deal with it also comes into Europe's little right to be forgotten.

874
00:50:24,100 --> 00:50:24,261
Speaker 0: Right.

875
00:50:24,281 --> 00:50:30,500
Speaker 0: It's like, let's say you did something really shitty a long time ago, like the prime minister with his pig dick thing.

876
00:50:30,720 --> 00:50:31,081
Speaker 0: Sure.

877
00:50:31,142 --> 00:50:31,342
Speaker 0: Yeah.

878
00:50:31,703 --> 00:50:36,920
Speaker 0: And then someone post that so that now the whole world knows it's true in the U.S.

879
00:50:37,120 --> 00:50:41,920
Speaker 0: Truth is safety from libel and slander because you did this thing a long time ago.

880
00:50:42,101 --> 00:50:42,544
Speaker 0: It's true.

881
00:50:42,665 --> 00:50:45,000
Speaker 0: And now you're it's like, well, that was a different time.

882
00:50:45,060 --> 00:50:45,645
Speaker 0: You understand?

883
00:50:45,665 --> 00:50:47,620
Speaker 0: I don't want to have to carry that my whole life.

884
00:50:47,760 --> 00:50:49,440
Speaker 0: Well, you shouldn't have fucked up now.

885
00:50:49,480 --> 00:50:52,820
Speaker 1: To be fair, it's easy for us to say that because we haven't fucked up.

886
00:50:53,001 --> 00:50:55,598
Speaker 0: Well, not only that, I haven't done anything that I'm ashamed of.

887
00:50:56,261 --> 00:50:58,439
Speaker 1: But what about things that you are not ashamed of?

888
00:50:58,740 --> 00:51:03,300
Speaker 1: But widespread knowledge of them would harm you in the society in which you live.

889
00:51:04,021 --> 00:51:06,560
Speaker 0: Anyone who tries to harm me, I'll fuck them over.

890
00:51:06,840 --> 00:51:10,060
Speaker 1: What if you are a disempowered minority who does not have the ability to fuck them over?

891
00:51:10,120 --> 00:51:12,440
Speaker 0: Then I'm not on the Internet, so it's not really a problem.

892
00:51:12,640 --> 00:51:14,360
Speaker 1: Yeah, there are disempowered minorities on the Internet.

893
00:51:14,540 --> 00:51:14,802
Speaker 1: Are you being?

894
00:51:14,822 --> 00:51:15,709
Speaker 1: are you racist?

895
00:51:15,749 --> 00:51:17,260
Speaker 1: You're saying that minorities don't use the Internet?

896
00:51:19,000 --> 00:51:21,500
Speaker 0: The Syrian refugees are not on the Internet.

897
00:51:21,683 --> 00:51:22,300
Speaker 0: I'm not talking about them.

898
00:51:22,300 --> 00:51:23,760
Speaker 0: The Internet is the least of their problems.

899
00:51:23,940 --> 00:51:24,141
Speaker 1: I'm not.

900
00:51:24,323 --> 00:51:26,739
Speaker 1: I'm talking about way higher in the tier than them.

901
00:51:27,522 --> 00:51:29,000
Speaker 0: OK, so not super disempowered.

902
00:51:29,400 --> 00:51:33,900
Speaker 1: Only still still pretty super disempowered, not mega or extremely disempowered.

903
00:51:34,101 --> 00:51:36,340
Speaker 0: OK, you got a different disempowerment scale over there.

904
00:51:36,540 --> 00:51:37,232
Speaker 1: Gargantuan, like D&D.

905
00:51:41,561 --> 00:51:41,863
Speaker 0: What's the?

906
00:51:41,904 --> 00:51:44,360
Speaker 0: what's the highest possible level of disempowerment?

907
00:51:44,440 --> 00:51:45,439
Speaker 0: You're left alone on the moon?

908
00:51:45,902 --> 00:51:47,720
Speaker 1: Yeah, on fire in a ditch, that whole thing.

909
00:51:48,020 --> 00:51:48,101
Speaker 0: Yeah.

910
00:51:48,424 --> 00:51:50,280
Speaker 1: OK, you derailed my train of thought.

911
00:51:50,341 --> 00:51:51,359
Speaker 1: I was going somewhere with this.

912
00:51:51,681 --> 00:51:53,260
Speaker 1: OK, I was going somewhere pretty good with this.

913
00:51:53,420 --> 00:51:56,380
Speaker 0: Why is anyone making a profile out of you if you're so disempowered?

914
00:51:56,500 --> 00:51:57,219
Speaker 0: Why does anyone care?

915
00:51:57,520 --> 00:52:04,040
Speaker 1: Well, because some bully in your high school decided to target just you and got everyone on board and then 4chan piled out on top of that for lulz.

916
00:52:04,620 --> 00:52:06,900
Speaker 0: OK, so there's a page on the Internet that says bad things about you.

917
00:52:06,980 --> 00:52:07,759
Speaker 0: This page exists.

918
00:52:08,020 --> 00:52:08,603
Speaker 1: And it's truth.

919
00:52:08,924 --> 00:52:12,640
Speaker 1: And it's and it says that you're homosexual and you live in Russia.

920
00:52:13,902 --> 00:52:15,460
Speaker 0: OK, why are you still living in Russia?

921
00:52:16,001 --> 00:52:17,680
Speaker 1: Because not everyone can just leave Russia.

922
00:52:18,042 --> 00:52:21,640
Speaker 0: OK, so go to someone else's page and write down that they're homosexual on it.

923
00:52:22,060 --> 00:52:23,019
Speaker 0: What are they going to do about it?

924
00:52:23,300 --> 00:52:27,240
Speaker 1: Except that you don't have the clout with all the anti homosexual bullies.

925
00:52:27,820 --> 00:52:28,205
Speaker 0: What do you mean?

926
00:52:28,225 --> 00:52:29,400
Speaker 0: You just went to someone else.

927
00:52:29,480 --> 00:52:32,682
Speaker 0: You went to every single page of everyone in your whole class and you wrote the same thing there.

928
00:52:32,883 --> 00:52:39,320
Speaker 1: But your page has a dog pile of all the other people that the bullies knew amplifying it in a way that you cannot.

929
00:52:39,501 --> 00:52:40,310
Speaker 0: How is it amplified?

930
00:52:40,350 --> 00:52:41,159
Speaker 0: It's on one page.

931
00:52:41,581 --> 00:52:42,567
Speaker 1: No, because they like it.

932
00:52:42,667 --> 00:52:44,819
Speaker 1: So it's got like ten thousand like, yes, this is true.

933
00:52:44,960 --> 00:52:45,582
Speaker 0: It has likes.

934
00:52:46,927 --> 00:52:47,669
Speaker 1: So they post.

935
00:52:47,830 --> 00:52:50,800
Speaker 1: so your profile has that from a thousand different accounts.

936
00:52:51,360 --> 00:52:58,180
Speaker 1: OK, and their profile has it from one account that they just say, well, obviously it's Scott because he's so mad.

937
00:52:58,320 --> 00:52:58,728
Speaker 0: How do they know?

938
00:52:58,768 --> 00:52:59,217
Speaker 1: how did him?

939
00:53:01,001 --> 00:53:01,706
Speaker 1: It's obviously not.

940
00:53:01,726 --> 00:53:04,182
Speaker 0: how do you how do they know that what's on my page is actually true?

941
00:53:04,847 --> 00:53:05,431
Speaker 1: Because they don't.

942
00:53:05,491 --> 00:53:06,559
Speaker 1: they were doing it just to bully you.

943
00:53:07,022 --> 00:53:08,619
Speaker 0: OK, so my page is a thing on it.

944
00:53:08,980 --> 00:53:15,699
Speaker 1: Yeah, so so now so they amplify that with other people that they know because they target you semi randomly at that point.

945
00:53:16,902 --> 00:53:23,120
Speaker 1: OK, so now there's an amplified signal against you and that signal is a signal that in that society could get you beaten up.

946
00:53:23,180 --> 00:53:24,559
Speaker 0: How do they amplify the signal?

947
00:53:25,580 --> 00:53:26,480
Speaker 1: Like I just specifically.

948
00:53:27,121 --> 00:53:30,483
Speaker 1: OK, so usually what happens is one bully decides to pick on one kid for whatever reason.

949
00:53:30,766 --> 00:53:31,209
Speaker 0: This has been.

950
00:53:31,229 --> 00:53:32,560
Speaker 0: this has been true before the Internet.

951
00:53:32,662 --> 00:53:32,886
Speaker 0: Yeah.

952
00:53:32,926 --> 00:53:33,720
Speaker 0: How is this any different?

953
00:53:33,860 --> 00:53:38,482
Speaker 1: Because he does it on the Internet so he can amplify that signal way more, way beyond.

954
00:53:38,964 --> 00:53:42,523
Speaker 1: In the old days, you could leave a high school, go to another high school, no one knew who you were.

955
00:53:42,845 --> 00:53:45,905
Speaker 1: Nowadays, that bully train literally follows you to that high school.

956
00:53:46,716 --> 00:53:46,818
Speaker 0: OK.

957
00:53:48,340 --> 00:53:49,300
Speaker 1: That it really does.

958
00:53:49,400 --> 00:53:50,312
Speaker 1: That's how it works now.

959
00:53:50,535 --> 00:53:50,860
Speaker 0: All right.

960
00:53:51,620 --> 00:53:52,324
Speaker 0: But I mean, so there's.

961
00:53:52,666 --> 00:53:58,159
Speaker 0: but all you're not saying that have a web page is a web page that exists that has your picture and it says you're homosexual on it.

962
00:53:58,702 --> 00:54:00,640
Speaker 0: How is that affecting you really that badly?

963
00:54:01,542 --> 00:54:04,420
Speaker 1: If you live in Russia and you could be killed for being a homosexual.

964
00:54:04,620 --> 00:54:05,669
Speaker 0: But how do they know that it's true?

965
00:54:05,729 --> 00:54:06,960
Speaker 0: Everyone's page says it on there.

966
00:54:07,780 --> 00:54:09,713
Speaker 1: Yours says it and more.

967
00:54:09,793 --> 00:54:10,740
Speaker 1: yours says it more often.

968
00:54:11,361 --> 00:54:12,657
Speaker 1: OK, like that's true.

969
00:54:13,281 --> 00:54:17,999
Speaker 0: So if I make a spam bot and post it on someone else's page a thousand times, that makes suddenly makes them gay.

970
00:54:18,300 --> 00:54:21,279
Speaker 1: And my 50 friends and their 500 friends all say it about you.

971
00:54:21,682 --> 00:54:25,737
Speaker 1: And then one of those people just goes and beats you up because they knew you were targeted by me.

972
00:54:26,583 --> 00:54:27,431
Speaker 1: What do you do about that?

973
00:54:27,471 --> 00:54:28,340
Speaker 1: You can't fight back.

974
00:54:28,440 --> 00:54:30,359
Speaker 1: You don't have an amplification back against that.

975
00:54:30,681 --> 00:54:31,466
Speaker 0: That's how they.

976
00:54:31,506 --> 00:54:33,704
Speaker 0: how can they tell the difference between a thousand people and a spam bot?

977
00:54:34,372 --> 00:54:34,979
Speaker 1: They don't need to.

978
00:54:35,140 --> 00:54:35,907
Speaker 1: They just know.

979
00:54:36,855 --> 00:54:37,379
Speaker 0: They just know.

980
00:54:37,620 --> 00:54:39,500
Speaker 1: Scott, you know how 4chan mobs form, right?

981
00:54:39,601 --> 00:54:41,940
Speaker 1: Someone post saying, go after this kid.

982
00:54:42,060 --> 00:54:42,804
Speaker 1: Here's his phone number.

983
00:54:43,146 --> 00:54:48,780
Speaker 1: And a few thousand people decide to go after that specific person just because they don't need a reason.

984
00:54:49,281 --> 00:54:50,580
Speaker 0: So 4chan already does this.

985
00:54:50,640 --> 00:54:52,980
Speaker 0: So what does it matter if there's one more website that does the same thing?

986
00:54:53,160 --> 00:54:56,459
Speaker 1: No, I'm saying that concept is the problem, not one more website doing it.

987
00:54:56,881 --> 00:54:57,143
Speaker 0: Right.

988
00:54:57,847 --> 00:54:59,860
Speaker 1: The problem still has to be dealt with in some fashion.

989
00:54:59,961 --> 00:55:01,240
Speaker 1: Right now, it's not being dealt with.

990
00:55:01,340 --> 00:55:03,000
Speaker 0: That problem has nothing to do with people.

991
00:55:03,960 --> 00:55:09,480
Speaker 1: People, as it was modeled, could probably make that problem worse because it's not.

992
00:55:09,520 --> 00:55:10,859
Speaker 1: it has so much media attention.

993
00:55:12,541 --> 00:55:13,708
Speaker 0: I still don't see how there is.

994
00:55:13,769 --> 00:55:15,560
Speaker 0: I could make a Web page tomorrow with a picture of.

995
00:55:15,721 --> 00:55:23,128
Speaker 1: no one would care about your page, but if people had gone live, people would have cared about it a lot more because it was in the news and grandma and everyone's talking about it.

996
00:55:23,716 --> 00:55:23,858
Speaker 0: OK.

997
00:55:24,321 --> 00:55:31,519
Speaker 1: And also, they're probably not going to have the the negative detection that we were talking about, because, like you said, how do they do that?

998
00:55:31,721 --> 00:55:34,160
Speaker 1: And they didn't say how they think they could do that.

999
00:55:34,280 --> 00:55:39,026
Speaker 0: I think the sort of humans reviewing, which is humans reviewing every single one, which is not going to work.

1000
00:55:39,508 --> 00:55:43,679
Speaker 1: I mean, guys, we used to review every single person who applied to the forum, and that was actually a lot of pain in the ass work.

1001
00:55:43,920 --> 00:55:48,200
Speaker 0: Well, it was only pain in the ass work because vanilla had really shitty spam filter, these spam applications.

1002
00:55:48,562 --> 00:55:49,960
Speaker 0: Now they fix that at least.

1003
00:55:50,101 --> 00:55:52,079
Speaker 0: So we still review everyone who tries to join the forum.

1004
00:55:52,381 --> 00:55:56,700
Speaker 0: Yeah, but now there's no there's very few spam applicants, so it's much easier.

1005
00:55:57,061 --> 00:56:02,644
Speaker 1: I've gone on for about an hour, but yeah, it looks like people came and went in a flash.

1006
00:56:02,968 --> 00:56:03,920
Speaker 0: There will be another people.

1007
00:56:03,960 --> 00:56:10,703
Speaker 1: There will be 10 things like people within five years that are all big enough to have the same impact.

1008
00:56:11,406 --> 00:56:16,906
Speaker 1: And it'll be interesting to see how that all evolves, because I don't want to miss out on this.

1009
00:56:16,966 --> 00:56:22,780
Speaker 1: I don't want to miss out on my Google Glass where I can find out if any of my friends have flagged someone as a creeper or racist.

1010
00:56:22,960 --> 00:56:23,765
Speaker 0: That is the right.

1011
00:56:23,805 --> 00:56:30,980
Speaker 0: That's the thing is people keep concentrating on like this worst case scenario, which isn't really any different than the Internet we have already.

1012
00:56:31,482 --> 00:56:31,744
Speaker 0: Right.

1013
00:56:31,804 --> 00:56:35,301
Speaker 0: And they're not focusing on the positive, not even thinking of any positive of this.

1014
00:56:35,341 --> 00:56:43,000
Speaker 0: And the positive of this is you can find out about people who really are bad well in advance and avoid them instead of like finding out later.

1015
00:56:43,543 --> 00:56:43,745
Speaker 0: Right.

1016
00:56:43,846 --> 00:56:45,080
Speaker 0: Horrible secrets about things.

1017
00:56:45,121 --> 00:56:46,580
Speaker 1: That's why maybe you make a really focused one.

1018
00:56:46,660 --> 00:56:46,740
Speaker 1: Like.

1019
00:56:46,761 --> 00:56:48,328
Speaker 1: I just want to make some like fedora someone

1020
00:56:48,369 --> 00:57:03,859
Speaker 0: who, you know, and people don't have the sense of like justice, I guess, that I have and that some other people may have is that if someone did a bad thing, truly, maybe they deserve social consequences for the bad thing that they truly did.

1021
00:57:04,242 --> 00:57:06,400
Speaker 0: And they shouldn't be able to get away from that somehow.

1022
00:57:06,621 --> 00:57:13,760
Speaker 1: But the counterpoint to that is that there's a lot of societies where things that the society as a whole declares bad are not bad.

1023
00:57:13,960 --> 00:57:16,640
Speaker 0: That's that the real problem is that society.

1024
00:57:17,102 --> 00:57:17,587
Speaker 0: Yeah.

1025
00:57:17,889 --> 00:57:19,000
Speaker 1: What do you do about Russia?

1026
00:57:19,200 --> 00:57:20,614
Speaker 1: What do you do about home up?

1027
00:57:22,700 --> 00:57:24,520
Speaker 0: Yeah, they look like they want to go to war.

1028
00:57:24,700 --> 00:57:25,358
Speaker 0: Let's give them war.

1029
00:57:25,600 --> 00:57:27,820
Speaker 1: I do seem to want to go to war and they want to go to war.

1030
00:57:28,100 --> 00:57:28,241
Speaker 0: Fine.

1031
00:57:28,281 --> 00:57:29,810
Speaker 0: I just like I just call up.

1032
00:57:29,871 --> 00:57:31,420
Speaker 0: if I was president, I would just call Putin.

1033
00:57:31,741 --> 00:57:32,647
Speaker 0: He'd be low on my list.

1034
00:57:32,928 --> 00:57:34,660
Speaker 0: I'd be calling up much worse places than that.

1035
00:57:34,820 --> 00:57:38,540
Speaker 0: But like I would call it I'd be calling up Saudi Arabia and I'd like Saudi Arabia.

1036
00:57:39,123 --> 00:57:40,420
Speaker 0: Let women drive tomorrow.

1037
00:57:40,761 --> 00:57:44,340
Speaker 0: No, I'm blowing up your country in one hour unless you let women drive.

1038
00:57:45,524 --> 00:57:46,639
Speaker 0: Are you the women driving it?

1039
00:57:47,002 --> 00:57:47,043
Speaker 0: No.

1040
00:57:47,104 --> 00:57:47,753
Speaker 0: Here come the F-16.

1041
00:57:48,540 --> 00:57:49,064
Speaker 1: So I remember.

1042
00:57:49,407 --> 00:57:50,859
Speaker 1: Oh, was that Mecca got blowed up?

1043
00:57:50,960 --> 00:57:51,884
Speaker 0: Why don't you fix this?

1044
00:57:52,928 --> 00:57:56,060
Speaker 0: Oh, how many aircraft carriers do you have that you can do about this?

1045
00:57:56,240 --> 00:57:57,018
Speaker 0: No, let the women drive.

1046
00:57:57,320 --> 00:58:01,040
Speaker 1: Wasn't that Ex Machina, the now Saudi United States, the New York marriage.

1047
00:58:01,220 --> 00:58:02,100
Speaker 1: Welcome to America.

1048
00:58:02,902 --> 00:58:03,548
Speaker 1: Why don't you make that?

1049
00:58:03,709 --> 00:58:04,860
Speaker 1: Why does someone make that same comic?

1050
00:58:04,981 --> 00:58:06,049
Speaker 1: But it's the president.

1051
00:58:06,412 --> 00:58:07,380
Speaker 1: But he acts like Batman.

1052
00:58:07,721 --> 00:58:07,983
Speaker 1: Yeah.

1053
00:58:09,011 --> 00:58:10,140
Speaker 0: I don't understand why we don't do this.

1054
00:58:10,240 --> 00:58:13,698
Speaker 0: Why do we spend all this money in his military if we're not going to use it?

1055
00:58:16,400 --> 00:58:17,679
Speaker 1: Well, Russia's working on it.

1056
00:58:18,000 --> 00:58:18,997
Speaker 0: Russia is working on it.

1057
00:58:19,160 --> 00:58:19,341
Speaker 0: Yeah.

1058
00:58:19,361 --> 00:58:23,699
Speaker 1: They're going to, I mean, you saw these, they authorized sending ground troops to Syria, which is amazing because...

1059
00:58:23,982 --> 00:58:24,839
Speaker 0: What do they want there?

1060
00:58:25,200 --> 00:58:25,715
Speaker 1: That so...

1061
00:58:27,020 --> 00:58:27,589
Speaker 0: What do they care?

1062
00:58:27,609 --> 00:58:28,300
Speaker 1: what happens there?

1063
00:58:28,720 --> 00:58:28,961
Speaker 1: ...to derail.

1064
00:58:28,981 --> 00:58:36,760
Speaker 1: But if it was a video game or a movie, I'd assume that that is to put, to oil the war machine to make sure it works, to get it going again.

1065
00:58:37,060 --> 00:58:37,360
Speaker 0: Practicing.

1066
00:58:37,620 --> 00:58:39,640
Speaker 1: But that's crazy in the modern era.

1067
00:58:39,822 --> 00:58:41,520
Speaker 1: Also, because Russia's military sucks.

1068
00:58:41,920 --> 00:58:43,840
Speaker 0: And why do they care what happens in Syria?

1069
00:58:44,120 --> 00:58:48,260
Speaker 1: Well, because Syria is their ally for a bunch of reasons and they sell a lot of arms to Syria.

1070
00:58:49,004 --> 00:58:50,432
Speaker 0: But now you're not selling them arms.

1071
00:58:50,452 --> 00:58:51,880
Speaker 0: You're using arms that you bought.

1072
00:58:53,440 --> 00:58:54,958
Speaker 0: That you're losing money doing this.

1073
00:58:55,800 --> 00:59:03,380
Speaker 1: It might hardly be because they want to keep this puppet regime there to counterbalance what they perceive stupidly as American influence in the region.

1074
00:59:03,460 --> 00:59:09,960
Speaker 1: Because, yeah, our Afghanistan and Iraq puppet states are so valuable and secure to us.

1075
00:59:10,365 --> 00:59:10,654
Speaker 0: Oh, yes.

1076
00:59:11,745 --> 00:59:12,840
Speaker 0: What if it's a big con game?

1077
00:59:12,960 --> 00:59:15,105
Speaker 1: This is a long scam by the U.S.

1078
00:59:15,306 --> 00:59:18,433
Speaker 1: to trick Russia into getting embroiled in a land war in the Middle East.

1079
00:59:18,473 --> 00:59:20,778
Speaker 1: so we can back away and be like, "Well, not our

1080
00:59:20,799 --> 00:59:21,199
Speaker 1: problem.".

1081
00:59:21,522 --> 00:59:22,100
Speaker 0: Good strategy.

1082
00:59:22,720 --> 00:59:24,520
Speaker 1: That would also be a good plot for a movie.

1083
00:59:24,943 --> 00:59:25,480
Speaker 0: A+ strategy.

1084
00:59:25,861 --> 00:59:28,300
Speaker 0: Haha, we tricked you into going to war and ruining your own country.

1085
00:59:28,560 --> 00:59:29,243
Speaker 0: Yeah, here's the movie.

1086
00:59:29,303 --> 00:59:33,040
Speaker 1: It's Dave, but he is trying to trick Russia into invading North Korea.

1087
00:59:33,581 --> 00:59:35,251
Speaker 0: Yeah, it works.

1088
00:59:35,432 --> 00:59:36,640
Speaker 0: Russia, the country is ruined.

1089
00:59:37,240 --> 00:59:38,847
Speaker 0: And it's like, "Oh, he did all our work for us.

1090
00:59:38,947 --> 00:59:39,851
Speaker 0: We don't need the military.

1091
00:59:39,871 --> 00:59:41,337
Speaker 0: We can just do everything by

1092
00:59:41,378 --> 00:59:41,679
Speaker 0: talking.".

1093
00:59:42,982 --> 00:59:44,338
Speaker 1: Alright, it's been an hour.

1094
00:59:45,460 --> 00:59:49,139
Speaker 1: Uh, Geek Nights will be continuing normally from this point on.

1095
00:59:49,680 --> 00:59:51,655
Speaker 1: Stay tuned for, you know, videos to come up.

1096
00:59:51,675 --> 00:59:52,280
Speaker 1: I got a huge backlog of videos.

1097
00:59:52,300 --> 00:59:55,440
Speaker 0: We had to make the craziest show to make people remember what Geek Nights is about.

1098
00:59:55,861 --> 00:59:57,019
Speaker 1: Yeah, it's about this.

1099
00:59:57,280 --> 00:59:59,660
Speaker 0: We couldn't make anything that was serious or sensible.

1100
01:00:00,040 --> 01:00:01,559
Speaker 1: I was serious, mostly.

1101
01:00:03,782 --> 01:00:06,940
Speaker 0: How could you be serious about something on a website that misspelled the word "people"?

1102
01:00:07,023 --> 01:00:07,337
Speaker 1: You know what?

1103
01:00:09,421 --> 01:00:12,400
Speaker 1: I am not as serious as Land the Water.

1104
01:00:13,141 --> 01:00:16,320
Speaker 1: Who I think is the most serious person in that entire...

1105
01:00:16,840 --> 01:00:18,399
Speaker 0: Land's middle name is serious.

1106
01:00:25,663 --> 01:00:27,800
Speaker 1: This has been Geek Nights with Rim and Scott.

1107
01:00:28,000 --> 01:00:32,940
Speaker 1: Special thanks to DJ Pretzel for the opening music, Kat Lee for web design, and Brando K for the logos.

1108
01:00:33,300 --> 01:00:38,340
Speaker 0: Be sure to visit our website at FrontRowCrew.com for show notes, discussion news, and more.

1109
01:00:38,620 --> 01:00:41,260
Speaker 1: Remember, Geek Nights is not one, but four different shows.

1110
01:00:41,540 --> 01:00:46,000
Speaker 1: Sci-Tech Mondays, Gaming Tuesdays, Anime Comic Wednesdays, and Indiscriminate Thursdays.

1111
01:00:46,361 --> 01:00:49,536
Speaker 0: Geek Nights is distributed under a Creative Commons Attribution 3.0 license.

1112
01:00:50,840 --> 01:00:53,820
Speaker 0: Geek Nights is recorded live with no studio and no audience.

1113
01:00:54,120 --> 01:00:56,960
Speaker 0: But unlike those other late shows, it's actually recorded at night.

