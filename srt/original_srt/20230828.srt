1
00:00:08,380 --> 00:00:09,987
Speaker 1: It's Monday, August 28th, 2023.

2
00:00:09,987 --> 00:00:10,167
Speaker 1: I'm Rym.

3
00:00:13,846 --> 00:00:14,280
Speaker 0: I'm Scott.

4
00:00:14,520 --> 00:00:15,665
Speaker 1: And this is Geek Nights.

5
00:00:15,685 --> 00:00:19,720
Speaker 1: Tonight we're talking about blocking on things like platforms and social media.

6
00:00:20,760 --> 00:00:21,757
Speaker 0: Let's do this.

7
00:00:22,860 --> 00:00:35,560
Speaker 1: So this weekend, because of a combination of wildfires, getting a sinus infection, having to travel for other stuff, Emily and I had not actually been to Sandy Hook Beach at any point, even though we usually go like two or three times a year.

8
00:00:36,544 --> 00:00:40,260
Speaker 0: I went one time last Monday by myself.

9
00:00:41,304 --> 00:00:43,260
Speaker 1: Yep, Monday, with your special Mondays.

10
00:00:44,523 --> 00:00:45,289
Speaker 0: It's not my fault.

11
00:00:45,309 --> 00:00:46,256
Speaker 0: Negotiate harder.

12
00:00:47,600 --> 00:00:48,343
Speaker 1: I'm working on that.

13
00:00:48,926 --> 00:00:50,994
Speaker 1: So we went to Sandy Hook, had a great time.

14
00:00:51,015 --> 00:00:52,240
Speaker 1: It was a perfect beach day.

15
00:00:52,720 --> 00:00:57,420
Speaker 1: The water was at its absolute peak temperature for the year, which is always...

16
00:00:57,440 --> 00:00:59,759
Speaker 0: The water when I was there was very nice.

17
00:01:01,102 --> 00:01:05,900
Speaker 1: And of course, it was the last weekend because next weekend is Labor Day weekend.

18
00:01:06,300 --> 00:01:12,080
Speaker 1: And even though with climate change, the beach is still pretty warm and the water is still nice.

19
00:01:12,881 --> 00:01:16,478
Speaker 1: Well into toward the end of September and even into October around New York.

20
00:01:17,521 --> 00:01:27,934
Speaker 0: But the problem is, is that, you know, in places where it's always warm, there are people who are just professional lifeguards, professional beach employees, professional resort employees, right?

21
00:01:27,974 --> 00:01:29,160
Speaker 0: They do that all year.

22
00:01:29,321 --> 00:01:30,751
Speaker 1: Those kids got to go back to school.

23
00:01:30,933 --> 00:01:31,900
Speaker 1: So the beach is closed.

24
00:01:32,641 --> 00:01:37,920
Speaker 0: Right, in New York, in northern places that have seasons, that's a seasonal job, right?

25
00:01:38,100 --> 00:01:40,452
Speaker 0: And schools start Labor Day.

26
00:01:40,532 --> 00:01:42,120
Speaker 0: And a lot of those people are younger.

27
00:01:42,360 --> 00:01:45,220
Speaker 0: College people, high school people even sometimes, right?

28
00:01:45,981 --> 00:01:47,991
Speaker 0: Because that's, you know, a seasonal summer job.

29
00:01:48,031 --> 00:01:51,871
Speaker 0: That's the kind of person that would, you know, or even if it's an adult, it'll be a teacher, right?

30
00:01:52,192 --> 00:01:53,680
Speaker 0: Who's going to work only in the summer?

31
00:01:54,080 --> 00:01:55,730
Speaker 0: Someone who works, not the summer.

32
00:01:55,750 --> 00:01:56,273
Speaker 0: Who is that?

33
00:01:56,414 --> 00:01:57,420
Speaker 0: Someone in academia.

34
00:01:57,802 --> 00:02:02,100
Speaker 0: And as soon as summer is over, they have to go back to the other, their more lucrative job.

35
00:02:02,761 --> 00:02:11,100
Speaker 0: And no matter, even if it remains 90 degrees, it's like we have nobody up here to work because it's not a full-time year-round job here.

36
00:02:11,581 --> 00:02:22,171
Speaker 0: And I think even if, you know, the summer extends to September, October, it's like we still can't quite make it a full-time job because it's like in February, nobody's going to, right?

37
00:02:22,232 --> 00:02:24,160
Speaker 0: It's like the person's not going to work, right?

38
00:02:24,501 --> 00:02:27,499
Speaker 1: It's not worth it to deal with like a couple more months.

39
00:02:28,200 --> 00:02:33,014
Speaker 0: Yeah, you can't have it be a full-time year-round job unless it's really tropical.

40
00:02:33,375 --> 00:02:37,360
Speaker 0: every single month, you know, or at least 11 out of 12 months or something like that.

41
00:02:37,560 --> 00:02:45,960
Speaker 0: So we're in this situation where we need pools and beaches open because it's still warm for, you know, everybody.

42
00:02:46,621 --> 00:02:51,559
Speaker 0: But we got nobody to work there, so we had to close them and it's still hot out.

43
00:02:52,141 --> 00:03:01,020
Speaker 1: Yup, because, you know, climate change is going to radically disturb every aspect of human society in ways that people are not even thinking about.

44
00:03:01,180 --> 00:03:04,980
Speaker 1: Like this tiny thing is going to get worse and worse and worse.

45
00:03:05,340 --> 00:03:12,020
Speaker 1: Ten years from now, it's probably going to be like 90 degrees in November and none of the pools are going to be open in New York City and people are going to die.

46
00:03:14,740 --> 00:03:19,520
Speaker 1: So at least hanging out at the beach, perfect beach day, a few observations.

47
00:03:19,920 --> 00:03:24,160
Speaker 1: So Sandy Hook has been getting more and more popular as we know, like more and more people hang out at that beach.

48
00:03:24,500 --> 00:03:25,959
Speaker 1: That ferry is like really bumping.

49
00:03:26,820 --> 00:03:39,720
Speaker 1: And when we used to go to Sandy Hook, the only food options, unless you biked like all the way over to Highlands, like over that bridge where there's a bunch of good seafood, were basically three food trucks of varying levels of sadness.

50
00:03:40,720 --> 00:03:48,040
Speaker 1: Now, not only are there more food trucks, but there are two full-on, normal restaurants on Sandy Hook.

51
00:03:48,540 --> 00:03:49,560
Speaker 1: That is a new development.

52
00:03:50,841 --> 00:03:54,057
Speaker 0: I only saw the one that was there last year, which is the like, you know...

53
00:03:54,802 --> 00:03:57,200
Speaker 1: I already forget the names, there's the one near the lighthouse.

54
00:03:57,300 --> 00:03:58,740
Speaker 1: Yeah, the one near the lighthouse is kind of small.

55
00:03:58,840 --> 00:04:01,260
Speaker 1: There's another one right next to the ferry dock.

56
00:04:02,780 --> 00:04:03,479
Speaker 0: Oh, okay, I didn't see it.

57
00:04:03,620 --> 00:04:09,620
Speaker 1: It's huge and we thought, like we ate dinner somewhere else because we wanted the good seafood over at Highland, like we biked over there.

58
00:04:09,701 --> 00:04:11,679
Speaker 1: But we went to check this place out.

59
00:04:12,081 --> 00:04:16,480
Speaker 1: There were easily like a hundred plus people in the main dining area of this.

60
00:04:16,540 --> 00:04:17,418
Speaker 0: So you were there on a weekend.

61
00:04:18,082 --> 00:04:20,779
Speaker 1: Yeah, but it was rocking, it was completely full.

62
00:04:20,880 --> 00:04:21,980
Speaker 1: There was like a line out the door.

63
00:04:22,040 --> 00:04:22,968
Speaker 0: Maybe that's why I didn't see it.

64
00:04:23,009 --> 00:04:24,260
Speaker 0: Maybe it wasn't open on a weekday.

65
00:04:24,660 --> 00:04:26,859
Speaker 1: Yeah, I imagine it's only open on weekends.

66
00:04:27,380 --> 00:04:28,759
Speaker 1: I didn't see any hours or anything.

67
00:04:29,201 --> 00:04:35,740
Speaker 1: But also, some minor updates, more of those houses are available for rentals.

68
00:04:36,500 --> 00:04:40,157
Speaker 0: I saw one that had a sign that said "for rent" with some kind of URL.

69
00:04:40,217 --> 00:04:40,820
Speaker 0: I didn't look at.

70
00:04:40,920 --> 00:04:44,739
Speaker 1: Yep, I went to that URL and I saw there's a bunch you can rent and there's also some on Airbnb.

71
00:04:46,360 --> 00:04:51,480
Speaker 1: Also, the campsite that used to, as best I can tell, was always for group camping.

72
00:04:51,640 --> 00:04:55,160
Speaker 1: You had to organize like in advance and it wasn't like a straightforward process.

73
00:04:55,561 --> 00:05:03,900
Speaker 1: Now it just has a bunch of individual tent camping sites you can just reserve on a website just like a hotel for a nominal fee.

74
00:05:04,340 --> 00:05:10,560
Speaker 1: And they even have a process, which was the thing that always kept me away from trying to rent one of the places on this island.

75
00:05:10,960 --> 00:05:16,260
Speaker 1: In the past, if you wanted to go there with your friends and you wanted to use that ferry, the ferry is very strict.

76
00:05:16,540 --> 00:05:23,080
Speaker 1: You can only book one day round trip tickets or like you'll get tackled like that crazy lady that one time.

77
00:05:24,540 --> 00:05:27,700
Speaker 1: So now, there's a thing on the Seastreak website.

78
00:05:28,541 --> 00:05:43,520
Speaker 1: If you are staying on the island or on the peninsula for multiple days because you're camping and you use the express ferry, you can call them and arrange a special multi-day trip where you can come on one day and leave on another day and not get tackled by the park service.

79
00:05:45,420 --> 00:05:51,540
Speaker 1: So we're thinking about camping on Sandy Hook in October and checking it out and seeing what that's like.

80
00:05:53,644 --> 00:05:54,388
Speaker 1: You can always come.

81
00:05:54,509 --> 00:05:55,816
Speaker 1: You just gotta get your own tent.

82
00:05:55,836 --> 00:05:56,480
Speaker 1: I only have one tent.

83
00:05:57,220 --> 00:05:58,499
Speaker 0: I have a tent, but it seems cold.

84
00:05:59,120 --> 00:05:59,341
Speaker 1: Cold?

85
00:05:59,361 --> 00:05:59,884
Speaker 1: Are you kidding?

86
00:05:59,904 --> 00:06:01,291
Speaker 1: In October?

87
00:06:01,311 --> 00:06:03,120
Speaker 1: It's gonna be perfectly comfortable to camp.

88
00:06:03,680 --> 00:06:09,200
Speaker 1: And in fact, camping in a tent is nicer in like late September or October because you got the nice warm sleeping bag.

89
00:06:09,660 --> 00:06:15,478
Speaker 1: It's not that comfortable usually to camp in a place like that in the dead of summer when it doesn't get under like 75 at night.

90
00:06:18,421 --> 00:06:20,207
Speaker 1: Anyway, Sandy Hook adventures.

91
00:06:20,328 --> 00:06:22,395
Speaker 1: Lots of tech news, not a tech news roundup.

92
00:06:22,576 --> 00:06:23,640
Speaker 1: We're saving that for the future.

93
00:06:24,220 --> 00:06:25,938
Speaker 1: But I'm sure you've seen.

94
00:06:27,522 --> 00:06:30,533
Speaker 0: If you go long enough, you can refill your quota.

95
00:06:30,834 --> 00:06:32,560
Speaker 0: You could do two tech news roundups in a row.

96
00:06:32,880 --> 00:06:33,242
Speaker 0: I could.

97
00:06:33,665 --> 00:06:36,000
Speaker 1: The listener is always asking for the tech news roundup.

98
00:06:37,220 --> 00:06:41,580
Speaker 0: There's like 10,000 podcasts and websites that are nothing but tech news roundups.

99
00:06:41,740 --> 00:06:43,800
Speaker 1: Yeah, and I get the impression either they're all bad.

100
00:06:44,422 --> 00:06:45,867
Speaker 0: Shouldn't we do something different?

101
00:06:46,107 --> 00:06:49,940
Speaker 0: If you want tech news roundup, why don't you just go to one of the people who do it every single day?

102
00:06:51,801 --> 00:06:56,237
Speaker 1: There's a thousand Spidermans all over the place, but why are we talking a lot about Spider-Verse?

103
00:06:56,298 --> 00:06:56,940
Speaker 1: That's the good one.

104
00:06:57,862 --> 00:06:58,420
Speaker 0: I'm just saying.

105
00:06:59,760 --> 00:07:09,320
Speaker 1: So in some news, and this is a technology news because this is an area where technology was employed and had problems and needs to be employed better.

106
00:07:09,340 --> 00:07:10,802
Speaker 1: And it fits into a common theme of geek nights.

107
00:07:11,443 --> 00:07:24,380
Speaker 1: One aspect of the extreme wildfires and the devastation in Hawaii and Maui during the wildfires not too long ago was that there are warning sirens on the island.

108
00:07:24,580 --> 00:07:25,580
Speaker 0: We talked about this already.

109
00:07:25,760 --> 00:07:26,745
Speaker 0: Yes.

110
00:07:26,986 --> 00:07:29,560
Speaker 1: The warning sirens were not used.

111
00:07:30,462 --> 00:07:33,979
Speaker 0: Yes, because they thought people would hear them and run up away from the water.

112
00:07:35,862 --> 00:07:47,240
Speaker 1: So the technology problem that is now in the news being talked about is how do you inform people in a place like Maui about different kinds of disasters?

113
00:07:47,880 --> 00:07:48,001
Speaker 0: Right.

114
00:07:48,021 --> 00:07:50,714
Speaker 0: We've been relying on our text message alerts, but guess what?

115
00:07:51,035 --> 00:07:51,920
Speaker 0: That shit was down.

116
00:07:52,060 --> 00:07:53,666
Speaker 0: Yep.

117
00:07:53,706 --> 00:07:54,409
Speaker 1: Put a tweet out.

118
00:07:54,449 --> 00:07:57,340
Speaker 1: Well, Twitter doesn't even work anymore, let alone people don't have internet.

119
00:07:57,620 --> 00:07:57,720
Speaker 0: Right.

120
00:07:57,740 --> 00:08:00,086
Speaker 0: The cell towers were on fire, right?

121
00:08:00,187 --> 00:08:02,834
Speaker 0: It's like, yeah, the radio, you know, you could have a radio tower.

122
00:08:02,874 --> 00:08:05,240
Speaker 0: that, you know, but people don't turn on radios.

123
00:08:05,560 --> 00:08:08,240
Speaker 1: Nor do most people even have radios anymore.

124
00:08:08,883 --> 00:08:10,120
Speaker 0: Or broadcast television.

125
00:08:10,260 --> 00:08:16,397
Speaker 1: The only radio in our apartment, I was thinking about this, the only one is gone.

126
00:08:17,900 --> 00:08:24,753
Speaker 1: Because the last radio we had was the same alarm clock radio that I had since middle school.

127
00:08:25,154 --> 00:08:28,100
Speaker 1: that could theoretically get AM and FM if I wanted it to.

128
00:08:28,480 --> 00:08:29,458
Speaker 1: And we got rid of that thing.

129
00:08:30,500 --> 00:08:30,622
Speaker 0: Yeah.

130
00:08:30,642 --> 00:08:32,260
Speaker 0: Well, I mean, I have radios.

131
00:08:32,820 --> 00:08:32,880
Speaker 1: Yep.

132
00:08:32,900 --> 00:08:35,339
Speaker 1: I don't have any because what would I ever use one for?

133
00:08:36,384 --> 00:08:40,480
Speaker 0: I mean, I have an emergency radio and I also have a little Sony radio.

134
00:08:41,360 --> 00:08:46,780
Speaker 1: But this gets into an even bigger problem because even if, like, how do we solve this problem?

135
00:08:47,281 --> 00:08:55,260
Speaker 1: Does the government need to start giving people emergency radios coupled with instructions on when and how to use them?

136
00:08:56,001 --> 00:08:56,102
Speaker 0: No.

137
00:08:56,122 --> 00:09:02,035
Speaker 0: I think by law, they should, you know, put AM/FM radios in all smartphones.

138
00:09:02,196 --> 00:09:03,579
Speaker 0: Otherwise, you can't sell them in the US.

139
00:09:03,599 --> 00:09:03,960
Speaker 0: Tough shit.

140
00:09:04,901 --> 00:09:09,720
Speaker 1: That would actually require some more expensive chips and I don't think people would use them anyway.

141
00:09:09,840 --> 00:09:11,466
Speaker 0: There have been cell phones in the past.

142
00:09:11,546 --> 00:09:15,200
Speaker 0: In Japan, flip phones could pick up broadcast television, right?

143
00:09:15,420 --> 00:09:15,761
Speaker 0: Yes.

144
00:09:15,821 --> 00:09:17,385
Speaker 1: My old cell phone could do that.

145
00:09:17,445 --> 00:09:17,967
Speaker 1: Guess what?

146
00:09:18,368 --> 00:09:23,020
Speaker 1: It required physical headphones plugged into it to act as the antenna.

147
00:09:23,480 --> 00:09:24,307
Speaker 1: You can't have an antenna.

148
00:09:24,327 --> 00:09:25,880
Speaker 1: You need a bigger antenna or that doesn't work.

149
00:09:26,440 --> 00:09:29,294
Speaker 1: All those phones required wired headphones plugged in.

150
00:09:29,314 --> 00:09:30,339
Speaker 1: Guess what iPhones don't have?

151
00:09:32,002 --> 00:09:32,980
Speaker 0: A point I'm pretty sure.

152
00:09:33,000 --> 00:09:36,680
Speaker 1: You need to be through an adapter because you need a direct connection for that type of antenna.

153
00:09:38,260 --> 00:09:40,018
Speaker 0: I think there'd be a way to accomplish this.

154
00:09:40,445 --> 00:09:41,059
Speaker 0: I don't know.

155
00:09:41,320 --> 00:09:42,099
Speaker 0: This doesn't seem impossible to me.

156
00:09:42,240 --> 00:09:47,240
Speaker 1: Yeah, put the headphone jack back on or give people an antenna that has to be plugged into their device.

157
00:09:48,840 --> 00:09:50,899
Speaker 0: I think that, you know, this is a solvable problem.

158
00:09:51,160 --> 00:09:57,340
Speaker 1: But also, even if you did that, one, most people are not going to have an up-to-date cell phone.

159
00:09:57,520 --> 00:10:00,000
Speaker 1: Like, most people either don't have a smartphone or have an old one.

160
00:10:01,621 --> 00:10:09,960
Speaker 1: And two, even if you do this, I don't think people would even think or know to activate that feature or even be aware that it existed.

161
00:10:10,520 --> 00:10:19,040
Speaker 0: That's okay because you can have the emergency broadcast system broadcast a signal and that signal would then automatically activate the radio in the phone.

162
00:10:19,580 --> 00:10:20,819
Speaker 0: You wouldn't have to, like, go through it on purpose.

163
00:10:20,860 --> 00:10:25,280
Speaker 1: That is more infeasible because they're not always listening.

164
00:10:26,800 --> 00:10:29,860
Speaker 1: And making them always listen would drain the batteries.

165
00:10:31,188 --> 00:10:31,700
Speaker 0: I'm just saying.

166
00:10:32,060 --> 00:10:34,380
Speaker 1: I'm saying there are significant technical challenges to that.

167
00:10:34,380 --> 00:10:35,220
Speaker 0: Broadcasting drains the batteries.

168
00:10:36,240 --> 00:10:36,533
Speaker 0: Receiving...

169
00:10:37,141 --> 00:10:45,200
Speaker 1: So you should look up the difference between AM and FM and why you can have unpowered radios of certain kinds, but not unpowered radios of other kinds.

170
00:10:45,860 --> 00:10:50,680
Speaker 0: Well, we're not using this spectrum for, you know, people aren't listening to actual radio anymore, so we use the unpowered kind.

171
00:10:51,763 --> 00:10:53,659
Speaker 1: Except we haven't shut all that existing stuff down yet.

172
00:10:53,960 --> 00:10:54,670
Speaker 0: Shut that shit off.

173
00:10:54,711 --> 00:10:55,279
Speaker 0: We ain't using it.

174
00:10:55,600 --> 00:10:56,602
Speaker 1: Yep.

175
00:10:56,782 --> 00:11:08,020
Speaker 1: I guess the technology problem here is pretty interesting because in New York City, the way, like, all commercial buildings work is there's one kind of sound that means fire GTFO.

176
00:11:08,762 --> 00:11:09,240
Speaker 1: And there's another...

177
00:11:09,240 --> 00:11:14,080
Speaker 0: Well, I mean, a lot of modern buildings, the alarm systems actually say words.

178
00:11:14,302 --> 00:11:15,259
Speaker 1: Well, that's what I was about to say.

179
00:11:15,760 --> 00:11:16,691
Speaker 1: They still require...

180
00:11:17,522 --> 00:11:18,519
Speaker 0: Or carbon monoxide.

181
00:11:19,263 --> 00:11:20,259
Speaker 1: Yes, that's type two.

182
00:11:20,920 --> 00:11:21,415
Speaker 1: Terrorist.

183
00:11:21,901 --> 00:11:23,628
Speaker 1: Is a different tone.

184
00:11:23,950 --> 00:11:26,520
Speaker 1: that, as far as I can tell, by law is a different tone.

185
00:11:26,980 --> 00:11:30,200
Speaker 1: And that tone means listen for further instructions.

186
00:11:30,801 --> 00:11:34,680
Speaker 1: And those are the only two tones because we have more than two tones.

187
00:11:35,361 --> 00:11:45,500
Speaker 1: Who the hell... What human, average human of average intelligence and average knowledge will know the difference between three or four or five different tones, especially when different states are going to do it differently.

188
00:11:45,802 --> 00:11:47,100
Speaker 1: So New York has got two tones.

189
00:11:47,500 --> 00:11:48,540
Speaker 1: One of them is fire.

190
00:11:48,820 --> 00:11:49,578
Speaker 1: Get the fuck out.

191
00:11:49,862 --> 00:11:51,880
Speaker 1: And the other one is listen for instructions.

192
00:11:52,240 --> 00:11:53,000
Speaker 1: Don't do anything.

193
00:11:53,440 --> 00:11:54,340
Speaker 1: Listen for instructions.

194
00:11:54,421 --> 00:11:55,719
Speaker 1: We'll tell you what to do with words.

195
00:11:56,980 --> 00:12:03,800
Speaker 1: And I feel like that type of system of there are no more than two different kinds of signals.

196
00:12:04,264 --> 00:12:11,280
Speaker 1: And one of them should be the... If you hear this signal, do the specific thing that we have been teaching you your entire lives to do.

197
00:12:11,701 --> 00:12:16,380
Speaker 1: Like in Hawaii, the thing you are told if that siren goes off is head up mountain.

198
00:12:16,646 --> 00:12:17,139
Speaker 1: Just get that.

199
00:12:17,300 --> 00:12:17,899
Speaker 1: There's tsunami coming.

200
00:12:18,040 --> 00:12:18,439
Speaker 1: Head up mountain.

201
00:12:18,841 --> 00:12:26,860
Speaker 1: So the second tone should be activate whatever emergency device the government gave you or turn on your cell phone and hit the emergency button or whatever.

202
00:12:27,200 --> 00:12:28,599
Speaker 1: Like wait for instructions.

203
00:12:29,420 --> 00:12:34,460
Speaker 0: I also feel like these low population areas with specific disaster concerns...

204
00:12:35,200 --> 00:12:39,580
Speaker 1: You can do what Costa Rica does and what a lot of countries do and this is super effective.

205
00:12:40,322 --> 00:12:49,060
Speaker 1: A truck with a megaphone and people on bikes with megaphones just fan out from the emergency center telling people what to do actively.

206
00:12:49,440 --> 00:12:53,080
Speaker 0: We definitely do not employ that method enough in the United States anywhere.

207
00:12:53,440 --> 00:12:54,226
Speaker 0: It's like in Japan.

208
00:12:54,266 --> 00:12:56,140
Speaker 0: you see them doing it for like political campaigning.

209
00:12:56,721 --> 00:12:58,279
Speaker 0: And remember the great northeast power outage?

210
00:12:59,240 --> 00:13:04,540
Speaker 0: I'm not saying we should use it for political campaigning or advertising but it's like that method is not used enough here.

211
00:13:04,980 --> 00:13:08,060
Speaker 0: It is effective and good in high population areas.

212
00:13:08,141 --> 00:13:08,385
Speaker 0: Yup.

213
00:13:08,609 --> 00:13:09,280
Speaker 1: Case in point.

214
00:13:09,961 --> 00:13:17,980
Speaker 1: If there's a riot because some live streamer caused a problem in Manhattan, a bunch of people immediately show up to handle the situation.

215
00:13:18,420 --> 00:13:25,120
Speaker 1: You'd think disaster response would be a similar high value thing for society but capital is angered by this idea.

216
00:13:26,461 --> 00:13:27,480
Speaker 1: Anyway, got any news?

217
00:13:29,104 --> 00:13:30,019
Speaker 0: We do have a news.

218
00:13:32,101 --> 00:13:39,500
Speaker 0: There's been a lot of hoo-ha around Dolby Vision, Dolby Atmos, Dolby everything lately.

219
00:13:40,081 --> 00:13:42,232
Speaker 1: I don't even have them all straight in my head.

220
00:13:42,272 --> 00:13:43,880
Speaker 1: I gotta look it up every time.

221
00:13:44,280 --> 00:13:45,877
Speaker 0: I watched some YouTube videos so now I know.

222
00:13:46,921 --> 00:14:27,160
Speaker 0: But basically Dolby, they make these technologies which are good/bad that allow basically creators of mostly movies but also television shows and other television productions to sort of distribute and master their audio and video in a certain way using Dolby technologies in order to try to guarantee to the extent feasible that when you watch, because they're mastering some movie doing color grading on like a monitor, a special studio monitor, that's like a reference thing that costs $40,000.

223
00:14:27,160 --> 00:14:35,000
Speaker 0: So there's no way that you with your $800 TV from Costco are going to be seeing the same color that they see.

224
00:14:35,921 --> 00:14:40,045
Speaker 0: So they want to try to guarantee that you see the color they see as much as you could.

225
00:14:40,886 --> 00:14:54,020
Speaker 0: or you don't have the sound system that they have in their recording studio but they want to make sure that you hear as much as close to the fancy movie theater as you possibly can with what you have in your home.

226
00:14:54,020 --> 00:14:57,085
Speaker 1: You want to know how movie theaters and stadiums actually set that up?

227
00:14:57,586 --> 00:15:05,860
Speaker 1: They'll send tones of different frequencies out all the speakers and they put sensors and people all over the facility and they use that to autotune.

228
00:15:06,420 --> 00:15:08,243
Speaker 0: The ones that care can set it up.

229
00:15:08,283 --> 00:15:17,440
Speaker 0: but the thing is the vast majority of theaters and home theaters especially but also real theaters do not go through the effort of setting everything up properly.

230
00:15:18,281 --> 00:15:18,822
Speaker 0: Imagine

231
00:15:18,842 --> 00:15:31,640
Speaker 1: the average person who has a TV and some stuff and then you tell them yes get this extra $100 device and put it in the middle of your living room and then hit a button and it's going to screech for an hour and let it do its thing.

232
00:15:31,900 --> 00:15:41,493
Speaker 0: There are those audiophile nerdy types but there are also those other types who aren't believing in audiophile nonsense but they just really want their home theater to be perfect.

233
00:15:41,773 --> 00:15:46,980
Speaker 0: so they'll pay someone to come calibrate their TV and pay someone to calibrate their stereo.

234
00:15:48,791 --> 00:15:50,754
Speaker 0: So Dolby has a thing called Atmos.

235
00:15:50,814 --> 00:15:56,080
Speaker 0: you probably heard of it and what Atmos is is basically just even more surround sound.

236
00:15:56,380 --> 00:15:57,301
Speaker 0: It's like you know.

237
00:15:57,481 --> 00:16:04,787
Speaker 0: see if we had we're used to like you know 5.1 said whatever right it's like Atmos will go the even further.

238
00:16:05,208 --> 00:16:19,600
Speaker 0: not just rear front center channels right but actually sounds going up and you know over your head right and things bouncing sounds off the ceiling and shit like that to make it sound like things are coming from anywhere.

239
00:16:19,843 --> 00:16:21,820
Speaker 1: Is that 14.1?

240
00:16:21,820 --> 00:16:22,021
Speaker 0: I have.

241
00:16:22,061 --> 00:16:23,463
Speaker 0: no I know it it's.

242
00:16:23,743 --> 00:16:26,728
Speaker 0: there's no set number for it because it depends what your equipment is.

243
00:16:27,248 --> 00:16:34,519
Speaker 0: but you know generally you know you're going to have like some rear speakers with some like upward firing drivers right that and shit like that.

244
00:16:35,901 --> 00:16:40,806
Speaker 0: And like your center channel would be like some soundbar with like who knows how many tiny drivers is.

245
00:16:40,866 --> 00:16:55,579
Speaker 1: a true audio file will want a 3D printed fully anatomically correct set of human heads arranged in their TV so that any characters dialogue is recreated with actual biological vocal cords in real time.

246
00:16:57,740 --> 00:16:58,261
Speaker 0: That'd be good.

247
00:16:59,181 --> 00:17:02,984
Speaker 0: so the thing with Dolby Atmos is that you know it works.

248
00:17:03,324 --> 00:17:07,867
Speaker 0: but you have to get like you know Dolby Atmos equipment and set it up specifically.

249
00:17:08,088 --> 00:17:12,391
Speaker 0: position the speakers right and you know a lot of people have different rooms right.

250
00:17:12,411 --> 00:17:18,095
Speaker 0: for example the room I have is not ideal because the you know it's not huge so the couch is up against the wall.

251
00:17:18,135 --> 00:17:21,718
Speaker 0: you can't really put speakers behind you right so you can't read.

252
00:17:21,738 --> 00:17:24,099
Speaker 0: the rear channels aren't very rear are they.

253
00:17:26,140 --> 00:17:30,064
Speaker 0: Or you know things of that nature and you know you get a lot of people.

254
00:17:30,104 --> 00:17:33,227
Speaker 0: you know not too many people have like wireless systems right.

255
00:17:33,267 --> 00:17:33,787
Speaker 0: that's you know.

256
00:17:34,147 --> 00:17:37,230
Speaker 0: there's also various companies for example Samsung.

257
00:17:37,270 --> 00:17:38,211
Speaker 0: I forget what they call it.

258
00:17:38,231 --> 00:17:44,436
Speaker 0: they have like a special Samsung only thing where you won't actually turn off the speakers in your television.

259
00:17:44,957 --> 00:17:48,560
Speaker 0: it'll incorporate them in to whatever sound system you already have.

260
00:17:51,422 --> 00:17:52,023
Speaker 0: Shit like that.

261
00:17:52,383 --> 00:17:56,329
Speaker 0: so Dolby actually announced the thing today.

262
00:17:56,729 --> 00:18:00,535
Speaker 0: it's called Dolby Atmos flex connect right.

263
00:18:01,115 --> 00:18:04,300
Speaker 0: so hypothetically the way this would work is that.

264
00:18:05,341 --> 00:18:12,006
Speaker 0: Just like rim said oh with the professional calibration they put microphones and sensors all around and play sounds out of all the speakers.

265
00:18:12,086 --> 00:18:15,668
Speaker 0: and then right it basically sort of does that in your home.

266
00:18:16,289 --> 00:18:20,852
Speaker 0: so your TV would play sounds out of all its speakers.

267
00:18:20,912 --> 00:18:31,580
Speaker 0: however many the fuck you've got with your sound bars and your wireless rear speakers or who knows what you got and then the you have microphones in the flex connect television.

268
00:18:32,081 --> 00:18:35,105
Speaker 0: Right and then that would figure out what to do.

269
00:18:35,746 --> 00:18:36,307
Speaker 0: and there you go.

270
00:18:36,347 --> 00:18:37,989
Speaker 0: now you've got a Dolby app.

271
00:18:38,049 --> 00:18:42,135
Speaker 0: you're going to get the as much at most as you can get with what you got.

272
00:18:42,696 --> 00:18:45,700
Speaker 0: so this is actually strange because.

273
00:18:46,780 --> 00:18:51,568
Speaker 0: Usually this Dolby shit is all about making money for TV manufacturers and for Dolby.

274
00:18:51,709 --> 00:18:53,612
Speaker 0: right because it's like number one.

275
00:18:54,153 --> 00:18:58,540
Speaker 0: if you want to have a TV with Dolby shit in it you have to pay a licensing fee to Dolby.

276
00:18:58,940 --> 00:19:13,780
Speaker 0: So for example some TV manufacturers you know just have HDR something something which is like open right and open license protocol whatever and they don't have Dolby vision because they would have to pay Dolby to have Dolby vision certification on their TVs.

277
00:19:14,541 --> 00:19:17,744
Speaker 0: And it's like alright you know is the HDR 10 whatever?

278
00:19:17,924 --> 00:19:20,006
Speaker 0: just as good probably.

279
00:19:20,686 --> 00:19:35,200
Speaker 0: but you know the thing is some people will only buy a TV if it has Dolby vision because they really want to make sure that if they get some booray that was Dolby vision that it's the colors are exactly right even though they probably couldn't tell if it was the HDR.

280
00:19:35,440 --> 00:19:39,005
Speaker 1: I mean that's why you know even doing like color like design work.

281
00:19:39,626 --> 00:19:50,680
Speaker 1: I have some Dell ultra sharps and they're pretty good on color but they're not like pro good and it's fine but they're definitely better than like random LG.

282
00:19:51,900 --> 00:19:52,120
Speaker 0: Right.

283
00:19:52,341 --> 00:20:02,331
Speaker 0: so there's a two levels of making money you pay the manufacturer pays Dolby for a license and then the manufacturer hopes to get increased sales because they can slap a Dolby logo on their product.

284
00:20:02,712 --> 00:20:10,320
Speaker 0: this the Dolby flex connect seems to satisfy both those things but also maybe not because.

285
00:20:11,121 --> 00:20:25,180
Speaker 0: Yes the you know the Dolby would make money from the licensing and the manufacturer of a television would make money from selling their flex connect television but they might actually lose money on selling sound systems.

286
00:20:25,781 --> 00:20:40,757
Speaker 0: Because hypothetically with flex connect you could just connect whatever the fuck speakers you've got not some Dolby vision you know or Dolby at most certified sound bar system which is probably what people would buy anyway.

287
00:20:40,817 --> 00:20:42,940
Speaker 0: but like you could theoretically make a TV.

288
00:20:43,940 --> 00:20:56,094
Speaker 0: That just has Bluetooth in it and you connect as many Bluetooth speakers as you can find and you throw them all over your room and you don't care where that where they are or what direction they're facing or what kind they are.

289
00:20:56,154 --> 00:21:02,020
Speaker 0: mix all the brands together like as many as you can pair right without Bluetooth failing.

290
00:21:03,461 --> 00:21:15,358
Speaker 0: And this will play sounds out of all of them and do as much Dolby at most as it can do with the speakers that you provided that were you know cheap Bluetooth speakers you bought off of.

291
00:21:15,819 --> 00:21:16,400
Speaker 0: you know discount.

292
00:21:16,480 --> 00:21:27,696
Speaker 1: You know what is that that idea scratches is something that every nerd was obsessed with back before computers you know had the idea of things like more than one core or more than one processor.

293
00:21:28,176 --> 00:21:30,720
Speaker 1: everybody wanted to make a Beowulf cluster of something.

294
00:21:31,421 --> 00:21:43,100
Speaker 0: Yep so this could also theoretically obviate the need for like the Samsung thing I talked about where it uses the TV where it incorporates the TV speaker because a flex connect TV would obviously just.

295
00:21:43,781 --> 00:21:53,300
Speaker 0: Play sound out of its speaker as part of the and always incorporate it right it would just every speaker it can find and make noise out of will be incorporated into the at most so.

296
00:21:55,081 --> 00:22:10,140
Speaker 0: Yeah I think maybe this is like a good sign like hey you know when if you need a new TV wait for flex connect to actually come out and get a flex connect TV and then you know that'll be good because like you know forward in time.

297
00:22:11,940 --> 00:22:15,745
Speaker 0: Whatever speakers you happen to own or whatever you know will always kind of work.

298
00:22:15,986 --> 00:22:17,868
Speaker 1: right now that my my my conundrum is one.

299
00:22:17,908 --> 00:22:26,560
Speaker 1: I'm looking at buying a TV now and I may wait because of this because the current TV has not died yet it's it's having some troubles but it has not died yet.

300
00:22:28,840 --> 00:22:34,334
Speaker 1: But I am vacillating on the audio side between a kind of a different problem or a different question.

301
00:22:35,036 --> 00:22:36,680
Speaker 1: do I want long term.

302
00:22:37,500 --> 00:22:47,100
Speaker 1: Hyper accurate audio to what the media intended or do I want to go the opposite direction like I used to do like listening to music in high school and.

303
00:22:47,701 --> 00:22:53,807
Speaker 1: Just fuck it all up and mix it to my own personal enjoyment regardless of what the creators intended.

304
00:22:54,187 --> 00:23:05,940
Speaker 1: for example maybe I just start boosting the mid range vocals and put compressors in my chains to compress everything down to make it more convenient to listen to and watch movies in my actual real life.

305
00:23:06,901 --> 00:23:08,202
Speaker 0: Yeah but I mean it depends.

306
00:23:08,263 --> 00:23:12,348
Speaker 0: right because certain you know different movies are going to that's you know we're going to need that.

307
00:23:12,648 --> 00:23:15,191
Speaker 0: some aren't right and also it's.

308
00:23:15,331 --> 00:23:22,600
Speaker 0: it's not so much about the how the the sound right the equalization or whatever you're going to do in that department but just the positioning.

309
00:23:22,700 --> 00:23:24,184
Speaker 0: Yeah right it's like you know.

310
00:23:24,204 --> 00:23:29,699
Speaker 0: do you want to hear a star destroyer actually fly over your head or are you OK with just.

311
00:23:31,301 --> 00:23:33,263
Speaker 0: Right because you're home and you're not at the movie theater?

312
00:23:33,283 --> 00:23:34,004
Speaker 0: who cares what?

313
00:23:34,025 --> 00:23:35,266
Speaker 1: it reminds me a total side thing.

314
00:23:35,306 --> 00:23:40,294
Speaker 1: I saw an article and I got to find it again because I want to see how much more there is.

315
00:23:40,494 --> 00:23:44,340
Speaker 1: an argument from a doctor that the current debate of.

316
00:23:45,421 --> 00:23:50,000
Speaker 1: Movies are mixed wrong and no one can hear the audio anymore has a complication.

317
00:23:51,341 --> 00:24:08,260
Speaker 1: People have damaged their hearing more it but we want the error we are in since when this complaint started to arise it happens to line up with a bunch of industry trends but the complaints are broad even in places where Hollywood has not penetrated in the same way.

318
00:24:09,081 --> 00:24:12,426
Speaker 1: So this doctor's argument was that what's actually happening?

319
00:24:12,846 --> 00:24:22,040
Speaker 1: this is the first generation that got old and lost their fucking hearing like everyone has for all of time and was online enough to complain about it.

320
00:24:23,260 --> 00:24:25,060
Speaker 1: That and is what this doctor's arguing.

321
00:24:28,168 --> 00:24:28,574
Speaker 1: And anyway.

322
00:24:31,041 --> 00:24:35,505
Speaker 1: I think it's time for things of the day.

323
00:24:35,905 --> 00:24:48,718
Speaker 1: so I'm back on my neutrino kick and cork kick and I'm increasingly watching ever increasingly mathematical videos about quantum physics and quantum theory.

324
00:24:49,038 --> 00:24:50,319
Speaker 1: but the video I want to link to is.

325
00:24:52,082 --> 00:24:53,064
Speaker 1: Just fantastic.

326
00:24:53,304 --> 00:25:01,580
Speaker 1: it's not long it's like 15 minutes long and what it does is it explains as simply as possible.

327
00:25:02,581 --> 00:25:12,419
Speaker 1: To the best of our current knowledge like 2023 what's the best we know about what the hell quantum theory means and what it is.

328
00:25:14,381 --> 00:25:15,442
Speaker 1: And it's just really well done.

329
00:25:15,482 --> 00:25:27,479
Speaker 1: it has this great diagram that kind of shows that everything we think of as a particle it's basically just like a field and each one of these fields is like one dimension of a wave in space and we're pretty sure that's what reality is.

330
00:25:29,721 --> 00:25:30,382
Speaker 1: Really good video.

331
00:25:30,642 --> 00:25:42,740
Speaker 1: it's not three blue one brown where it's gonna feel like you understand and then it shows an equation that you can't parse and then it's all down here from there and never gets to the point of showing you an equation that you will not understand.

332
00:25:45,460 --> 00:25:47,562
Speaker 0: Okay so you ever go to restaurant.

333
00:25:48,623 --> 00:25:53,467
Speaker 0: usually it's going to be like a Chinese restaurant jab you know East Asian restaurant but not always.

334
00:25:54,008 --> 00:26:04,497
Speaker 0: and there is you know food that is not edible is plastic food that is on display to show you what the meal looks like but it is made of plastic.

335
00:26:04,777 --> 00:26:08,380
Speaker 0: right but it looks like you know like that's what the food looks like.

336
00:26:09,020 --> 00:26:14,305
Speaker 0: Or pretty close to it other than maybe like a hint of shininess that lets you know it's plastic and not edible.

337
00:26:14,646 --> 00:26:19,911
Speaker 0: yeah I've seen those around quite a bit in my life and the question is where do those come from?

338
00:26:20,311 --> 00:26:24,976
Speaker 0: is there just like you know did someone make the food and then like cast it in wax?

339
00:26:25,036 --> 00:26:25,736
Speaker 0: did somebody?

340
00:26:26,017 --> 00:26:28,299
Speaker 0: is there a catalog of like fake food you can buy?

341
00:26:28,319 --> 00:26:29,660
Speaker 0: and right.

342
00:26:30,421 --> 00:26:38,649
Speaker 0: And the answer is there's people like this guy in this video who have been making fake plastic food for like fifty years.

343
00:26:38,709 --> 00:26:43,613
Speaker 0: he's like a craftsman an artisan and he makes fake food.

344
00:26:44,034 --> 00:26:48,538
Speaker 0: and in this video he makes fake food and he just he just comes right out of the gate.

345
00:26:48,578 --> 00:26:50,099
Speaker 0: he makes a lettuce like out of nothing.

346
00:26:50,180 --> 00:26:50,580
Speaker 0: it's like what.

347
00:26:52,281 --> 00:26:54,163
Speaker 0: It's like a wizard of making fake food.

348
00:26:54,623 --> 00:26:56,465
Speaker 0: if only making real food was so easy.

349
00:26:56,485 --> 00:26:58,327
Speaker 0: well I mean it's not easy.

350
00:26:58,367 --> 00:27:06,934
Speaker 0: the guys you know a highly talented skilled you know legend of the craft but you know this is this is just fascinating.

351
00:27:07,054 --> 00:27:09,897
Speaker 0: this video right it's like he just makes it with like this.

352
00:27:09,917 --> 00:27:13,680
Speaker 0: he's got some sort of chemical some sort of plastic thing where you put it in water.

353
00:27:14,161 --> 00:27:15,723
Speaker 0: And it starts to solidify.

354
00:27:15,783 --> 00:27:21,349
Speaker 0: but he can sort of you know mix it up and reshape it and mix the colors of it before that happens.

355
00:27:22,411 --> 00:27:29,940
Speaker 0: I wonder what that material is but it's pretty just you know even if I had the material I couldn't work with it like this guy right.

356
00:27:29,960 --> 00:27:31,983
Speaker 0: Just gets it perfect immediately.

357
00:27:32,003 --> 00:27:35,607
Speaker 0: right you can make any kind of food make you know ice creams or whatever.

358
00:27:35,627 --> 00:27:46,040
Speaker 1: this feels like the kind of thing where this person has one or more apprentices and people learn it by learning from someone who is good at it and not from an institution.

359
00:27:48,841 --> 00:28:00,100
Speaker 1: In the meta moment the geek nights book club book the murderbot diaries I have read 1.4 of the murderbot diaries and I expect to have read a lot of them by the time we get back from PAX because I have two six hour flights.

360
00:28:00,320 --> 00:28:00,781
Speaker 0: I've read.

361
00:28:00,801 --> 00:28:07,160
Speaker 0: I've read like four murderbot diaries for I think four maybe five I'm not sure.

362
00:28:07,600 --> 00:28:10,560
Speaker 1: I feel like around the first or second week of October.

363
00:28:10,740 --> 00:28:12,511
Speaker 0: I only have two left and I'm gonna get other.

364
00:28:12,551 --> 00:28:13,960
Speaker 0: I'm gonna get them from the library soon.

365
00:28:14,221 --> 00:28:18,300
Speaker 1: Which implies we're probably gonna have read all the murderbot diaries by the time we do this.

366
00:28:18,380 --> 00:28:21,680
Speaker 0: There's one that's coming out in November that so we're not if we haven't read all of them.

367
00:28:21,881 --> 00:28:26,660
Speaker 1: All the murderbot diaries that exist as of August 28, 2023.

368
00:28:26,660 --> 00:28:29,767
Speaker 0: You know what we could do since they're so easy to read and so fast.

369
00:28:29,827 --> 00:28:35,600
Speaker 0: we could just wait till the one comes out in November right read it and then do the episode in November.

370
00:28:35,960 --> 00:28:36,749
Speaker 1: We could do that.

371
00:28:37,093 --> 00:28:37,620
Speaker 1: target November.

372
00:28:37,700 --> 00:28:42,480
Speaker 0: Yeah and since it's so many books that gives people time because I think one of them is not a short one.

373
00:28:42,621 --> 00:28:44,000
Speaker 0: I think one of them is like an actual novel.

374
00:28:44,180 --> 00:28:49,240
Speaker 1: Well our friend Luke in the forum was complaining that starting with the fifth book they get really long.

375
00:28:50,081 --> 00:28:52,080
Speaker 0: That must be the fifth one that I'm about to read.

376
00:28:52,600 --> 00:28:54,746
Speaker 0: So let's do it.

377
00:28:54,846 --> 00:29:00,820
Speaker 0: let's just go to November and then we can have all of them read including the brand new one and we'll have a relevant book club episode.

378
00:29:01,121 --> 00:29:03,789
Speaker 1: Yeah so start reading the murderbot diaries.

379
00:29:03,870 --> 00:29:06,157
Speaker 1: So far I have enjoyed them.

380
00:29:06,197 --> 00:29:07,100
Speaker 1: There's a lot going on.

381
00:29:08,040 --> 00:29:14,240
Speaker 1: They're not the best books I've ever read and they're not exactly going to be mind-blowing if you are well versed in science fiction.

382
00:29:15,000 --> 00:29:17,732
Speaker 0: Spoiler it's one of those books where it's most.

383
00:29:17,792 --> 00:29:19,660
Speaker 0: it's not entirely about what happens.

384
00:29:19,880 --> 00:29:26,080
Speaker 0: It's mostly about what happens and it's it does have something to say but it's mostly what happens right.

385
00:29:26,803 --> 00:29:31,520
Speaker 0: But it's fun and the characters are likable and that's why.

386
00:29:31,880 --> 00:29:32,941
Speaker 0: I really like murderbot.

387
00:29:32,961 --> 00:29:48,136
Speaker 1: I just imagine murderbot as being this this in its in its own mind this gremlin like a gremlin like entity whose sole goal is to fuck around not have to do work watch TV play video games and the world keeps intruding.

388
00:29:48,216 --> 00:29:49,397
Speaker 1: and it's just like I guess.

389
00:29:49,697 --> 00:29:52,540
Speaker 1: but it actually does kind of care a little but it's shy.

390
00:29:54,301 --> 00:29:56,206
Speaker 1: Anyway I've read 1.4 of these books.

391
00:29:56,286 --> 00:29:56,868
Speaker 1: we'll see if it.

392
00:29:57,550 --> 00:30:00,719
Speaker 1: murderbot has increasing troubles as time goes on.

393
00:30:01,520 --> 00:30:03,059
Speaker 0: Also yes it yes it does.

394
00:30:04,121 --> 00:30:11,220
Speaker 1: We will not be doing a show on Thursday because we will be flying to Seattle for PAX West 2023.

395
00:30:11,220 --> 00:30:16,794
Speaker 1: We're doing an all new panel games you can't play on Sunday at 3 30 p.m.

396
00:30:17,235 --> 00:30:19,420
Speaker 1: in the blue morpho theater.

397
00:30:21,820 --> 00:30:34,840
Speaker 0: Otherwise the geek nights website is actually you're not gonna believe this it is like nearing completion not completion but like the point at which it does everything the current website does and it's better than the current website.

398
00:30:35,100 --> 00:30:45,440
Speaker 0: Therefore we can launch it and they continue to work on it which will be easier to do than working on the old website because it's actually using modern technologies and not ancient versions of everything.

399
00:30:45,440 --> 00:30:47,745
Speaker 1: I think the most important indicator that this is coming along.

400
00:30:47,826 --> 00:30:53,699
Speaker 1: we're at the point where I have to actually start doing my short task list of things that only I can do or that I can do it.

401
00:30:54,320 --> 00:31:00,348
Speaker 0: So what we're gonna do is we're gonna pick a day maybe in a couple weeks and we're gonna launch it on some server.

402
00:31:00,368 --> 00:31:08,560
Speaker 0: you can't get to listener right and then we're gonna hack away at it until it's correct and then we'll move the DNS entry and then it'll be live.

403
00:31:10,301 --> 00:31:17,251
Speaker 1: And so means I gotta do my full elevated adobe marker test to make sure that adobe didn't break anything.

404
00:31:17,552 --> 00:31:20,937
Speaker 0: if it that really is for me that the markers don't work they don't work right.

405
00:31:20,957 --> 00:31:22,900
Speaker 0: to work on that later it's not a necessary feature.

406
00:31:26,900 --> 00:31:30,543
Speaker 0: Also you know once it goes live I'm gonna make the.

407
00:31:30,743 --> 00:31:33,305
Speaker 0: there is a. you know the git repository open source.

408
00:31:33,826 --> 00:31:36,568
Speaker 0: so if you want to then for once it's live.

409
00:31:37,048 --> 00:31:40,611
Speaker 0: you can then help work on the website if you so desire.

410
00:31:40,631 --> 00:31:51,560
Speaker 0: there's a list of things that are not done that could be done like for example it doesn't currently automatically like post a new episode to discord right that's a feature that pretty easy to add.

411
00:31:52,281 --> 00:31:55,189
Speaker 0: It might take like a you know a couple hours of work but I haven't done it.

412
00:31:55,550 --> 00:31:57,695
Speaker 0: so you could.

413
00:31:57,715 --> 00:31:59,480
Speaker 0: you could do that so I don't have to if you want.

414
00:31:59,980 --> 00:32:02,779
Speaker 0: Send a full request and I may or may not reject it.

415
00:32:03,200 --> 00:32:08,827
Speaker 1: Not all help we need or would ask for or would be happy to receive is programming.

416
00:32:08,888 --> 00:32:18,180
Speaker 1: for example a while ago we crowd sourced our terms of service and community guidelines and there is stuff like that that you could help us with on the website as well.

417
00:32:18,560 --> 00:32:21,724
Speaker 1: So don't think that if you're not a programmer you can't help.

418
00:32:22,065 --> 00:32:34,660
Speaker 1: not that the programming is hard for this kind of thing but there's a lot of like text and like categorization and helping us with labels and things that you could actually for real help with.

419
00:32:35,281 --> 00:32:36,123
Speaker 0: Yeah we're going to start.

420
00:32:36,303 --> 00:32:43,280
Speaker 0: also you know another feature that's planned is to help clear out the 404s and dead links on news is things of the day etc.

421
00:32:43,840 --> 00:32:52,156
Speaker 1: Oh man I just randomly the other day I found an old episode of geek nights and I saw the name of the thing of the day and I was like what the fuck is that?

422
00:32:52,176 --> 00:32:54,420
Speaker 1: and of course it goes nowhere like it's dead.

423
00:32:57,704 --> 00:32:59,360
Speaker 0: You could listen to the episode and find out.

424
00:32:59,560 --> 00:33:01,160
Speaker 1: I could and we'll see.

425
00:33:01,501 --> 00:33:02,967
Speaker 0: That's what the listener would do.

426
00:33:03,028 --> 00:33:05,600
Speaker 0: is they would go and you know.

427
00:33:06,962 --> 00:33:10,609
Speaker 1: Yeah anyway let's get into the main bit.

428
00:33:10,929 --> 00:33:16,460
Speaker 1: so this was partly predicated by a news which we'll talk about as part of this but also.

429
00:33:16,740 --> 00:33:17,680
Speaker 0: Let's talk about that news first.

430
00:33:18,041 --> 00:33:19,144
Speaker 1: But this is a broader topic.

431
00:33:19,525 --> 00:33:24,860
Speaker 1: so Twitter which was kind of one of the more important social networks in history for a lot of reasons.

432
00:33:28,940 --> 00:33:34,469
Speaker 1: Notable and again this is a I'm not saying this is good I'm saying this is what happened situation.

433
00:33:34,810 --> 00:33:41,220
Speaker 1: Twitter of course has shat the bed and somehow has continued to shit the bed in increasing ways.

434
00:33:41,721 --> 00:33:49,400
Speaker 1: But this latest one isn't just annoying it is dangerous to a degree to the people still using Twitter.

435
00:33:50,540 --> 00:33:54,020
Speaker 1: Twitter is removing the ability to block other users.

436
00:33:55,421 --> 00:33:58,949
Speaker 1: Just full stop now there we could.

437
00:33:59,350 --> 00:34:03,640
Speaker 1: we don't need to address why they're doing it which comes down to the right wing.

438
00:34:04,741 --> 00:34:09,679
Speaker 1: People on Twitter who are angry at being blocked which is one of the main things driving Twitter.

439
00:34:10,360 --> 00:34:18,000
Speaker 1: Also advertisers and influencers who are obsessed with having their opinions are supposed to be seen.

440
00:34:18,520 --> 00:34:26,719
Speaker 1: A lot of bad people don't want you to be able to block people and blocking is a fundamental safety feature of any interactive platform in the world.

441
00:34:26,739 --> 00:34:27,199
Speaker 1: full stop.

442
00:34:27,962 --> 00:34:30,649
Speaker 0: So they are keeping muting right.

443
00:34:30,768 --> 00:34:35,080
Speaker 0: so let's talk about how it's implemented specifically on Twitter right.

444
00:34:35,679 --> 00:34:42,820
Speaker 0: And I'm not saying it's entirely right to get rid of blocking but it's not entirely wrong either because.

445
00:34:43,239 --> 00:34:48,100
Speaker 1: I do disagree with what you're about to say pretty strongly because you didn't use Twitter the way most people use it.

446
00:34:48,801 --> 00:34:57,520
Speaker 0: That's fine but blocking on Twitter right doesn't actually never even when it was there did not actually block anyone right.

447
00:34:57,720 --> 00:35:09,880
Speaker 0: If your account was unprotected meaning that your default tweets were completely public or if you had a protected account blocking is meaningless because no one can interact with you unless you allow them right so that that doesn't account.

448
00:35:10,421 --> 00:35:15,154
Speaker 0: So if you had an unprotected account someone who was blocked right they would not.

449
00:35:15,234 --> 00:35:17,360
Speaker 0: if they tried they couldn't follow you right.

450
00:35:17,880 --> 00:35:21,980
Speaker 0: And if they you know if you tweeted they wouldn't see your tweets.

451
00:35:22,360 --> 00:35:23,404
Speaker 1: They also couldn't search for you.

452
00:35:23,504 --> 00:35:23,765
Speaker 1: they could.

453
00:35:23,805 --> 00:35:26,435
Speaker 1: basically as long as they were logged in they could not see.

454
00:35:26,455 --> 00:35:27,700
Speaker 1: it was like you didn't exist anymore.

455
00:35:28,100 --> 00:35:30,594
Speaker 0: But they could log out and then see you.

456
00:35:30,855 --> 00:35:31,680
Speaker 0: so there's no point.

457
00:35:31,800 --> 00:35:35,227
Speaker 0: There is no reason to hide something that is public from someone right.

458
00:35:42,280 --> 00:35:46,526
Speaker 0: It's like yeah there's some Nazi right and it's like you know.

459
00:35:46,806 --> 00:35:49,129
Speaker 0: if they're they're harassing me right.

460
00:35:49,229 --> 00:35:55,738
Speaker 0: it's like okay if I want to prevent them from seeing my tweets but my tweets are still public and they can log out and see them.

461
00:35:55,778 --> 00:35:57,500
Speaker 0: why prevent them from seeing them when they're logged in.

462
00:35:57,580 --> 00:36:11,580
Speaker 1: Because as most people who were harassed especially minorities and targeted groups the main reason they use this is because yes it's not perfect but it introduced significant friction to harassers.

463
00:36:12,120 --> 00:36:14,725
Speaker 1: In that someone who wants to harass has it.

464
00:36:14,986 --> 00:36:22,200
Speaker 1: it's not as like an impulsive person a Nazi who just sees someone they don't like and wants to harass them and spout slurs at them or whatever.

465
00:36:22,561 --> 00:36:24,944
Speaker 1: You block them now they don't see you anymore.

466
00:36:25,345 --> 00:36:28,070
Speaker 1: they probably don't think about you much anymore.

467
00:36:28,150 --> 00:36:29,272
Speaker 1: they don't see your content.

468
00:36:29,472 --> 00:36:34,240
Speaker 1: you don't pop into their feeds especially because these communities were sharing block lists.

469
00:36:34,600 --> 00:36:46,657
Speaker 0: But if they wanted to harass you right it's like sure they can't tweet at you but they could write a tweet that's like the letter A the letter T space rim like hey my followers everyone tweet AT space RYM.

470
00:36:47,078 --> 00:36:48,680
Speaker 0: he's a person we want to harass.

471
00:36:48,700 --> 00:36:49,987
Speaker 0: It didn't actually protect you.

472
00:36:52,720 --> 00:36:57,000
Speaker 1: It did to a meaningful degree that friction really cut down on the amount of harassment.

473
00:36:57,240 --> 00:37:05,460
Speaker 0: What they should have done is implemented actual blocking right which is you know like there's no way it right.

474
00:37:06,300 --> 00:37:12,160
Speaker 1: I do disagree because that's infeasible and the blocking feature was extremely effective for marginalized groups.

475
00:37:12,240 --> 00:37:20,173
Speaker 1: You're really underestimating how powerful the blocking as it was was especially before muting.

476
00:37:20,494 --> 00:37:24,480
Speaker 0: the muting that they still have right effectively accomplishes the same.

477
00:37:24,640 --> 00:37:25,695
Speaker 1: No it absolutely does not.

478
00:37:26,700 --> 00:37:27,722
Speaker 0: Not how is it not?

479
00:37:27,902 --> 00:37:37,200
Speaker 1: because one the biggest preventing any tweet that that person makes you won't know because almost no one blocked people to not see the harassment coming at them.

480
00:37:37,280 --> 00:37:47,580
Speaker 1: The main reason targeted groups use the blocking feature was also to make sure that their tweets generally didn't penetrate as far into those bad spaces because these groups were sharing block lists.

481
00:37:48,220 --> 00:38:03,480
Speaker 1: And if someone's a harasser usually everyone who follows them was also on the same block list and that introduced a huge amount of very real and material friction to that community of shitheads even noticing that their targets were still active.

482
00:38:03,861 --> 00:38:12,796
Speaker 1: It materially reduced the harassment that they received not because they didn't see the messages but because you couldn't even just retweet.

483
00:38:12,877 --> 00:38:14,800
Speaker 1: if you want to retweet to direct hated someone.

484
00:38:15,200 --> 00:38:17,223
Speaker 1: You had to log out make a burner account.

485
00:38:17,264 --> 00:38:19,487
Speaker 1: you had to do all these extra steps that only you know.

486
00:38:19,507 --> 00:38:26,720
Speaker 0: you could just tweet on your account and just don't put the at symbol in front of the person's name and then tell all your followers hey everyone you know.

487
00:38:28,283 --> 00:38:32,640
Speaker 1: Most of those followers are usually also on the same block list because of the shared block list.

488
00:38:32,740 --> 00:38:35,119
Speaker 0: You could have a mute list and now you don't see any of the harassment.

489
00:38:35,240 --> 00:38:43,980
Speaker 1: No but the followers still see it and the harassers can still organize around doxing you pointing people at you so they come to your website and other things.

490
00:38:44,400 --> 00:38:45,960
Speaker 1: The blocking being too way was very effective.

491
00:38:45,960 --> 00:38:47,640
Speaker 0: They could do that even if they can't see your tweets.

492
00:38:48,020 --> 00:38:50,119
Speaker 0: Yes they could but they didn't.

493
00:38:50,440 --> 00:38:52,520
Speaker 0: It doesn't actually protect you from anything.

494
00:38:53,142 --> 00:38:56,713
Speaker 1: Scott go talk to any of the communities who use these features.

495
00:38:56,753 --> 00:38:58,940
Speaker 1: they will tell you they were very effective.

496
00:38:59,500 --> 00:39:08,240
Speaker 1: So I do not agree even remotely that muting and blocking are comparable in any way in terms of how people actually use Twitter.

497
00:39:09,881 --> 00:39:11,344
Speaker 0: I think the whole point right.

498
00:39:11,384 --> 00:39:19,560
Speaker 0: the fundamental issue here is that this argument we're having right highlights the core problem not just Twitter right.

499
00:39:19,900 --> 00:39:32,720
Speaker 0: But basically the whole internet the battle that we've been fighting on the internet one of the core battles of the internet since its inception or maybe even pre internet right which is that you are a person as a consumer of information right.

500
00:39:33,503 --> 00:39:36,020
Speaker 0: Everyone everyone in the whole world wears both hats right.

501
00:39:36,140 --> 00:39:46,160
Speaker 0: But as the consumer of information you only want to see what you want to see and you don't want to see anything that you don't want to see right.

502
00:39:46,940 --> 00:39:48,803
Speaker 0: It's like here are the things that I want to see.

503
00:39:48,883 --> 00:39:50,046
Speaker 0: I want to see tech news.

504
00:39:50,166 --> 00:39:51,388
Speaker 0: I want to listen to geek nights.

505
00:39:51,488 --> 00:39:56,437
Speaker 0: I want to know how the Mets are doing and I don't want to know anything else that I didn't ask for.

506
00:39:56,457 --> 00:39:58,000
Speaker 0: I don't want it right.

507
00:39:58,340 --> 00:40:00,780
Speaker 0: Harassers I don't want to see anything harassers are saying.

508
00:40:01,161 --> 00:40:04,354
Speaker 0: Ellen Musk don't want to see anything he's saying advertising some companies.

509
00:40:04,575 --> 00:40:05,940
Speaker 0: I don't want to see that right.

510
00:40:06,780 --> 00:40:15,752
Speaker 0: And then the other hat right which is I am a producer of information right or art or whatever right a journalist anyone.

511
00:40:15,852 --> 00:40:17,073
Speaker 0: I've created information.

512
00:40:17,093 --> 00:40:19,016
Speaker 0: I wrote something right I had.

513
00:40:19,056 --> 00:40:19,917
Speaker 0: I just had an idea.

514
00:40:19,977 --> 00:40:21,199
Speaker 0: randomly I farted.

515
00:40:21,279 --> 00:40:22,260
Speaker 0: I wanted to share my fart.

516
00:40:22,340 --> 00:40:25,144
Speaker 1: Now that person wants people to see on.

517
00:40:26,546 --> 00:40:31,093
Speaker 1: ethically that person may want to force people to see exactly.

518
00:40:31,113 --> 00:40:33,998
Speaker 0: you share the thing that you want to share with the world.

519
00:40:34,038 --> 00:40:35,580
Speaker 0: you put it out there right.

520
00:40:35,960 --> 00:40:41,167
Speaker 0: And the question is well there are people who are going to ask to see the thing that I shared.

521
00:40:41,227 --> 00:40:46,374
Speaker 0: the listener of geek nights right is like they are explicitly subscribing to geek nights.

522
00:40:46,775 --> 00:40:50,460
Speaker 0: they want geek nights so if I put out a geek nights they can see it.

523
00:40:51,040 --> 00:40:57,673
Speaker 0: But should someone who is not subscribed to geek nights should geek nights ever show up on their screen right now?

524
00:40:57,733 --> 00:40:58,113
Speaker 0: should there?

525
00:40:58,254 --> 00:41:01,159
Speaker 0: should it even be possible for that to happen?

526
00:41:01,560 --> 00:41:01,760
Speaker 0: right.

527
00:41:02,400 --> 00:41:10,451
Speaker 0: And it's like well if it's not then how would anyone ever find geek nights you if the only things that they would have to know about it already?

528
00:41:10,552 --> 00:41:16,179
Speaker 1: now that zooms out to an even bigger problem discoverability of why is finding geek nights.

529
00:41:18,281 --> 00:41:26,259
Speaker 1: Geek nights is the example that we're not making an argument about us here the listener already found us but geek nights.

530
00:41:27,680 --> 00:41:32,245
Speaker 1: Why would geek nights be so desperate to get people to see it?

531
00:41:32,726 --> 00:41:35,489
Speaker 1: mostly because capitalism capitalism.

532
00:41:35,829 --> 00:41:45,820
Speaker 1: most people who are making content and making things and having ideas and aggressively promoting on the internet are themselves hustling because they need people to see that or they will starve.

533
00:41:46,661 --> 00:41:54,546
Speaker 0: Right there are some people who are doing it for the money some for the fame some for both right right and it's like people just want to be seen.

534
00:41:55,026 --> 00:41:55,307
Speaker 0: right.

535
00:41:55,747 --> 00:42:06,014
Speaker 0: and it's like if you're blocking ads but then you're like also trying to get someone to see even if it's not an ad for a product or something you'll make money from.

536
00:42:06,054 --> 00:42:10,537
Speaker 0: but like you just really want your tweet to be seen by a lot of people.

537
00:42:10,577 --> 00:42:14,800
Speaker 0: you told a funny joke and you want a lot of people to laugh people who aren't following you right.

538
00:42:15,861 --> 00:42:17,943
Speaker 0: It's like well then you're that's.

539
00:42:18,123 --> 00:42:31,574
Speaker 1: you're still pushing information on people who didn't ask for it which right like I think most billboards should be banned like I think non-consensual information sharing is should be strictly regulated.

540
00:42:31,655 --> 00:42:37,960
Speaker 0: the ideal the ideal system is one in which you don't have blocking because everything is blocked.

541
00:42:38,220 --> 00:42:41,443
Speaker 0: Absolutely everything by default is equivalently blocked.

542
00:42:41,503 --> 00:42:44,226
Speaker 0: you only see what you ask to see.

543
00:42:44,286 --> 00:42:53,954
Speaker 0: so if you tweet into the wind or whatever you do activity pub into the wind right and a bunch of harassers see it and they you know pass it all around.

544
00:42:53,994 --> 00:43:00,240
Speaker 0: all the Nazis pass Scott's tweet around that says Nazis suck right and they're all sharing it amongst each other and hating on me.

545
00:43:00,840 --> 00:43:01,541
Speaker 0: I won't see that.

546
00:43:01,641 --> 00:43:02,642
Speaker 0: I won't even know what happened.

547
00:43:02,982 --> 00:43:09,147
Speaker 1: right you can be dangerous and there are instances of this where I mean it's no different than like writing in your journalist.

548
00:43:09,167 --> 00:43:10,528
Speaker 0: you write an article in the newspaper.

549
00:43:10,569 --> 00:43:13,291
Speaker 0: you have no idea who reads it or who's discussing it in the.

550
00:43:13,391 --> 00:43:16,153
Speaker 0: at the got it pinned up on the wall at the clan house.

551
00:43:16,513 --> 00:43:16,974
Speaker 0: you don't know.

552
00:43:17,474 --> 00:43:17,775
Speaker 0: it's like.

553
00:43:17,875 --> 00:43:18,875
Speaker 0: it's no different than that.

554
00:43:18,976 --> 00:43:24,300
Speaker 0: it's like you put information in the world and you do not know who is reading it what anyone's doing with it.

555
00:43:24,841 --> 00:43:28,929
Speaker 0: At all right you just tossed it out there and you don't know how many clicks it got.

556
00:43:28,949 --> 00:43:29,851
Speaker 0: you know how many views it got.

557
00:43:29,871 --> 00:43:31,354
Speaker 0: you don't know how many how famous you are.

558
00:43:31,374 --> 00:43:32,496
Speaker 0: you don't know how much money you made.

559
00:43:32,977 --> 00:43:33,618
Speaker 0: you don't know nothing.

560
00:43:33,738 --> 00:43:34,620
Speaker 0: you just putting it out.

561
00:43:34,780 --> 00:43:35,982
Speaker 1: And I think this is there are two.

562
00:43:36,082 --> 00:43:44,334
Speaker 1: I think the blocking to prevent someone else from interacting with your information is a separate but adjacent conversation.

563
00:43:44,374 --> 00:43:48,340
Speaker 1: to blocking to not see someone's content because exactly they are both.

564
00:43:48,400 --> 00:43:48,961
Speaker 0: The same word.

565
00:43:49,503 --> 00:43:52,831
Speaker 0: the same word is used for both things but they are completely different.

566
00:43:52,951 --> 00:43:53,412
Speaker 0: and around.

567
00:43:53,452 --> 00:43:56,380
Speaker 1: back out of the Twitter thing our disagreement just now.

568
00:43:57,880 --> 00:44:07,371
Speaker 1: Twitter achieved both with a moderate amount of success but some significant limitations and Twitter also was a very widely used platform.

569
00:44:08,011 --> 00:44:15,580
Speaker 1: so now we're in a situation where both sides of that equation just got gutted on what was one of the biggest social networks in the world.

570
00:44:15,901 --> 00:44:17,926
Speaker 0: No the only one side was gutted which is the.

571
00:44:18,246 --> 00:44:20,772
Speaker 0: you try to make it harder for people to see your stuff.

572
00:44:20,812 --> 00:44:22,777
Speaker 0: the you only see what you want to see.

573
00:44:22,877 --> 00:44:23,920
Speaker 0: stuff is still the same.

574
00:44:24,200 --> 00:44:31,800
Speaker 1: So according to this article mutes seem to not interface correct like you will still see things you didn't subscribe to.

575
00:44:33,181 --> 00:44:39,536
Speaker 0: That is a separate problem because Twitter right and all these newer social networks.

576
00:44:39,616 --> 00:44:41,420
Speaker 1: also there's a limit on how many accounts you can mute.

577
00:44:42,202 --> 00:44:43,847
Speaker 0: Well that's also my block list.

578
00:44:43,907 --> 00:44:46,154
Speaker 1: before Twitter shut down the API had more than 400,000 accounts on it.

579
00:44:48,180 --> 00:44:51,364
Speaker 0: Yeah that's a. that's a problem for sure right it should be infinity in fact right.

580
00:44:51,544 --> 00:45:00,535
Speaker 0: but anyway the all of these things have their sort of algorithmic feeds YouTube's recommendations Twitter's.

581
00:45:00,875 --> 00:45:04,860
Speaker 0: you know the all any right all those sort of feeds you know.

582
00:45:06,370 --> 00:45:07,691
Speaker 0: All that shit right.

583
00:45:08,111 --> 00:45:10,572
Speaker 0: that is not just the reverse.

584
00:45:10,592 --> 00:45:24,239
Speaker 0: chronological order list of things you follow is fundamentally you are seeing things that someone else wants you to see and not something you asked for and that is the core problem.

585
00:45:24,519 --> 00:45:26,340
Speaker 0: anything like that should just get the fuck out.

586
00:45:26,740 --> 00:45:29,823
Speaker 1: YouTube go to youtube.com.

587
00:45:29,904 --> 00:45:32,847
Speaker 0: such a thing because Twitter has such a thing.

588
00:45:32,867 --> 00:45:35,409
Speaker 0: that is why mute fails.

589
00:45:35,689 --> 00:45:36,210
Speaker 0: right?

590
00:45:36,250 --> 00:45:41,315
Speaker 0: if they didn't have that mute would be perfect because that were a secondary experience.

591
00:45:41,375 --> 00:45:45,880
Speaker 1: if the default experience was here's what you subscribe to and like Twitter used to be.

592
00:45:46,460 --> 00:45:57,033
Speaker 0: And if there is some other feed of other things that I'm not following I at least have to click on it which means I have asked to see the things that I don't follow.

593
00:45:57,093 --> 00:46:03,140
Speaker 0: it should never be the default screen because then I am seeing things I do not follow without asking for it.

594
00:46:04,741 --> 00:46:12,954
Speaker 0: You can have all those things as long as they're a click away or a command away or somewhere else other than a pay a place.

595
00:46:12,994 --> 00:46:15,659
Speaker 0: you cannot avoid looking like the default homepage.

596
00:46:15,699 --> 00:46:16,440
Speaker 0: that can't be changed.

597
00:46:17,302 --> 00:46:21,793
Speaker 0: They're perfectly fine to exist but it should never be unavoidable.

598
00:46:21,974 --> 00:46:22,896
Speaker 0: it should always be.

599
00:46:22,916 --> 00:46:24,320
Speaker 0: I asked to see this.

600
00:46:24,860 --> 00:46:26,141
Speaker 1: What do you propose?

601
00:46:26,181 --> 00:46:37,409
Speaker 1: this angers capital because it does remember and I know we talk about this a lot but you really really have to understand that this is like the fundamental crisis of the entire Internet.

602
00:46:37,809 --> 00:46:40,331
Speaker 1: the whole fucking thing is propped up on advertising.

603
00:46:40,651 --> 00:46:48,356
Speaker 1: even if we ignore the fact that most of American society is propped up on advertising the Internet is like more propped up on advertising.

604
00:46:48,696 --> 00:46:49,517
Speaker 1: no fucking webs.

605
00:46:50,077 --> 00:46:54,080
Speaker 1: if there were no ads tomorrow the Internet would go back to what it was like.

606
00:46:54,440 --> 00:47:01,454
Speaker 1: Before it was commercialized there's a few hundred websites and wealthy white people have made all of them with whatever they wanted.

607
00:47:01,775 --> 00:47:02,917
Speaker 1: gig nights would keep going.

608
00:47:03,218 --> 00:47:04,400
Speaker 1: there wouldn't be any other podcast.

609
00:47:05,740 --> 00:47:13,239
Speaker 0: Yep I mean it's like if you put up some e-commerce right on an Internet where people only saw what they asked to see.

610
00:47:15,101 --> 00:47:21,311
Speaker 0: The only way anyone to find your e-commerce is if they already knew you somehow right.

611
00:47:21,551 --> 00:47:25,537
Speaker 0: they found your business in the real world or something or you know.

612
00:47:25,898 --> 00:47:27,400
Speaker 0: it's like how right it's.

613
00:47:28,201 --> 00:47:34,166
Speaker 1: How do you and I as a case study want to find out about things we wouldn't otherwise know about?

614
00:47:34,326 --> 00:47:34,466
Speaker 1: one?

615
00:47:35,046 --> 00:47:36,027
Speaker 1: I read a bunch.

616
00:47:36,167 --> 00:47:41,512
Speaker 1: I go to specific websites that aggregate and curate news and areas I care about.

617
00:47:41,812 --> 00:47:43,013
Speaker 1: that's Paul I'm choosing.

618
00:47:43,533 --> 00:47:47,877
Speaker 1: I read The Verge because I want to know about some of the kinds of things The Verge has.

619
00:47:47,937 --> 00:47:48,618
Speaker 1: it's not perfect.

620
00:47:49,058 --> 00:47:51,460
Speaker 1: I would like a more curated feed but it's not that bad.

621
00:47:52,141 --> 00:48:01,212
Speaker 1: I used to follow a bunch of people on Twitter partly because they were the people who would tell me about things I wouldn't have thought to look for and I trust their opinion.

622
00:48:01,252 --> 00:48:02,193
Speaker 1: but again I chose.

623
00:48:02,734 --> 00:48:07,240
Speaker 1: I want to hear what Mike tool has to say because he'll tell me about an anime would have otherwise not found out about.

624
00:48:08,023 --> 00:48:11,380
Speaker 0: I listen to somebody else already follow.

625
00:48:12,621 --> 00:48:21,277
Speaker 0: For explicitly right some other source of information you do know and there is some path through that to the thing that you don't follow.

626
00:48:21,357 --> 00:48:22,560
Speaker 1: and for products you know what I do.

627
00:48:23,680 --> 00:48:29,996
Speaker 1: I don't look for products to buy unless I've decided I need to buy something to solve X problem.

628
00:48:30,256 --> 00:48:31,580
Speaker 1: and then I do research.

629
00:48:32,781 --> 00:48:38,030
Speaker 0: Yeah but the research is using a search engine and the search engine is you know.

630
00:48:38,330 --> 00:48:43,680
Speaker 0: yes you're in some sense asking but in the other sense the SEO is determining what you see and what you don't see.

631
00:48:43,920 --> 00:48:47,208
Speaker 1: Let's see I'm going to type something to YouTube right now because I'm extra annoyed about this.

632
00:48:47,228 --> 00:48:48,271
Speaker 1: let's see I'm going to type.

633
00:48:48,612 --> 00:48:50,176
Speaker 1: I don't know minotaur.

634
00:48:50,196 --> 00:48:51,840
Speaker 1: I just picked a random word.

635
00:48:53,060 --> 00:48:54,240
Speaker 0: Wikipedia page for minotaur.

636
00:48:54,500 --> 00:48:55,540
Speaker 1: So what does YouTube return?

637
00:48:56,142 --> 00:48:57,520
Speaker 0: D&D monster page for minotaur.

638
00:48:57,680 --> 00:49:08,320
Speaker 1: So YouTube returns a random curated set of videos that include the word minotaur in the title and then after one two three four five six seven eight nine ten results.

639
00:49:09,180 --> 00:49:15,429
Speaker 1: Now it says people also watched in the tiniest font and it if you scroll by it looks like it's more search results.

640
00:49:15,770 --> 00:49:16,651
Speaker 1: but it's not.

641
00:49:17,052 --> 00:49:22,440
Speaker 1: it's showing me what other people who watch some of the videos from the search.

642
00:49:23,460 --> 00:49:37,700
Speaker 1: Themselves watched not things that matched that search and then it shows me a bunch of shorts and the more I scroll down it's just a chum bucket of garbage until eventually I hit for you and you know what that's showing me?

643
00:49:38,400 --> 00:49:39,944
Speaker 1: Literally a bunch of videos I've already watched.

644
00:49:41,688 --> 00:49:42,350
Speaker 1: Fantastic.

645
00:49:44,796 --> 00:49:46,419
Speaker 1: Thank you Google for being a terrible search.

646
00:49:47,381 --> 00:49:47,922
Speaker 0: So yeah there's.

647
00:49:48,342 --> 00:49:49,664
Speaker 0: the war is again.

648
00:49:50,224 --> 00:49:51,206
Speaker 0: you only want to see what.

649
00:49:51,246 --> 00:49:57,814
Speaker 0: you want to see people what you also as a producer want people to see your shit even if they didn't ask for it.

650
00:49:57,914 --> 00:50:02,600
Speaker 0: and then vice versa you don't want to see shit people trying to push on you and alright.

651
00:50:02,880 --> 00:50:08,799
Speaker 1: So on YouTube why can't I block an account if I see an account and a video is recommended to me.

652
00:50:09,721 --> 00:50:10,161
Speaker 0: And why?

653
00:50:10,241 --> 00:50:11,403
Speaker 0: no that's not the question.

654
00:50:11,443 --> 00:50:16,469
Speaker 0: the question is why did not every single account start blocked?

655
00:50:16,589 --> 00:50:24,998
Speaker 0: everything should be blocked by default and instead you should be turning things on right not turning things off and by default.

656
00:50:25,039 --> 00:50:26,320
Speaker 0: you see the world right.

657
00:50:27,001 --> 00:50:31,426
Speaker 0: Twitter originally the original Twitter was effectively an IRC chat room.

658
00:50:31,626 --> 00:50:37,333
Speaker 0: right effectively or you could only put short messages but it IRC chat room but everyone was.

659
00:50:37,493 --> 00:50:41,218
Speaker 0: you go in the chat room and you see all the names but everyone is muted.

660
00:50:41,278 --> 00:50:41,779
Speaker 0: by default.

661
00:50:41,799 --> 00:50:42,840
Speaker 0: you don't see any chats.

662
00:50:42,960 --> 00:50:46,300
Speaker 1: And you pick the set of people you want to see and everyone picks a different set.

663
00:50:46,360 --> 00:50:51,660
Speaker 0: You unmute people right and then you see only the things they're saying and everyone else is shut the fuck up.

664
00:50:51,660 --> 00:50:53,214
Speaker 1: That was the only good thing Twitter ever did.

665
00:50:53,315 --> 00:50:53,879
Speaker 1: the first thing.

666
00:50:54,420 --> 00:50:57,828
Speaker 0: Right that was the original Twitter and that's that is the model.

667
00:50:57,848 --> 00:50:58,830
Speaker 0: that's the correct model.

668
00:50:58,870 --> 00:51:00,394
Speaker 0: the whole internet should be like that.

669
00:51:00,735 --> 00:51:03,040
Speaker 0: you only see what you want to see right.

670
00:51:03,200 --> 00:51:10,640
Speaker 0: When you go to Google you start googling and it should be like you don't see anything and then you pick domains that you want to search right.

671
00:51:10,840 --> 00:51:10,980
Speaker 0: Like.

672
00:51:11,081 --> 00:51:11,621
Speaker 0: I only want to.

673
00:51:11,741 --> 00:51:12,002
Speaker 0: you know.

674
00:51:12,162 --> 00:51:12,662
Speaker 0: you know.

675
00:51:12,723 --> 00:51:26,860
Speaker 0: right now you can do it with like the site command right like imagine if you use Google and you only had certain domains that you trusted and liked and newer bullshit and only search those domains and every other domain you never saw results from.

676
00:51:27,920 --> 00:51:28,902
Speaker 0: It's like you block.

677
00:51:28,942 --> 00:51:36,698
Speaker 0: you shouldn't be block having to block because block should be the default in terms of what you see now in terms of what you send out into the world.

678
00:51:36,719 --> 00:51:36,819
Speaker 0: right.

679
00:51:37,960 --> 00:51:40,685
Speaker 0: Me and rim have a difference of opinion but I believe right.

680
00:51:40,946 --> 00:51:41,246
Speaker 0: if you're.

681
00:51:41,727 --> 00:51:47,218
Speaker 0: if you're choosing to send something to a private group or individual that's private messaging.

682
00:51:47,258 --> 00:51:48,000
Speaker 0: that's already right.

683
00:51:48,781 --> 00:51:55,730
Speaker 0: But if you are sending something out into the world publicly you have to just accept the fact that you have made that information public.

684
00:51:56,211 --> 00:52:02,620
Speaker 0: and it is this trying to prevent some people in the world from seeing it but having most of the world see it.

685
00:52:02,880 --> 00:52:03,461
Speaker 1: Well that's the thing.

686
00:52:03,621 --> 00:52:06,204
Speaker 1: it doesn't actually prevent people from seeing it.

687
00:52:06,565 --> 00:52:08,748
Speaker 1: it introduces friction within that platform.

688
00:52:08,788 --> 00:52:17,560
Speaker 1: and that's the value that if there is a widely used platform then introducing friction to bad actors who would try to engage with you.

689
00:52:17,720 --> 00:52:19,939
Speaker 0: I mean the bad actors shouldn't be there in the first place.

690
00:52:20,601 --> 00:52:22,720
Speaker 1: Yes but they're there and the tool was effective.

691
00:52:24,161 --> 00:52:31,340
Speaker 0: Secondly if the bad actors can't message you then you know because the other patch is correct.

692
00:52:31,340 --> 00:52:32,542
Speaker 1: It's not just that they can't message you.

693
00:52:32,582 --> 00:52:33,403
Speaker 1: I'll give you an example.

694
00:52:33,463 --> 00:52:44,120
Speaker 1: there was that the series of studies showing that individual entities on a platform like Twitter or YouTube will always randomly be selected to be extremely popular.

695
00:52:44,461 --> 00:52:56,040
Speaker 1: If you make a fake Twitter with a bunch of pseudo ML mechanisms that all randomly retweet things over time certain random messages and random accounts just become the most widely followed and widely used like that.

696
00:52:56,540 --> 00:53:01,520
Speaker 1: That happens as a consequence of the ability to be able to share and reshare content just in general.

697
00:53:02,540 --> 00:53:04,107
Speaker 0: So just don't do that.

698
00:53:04,409 --> 00:53:06,820
Speaker 0: but if everyone's blocked by default will that happen?

699
00:53:07,522 --> 00:53:14,080
Speaker 1: But if everyone's blocked by default then I can still subscribe to anyone and retweet to my people.

700
00:53:14,660 --> 00:53:15,579
Speaker 1: Reshare to my people.

701
00:53:17,703 --> 00:53:20,773
Speaker 0: Talking about retweet I think it's a design failure.

702
00:53:20,854 --> 00:53:22,700
Speaker 0: it shouldn't be so simple to retweet.

703
00:53:23,460 --> 00:53:27,760
Speaker 1: But at the same time that was the feature I used on Twitter the most.

704
00:53:28,561 --> 00:53:31,039
Speaker 0: Regardless that's a separate topic but the point is.

705
00:53:31,200 --> 00:53:35,327
Speaker 1: But I'm saying if you have a platform the friction of making it.

706
00:53:35,687 --> 00:53:43,180
Speaker 1: if I block you on a platform then it introduces friction of you not just interacting with me.

707
00:53:43,900 --> 00:53:48,910
Speaker 1: But also resharing and like interacting with my content within that platform.

708
00:53:49,190 --> 00:53:53,940
Speaker 1: meaning if you are a bad actor who wants to take the extra step to harass beyond the block.

709
00:53:54,601 --> 00:54:05,280
Speaker 1: Now you have to do things outside of what the platform directly supports which introduces the ability to have you to easily block or ban you or bring legal consequences to you or prove.

710
00:54:05,400 --> 00:54:08,586
Speaker 0: I mean they could just log out see your tweet copy it paste.

711
00:54:08,606 --> 00:54:09,588
Speaker 1: yes they can push.

712
00:54:09,628 --> 00:54:10,049
Speaker 0: that's a.

713
00:54:10,109 --> 00:54:14,117
Speaker 1: that's a far cry for most people to go through that much effort.

714
00:54:14,177 --> 00:54:15,880
Speaker 1: that's why that feature was right effective.

715
00:54:16,121 --> 00:54:17,263
Speaker 0: And I think that it's not.

716
00:54:17,383 --> 00:54:19,408
Speaker 0: I don't think that the block is the right answer.

717
00:54:19,448 --> 00:54:24,600
Speaker 0: I think the right answer is there shouldn't be such a low friction to retweet in the first place.

718
00:54:24,800 --> 00:54:25,000
Speaker 0: It should.

719
00:54:25,141 --> 00:54:33,140
Speaker 0: everyone who wants to retweet should have to explicitly when you're putting things out into the world right that the whole world is going to see.

720
00:54:33,601 --> 00:54:38,380
Speaker 1: I want everyone who follows me to see everything I say if they want which includes retweets.

721
00:54:38,761 --> 00:54:40,826
Speaker 0: If they want that's that's fine right.

722
00:54:41,106 --> 00:54:46,980
Speaker 0: but the point is is that if you are going to publish or republish something right on any platform.

723
00:54:47,621 --> 00:54:51,468
Speaker 0: That is you know and knowing that the whole world will see a public thing right.

724
00:54:52,129 --> 00:54:53,432
Speaker 0: that should never be.

725
00:54:53,572 --> 00:54:57,400
Speaker 0: it's a bad design to have that be a low friction action.

726
00:54:58,082 --> 00:55:00,108
Speaker 0: It should because you're you're doing something serious.

727
00:55:00,168 --> 00:55:01,452
Speaker 0: right you are publishing right.

728
00:55:01,512 --> 00:55:04,160
Speaker 0: publishing should always be a big action like post.

729
00:55:04,960 --> 00:55:07,183
Speaker 0: And therefore that shouldn't be so simple.

730
00:55:07,203 --> 00:55:17,898
Speaker 0: with like one click to completely take a huge thing or someone else's post and completely repost it you should have to copy it paste it look at it see where I disagree.

731
00:55:17,938 --> 00:55:18,900
Speaker 1: there is that.

732
00:55:19,940 --> 00:55:27,880
Speaker 1: Society has shown that low friction is what people want and that is what built a lot of very positive spaces and positive communities as well.

733
00:55:28,400 --> 00:55:28,861
Speaker 0: It can build.

734
00:55:28,961 --> 00:55:30,225
Speaker 0: it can go both ways.

735
00:55:30,365 --> 00:55:35,418
Speaker 0: right you know a fast road gets you where you're going faster and it also kills people right.

736
00:55:35,478 --> 00:55:36,260
Speaker 1: that's why I'm saying.

737
00:55:36,940 --> 00:55:38,443
Speaker 0: I think we would all be better off.

738
00:55:38,623 --> 00:55:47,000
Speaker 0: in general though with a slow road right you get where you're going still and less people die even though we don't have the fast trips.

739
00:55:47,361 --> 00:55:48,383
Speaker 1: But that's where I'm saying.

740
00:55:48,403 --> 00:55:54,840
Speaker 1: in a world where the reality is almost all people want the ability to have rapidly reshare and that's not going to go away.

741
00:55:55,520 --> 00:55:57,547
Speaker 0: Do they want or do they not want?

742
00:55:57,607 --> 00:56:01,100
Speaker 0: right it's like it's one of those things where it's like when people have this.

743
00:56:01,300 --> 00:56:04,306
Speaker 1: I think they want it partly because Twitter and platforms like it.

744
00:56:04,767 --> 00:56:11,020
Speaker 1: this was not a primary feature and retweets didn't even work that well and they rapidly became the most used thing without being pushed.

745
00:56:11,100 --> 00:56:14,007
Speaker 0: They were they were very used but that was first of all.

746
00:56:14,427 --> 00:56:20,080
Speaker 0: they want the people designing the system designed it to make people use that on purpose right.

747
00:56:21,000 --> 00:56:22,663
Speaker 0: And it was so.

748
00:56:22,703 --> 00:56:26,411
Speaker 0: it's like when it's there right it's like yes people ate it.

749
00:56:26,471 --> 00:56:30,880
Speaker 0: it's like yes when I put the mouse in the box with the cheese the mouse ate the cheese.

750
00:56:31,040 --> 00:56:32,163
Speaker 0: Take any group of nerds.

751
00:56:32,463 --> 00:56:40,400
Speaker 1: put them in a room with a computer and nine times out of ten they all have five YouTube videos they each want to show to everyone else there.

752
00:56:40,900 --> 00:56:43,368
Speaker 1: And there's the big fight about who puts on which video.

753
00:56:43,629 --> 00:56:46,980
Speaker 1: like every nerd group always has this exact same dynamic.

754
00:56:47,240 --> 00:56:49,386
Speaker 0: Yes people have a desire to share things.

755
00:56:49,426 --> 00:56:51,070
Speaker 0: that is without a doubt right.

756
00:56:51,111 --> 00:56:52,274
Speaker 0: Ivan I have that desire right.

757
00:56:52,294 --> 00:56:52,715
Speaker 0: what are we doing?

758
00:56:52,735 --> 00:56:53,617
Speaker 0: things of the day on here?

759
00:56:53,658 --> 00:56:54,520
Speaker 0: for no reason right.

760
00:56:54,881 --> 00:56:56,603
Speaker 0: Come on everyone has things.

761
00:56:56,623 --> 00:57:00,249
Speaker 0: when they see a cool thing you want to tell your friends about the.

762
00:57:00,329 --> 00:57:02,353
Speaker 1: I'm saying I don't think the friction is a problem.

763
00:57:02,393 --> 00:57:06,800
Speaker 1: I think that there's other societal problem but I make the lack of friction on resharing.

764
00:57:07,060 --> 00:57:11,329
Speaker 0: I think we would be better off if the re sharing action right.

765
00:57:11,389 --> 00:57:17,020
Speaker 0: if you're you know everyone everyone has a lot of sees cool things all the time that they want to share with everyone right.

766
00:57:17,461 --> 00:57:25,791
Speaker 0: If everyone just shared everything then it's like you know it's just wait it's too much it's too noisy and a lot of low quality stuff gets through.

767
00:57:25,951 --> 00:57:33,100
Speaker 0: if we added a little friction to that process on all platforms right to where it's like oh you want to share that cool YouTube video with everyone.

768
00:57:36,301 --> 00:57:40,289
Speaker 0: Then that would raise the bar a little bit raise the quality a little.

769
00:57:40,330 --> 00:57:43,095
Speaker 1: I have an alternative but complimentary argument.

770
00:57:43,456 --> 00:57:45,340
Speaker 1: that the only reason.

771
00:57:46,961 --> 00:57:57,995
Speaker 1: The bar is so low and what you call qualitatively low quality content is indeed qualitatively yes I am also similarly ice.

772
00:57:58,176 --> 00:57:59,678
Speaker 1: I have the same quality judgment.

773
00:57:59,718 --> 00:58:00,158
Speaker 1: is you like?

774
00:58:00,198 --> 00:58:01,400
Speaker 1: don't think that I'm okay.

775
00:58:01,580 --> 00:58:03,283
Speaker 0: Okay I'm just saying I'm just.

776
00:58:03,343 --> 00:58:10,014
Speaker 1: I'm noting that there's someone out there who earnestly likes that bottom tier content like there's.

777
00:58:10,054 --> 00:58:13,380
Speaker 0: yeah I mean it wouldn't be you know but that person is going to be following people.

778
00:58:14,000 --> 00:58:21,073
Speaker 0: Right who are more like them and with the higher bar are going to see more of that stuff we think is bottom tier that they love a little bit.

779
00:58:21,173 --> 00:58:22,315
Speaker 0: I'm saying the only reason.

780
00:58:25,701 --> 00:58:33,819
Speaker 1: Almost any of that low tier content exists in the first place is because of the extreme pressures of capitalism in the at all.

781
00:58:34,682 --> 00:58:37,720
Speaker 0: Could be depends on depends on which content exactly you're talking about.

782
00:58:38,160 --> 00:58:39,964
Speaker 1: All of it there are exceptions.

783
00:58:40,225 --> 00:58:42,891
Speaker 1: one exception I can think of is fascist indoctrination.

784
00:58:43,172 --> 00:58:46,280
Speaker 1: that is not directly profit motive that is evil motive.

785
00:58:47,101 --> 00:58:58,356
Speaker 0: It's true yes without the profit motive, a lot of people out there who are making content, you know, a lot of variety, the people who say like and subscribe would not be making it right unlike the geek nights.

786
00:58:58,416 --> 00:59:01,740
Speaker 0: that makes it even if there's one listener doesn't put ads right.

787
00:59:02,301 --> 00:59:16,160
Speaker 1: I'm saying on a given week, instead of 400,000 Minecraft videos that I have a high production value and let's just say qualitatively to low quality content, there would be an order of magnitude fewer.

788
00:59:16,880 --> 00:59:25,780
Speaker 1: And if you look at the old internet before anyone even realized the internet could be commercialized every website was just kind of great and just had the content you wanted.

789
00:59:26,962 --> 00:59:39,300
Speaker 0: That is the thing is I think that without the ability to make people see your thing and to chase view counts or anything I think that is a motivator for a lot of people to post and create in the first place.

790
00:59:39,860 --> 00:59:41,114
Speaker 0: I think the primary motivator.

791
00:59:44,045 --> 00:59:46,300
Speaker 0: It is the primary motivator for that kind of person.

792
00:59:46,940 --> 00:59:53,535
Speaker 1: But I think that is only the primary motivator for so many people because that is capitalism.

793
00:59:53,595 --> 00:59:55,379
Speaker 1: like everyone's got their hustle.

794
00:59:56,300 --> 01:00:00,940
Speaker 0: Capitalism is a part of it but there are some people who just want to be famous regardless of the money.

795
01:00:04,083 --> 01:00:08,700
Speaker 0: If we took that away a lot of people would simply stop creating, stop sharing.

796
01:00:08,840 --> 01:00:14,860
Speaker 0: The only people who would create and share were the people who are doing it like we are because for other reasons.

797
01:00:17,102 --> 01:00:22,240
Speaker 0: And I think that would be a better internet but it would be a quieter internet but it would be a safer internet I think.

798
01:00:22,500 --> 01:00:38,260
Speaker 1: It absolutely would and we have to solve this real quick as a society and culture because large language models are going to generate a literal infinite sea of garbage content.

799
01:00:38,760 --> 01:00:42,700
Speaker 1: And that is why you will never be able to find anything good again in that sea.

800
01:00:43,080 --> 01:00:46,800
Speaker 1: It is going to be like the cork foam that I just learned about from one of those Arvin Ash videos.

801
01:00:47,741 --> 01:00:52,760
Speaker 0: So we agree that blocking what's coming in, you should only see what you want to see.

802
01:00:53,261 --> 01:00:55,220
Speaker 0: And we disagree what's going out.

803
01:00:55,420 --> 01:01:03,120
Speaker 0: I think if you're willing to send something out that there should be a little bit of friction ideally because it's not a small action that you're taking.

804
01:01:03,280 --> 01:01:05,960
Speaker 0: It's a serious action, you should think about it for at least a second.

805
01:01:06,520 --> 01:01:13,020
Speaker 0: And also that you have to accept the fact that you're putting it out into the whole world, Nazis are going to see it.

806
01:01:13,261 --> 01:01:19,160
Speaker 0: Even though if we at least get the first part right you won't ever hear the Nazis coming back to you and you disagree.

807
01:01:20,401 --> 01:01:22,000
Speaker 1: Here's an idea there, a specific one.

808
01:01:22,260 --> 01:01:29,980
Speaker 1: Let's say we solve the depredations of capitalism problem so now it's more Nazis versus literally everyone else in terms of posting.

809
01:01:31,821 --> 01:01:34,519
Speaker 1: Which wouldn't be that far off from that when we get to that point.

810
01:01:35,961 --> 01:01:44,740
Speaker 1: So say we're in that environment, then arguably blocking features within platforms for the publishing if the barrier to resharing is low.

811
01:01:45,280 --> 01:01:54,460
Speaker 1: And the barrier to resharing being low would likely plausibly be a benefit to society because we've removed all this low tier content that was being generated by capitalism.

812
01:01:55,620 --> 01:02:00,080
Speaker 1: Then, now already I realize I have so many caveats that this is such a narrow point.

813
01:02:00,983 --> 01:02:06,100
Speaker 1: Then the blocking features are a very specific ratchet style tool.

814
01:02:06,920 --> 01:02:18,960
Speaker 1: They, in aggregate, decrease the friction of people interacting with my content by default, but increase the friction of people I don't want to interact with my content.

815
01:02:19,400 --> 01:02:23,680
Speaker 1: But it's not necessarily blocking more, it's almost like limiting, it's not muting either.

816
01:02:24,141 --> 01:02:33,560
Speaker 1: It basically means everyone can reshare my content, but specific motherfuckers who have crossed me in some way have more friction to do the same.

817
01:02:34,060 --> 01:02:43,760
Speaker 1: And in a large long term system, that would lead to, over time, what I see as bad or what society sees as bad actors being more limited.

818
01:02:45,560 --> 01:02:50,800
Speaker 1: But, to your point, that isn't really blocking as it is used today by most people.

819
01:02:51,120 --> 01:03:09,440
Speaker 0: If we get the first part right, where you only see what you want to see, then it's like, no matter how much Nazis reshare amongst themselves my anti-Nazi screed, I'll never hear from them, you'll never hear from them, we'll never know that that's going on, and they will be cut off from society because no one will see their Nazi conversation other than themselves.

820
01:03:09,660 --> 01:03:12,780
Speaker 0: They'll be in their own little bubble, which is effectively what they are anyway.

821
01:03:12,940 --> 01:03:17,780
Speaker 1: So do we just have another episode of Geek Nights where the moral of how to solve a problem is we have to destroy capitalism?

822
01:03:18,562 --> 01:03:32,578
Speaker 0: I mean, we already know that, but the point is, we disagree on the "block what you post" part, we agree on the "block what you're reading" part, and I'm, you know, working on building exactly something, right?

823
01:03:33,880 --> 01:03:47,560
Speaker 0: I'm basically being an activity pub server that follows the philosophy that I've just espoused, right, where when you post something, it's out to the world to deal with it, but the only things you ever see are the things you ask to see and nothing else, the end.

824
01:03:49,104 --> 01:03:50,599
Speaker 0: And we'll see if that actually works or not.

825
01:03:51,901 --> 01:03:57,078
Speaker 1: And in the interim, like, if you're using Twitter and these block features go away...

826
01:03:58,066 --> 01:03:58,900
Speaker 0: Twitter is done, I think.

827
01:03:59,000 --> 01:04:15,140
Speaker 1: But if you're still using it, be ready for the fact that if blocking goes away, because that platform is designed the way it is, it could become specifically more dangerous to you, especially if you are a group, like, typically targeted.

828
01:04:15,481 --> 01:04:20,220
Speaker 0: Well, I think because the information I didn't know of the mute being limited, right?

829
01:04:20,660 --> 01:04:33,820
Speaker 0: You could eventually, you could basically run into a situation where, you know, you've muted all the bad people and then there's more mad people and you can't mute them, and now the bad people can tweet at you and you're gonna see it, you're gonna see something you didn't ask to see, and now it's unsafe.

830
01:04:33,840 --> 01:04:36,200
Speaker 1: So funnily enough, before I got rid of my Twitter account...

831
01:04:36,262 --> 01:04:36,579
Speaker 0: It's unusable.

832
01:04:36,761 --> 01:04:38,048
Speaker 1: You know what terms I had muted?

833
01:04:38,068 --> 01:04:39,415
Speaker 1: Patreon.

834
01:04:42,263 --> 01:04:43,700
Speaker 1: That's it, that's the only term I had muted.

835
01:04:48,042 --> 01:04:50,180
Speaker 1: This has been Geek Nights with Rim and Scott.

836
01:04:50,380 --> 01:04:55,320
Speaker 1: Special thanks to DJ Pretzel for the opening music, Kat Lee for web design, and Brando K for the logos.

837
01:04:55,700 --> 01:05:00,720
Speaker 0: Be sure to visit our website at FrontRowCrew.com for show notes, discussion news, and more.

838
01:05:01,040 --> 01:05:03,660
Speaker 1: Remember, Geek Nights is not one, but four different shows.

839
01:05:03,920 --> 01:05:08,140
Speaker 1: Sci-Tech Mondays, Gaming Tuesdays, Anime Comic Wednesdays, and Indiscriminate Thursdays.

840
01:05:08,763 --> 01:05:11,937
Speaker 0: Geek Nights is distributed under a Creative Commons Attribution 3.0 license.

841
01:05:13,280 --> 01:05:16,240
Speaker 0: Geek Nights is recorded live with no studio and no audience.

842
01:05:16,460 --> 01:05:19,360
Speaker 0: But unlike those other late shows, it's actually recorded at night.

843
01:05:19,921 --> 01:05:42,320
Speaker 1: And the Geek Nights Patreon patrons for this episode are... I assume to get access to that sweet Patreon-exclusive RSS feed.

844
01:05:42,460 --> 01:05:45,400
Speaker 1: That is the same as our feed, but it works within Patreon.

845
01:05:46,482 --> 01:05:46,865
Speaker 1: Uh, yeah.

846
01:05:47,854 --> 01:05:48,339
Speaker 1: See you at PAX.

847
01:05:49,401 --> 01:05:51,030
Speaker 1: Definitely not do another show this week.

848
01:05:51,050 --> 01:05:52,960
Speaker 1: We'll probably do one show next week.

849
01:05:53,361 --> 01:05:55,138
Speaker 1: And I leave you tonight only with...

850
01:05:55,341 --> 01:05:55,999
Speaker 0: The Soviet Union.

851
01:05:56,620 --> 01:05:57,517
Speaker 0: I thought you guys broke up.

852
01:05:58,221 --> 01:06:00,419
Speaker 1: Yes, that's what we wanted you to think.

853
01:06:00,703 --> 01:06:01,008
Speaker 0: [Laughing].

854
01:06:05,521 --> 01:06:24,100
Speaker 1: [Singing] Must crush capitalism!

855
01:06:24,800 --> 01:06:25,180
Speaker 1: [Growling].

