1
00:00:09,740 --> 00:00:11,977
Speaker 1: It's Monday January 7th.

2
00:00:12,398 --> 00:00:12,900
Speaker 1: I'm rim.

3
00:00:13,161 --> 00:00:16,090
Speaker 1: I'm Scott and this is geek knives tonight.

4
00:00:16,533 --> 00:00:18,809
Speaker 1: Love sex and robots.

5
00:00:25,801 --> 00:00:26,796
Speaker 1: Let's do this.

6
00:00:28,541 --> 00:00:34,060
Speaker 0: You think in New York City that the you know big one of the most important cities in the world if not the most important.

7
00:00:34,585 --> 00:00:36,220
Speaker 0: You could get a decent internet connection.

8
00:00:36,262 --> 00:00:44,360
Speaker 1: But no Well, uh, I would wager that while New York City is one of the most important cities in the world Your company is not one of the most important companies in the way.

9
00:00:44,420 --> 00:00:46,460
Speaker 0: So it's nothing to do with our company has to do with the building.

10
00:00:46,520 --> 00:00:49,940
Speaker 0: You see you when you're in New York City, you don't own a building.

11
00:00:50,121 --> 00:00:55,660
Speaker 0: I mean if you do own a building then your company is a company that owns buildings and doesn't do anything else, right?

12
00:00:55,900 --> 00:01:00,380
Speaker 1: You know, I can't really make fun of this too much because I've actually been having similar issues at my company.

13
00:01:00,602 --> 00:01:02,195
Speaker 1: Yeah, it's like we're sitting around.

14
00:01:02,216 --> 00:01:06,934
Speaker 1: we're like, alright How can we get better wires into our business?

15
00:01:07,396 --> 00:01:09,627
Speaker 1: and the answer was well How much you're willing to pay?

16
00:01:09,667 --> 00:01:13,142
Speaker 1: and the answer to that was anything Anything.

17
00:01:13,363 --> 00:01:16,417
Speaker 1: we just want it to be better and there's no way.

18
00:01:16,739 --> 00:01:19,249
Speaker 0: nope Cuz you're at the mercy of the building.

19
00:01:19,329 --> 00:01:21,940
Speaker 1: so and it's not that you can't get it technologically.

20
00:01:22,001 --> 00:01:27,693
Speaker 1: It's that the people who run the buildings in New York City You just don't know jack all about technology and not only are we at the mercy of the building.

21
00:01:27,893 --> 00:01:30,880
Speaker 0: We're also at the mercy of Verizon.

22
00:01:31,881 --> 00:01:31,922
Speaker 0: In

23
00:01:33,647 --> 00:01:42,104
Speaker 1: In all my life I've discovered that Verizon is the least shitty of the people you have to call if you've got like a t1 down or something

24
00:01:42,144 --> 00:01:56,735
Speaker 0: and that's why they can afford to sell t1s and but also lease out their copper to other people to sell t1s on because you can buy a t1 from someone else who leases Verizon's copper and then sells it to you at a lower price and you save money that way.

25
00:01:57,357 --> 00:01:58,921
Speaker 0: or you can buy a t1 from Verizon.

26
00:01:58,941 --> 00:02:05,080
Speaker 0: but you know what if you pay for a t1 from the people actually own the copper things are usually better for you.

27
00:02:05,263 --> 00:02:07,477
Speaker 0: It's a racket It works out.

28
00:02:08,009 --> 00:02:15,364
Speaker 0: But anyway We have some like Ethernet loops to this company down the road and it went out once and it went out twice and now it Went out again.

29
00:02:15,465 --> 00:02:15,867
Speaker 1: Wait a minute.

30
00:02:15,907 --> 00:02:16,329
Speaker 1: Wait a minute.

31
00:02:16,369 --> 00:02:21,634
Speaker 1: I think you've done this opening bit before Maybe talking about your internet being down at work.

32
00:02:21,695 --> 00:02:22,540
Speaker 1: now you couldn't do anything.

33
00:02:22,560 --> 00:02:28,579
Speaker 0: But anyway, there's like there's one of those companies that lets you aim a dish at their you know To do the might the direct link thing.

34
00:02:28,702 --> 00:02:30,611
Speaker 0: Yeah But the the building won't.

35
00:02:30,631 --> 00:02:35,640
Speaker 0: let us put a dish on the roof Even though we already have a direct TV dish up there because the building doesn't allow cable.

36
00:02:35,901 --> 00:02:37,106
Speaker 0: There's no cable in the building.

37
00:02:37,126 --> 00:02:40,780
Speaker 1: tell them it's another direct TV dish and paint it to look like one.

38
00:02:41,262 --> 00:02:46,225
Speaker 0: Yeah, but they're also doing like construction up this they don't want anyway But also it just.

39
00:02:46,245 --> 00:02:55,000
Speaker 0: they're just being a huge pain in the ass and there's nobody that we can get fast internet from in that Building even though this shit tons of bandwidth all around.

40
00:02:55,663 --> 00:02:58,600
Speaker 0: We can't get it in that building because I tell you what if we ever?

41
00:02:59,382 --> 00:03:07,629
Speaker 1: That's the one thing if we like, you know Go pro with this or whatever and we end up just having some sort of computer shop here in Beacon We can get some pretty damn fast internet.

42
00:03:07,669 --> 00:03:10,540
Speaker 1: It'll probably be pretty damn awesome fucking fiber or something.

43
00:03:10,540 --> 00:03:10,680
Speaker 0: There's.

44
00:03:10,700 --> 00:03:12,366
Speaker 0: no can't get any fiber or anything.

45
00:03:12,406 --> 00:03:13,449
Speaker 0: It's horrendous man.

46
00:03:13,489 --> 00:03:17,060
Speaker 1: Still bothers me that the FiOS is like right there down the road.

47
00:03:17,261 --> 00:03:32,480
Speaker 1: Yep, like I can walk to where the FiOS I'd get it in a second But in other news because I feel like we've talked about this before when your company's internet goes down Scott and I once again ran afoul of a fat and dignit lady.

48
00:03:32,901 --> 00:03:38,140
Speaker 0: You're talking about me talking about an opening bit that we've done before and now you're talking about a fat and dignit lady.

49
00:03:38,341 --> 00:03:39,550
Speaker 1: That might have been intentional.

50
00:03:40,053 --> 00:03:45,032
Speaker 1: I don't know maybe But seriously, it was like we're up the road pretty much.

51
00:03:45,072 --> 00:03:47,140
Speaker 1: I think this is the last time we're gonna go up the road.

52
00:03:47,281 --> 00:03:48,828
Speaker 0: You know a long time at least.

53
00:03:48,848 --> 00:03:51,320
Speaker 1: we always say up the road and basically live in Beacon.

54
00:03:52,002 --> 00:03:57,760
Speaker 1: Everything we need is in Beacon or on the internet, but there's residual things that except for groceries which are in Vishal.

55
00:03:58,101 --> 00:04:03,180
Speaker 1: Yeah, well they exist in Beacon, but I would not consider that to be a grocery store more.

56
00:04:03,501 --> 00:04:06,771
Speaker 0: I don't consider anything nearby to be a grocery store.

57
00:04:07,112 --> 00:04:09,620
Speaker 1: Well, something could be nearby and be a grocery store.

58
00:04:09,660 --> 00:04:13,137
Speaker 1: However, what is nearby is not a grocery store and smells.

59
00:04:13,499 --> 00:04:22,532
Speaker 1: Yes So, uh, I I mean the last time I drove to the mall was I tried to get some glasses during a blizzard and I discovered that Who doesn't go out during the blizzard?

60
00:04:22,794 --> 00:04:24,060
Speaker 0: opticians opticians?

61
00:04:24,800 --> 00:04:29,437
Speaker 1: So I show up and there's the doctor like yeah, you can buy glasses, but you can't get a checkup.

62
00:04:29,457 --> 00:04:30,260
Speaker 1: There's no doctors.

63
00:04:30,722 --> 00:04:33,753
Speaker 1: So I paid four times more to just deal with it in the city.

64
00:04:33,773 --> 00:04:34,858
Speaker 1: But then again, I didn't pay anything.

65
00:04:34,898 --> 00:04:45,913
Speaker 1: I didn't care Yeah, but uh, so we went up that road pretty much for the last time and we went beyond the mall All the way up the road to the gaming store which had nothing.

66
00:04:46,174 --> 00:04:46,797
Speaker 1: yeah, we went in.

67
00:04:46,817 --> 00:04:49,448
Speaker 1: we're like, oh wow Yeah, this place hasn't changed much.

68
00:04:50,090 --> 00:04:52,480
Speaker 0: Wow, actually it changed a lot, but they didn't have anything for us.

69
00:04:52,520 --> 00:04:55,254
Speaker 1: Remember we used to come here every month and play games with those guys.

70
00:04:55,455 --> 00:04:56,440
Speaker 1: What if they're still alive?

71
00:04:56,940 --> 00:04:58,184
Speaker 0: No, they're probably still alive.

72
00:04:58,225 --> 00:05:00,452
Speaker 0: But I think they're game organized.

73
00:05:00,492 --> 00:05:01,355
Speaker 0: gaming days are over.

74
00:05:01,736 --> 00:05:02,900
Speaker 1: Yeah kind of sad.

75
00:05:02,980 --> 00:05:04,386
Speaker 0: Well, probably see them at that gaming for hope.

76
00:05:04,406 --> 00:05:12,214
Speaker 1: maybe yeah, but we know we pretty much did everything we could do up the road Craft store to buy stuff to build a clock decided it was worth it.

77
00:05:12,334 --> 00:05:14,280
Speaker 1: Yeah, we got there and we're like, where's the clock shit?

78
00:05:14,360 --> 00:05:14,845
Speaker 1: Where's the clock shit?

79
00:05:14,885 --> 00:05:20,116
Speaker 1: We found the clock stuff like alright All we have to do is buy the mechanisms and we can make our custom fuck it.

80
00:05:20,498 --> 00:05:20,959
Speaker 1: and then we left.

81
00:05:21,301 --> 00:05:23,970
Speaker 0: Yeah, those are not the kind of mechanisms I was looking for.

82
00:05:24,331 --> 00:05:28,808
Speaker 1: Yeah, so, uh, we're in this parking lot And you know, I'm gonna leave and go back home.

83
00:05:28,848 --> 00:05:30,597
Speaker 1: I got I didn't buy a ski jacket.

84
00:05:31,019 --> 00:05:33,302
Speaker 1: and Thank you internet, you know I go to EMS.

85
00:05:33,322 --> 00:05:34,989
Speaker 1: I buy a ski mask buying Maljean.

86
00:05:35,049 --> 00:05:36,234
Speaker 1: buy all this winter hat.

87
00:05:36,274 --> 00:05:36,856
Speaker 1: cuz I realized.

88
00:05:37,077 --> 00:05:37,900
Speaker 0: EMS a good store.

89
00:05:38,061 --> 00:05:39,045
Speaker 1: I don't own a winter hat.

90
00:05:39,426 --> 00:05:40,852
Speaker 1: I haven't owned a winter hat years.

91
00:05:40,993 --> 00:05:41,816
Speaker 0: Are you ears cold?

92
00:05:41,917 --> 00:05:42,700
Speaker 0: No, why not?

93
00:05:43,001 --> 00:05:44,559
Speaker 1: Cuz I don't know they just don't get cold.

94
00:05:45,661 --> 00:05:46,745
Speaker 1: So, uh, all right.

95
00:05:46,765 --> 00:05:48,651
Speaker 1: I'm gonna buy a ski jacket cheapest one.

96
00:05:48,691 --> 00:05:50,016
Speaker 1: They got 300 bucks.

97
00:05:50,698 --> 00:05:51,160
Speaker 0: I bought mine.

98
00:05:51,200 --> 00:05:53,194
Speaker 0: There wasn't 300 bucks wasn't a ski jacket.

99
00:05:53,215 --> 00:05:56,771
Speaker 1: Oh So, uh, all right, I go online.

100
00:05:56,811 --> 00:05:57,876
Speaker 1: I decide not to buy it.

101
00:05:57,956 --> 00:05:58,880
Speaker 1: I look online.

102
00:05:59,100 --> 00:06:02,271
Speaker 1: I can buy that exact same ski jacket for 200 bucks on the internet.

103
00:06:02,772 --> 00:06:03,013
Speaker 0: Go.

104
00:06:03,033 --> 00:06:03,214
Speaker 0: Yeah.

105
00:06:03,314 --> 00:06:07,067
Speaker 0: Thank you internet retail stores Not so useful anymore granted.

106
00:06:07,087 --> 00:06:08,572
Speaker 1: The worst thing is I'm there right now.

107
00:06:08,833 --> 00:06:09,194
Speaker 1: I'm playing.

108
00:06:09,214 --> 00:06:10,840
Speaker 1: I was gonna go skiing this coming weekend.

109
00:06:10,900 --> 00:06:11,885
Speaker 1: I was all set to go skiing.

110
00:06:11,905 --> 00:06:14,596
Speaker 1: I haven't skied in like slow warm to go ski.

111
00:06:14,637 --> 00:06:16,585
Speaker 1: Well, you see yeah That's this thing now.

112
00:06:16,646 --> 00:06:18,334
Speaker 1: It's like 70 degrees.

113
00:06:18,434 --> 00:06:25,857
Speaker 1: So uh Skiing might not happen fund but on the way out in the parking lot narrow parking lot I was parked in a parking space.

114
00:06:26,321 --> 00:06:32,350
Speaker 1: We get in the car and there's this fat woman sitting in the car next to us Suv by the way, and she's.

115
00:06:32,672 --> 00:06:34,059
Speaker 1: she keeps like talking at us.

116
00:06:34,280 --> 00:06:37,496
Speaker 0: Well, she talked at me and she was like blabbity blabbity blah and I was just like what.

117
00:06:37,777 --> 00:06:40,710
Speaker 0: and she's like I had to crawl in through the passenger seat.

118
00:06:40,790 --> 00:06:51,106
Speaker 0: cuz you know, I couldn't get in this way and What I should have said was well, maybe if you weren't fat and driving an SUV would never problem I can get in this car just fine.

119
00:06:51,307 --> 00:06:53,073
Speaker 1: But instead Scott gets in the car.

120
00:06:53,093 --> 00:06:56,129
Speaker 0: He said I'm just like talk to him I'm not driving and he gets to.

121
00:06:56,149 --> 00:06:57,860
Speaker 1: the car is like that lady wants you and like what?

122
00:06:58,360 --> 00:07:04,612
Speaker 1: so I like open my door and I stand up and I look to the right and I'm like Hello, and she's like you parked too close to me.

123
00:07:04,632 --> 00:07:05,937
Speaker 1: I couldn't get into my car.

124
00:07:06,057 --> 00:07:06,820
Speaker 1: There wasn't enough space.

125
00:07:06,901 --> 00:07:08,019
Speaker 1: I had to get in from the other side.

126
00:07:08,321 --> 00:07:16,272
Speaker 1: So I look at her for a second and I'm about to just like drive away cuz I don't care and she says it again Basically, so I stopped and I look now.

127
00:07:16,292 --> 00:07:17,780
Speaker 0: keep in mind this parking lot.

128
00:07:17,880 --> 00:07:22,860
Speaker 0: The spots were really close together like this parking lot was obviously old and not designed for large video.

129
00:07:22,981 --> 00:07:26,319
Speaker 0: No, these were tiny parking space very tiny and close together parking spaces.

130
00:07:26,601 --> 00:07:31,042
Speaker 1: So what I do is I just said alright and I look on both sides of my car and I walk around my car And I go, huh?

131
00:07:31,585 --> 00:07:38,799
Speaker 1: I turned to her and I say well, I'm parked fully within the lines I'm no closer to your car than I am to the car on the other side of me.

132
00:07:39,221 --> 00:07:41,089
Speaker 1: so it's obviously not my problem.

133
00:07:42,013 --> 00:07:47,292
Speaker 1: and I go to get back in the car and I can see her getting angry and her face starts turning.

134
00:07:47,312 --> 00:07:49,280
Speaker 0: I think she was angry before we even showed up.

135
00:07:49,401 --> 00:07:51,940
Speaker 1: I think she was waiting for us to come back to try to yell at us.

136
00:07:52,100 --> 00:07:57,340
Speaker 1: She was definitely waiting for us to come and she must've been waiting a while though cuz we had lunch and we wandered around.

137
00:07:57,481 --> 00:07:58,867
Speaker 1: But so we're sitting there.

138
00:07:58,887 --> 00:07:59,691
Speaker 0: We had lunch after that.

139
00:08:00,053 --> 00:08:00,454
Speaker 1: Oh, we don't.

140
00:08:00,475 --> 00:08:00,957
Speaker 1: Yeah, we did.

141
00:08:00,977 --> 00:08:02,726
Speaker 1: Mm-hmm I weren't in there that long.

142
00:08:02,747 --> 00:08:03,974
Speaker 1: then we just failed to buy clocks.

143
00:08:04,256 --> 00:08:07,206
Speaker 0: Yep, and We succeeded in getting paper.

144
00:08:07,427 --> 00:08:08,309
Speaker 1: Yeah, which we kind of needed.

145
00:08:08,470 --> 00:08:09,091
Speaker 0: We really needed.

146
00:08:09,573 --> 00:08:12,320
Speaker 1: so alright, so I just ignore her at this point.

147
00:08:12,380 --> 00:08:15,672
Speaker 1: I go to get back in the car and she says well blah blah blah blah.

148
00:08:15,733 --> 00:08:17,700
Speaker 1: people could be polite blah blah blah blah.

149
00:08:18,001 --> 00:08:19,265
Speaker 1: I hope that someone does this to you.

150
00:08:19,285 --> 00:08:20,730
Speaker 1: so blah blah blah blah blah blah blah.

151
00:08:20,971 --> 00:08:22,697
Speaker 1: and she's getting louder and louder.

152
00:08:23,018 --> 00:08:29,700
Speaker 1: as I'm Slowly like getting in the car ignoring her and closing the door and I could see her still talking as I was driving away.

153
00:08:30,081 --> 00:08:33,510
Speaker 1: That woman was the third most indignant person.

154
00:08:33,610 --> 00:08:35,554
Speaker 1: I have ever personally dealt with.

155
00:08:36,056 --> 00:08:37,600
Speaker 0: I've dealt with a lot more indignant.

156
00:08:37,922 --> 00:08:39,793
Speaker 0: Yeah, she was a fat indignant lady.

157
00:08:39,852 --> 00:08:45,700
Speaker 1: the most indignant person I ever dealt with was waiting in line to go over the Lewiston bridge into Canada.

158
00:08:46,504 --> 00:08:49,196
Speaker 1: That was the most indignant I've ever seen a human being.

159
00:08:49,437 --> 00:08:52,070
Speaker 0: what about That lady who blocked the hallway?

160
00:08:52,492 --> 00:09:00,868
Speaker 1: that lady was indignant But at the same time she was so furious when that guy said well Maybe you could lose some weights that she chooses.

161
00:09:00,928 --> 00:09:04,920
Speaker 1: She was just standing there seething and she went from indignant into hilarious.

162
00:09:07,140 --> 00:09:08,308
Speaker 0: Dignity is hilarious.

163
00:09:08,329 --> 00:09:10,804
Speaker 1: I Think that's the point.

164
00:09:11,227 --> 00:09:11,629
Speaker 0: All right.

165
00:09:11,649 --> 00:09:11,991
Speaker 0: All right.

166
00:09:12,011 --> 00:09:12,895
Speaker 1: So what do you got in the news?

167
00:09:13,096 --> 00:09:13,740
Speaker 0: What happened the news?

168
00:09:13,841 --> 00:09:15,210
Speaker 0: Okay, so what happened?

169
00:09:15,250 --> 00:09:16,338
Speaker 1: CES can talk about CES.

170
00:09:18,200 --> 00:09:20,531
Speaker 0: Well, basically, there's so much new technology.

171
00:09:20,551 --> 00:09:22,400
Speaker 0: It's sort of impossible to talk about anything.

172
00:09:22,581 --> 00:09:25,551
Speaker 0: Yeah, I'm gonna buy unless he did the whole show on it.

173
00:09:25,832 --> 00:09:27,960
Speaker 0: I mean we could just go down look go to Engadget.

174
00:09:28,000 --> 00:09:30,720
Speaker 0: There's more stories posted on Engadget in the last two days.

175
00:09:30,760 --> 00:09:38,445
Speaker 0: There have been like the last two months and every story is like new HDTV new phone new HDTV new phone new New this new that new this.

176
00:09:38,506 --> 00:09:38,747
Speaker 0: do that.

177
00:09:38,827 --> 00:09:40,734
Speaker 0: It isn't that and a lot of it's cool.

178
00:09:40,755 --> 00:09:42,120
Speaker 0: A lot of its kind of.

179
00:09:43,061 --> 00:09:45,874
Speaker 0: Bill Gates made his last keynote not so exciting.

180
00:09:46,115 --> 00:09:47,300
Speaker 1: I heard it was a pretty good speech.

181
00:09:47,581 --> 00:09:50,551
Speaker 0: Yeah, I guess you know for Bill Gates normal, whatever.

182
00:09:50,572 --> 00:09:52,298
Speaker 1: Yeah, he's not the best speaker.

183
00:09:52,318 --> 00:10:00,016
Speaker 0: Yeah I mean basically it's like, you know It really all I care about is the new technology like a lot of people reporting on the show itself.

184
00:10:00,137 --> 00:10:00,899
Speaker 0: It's like come on.

185
00:10:01,903 --> 00:10:05,280
Speaker 1: It's not like an anime con where cool things happen at the convention.

186
00:10:05,461 --> 00:10:10,257
Speaker 0: Yeah at the show tell me about the thing that things themselves and some of the things that are going on there.

187
00:10:10,317 --> 00:10:10,457
Speaker 0: now.

188
00:10:10,498 --> 00:10:14,972
Speaker 1: granted if Steve Somehow started choking on the new iPhone that I might care about that.

189
00:10:15,634 --> 00:10:17,260
Speaker 0: Yeah, Apple doesn't do too much at CES.

190
00:10:17,480 --> 00:10:23,340
Speaker 0: No, they do their Mac worlds in there their personal things and they're hey the Apple stores down.

191
00:10:23,904 --> 00:10:25,215
Speaker 1: Yeah, something's happening.

192
00:10:26,740 --> 00:10:30,532
Speaker 0: Knows we can't make a website that updates seamlessly without going down.

193
00:10:30,873 --> 00:10:33,240
Speaker 1: I think they do that on purpose to generate buzz.

194
00:10:33,401 --> 00:10:35,219
Speaker 0: I think they also do it to make it easier.

195
00:10:35,883 --> 00:10:37,651
Speaker 0: Cuz Amazon doesn't even have a problem.

196
00:10:37,671 --> 00:10:39,440
Speaker 0: They don't need to take their site down to update it.

197
00:10:39,621 --> 00:10:48,440
Speaker 1: Yeah, that's the one thing about not work like when I worked at IBM was like, oh we can't ever take anything down But anytime you have a server that only has to be accessed during business hours.

198
00:10:48,962 --> 00:10:51,673
Speaker 1: It is so great to just take that fucker down and do something.

199
00:10:51,693 --> 00:10:54,360
Speaker 1: today cherries like alright I can update the database.

200
00:10:54,781 --> 00:10:57,128
Speaker 1: Well, the database is now read locked.

201
00:10:57,530 --> 00:10:59,074
Speaker 1: The database is now down.

202
00:10:59,395 --> 00:11:00,559
Speaker 1: the database is back up.

203
00:11:01,041 --> 00:11:03,332
Speaker 1: Yep, as opposed to a shit someone connected.

204
00:11:03,392 --> 00:11:04,397
Speaker 1: now everything went to hell.

205
00:11:04,778 --> 00:11:07,442
Speaker 0: Yep So, yeah that Like.

206
00:11:07,463 --> 00:11:10,380
Speaker 0: I thought that this week is be full of CES news and you know what?

207
00:11:10,520 --> 00:11:19,620
Speaker 0: I think that as soon as the news starts to simmer down, you know It will boil and sediment and the most important bits of news will arise to the top and then we can discuss them.

208
00:11:19,660 --> 00:11:20,535
Speaker 0: but right now it's just.

209
00:11:21,101 --> 00:11:26,005
Speaker 0: This is this is this is this and this and this and this and this is this and if you actually care you can go Reading gadget or something.

210
00:11:26,125 --> 00:11:36,183
Speaker 1: All I can really say is I think I found the laptop I am going to purchase unless it unless a very small power book comes out MacBook Pro.

211
00:11:36,224 --> 00:11:36,685
Speaker 0: Well, what is?

212
00:11:36,745 --> 00:11:38,894
Speaker 0: the Mac world is pretty soon the Mac world?

213
00:11:38,974 --> 00:11:40,580
Speaker 1: I'm gonna hold out until Mac world.

214
00:11:40,881 --> 00:11:45,802
Speaker 1: Yeah, it's it's in a little while and pretty much if what I want comes out of Apple I'm buying that.

215
00:11:45,942 --> 00:11:47,928
Speaker 1: if it doesn't I'm buying that other laptop.

216
00:11:48,109 --> 00:11:49,653
Speaker 0: Anyway, so here's a news ready.

217
00:11:50,195 --> 00:11:52,382
Speaker 0: No, no, no, okay I'm wait.

218
00:11:52,623 --> 00:11:52,844
Speaker 0: Okay.

219
00:11:52,884 --> 00:11:53,225
Speaker 1: Now I am.

220
00:11:53,466 --> 00:11:53,667
Speaker 0: Okay.

221
00:11:53,888 --> 00:12:00,052
Speaker 0: Okay this guy he came from Canada to Vermont I think.

222
00:12:00,153 --> 00:12:04,673
Speaker 0: well, obviously Not all the details of what happened here are listed.

223
00:12:04,694 --> 00:12:05,296
Speaker 0: So I'm not sure.

224
00:12:05,356 --> 00:12:12,400
Speaker 0: maybe I read the news already But maybe I don't have all the details of this news But I have the the most important parts that they're relevant.

225
00:12:12,862 --> 00:12:16,540
Speaker 0: The guy crossed the US Canadian border in some way and in some way it involves Vermont.

226
00:12:16,922 --> 00:12:20,460
Speaker 0: He was suspected of having the child prawns on the computer.

227
00:12:20,540 --> 00:12:26,740
Speaker 0: I guess they had warrants to you know, search his business and all that right and so they did search his business and whatever.

228
00:12:27,221 --> 00:12:29,488
Speaker 0: But I guess they didn't have enough evidence.

229
00:12:29,889 --> 00:12:30,169
Speaker 0: right.

230
00:12:30,571 --> 00:12:36,166
Speaker 0: and this guy, you know, if he is having the child prawns It's not cool and I don't condone that.

231
00:12:36,627 --> 00:12:44,937
Speaker 0: but he was smart enough to use the PGP encryption to encrypt his stuff So that they couldn't you know decrypt his drive and see what he had on there.

232
00:12:45,098 --> 00:12:45,540
Speaker 1: All right, great.

233
00:12:45,640 --> 00:12:48,979
Speaker 1: So the police get the computer and say hey you've got.

234
00:12:49,079 --> 00:12:53,011
Speaker 1: well I'm surprised the police got to the point of realizing there was encryption in place.

235
00:12:53,332 --> 00:12:54,455
Speaker 0: Yeah, that's pretty.

236
00:12:54,776 --> 00:12:58,087
Speaker 1: he probably has that like PGP Disk encryptor that encrypts the whole disk.

237
00:12:58,187 --> 00:12:59,472
Speaker 1: You have to put a password into boot.

238
00:12:59,753 --> 00:13:01,058
Speaker 1: Maybe he's otherwise there's no way.

239
00:13:01,098 --> 00:13:03,690
Speaker 0: they'd know It's got to be something like that or they hired.

240
00:13:03,710 --> 00:13:05,700
Speaker 1: a forensics guy like Katsu can do that stuff.

241
00:13:05,765 --> 00:13:05,940
Speaker 1: Yeah.

242
00:13:06,341 --> 00:13:13,620
Speaker 0: But anyway, there was a subpoena from a grand jury that directed him to provide any passwords used with the laptop, right?

243
00:13:14,480 --> 00:13:15,343
Speaker 0: Which sort of?

244
00:13:15,684 --> 00:13:17,610
Speaker 0: and the judge right?

245
00:13:17,971 --> 00:13:19,817
Speaker 0: So he goes hey, I'm not telling you the passwords.

246
00:13:19,837 --> 00:13:20,399
Speaker 0: He can't make me.

247
00:13:21,447 --> 00:13:25,380
Speaker 0: So the judge had to decide Does he have to give up the passwords or not?

248
00:13:25,500 --> 00:13:32,450
Speaker 0: And of course if you don't give up the passwords and the judge says you have to you know what that is That's the Fifth Amendment contempt.

249
00:13:32,811 --> 00:13:39,065
Speaker 0: Oh, yeah, but the judge said no You don't have to give the passwords now because of the Fifth Amendment Exactly.

250
00:13:39,729 --> 00:13:41,460
Speaker 0: You don't have to incriminate yourself, right?

251
00:13:41,620 --> 00:13:48,766
Speaker 0: So I think it's pretty interesting and that when if I let's say I have in my house Something illegal drugs.

252
00:13:48,826 --> 00:13:49,107
Speaker 0: I don't know.

253
00:13:49,147 --> 00:13:51,054
Speaker 0: I don't have drugs in the house except Tylenol, I guess.

254
00:13:51,135 --> 00:13:59,580
Speaker 0: but let's pretend I do okay, and The police are have reasonable suspicion enough to get a warrant from a judge and they want to search my house and have a warrant.

255
00:13:59,600 --> 00:14:01,048
Speaker 0: They're allowed to search my house with a warrant.

256
00:14:01,551 --> 00:14:07,660
Speaker 0: if I don't give them the key to my house They can either force me to give them the key or bust the door down and just search my house.

257
00:14:07,740 --> 00:14:09,175
Speaker 0: There's nothing that's that's legal.

258
00:14:09,478 --> 00:14:09,579
Speaker 0: now

259
00:14:09,660 --> 00:14:18,851
Speaker 1: Luckily for this guy busting the door down to PGP is a little more difficult than busting down that shoddy-ass like hollow metal frame door you've got

260
00:14:19,091 --> 00:14:32,820
Speaker 0: right now if the Basically this guy they had a warrant to search his computer and they did search his computer as much as they could But the door on his computer was not opened by a physical object and could not be opened.

261
00:14:32,961 --> 00:14:36,820
Speaker 0: I guess it could be opened by force which if they did that that would be fine.

262
00:14:36,920 --> 00:14:42,380
Speaker 1: But I have a feeling the statute of limitations would run out long before they decrypted his drive exactly.

263
00:14:42,460 --> 00:14:48,360
Speaker 0: It's so difficult to open by force that it's effectively unopenable right unless they get incredibly lucky.

264
00:14:48,380 --> 00:14:50,630
Speaker 1: You know, there was a Superman about.

265
00:14:50,690 --> 00:14:52,338
Speaker 0: that was there way back.

266
00:14:53,202 --> 00:15:02,580
Speaker 1: I remember watching this where some guy Committed some crime and what he did is he locked himself in an impenetrable box until the statute of limitations ran out.

267
00:15:03,046 --> 00:15:03,879
Speaker 0: How do you know this?

268
00:15:04,220 --> 00:15:04,722
Speaker 1: So they tried to.

269
00:15:04,762 --> 00:15:13,097
Speaker 1: Superman tried to bust in right because they had this clock and they're like, all right The statute of limitations runs up in like 12 hours.

270
00:15:13,137 --> 00:15:17,315
Speaker 1: Superman Bust in there and get this guy and Superman couldn't bust in.

271
00:15:17,356 --> 00:15:26,116
Speaker 1: so we talked to some guy I don't know what you this guy was who taught him about Adams and how we could Faze through matter by making this Adams dodge the other Adams and like the fuse in.

272
00:15:26,257 --> 00:15:26,960
Speaker 1: where did you read this?

273
00:15:27,300 --> 00:15:31,399
Speaker 1: I saw it where it was a tea Superman where I saw Superman on TV.

274
00:15:32,340 --> 00:15:35,048
Speaker 0: Okay, black and white Superman black and white.

275
00:15:35,129 --> 00:15:37,074
Speaker 0: Yeah card live-action.

276
00:15:37,175 --> 00:15:37,496
Speaker 0: Yeah.

277
00:15:37,937 --> 00:15:41,586
Speaker 0: Okay, Nick at night Okay, I never saw that one.

278
00:15:42,168 --> 00:15:44,898
Speaker 0: I saw the old cartoon one which is in color, you know, doo-doo-doo.

279
00:15:45,463 --> 00:15:56,848
Speaker 1: Superman Starts phasing through the wall and he gets halfway in and then the guy's like, oh crap Superman's coming I don't know how he knew and he's like, hey Superman What if you get stuck in that wall?

280
00:15:56,908 --> 00:15:57,530
Speaker 1: Superman goes?

281
00:15:57,591 --> 00:15:58,816
Speaker 1: Ah shit, you're right and leaves.

282
00:15:59,318 --> 00:16:01,407
Speaker 1: Yeah Anyway, how they get him?

283
00:16:01,607 --> 00:16:02,451
Speaker 1: you want to know how they get him.

284
00:16:02,471 --> 00:16:03,234
Speaker 0: I don't care.

285
00:16:03,415 --> 00:16:03,897
Speaker 1: You don't care.

286
00:16:03,997 --> 00:16:05,280
Speaker 1: It's kind of funny All right.

287
00:16:05,481 --> 00:16:12,749
Speaker 1: So he comes out after the statute of limitations up because he's got his atomic clock in there and he's like, all right Haha, I'm out.

288
00:16:13,212 --> 00:16:14,037
Speaker 1: Ah, you can't arrest me.

289
00:16:14,078 --> 00:16:14,460
Speaker 1: They arrest him.

290
00:16:14,520 --> 00:16:18,879
Speaker 1: Anyway, Superman messed with his clock and he came out five minutes early.

291
00:16:20,420 --> 00:16:21,220
Speaker 0: Okay, anyway.

292
00:16:22,382 --> 00:16:27,087
Speaker 0: so yeah, basically, I think it's pretty interesting because That you Fifth Amendment.

293
00:16:27,127 --> 00:16:29,436
Speaker 0: You don't have to you know, incriminate yourself.

294
00:16:29,496 --> 00:16:31,846
Speaker 0: You can just shut up You can go to you don't have to sit.

295
00:16:31,887 --> 00:16:33,172
Speaker 0: You don't have to testify in court.

296
00:16:33,654 --> 00:16:36,139
Speaker 0: You can just be silent You don't have to say anything.

297
00:16:36,361 --> 00:16:40,819
Speaker 0: Of course anything you do say will be held against you but no one can make you say anything in the u.s.

298
00:16:41,325 --> 00:16:41,547
Speaker 1: Funny.

299
00:16:41,608 --> 00:16:43,879
Speaker 1: oh that's such us I mean if you really think about it.

300
00:16:44,241 --> 00:16:53,979
Speaker 1: That is such a strange right to give someone that you have to tell the truth unless something you say is Incriminating and then you don't have to say anything.

301
00:16:54,280 --> 00:16:58,972
Speaker 0: Well, you if you do you basically you can choose to shut up or talk.

302
00:16:59,213 --> 00:17:02,120
Speaker 0: you can basically choose between truth and shutting up.

303
00:17:02,180 --> 00:17:02,863
Speaker 0: You can't lie.

304
00:17:02,883 --> 00:17:04,608
Speaker 1: I mean, I'm all I'm.

305
00:17:04,690 --> 00:17:05,512
Speaker 1: don't get me wrong.

306
00:17:05,532 --> 00:17:09,536
Speaker 1: I'm not saying we don't need the Fifth Amendment Yeah, I'm just saying it's funny how it works out.

307
00:17:09,636 --> 00:17:12,800
Speaker 0: so well Yeah, but I think it's pretty interesting.

308
00:17:12,880 --> 00:17:16,740
Speaker 0: What if I had a house like a physical house and the only way into the house?

309
00:17:17,160 --> 00:17:23,180
Speaker 0: Was with information that only I knew and I I couldn't be forced to reveal that information to incriminate myself.

310
00:17:23,803 --> 00:17:26,839
Speaker 0: I could be forced to reveal the information to incriminate someone else though.

311
00:17:27,281 --> 00:17:36,219
Speaker 1: So yeah, so as long as you murdered the guy who designed the password scheme and you buried his body in the house Yes, so it's weird.

312
00:17:37,224 --> 00:17:39,595
Speaker 0: I'm fully in favor of the Fifth Amendment because without it.

313
00:17:39,877 --> 00:17:40,560
Speaker 0: It'll be horrible.

314
00:17:40,641 --> 00:17:42,980
Speaker 0: It'll be like it's almost as bad as no habeas corpus.

315
00:17:43,080 --> 00:17:45,430
Speaker 0: But on the other hand having the Fifth Amendment.

316
00:17:45,852 --> 00:17:52,719
Speaker 0: in a world where you know We can use information to lock things and people you know are you know?

317
00:17:52,900 --> 00:18:02,000
Speaker 0: Basically, we can use information not beat that was protected by law To seal up evidence and make it impossible to get at legally.

318
00:18:02,522 --> 00:18:05,915
Speaker 0: It's it's easier to get away with things if you're smarter and think about this.

319
00:18:05,935 --> 00:18:20,527
Speaker 1: this wasn't even that Deniable encryption where you could give someone a key that works and decrypts data But there's no way to prove beyond any doubt at all or even any reasonable doubt even any like unreasonable doubt That there's more or less data in there.

320
00:18:20,627 --> 00:18:21,791
Speaker 1: It's perfectly deniable.

321
00:18:22,113 --> 00:18:23,999
Speaker 1: Yep within you know and layers this guy.

322
00:18:24,360 --> 00:18:28,960
Speaker 0: This was not the strongest most best encryption you could use for avoiding the law.

323
00:18:29,000 --> 00:18:34,527
Speaker 0: There are better ways to do it and that the guy did it a sort of shoddy way And he still got away with it.

324
00:18:34,547 --> 00:18:35,974
Speaker 1: see the moral here is pretty simple.

325
00:18:36,034 --> 00:18:39,419
Speaker 0: on his Alienware laptop Which shows you how smart this guy is you should?

326
00:18:40,500 --> 00:18:42,339
Speaker 1: Encrypt your important business?

327
00:18:43,120 --> 00:18:47,910
Speaker 1: Yeah, probably and if you're using Gmail This won't hide it from Google.

328
00:18:48,192 --> 00:18:49,459
Speaker 1: It'll hide it from other people.

329
00:18:50,643 --> 00:18:53,621
Speaker 1: type HTTP s Doesn't?

330
00:18:53,842 --> 00:18:54,665
Speaker 0: it does it on its own.

331
00:18:54,906 --> 00:18:55,347
Speaker 1: No it doesn't.

332
00:18:55,367 --> 00:18:58,097
Speaker 1: it goes back to HTTP after you log in.

333
00:18:58,117 --> 00:18:58,860
Speaker 0: are you sure?

334
00:18:59,161 --> 00:19:00,467
Speaker 1: I sniffed it unless it's changed.

335
00:19:00,889 --> 00:19:01,673
Speaker 0: I'll have to check guys.

336
00:19:01,713 --> 00:19:03,180
Speaker 1: I'm logged in at work today.

337
00:19:03,381 --> 00:19:09,020
Speaker 0: You can also use fire GPG to add Pete fire PGP GPG fire GPG.

338
00:19:09,120 --> 00:19:12,189
Speaker 0: I'm PGP adding G to add encryption to your Gmail.

339
00:19:12,270 --> 00:19:15,620
Speaker 1: Yeah, don't use PGP use GPG exactly.

340
00:19:15,640 --> 00:19:15,740
Speaker 1: good

341
00:19:15,760 --> 00:19:16,783
Speaker 0: God all right doing news,

342
00:19:17,385 --> 00:19:29,513
Speaker 1: so I'm not gonna talk about this in depth partly because I think I want to do a whole show About it, but there's this article on slash dot by some guy Nicholas Carr who wrote a book about it Nicholas

343
00:19:29,533 --> 00:19:29,758
Speaker 0: truck

344
00:19:30,920 --> 00:19:31,945
Speaker 1: Nicholas autobus

345
00:19:32,507 --> 00:19:33,652
Speaker 0: out the booth.

346
00:19:33,693 --> 00:19:35,059
Speaker 1: that was pretty bad set up.

347
00:19:35,461 --> 00:19:39,779
Speaker 1: so basically the headline is is the IT department dead?

348
00:19:39,799 --> 00:19:43,654
Speaker 0: and As long as companies have computers probably not.

349
00:19:43,674 --> 00:19:44,539
Speaker 1: the answer is no.

350
00:19:45,864 --> 00:19:47,820
Speaker 1: Now the thing is this article is kind of weird.

351
00:19:47,820 --> 00:19:55,500
Speaker 1: I have to read it again to really figure out because it's pretty much just PR fluff to sell this book and the book is Somewhat inflammatory just to sell better.

352
00:19:56,264 --> 00:19:59,420
Speaker 0: But there seems to be a lot of people writing inflammatory books just to sell them.

353
00:19:59,802 --> 00:20:02,378
Speaker 1: But it seems like the idea here is that?

354
00:20:02,920 --> 00:20:11,403
Speaker 1: Computers are so good now and you can centralize things with things like Google so much that you don't need IT support anymore You can.

355
00:20:11,443 --> 00:20:13,611
Speaker 1: just people can just do it all on their own.

356
00:20:14,052 --> 00:20:15,759
Speaker 1: and the answer to that is ha ha ha.

357
00:20:16,742 --> 00:20:30,397
Speaker 0: If they I guess you know he's right in a way in that it seems like people are so Ignorant that if they just sort of did things their own way and figured out on their own Except they wouldn't not yet right then at least it's like.

358
00:20:30,457 --> 00:20:43,006
Speaker 0: right now We're in a situation where people the IT Departments are forcing the employees to do things the way that they know is best, but the employees are having hard time Doing things the best way.

359
00:20:43,067 --> 00:20:44,051
Speaker 0: they can't live up to that.

360
00:20:44,111 --> 00:20:46,300
Speaker 1: the thing is most employees can't even do things at all.

361
00:20:46,461 --> 00:20:56,280
Speaker 0: I know I know, but if you just let them do it on their own know that nothing will get done Or they'll just do it the best way they know how which is the best that they would do it anyway.

362
00:20:56,300 --> 00:21:01,220
Speaker 1: No It's actually far worse because then all your data gets compromised with spyware and Trojans.

363
00:21:01,840 --> 00:21:04,208
Speaker 0: All those sorts of safeguards go away.

364
00:21:04,469 --> 00:21:05,773
Speaker 1: pretty much that.

365
00:21:05,793 --> 00:21:23,500
Speaker 1: to sum my position up on this article the the the things in it that are not bullshit are very few and far between and Basically the the only thing I can really agree with is that yes It's true that most companies really kind of do redundant IT work, or it's not really even IT work.

366
00:21:23,540 --> 00:21:25,238
Speaker 1: It's computer work that they call IT.

367
00:21:26,021 --> 00:21:33,879
Speaker 1: but a lot of companies invest a lot of money in technology infrastructure without necessarily understanding what that infrastructure actually does.

368
00:21:33,899 --> 00:21:44,768
Speaker 1: and It's those poor and stupid uses of technology by people who don't know better that give the perception among a lot of employees and employers That technology and IT are a big money sink.

369
00:21:45,069 --> 00:21:51,150
Speaker 1: companies that use IT correctly to manage their information and their business processes Save so much money.

370
00:21:51,170 --> 00:21:52,074
Speaker 1: It's you.

371
00:21:52,114 --> 00:21:53,319
Speaker 1: you couldn't even believe it.

372
00:21:53,661 --> 00:22:01,200
Speaker 1: The problem is most people can't do that and aren't willing to pay people who know how to do it and are willing to learn How to do it because it's not easy.

373
00:22:01,240 --> 00:22:05,994
Speaker 0: It requires lots of changing the way you think about business and the way you do business.

374
00:22:06,014 --> 00:22:09,315
Speaker 0: you have to change and people fear change More than they fear anything else.

375
00:22:09,538 --> 00:22:15,080
Speaker 1: Yep The sunk cost fallacy is probably the biggest thing holding back IT infrastructure in the entire world today.

376
00:22:15,660 --> 00:22:18,389
Speaker 0: Probably the sunk cost fallacy holding a lot of things back.

377
00:22:18,771 --> 00:22:23,470
Speaker 1: Yeah now, uh, you know the sunk cost fallacy I think keeps a lot of people playing World of Warcraft.

378
00:22:23,651 --> 00:22:25,401
Speaker 1: Yeah, I already made it to level 60.

379
00:22:25,401 --> 00:22:29,968
Speaker 0: It also keeps a lot of people from dropping out of school Yeah, and that's that's funny.

380
00:22:30,008 --> 00:22:30,510
Speaker 1: But you know what?

381
00:22:30,550 --> 00:22:32,759
Speaker 1: There are a lot of people at RIT who probably should have dropped out.

382
00:22:33,101 --> 00:22:38,060
Speaker 1: Yep, we had some friends who were smart enough to drop out early on and go somewhere that was more suited to them.

383
00:22:44,770 --> 00:22:46,114
Speaker 1: Things of the day.

384
00:22:46,616 --> 00:22:48,421
Speaker 1: so, uh, we like Futurama.

385
00:22:48,742 --> 00:22:51,330
Speaker 1: the new Futurama was okay wasn't super great.

386
00:22:51,410 --> 00:22:52,237
Speaker 1: It was pretty good.

387
00:22:52,519 --> 00:22:53,103
Speaker 0: It was okay.

388
00:22:53,144 --> 00:22:53,930
Speaker 0: It got some chuckles.

389
00:22:54,010 --> 00:22:57,160
Speaker 0: I think the Family Guy movie was better than the Futurama movie.

390
00:22:57,240 --> 00:23:02,256
Speaker 0: as far as direct-to-video Fox cartoons go I think you're forgetting.

391
00:23:02,376 --> 00:23:03,881
Speaker 1: everybody loves Hypno toad.

392
00:23:04,323 --> 00:23:06,450
Speaker 0: That was the when the extras better than the movie.

393
00:23:06,491 --> 00:23:07,270
Speaker 0: That's not a good thing.

394
00:23:07,310 --> 00:23:11,485
Speaker 1: That was that was one of the defining moments in my life is watching an entire episode of.

395
00:23:11,566 --> 00:23:12,650
Speaker 1: everybody loves Hypno toad.

396
00:23:12,710 --> 00:23:13,292
Speaker 0: Are you serious?

397
00:23:13,332 --> 00:23:14,395
Speaker 0: Not ironically.

398
00:23:14,415 --> 00:23:15,117
Speaker 1: Are you serious?

399
00:23:15,258 --> 00:23:17,384
Speaker 1: Not best moments defining moments.

400
00:23:17,625 --> 00:23:19,230
Speaker 1: It defined a part of me.

401
00:23:19,571 --> 00:23:25,790
Speaker 0: I think that part of me was defined on an April Fool's Day many years past and that this was just a reminder of that.

402
00:23:26,432 --> 00:23:35,835
Speaker 1: I was not party to that because I while I caused that April Fool's Day that that that momentous occasion for many other people I Did not suffer through it.

403
00:23:35,955 --> 00:23:40,951
Speaker 1: I in fact was standing outside the room waiting for people to figure it out and I didn't suffer through It.

404
00:23:40,991 --> 00:23:47,230
Speaker 0: but I sat there sort of watching the other suffer through it, but I watch Hypno toad non-ironically.

405
00:23:48,051 --> 00:23:49,075
Speaker 1: Anyway, I'll make this quick.

406
00:23:49,115 --> 00:23:53,350
Speaker 1: Remember when bender brewed beer inside bender bender brow?

407
00:23:54,011 --> 00:23:55,315
Speaker 0: Yeah, that's a good episode.

408
00:23:55,636 --> 00:23:59,967
Speaker 1: someone made a bender that you can in which you can brew beer.

409
00:24:00,348 --> 00:24:04,239
Speaker 0: Does it have a Poorly placed tap possibly.

410
00:24:04,380 --> 00:24:05,042
Speaker 1: No, it doesn't.

411
00:24:05,263 --> 00:24:05,564
Speaker 0: I thought it.

412
00:24:05,665 --> 00:24:06,267
Speaker 0: I know it does.

413
00:24:06,387 --> 00:24:06,990
Speaker 0: actually I saw it.

414
00:24:07,110 --> 00:24:08,234
Speaker 1: I didn't actually look at it yet.

415
00:24:08,415 --> 00:24:10,984
Speaker 0: The tap is in a quite a bad position.

416
00:24:11,004 --> 00:24:11,586
Speaker 0: Oh, wow.

417
00:24:11,606 --> 00:24:17,335
Speaker 1: Yes Okay This is however Extremely well done.

418
00:24:17,375 --> 00:24:25,266
Speaker 1: like the level of quality is too much effort Wallet it reeks of effort while it reeks of effort at the same time kind of effort.

419
00:24:25,307 --> 00:24:26,270
Speaker 0: bender would not expend.

420
00:24:26,734 --> 00:24:28,229
Speaker 1: It is really really cool.

421
00:24:28,751 --> 00:24:35,109
Speaker 1: Now the only thing the only thing that worries me is I really really hope that no one tries to have sex with it.

422
00:24:36,840 --> 00:24:40,709
Speaker 0: Okay Anyway, this is a funny video that's gone around the Internet's.

423
00:24:40,790 --> 00:24:47,412
Speaker 0: You've probably seen it already if you're paying attention the Internet's but maybe you haven't seen it and the videos called you suck at Photoshop Number one.

424
00:24:47,873 --> 00:24:55,350
Speaker 0: Oh you're doing this and basically some guy made a little Photoshop tutorial and I thought you know I wasn't quite sure what it was when I watched it.

425
00:24:55,410 --> 00:24:57,358
Speaker 0: I just saw links that said you suck at Photoshop.

426
00:24:57,398 --> 00:25:02,236
Speaker 1: click here and suck is spelled wrong in that kind of Spelled wrong on the YouTube.

427
00:25:02,637 --> 00:25:05,485
Speaker 1: So but all the posts I saw to it were sujk.

428
00:25:05,625 --> 00:25:07,230
Speaker 0: Well, it's as you see K on YouTube.

429
00:25:07,291 --> 00:25:18,910
Speaker 0: But anyway, there's a video and this guy it's just a screencast of his Mac where he's got Photoshop and says other Adobe photo program and he's Talking over this screen capture, right?

430
00:25:19,290 --> 00:25:23,809
Speaker 0: And he's basically gonna demo how to do some stuff in Photoshop and he sort of does.

431
00:25:24,792 --> 00:25:26,179
Speaker 0: He taught me how to do stuff in Photoshop.

432
00:25:26,199 --> 00:25:26,863
Speaker 0: I didn't know how to do.

433
00:25:27,325 --> 00:25:28,733
Speaker 0: I don't have Photoshop those It doesn't matter.

434
00:25:29,337 --> 00:25:30,504
Speaker 0: and I was pretty interesting.

435
00:25:31,028 --> 00:25:40,695
Speaker 0: It's He's sort of in his Photoshop tutorial telling a story in the way a humorous Story and it's.

436
00:25:41,137 --> 00:25:55,910
Speaker 0: I feel like this sort of joke has been done before but I can't remember exactly when and where and this is a good execution of this joke and Humor is there and if you want to be making the funnies, you should be watching this video.

437
00:25:56,251 --> 00:25:58,021
Speaker 1: I found this just utterly hilarious.

438
00:25:58,041 --> 00:25:58,805
Speaker 1: I don't know what it is.

439
00:25:59,026 --> 00:25:59,830
Speaker 0: It's pretty funny.

440
00:25:59,830 --> 00:26:00,593
Speaker 0: I didn't think was utterly.

441
00:26:00,613 --> 00:26:11,582
Speaker 1: I think what made it hilarious for me is that I've always liked very kind of Straight man humor like Steven Wright always so that with a deadpan straight face You know your dictionary zebra did it never did.

442
00:26:11,642 --> 00:26:12,847
Speaker 1: awesome dehydrated water.

443
00:26:12,867 --> 00:26:15,882
Speaker 1: now I don't know what to add got some spot remover.

444
00:26:15,902 --> 00:26:16,565
Speaker 1: Now.

445
00:26:16,585 --> 00:26:17,510
Speaker 1: I can't find my dog.

446
00:26:18,151 --> 00:26:33,900
Speaker 1: I just I love that sort of deadpan humor and I think what makes makes something like doubly funny for me is if you could look at it and maybe if you weren't the brightest bulb or if you weren't paying attention or just it is Conceivable that you would watch it and not realize it was a joke.

447
00:26:34,341 --> 00:26:37,511
Speaker 0: I think that's something that excellent humor does very well.

448
00:26:37,531 --> 00:26:45,300
Speaker 0: is that it makes the person laughing at it feel smart that you know If you're if you tell a joke right that anyone in the world will get the joke.

449
00:26:45,901 --> 00:26:52,074
Speaker 0: But anyone who gets the joke feels like other people won't get the joke whether they will or they won't.

450
00:26:54,861 --> 00:26:57,719
Speaker 0: Penny arcade and I know that only video game people understand it.

451
00:26:58,145 --> 00:26:59,159
Speaker 0: It adds to the joke.

452
00:26:59,421 --> 00:27:02,540
Speaker 0: So the best joke in the world is the inside joke.

453
00:27:03,022 --> 00:27:06,855
Speaker 0: But the best joke in the world can't be an inside joke because it's funny to so few people.

454
00:27:06,895 --> 00:27:12,880
Speaker 0: you need a joke where everyone Feels like it's an inside joke or it makes them feel smarter or better than other people.

455
00:27:13,342 --> 00:27:16,175
Speaker 0: But it makes everyone feel that way and that's just perfect joke.

456
00:27:16,396 --> 00:27:18,305
Speaker 1: It wasn't overdone it wasn't overproduced.

457
00:27:18,445 --> 00:27:23,583
Speaker 1: all the all the quips and all the humorous bits were Extremely subtle.

458
00:27:23,623 --> 00:27:24,727
Speaker 1: like they they were.

459
00:27:24,787 --> 00:27:28,380
Speaker 0: subtly starts out real subtle and he gets less subtle as it goes on.

460
00:27:28,440 --> 00:27:32,631
Speaker 1: Yeah, but even then it's in such a believable progression in terms of like.

461
00:27:32,672 --> 00:27:37,099
Speaker 1: you could see someone doing this not as a joke But you know, this is a joke.

462
00:27:37,421 --> 00:27:42,640
Speaker 1: But yet, you know, there are people out there who feel like this and have done this sort of thing and it wasn't a joke.

463
00:27:43,041 --> 00:27:44,966
Speaker 1: Yep, I hope it was a joke.

464
00:27:45,528 --> 00:27:46,270
Speaker 0: All right main bit.

465
00:27:46,651 --> 00:27:46,992
Speaker 1: All right.

466
00:27:47,073 --> 00:27:50,182
Speaker 1: So speaking of having sex with bender Oh good.

467
00:27:50,222 --> 00:27:55,660
Speaker 1: God hungry Joe posts in the forums a while ago, and I'm surprised how little discussion is generated.

468
00:27:56,543 --> 00:27:57,900
Speaker 0: Well, you wanted to talk about this.

469
00:27:57,980 --> 00:28:03,241
Speaker 1: So well part the other reason I really wanted to talk about this because Scott couldn't come up with anything better and he agreed To it.

470
00:28:03,321 --> 00:28:03,582
Speaker 0: Yeah.

471
00:28:03,602 --> 00:28:06,332
Speaker 0: Well, I I'm still because you wanted to do this.

472
00:28:06,372 --> 00:28:06,653
Speaker 0: you had.

473
00:28:06,673 --> 00:28:11,860
Speaker 1: it's up to you to get the discussion rolling Alright, well basically this was what was posted in our forum.

474
00:28:12,201 --> 00:28:28,205
Speaker 1: David Levy has a new book title love and sex with robots in which he predicts that robot technology will allow for such human-like creations in the near future that we can follow in love with them that the robots can at least mimic that they love us back and that they will be Viable sex partners.

475
00:28:28,265 --> 00:28:32,980
Speaker 1: now I submit to you that this has already occurred and my evidence is the dildo.

476
00:28:33,060 --> 00:28:35,000
Speaker 1: It is a viable sex partner.

477
00:28:35,462 --> 00:28:40,640
Speaker 1: It may not love you back unless you have double D cells, but it is in fact a viable sex partner.

478
00:28:40,740 --> 00:28:41,965
Speaker 1: You can have sex with it.

479
00:28:42,205 --> 00:28:45,537
Speaker 0: Yeah, I have a better evidence than that that this has already happened.

480
00:28:45,758 --> 00:28:46,320
Speaker 0: real dolls?

481
00:28:46,702 --> 00:28:49,300
Speaker 0: No, the the moe is there.

482
00:28:49,440 --> 00:28:58,793
Speaker 0: I mean there are sick dudes out there that I do not condone but they honestly I think these sicko people They honestly fall in love with these animated fictional character.

483
00:28:58,813 --> 00:28:58,914
Speaker 1: Now.

484
00:28:58,934 --> 00:29:00,720
Speaker 1: We're not talking 4chan fat thing.

485
00:29:00,720 --> 00:29:02,405
Speaker 1: We're not talking someone masturbates to it.

486
00:29:02,425 --> 00:29:09,987
Speaker 1: We're talking people actually have real strong emotions toward moe characters and bad shows.

487
00:29:10,047 --> 00:29:17,813
Speaker 0: yeah, these people actually have fictional characters and while they may not physically have Sex with a fictional character because it's just a drawing on it.

488
00:29:17,934 --> 00:29:19,140
Speaker 1: Oh, you can print it out.

489
00:29:19,300 --> 00:29:21,690
Speaker 0: Yeah, they might print it out or they might have.

490
00:29:21,971 --> 00:29:22,875
Speaker 1: they might have a real.

491
00:29:23,096 --> 00:29:24,060
Speaker 1: I wasn't being serious.

492
00:29:24,422 --> 00:29:27,959
Speaker 1: I don't think many people have printed out a piece of paper on their inkjet and then had sex with it.

493
00:29:28,221 --> 00:29:28,783
Speaker 0: No, but they had.

494
00:29:28,923 --> 00:29:34,610
Speaker 0: these people have like real dolls and they have all sorts of sicko stuff that I you know I creased me out.

495
00:29:34,832 --> 00:29:43,337
Speaker 0: I'm not comfortable with it But there are people out there who are effectively falling in love with and having sex with things that are not human beings.

496
00:29:43,357 --> 00:29:46,026
Speaker 1: I Just I was thinking of disturbing things.

497
00:29:46,087 --> 00:29:57,133
Speaker 0: All right, so yeah, it's all disturbing but it's it's happening and I really don't see having sex with say a Robot sort of Android that imitates a human being being much different.

498
00:29:57,495 --> 00:30:00,302
Speaker 1: Well, I think there is definitely a Separation.

499
00:30:00,322 --> 00:30:09,153
Speaker 1: I mean some people can make this distinction some people don't but a lot of people do very much separate Sex and love or sex and emotion people.

500
00:30:09,233 --> 00:30:09,916
Speaker 0: I separate them.

501
00:30:10,137 --> 00:30:17,260
Speaker 0: people will have sex They can go together but they are two separate things and they will enjoy their best together sort of like chips and salsa.

502
00:30:18,221 --> 00:30:21,674
Speaker 0: But you can just eat salsa and you can just eat chips if you want to.

503
00:30:21,694 --> 00:30:23,460
Speaker 1: it was actually a pretty apt analogy.

504
00:30:23,681 --> 00:30:25,408
Speaker 1: Yeah, all right to continue this.

505
00:30:25,870 --> 00:30:28,120
Speaker 1: of course, there is nothing new with this prediction.

506
00:30:28,220 --> 00:30:30,768
Speaker 1: It's one of the oldest tropes in science fiction, you know.

507
00:30:30,788 --> 00:30:37,570
Speaker 1: that trope guy makes a robot falls in love with the robot Robot kills him because it doesn't actually love him back and doesn't.

508
00:30:37,610 --> 00:30:38,412
Speaker 1: it's just a machine.

509
00:30:38,433 --> 00:30:42,065
Speaker 0: Yeah every ghost in the shell story Yeah, half of them.

510
00:30:42,206 --> 00:30:45,498
Speaker 1: Well, the other half of ghost in the shell is it's not actually a machine.

511
00:30:45,558 --> 00:30:46,060
Speaker 1: It's sentient.

512
00:30:46,241 --> 00:30:47,186
Speaker 0: Yes, what do we do?

513
00:30:47,186 --> 00:30:48,191
Speaker 0: 75% of Masamune shiro stories?

514
00:30:50,781 --> 00:30:55,474
Speaker 1: They can say one thing though 100% of Masamune shiro stories have the big butt.

515
00:30:56,016 --> 00:30:56,176
Speaker 1: Yeah.

516
00:30:56,638 --> 00:30:56,858
Speaker 1: Okay.

517
00:30:56,979 --> 00:30:57,340
Speaker 1: It's there.

518
00:30:57,742 --> 00:31:00,500
Speaker 0: Yeah, that guy let's get the bus shiro tasm.

519
00:31:00,841 --> 00:31:06,480
Speaker 1: If we'd done an episode on shiro just like as like the body of his work just go on with what you're talking about.

520
00:31:06,480 --> 00:31:07,325
Speaker 0: So I'm trying to kill time.

521
00:31:07,627 --> 00:31:10,605
Speaker 1: I'm not trying to kill time mustn't kill time boy Must spend time.

522
00:31:10,625 --> 00:31:17,360
Speaker 1: Let's cherish it like five bucks to go get loaded loaded on Sexy robots, right?

523
00:31:17,600 --> 00:31:22,559
Speaker 1: So can we become so attached to a machine that we can be said to love it?

524
00:31:23,100 --> 00:31:25,560
Speaker 1: Would we feel gratified if a machine mimic?

525
00:31:26,340 --> 00:31:28,939
Speaker 0: And if you're asking questions, why don't we answer them one at a time one by one?

526
00:31:29,260 --> 00:31:33,652
Speaker 1: All right, so can't know let's do this in the royal we sense as humans.

527
00:31:34,013 --> 00:31:35,477
Speaker 1: can human the royal?

528
00:31:35,497 --> 00:31:37,629
Speaker 0: we saw only Kings Which includes me.

529
00:31:37,649 --> 00:31:43,619
Speaker 1: can Humans become so attached to machines that they can be said to love them?

530
00:31:43,679 --> 00:31:50,488
Speaker 1: now I think before I mean, I think the real tricky part here is that you know people always assume All right, it's either human or it isn't.

531
00:31:50,528 --> 00:31:53,059
Speaker 1: it's either a machine or it's a human being.

532
00:31:53,662 --> 00:31:57,600
Speaker 1: But what exactly is the line between sentience and not sentience?

533
00:32:00,542 --> 00:32:06,232
Speaker 1: During tests during tests, uh, I'm just picking something I know cuz I submit that there are some.

534
00:32:06,372 --> 00:32:11,731
Speaker 1: there have been several monkeys Well apes at least in history that could pass the Turing test.

535
00:32:11,972 --> 00:32:13,135
Speaker 1: All right, so are they sentient?

536
00:32:13,496 --> 00:32:17,028
Speaker 1: maybe so well Maybe you can't I don't know.

537
00:32:17,108 --> 00:32:18,594
Speaker 0: I'm just I'm just shooting out there.

538
00:32:18,734 --> 00:32:22,591
Speaker 1: I know I'm not making a stance yet I mean, I think the Turing test is the closest we've got.

539
00:32:22,631 --> 00:32:29,680
Speaker 1: but even then that really only takes into account human intelligence or intelligence recognizable as Exactly what we expect.

540
00:32:29,700 --> 00:32:34,980
Speaker 0: I know some incredible alien could come with advanced alien technology and still not understand the Turing test to be able to take it.

541
00:32:35,402 --> 00:32:39,162
Speaker 1: So I guess all right is sentience the line I mean.

542
00:32:39,202 --> 00:32:40,546
Speaker 1: what is it?

543
00:32:40,686 --> 00:32:49,289
Speaker 1: What makes having sex with the dildo different from having sex with say your Real doll, but or your pool cleaner.

544
00:32:49,309 --> 00:32:53,840
Speaker 0: Well, if you're talking about sex alone, right just the salsa, right?

545
00:32:53,920 --> 00:32:55,359
Speaker 0: I don't know why sex is the salsa, but

546
00:32:56,802 --> 00:33:05,820
Speaker 1: You know, it seems to fit because I don't I wouldn't want to have sex with a chip But having sex with salsa wouldn't be that bad unless unless it was a habanero salsa

547
00:33:06,881 --> 00:33:08,547
Speaker 0: You could just if you sealed the tip.

548
00:33:08,587 --> 00:33:09,350
Speaker 0: it wouldn't be so again.

549
00:33:09,430 --> 00:33:11,116
Speaker 1: Anyway, let's not go there.

550
00:33:11,277 --> 00:33:12,059
Speaker 0: Let's not go there.

551
00:33:12,702 --> 00:33:15,796
Speaker 0: All right, if you're talking about just the salsa, I just pictured everyone in the front row.

552
00:33:15,816 --> 00:33:19,235
Speaker 1: crew was thinking to themselves I'm never fucking having salsa at rims house again.

553
00:33:19,316 --> 00:33:24,365
Speaker 0: good more for us Untainted salsa Of course.

554
00:33:24,446 --> 00:33:26,178
Speaker 0: if they see us eating it they'll know not to eat it.

555
00:33:30,183 --> 00:33:35,233
Speaker 0: They'll know it's safe to eat.

556
00:33:35,273 --> 00:33:37,497
Speaker 0: if we right we have to eat it in secret.

557
00:33:37,517 --> 00:33:38,038
Speaker 0: so they don't know.

558
00:33:40,202 --> 00:33:42,519
Speaker 0: They don't know which sauces are good and which ones are tainted anyway.

559
00:33:42,660 --> 00:33:43,544
Speaker 1: So what were you saying?

560
00:33:43,905 --> 00:33:46,314
Speaker 0: I was saying you're talking about just salsa.

561
00:33:46,836 --> 00:33:47,539
Speaker 0: You got to get the good.

562
00:33:47,579 --> 00:33:53,667
Speaker 0: now If you're talking about just salsa just sex, right Sex on its own is just.

563
00:33:54,089 --> 00:34:03,678
Speaker 0: you're playing with parts of your body that happen have a lot of nerve you're stimulating nerve endings and then your brain is releasing chemicals that make you feel good and That's about it.

564
00:34:03,800 --> 00:34:09,175
Speaker 0: So whatever way you make that happen if that's your only goal is to it's.

565
00:34:09,195 --> 00:34:09,657
Speaker 0: basically.

566
00:34:09,857 --> 00:34:11,924
Speaker 0: it's no different than like You know snorting cocaine.

567
00:34:11,964 --> 00:34:16,800
Speaker 0: your brain releases chemicals that make you feel good because you stimulated nerve endings.

568
00:34:17,322 --> 00:34:19,793
Speaker 0: I mean anyway, you stimulate those nerve endings.

569
00:34:20,395 --> 00:34:21,299
Speaker 0: What's wrong with that?

570
00:34:21,699 --> 00:34:24,560
Speaker 1: I mean doesn't matter how because it's kind of relevant ghost in the shell.

571
00:34:24,801 --> 00:34:39,900
Speaker 1: there was that there's a lot of talk in the manga about the idea that if you're a cyborg or if we have such Technologies where we can understand the brain so well instead of having physical sex people can just stimulate each other's pleasure centers directly.

572
00:34:40,442 --> 00:34:43,070
Speaker 1: Yep, and does that still count as salsa?

573
00:34:43,391 --> 00:34:52,527
Speaker 0: Yeah, I mean it might be more fun if say someone else who are stimulating your nerve endings in a Unpredictable or superior fashion.

574
00:34:52,567 --> 00:34:53,853
Speaker 0: because you know, there are certain ways.

575
00:34:53,913 --> 00:34:55,659
Speaker 0: It's not easy to stimulate the nerve endings.

576
00:34:55,659 --> 00:35:02,328
Speaker 0: They're pretty complex, you know and on your own you can only do so many things and with more people You can do different things.

577
00:35:02,428 --> 00:35:04,480
Speaker 1: Everybody was gaga deep in other people.

578
00:35:04,821 --> 00:35:09,940
Speaker 0: Yeah, and with a robot the right kind of robot, maybe there'd be more possibilities available to you.

579
00:35:10,040 --> 00:35:14,907
Speaker 0: But if you're just talking about nerve ending stimulation Anything goes.

580
00:35:14,967 --> 00:35:16,860
Speaker 1: I guess, you know, there's actually a comic I remember.

581
00:35:16,980 --> 00:35:25,260
Speaker 1: I don't remember if this was a thin H line or if it was a Sunday morning coffee But it was a lab and they made a sex bot.

582
00:35:25,440 --> 00:35:30,980
Speaker 1: It was up, you know, but classic anime kind of micro 2010 the perverted manga not the cute anime.

583
00:35:31,542 --> 00:35:33,267
Speaker 1: It's a robot you have sex with.

584
00:35:33,427 --> 00:35:38,432
Speaker 1: oh my god, and the scientists are of course men and the woman scientist is like What's wrong with you?

585
00:35:38,452 --> 00:35:39,140
Speaker 1: This is disgusting.

586
00:35:39,381 --> 00:35:47,448
Speaker 1: Why would you have sex with a machine and then blah blah blah blah and then that night she's using her dildo And then she stopped.

587
00:35:47,468 --> 00:35:48,414
Speaker 1: she's like wait a minute.

588
00:35:48,918 --> 00:35:49,937
Speaker 1: Ah Damn it.

589
00:35:50,783 --> 00:35:51,004
Speaker 0: Yep.

590
00:35:51,265 --> 00:35:51,466
Speaker 0: All right.

591
00:35:51,486 --> 00:35:52,550
Speaker 0: So now you're gonna talk about the chips.

592
00:35:52,570 --> 00:35:53,333
Speaker 0: You wanna talk about the chips.

593
00:35:53,735 --> 00:35:55,381
Speaker 1: Maybe we should talk about the chips All right.

594
00:35:55,422 --> 00:36:03,389
Speaker 0: So the thing with the chips right is that you basically have a strong Emotional attachment to another person.

595
00:36:03,429 --> 00:36:04,693
Speaker 0: that's considered normal.

596
00:36:04,794 --> 00:36:05,135
Speaker 0: I guess.

597
00:36:05,456 --> 00:36:05,636
Speaker 1: Okay.

598
00:36:05,737 --> 00:36:06,499
Speaker 1: Well, it's it's love.

599
00:36:06,579 --> 00:36:07,784
Speaker 1: now We can start.

600
00:36:07,825 --> 00:36:09,451
Speaker 1: I mean first, you know, we have to define our terms.

601
00:36:09,532 --> 00:36:10,235
Speaker 1: what is love?

602
00:36:10,817 --> 00:36:13,370
Speaker 0: it's love It's the words love.

603
00:36:13,893 --> 00:36:15,080
Speaker 1: all you need is love.

604
00:36:16,180 --> 00:36:29,680
Speaker 0: Okay, right, but it it's viewed by me and I guess other people that having a strong Emotional attachment right because the strongest emotional attachment people ever have is to like, you know people they fall in love with right?

605
00:36:29,760 --> 00:36:35,140
Speaker 0: You really that's that's pretty much what comes down to and you know, you can have emotional attachments to other things.

606
00:36:35,661 --> 00:36:41,840
Speaker 0: But if they're that strong, it's sort of disturbing, you know, I mean like some people might love their teddy bear.

607
00:36:42,323 --> 00:36:47,468
Speaker 0: but if you love your teddy bear as much as you love Your wife that's sort of like.

608
00:36:48,131 --> 00:36:49,475
Speaker 0: yeah, it's a little weird.

609
00:36:49,575 --> 00:36:50,458
Speaker 1: See now it's easy to.

610
00:36:50,478 --> 00:36:52,332
Speaker 1: I mean It's kind of like with a lot of arguments.

611
00:36:52,372 --> 00:37:00,700
Speaker 1: It's very easy to say Well, that's and that's just because that's kinky and that's boobah Yeah, just because there's such a stark comparison.

612
00:37:00,760 --> 00:37:05,374
Speaker 1: But what about say the love for a pet versus the love for a fellow human being?

613
00:37:05,394 --> 00:37:08,945
Speaker 1: because now it's a lot closer in terms Of you know, it's a living thing.

614
00:37:09,186 --> 00:37:12,696
Speaker 1: It's it's it's it's probably intelligent to some degree.

615
00:37:12,716 --> 00:37:15,527
Speaker 1: it can respond Organically that sort of thing.

616
00:37:16,029 --> 00:37:18,480
Speaker 1: What about again, it comes down to sentience.

617
00:37:18,580 --> 00:37:19,242
Speaker 1: What's the line?

618
00:37:19,363 --> 00:37:24,620
Speaker 1: is love with a sentient being shared love different from one way love with a non sentient item?

619
00:37:25,161 --> 00:37:31,900
Speaker 0: Yeah, I mean do you really care if someone else has and I mean someone having an emotional attachment is something that's not real?

620
00:37:31,960 --> 00:37:35,960
Speaker 0: All right, I guess the robot is definitely real, right?

621
00:37:36,060 --> 00:37:40,157
Speaker 0: but I mean something that is not, you know, a human or is not the same species.

622
00:37:40,218 --> 00:37:42,925
Speaker 0: whatever is Disturbing.

623
00:37:42,945 --> 00:37:49,500
Speaker 0: I don't know exactly why is disturbing and have to think about it for a minute And I can't really think if I'm saying stuff like this, but it is disturbing.

624
00:37:50,401 --> 00:37:50,803
Speaker 1: That's the thing.

625
00:37:50,843 --> 00:37:57,220
Speaker 1: if you it's very this kind of argument or we're not really arguing It's just kind of a debate because I don't really have a position me there at all.

626
00:37:57,521 --> 00:37:59,469
Speaker 1: but there's the you can.

627
00:37:59,690 --> 00:38:03,463
Speaker 1: you can look at it from a purely like Subjective.

628
00:38:03,684 --> 00:38:06,660
Speaker 1: Well, I like this and I don't like this and this is okay This isn't okay.

629
00:38:06,981 --> 00:38:11,274
Speaker 1: And you can also kind of remove yourself from it and look at it from a purely clinical kind of.

630
00:38:11,756 --> 00:38:13,040
Speaker 1: what exactly is the line?

631
00:38:13,160 --> 00:38:14,446
Speaker 1: You know like like bestiality.

632
00:38:14,486 --> 00:38:17,220
Speaker 1: there's a word I can throw out there since we're throwing out words.

633
00:38:17,623 --> 00:38:19,397
Speaker 0: Well, I think the problem with bestiality

634
00:38:19,437 --> 00:38:35,580
Speaker 1: is that Regardless of that just I know what you're gonna say, but for me purely like emotional or subjective stance most people are disgusted by the idea of bestiality or a lot of things like that and They wouldn't really think about exactly why it bothers them.

635
00:38:35,620 --> 00:38:37,711
Speaker 1: There's kind of just this innate disgust for it.

636
00:38:38,113 --> 00:38:48,940
Speaker 1: and yet at the same time clinically if you remove the emotion entirely you can look at it and say Alright well, obviously the non-sentient or the animal or whatever cannot give consent and blah blah blah danger.

637
00:38:50,081 --> 00:38:50,703
Speaker 1: And there's kind of.

638
00:38:51,024 --> 00:38:53,451
Speaker 1: there's two perspectives both of which condemn it.

639
00:38:53,852 --> 00:38:54,013
Speaker 1: Yep.

640
00:38:54,334 --> 00:38:56,440
Speaker 1: What do you do when it's not so clear-cut?

641
00:38:56,680 --> 00:39:00,433
Speaker 1: What uh, what about a computer or an Android or a robot?

642
00:39:00,473 --> 00:39:02,320
Speaker 1: That is I wrote it in basic.

643
00:39:02,785 --> 00:39:04,240
Speaker 1: I know I wrote it a hundred percent.

644
00:39:04,622 --> 00:39:08,879
Speaker 1: I know exactly how it works because I wrote the software and someone else falls in love with it.

645
00:39:09,181 --> 00:39:12,600
Speaker 1: Didn't they just fall in love with me by proxy or my programming skills?

646
00:39:13,202 --> 00:39:14,064
Speaker 0: I don't know it.

647
00:39:14,245 --> 00:39:18,840
Speaker 0: it's I mean people fall in love with other people's creations all the time.

648
00:39:18,901 --> 00:39:19,428
Speaker 0: I mean people.

649
00:39:19,468 --> 00:39:20,117
Speaker 0: have you know?

650
00:39:20,661 --> 00:39:23,350
Speaker 0: Someone made that anime that moe show.

651
00:39:23,390 --> 00:39:26,500
Speaker 0: there's some artist character designer and then someone else fell in love with it.

652
00:39:26,520 --> 00:39:29,607
Speaker 0: They didn't fall in love with the character designer they don't even know the characters, but maybe they did.

653
00:39:29,647 --> 00:39:45,730
Speaker 1: because think about it if you fall in love with an entity that was created wholly and Predictably by a person then you fall in love with something that was in created entirely by that person's mind And by proxy that person's creative output.

654
00:39:46,131 --> 00:39:52,837
Speaker 0: So if I fall in love with someone I'm I fall in love with their mom Because the mom did not create unambiguously the person.

655
00:39:53,199 --> 00:39:56,898
Speaker 0: now What if they Jeanette we get in the future and we're genetically engineering children.

656
00:39:56,938 --> 00:39:58,083
Speaker 0: exactly That's that.

657
00:39:58,585 --> 00:40:04,471
Speaker 1: if it was down to the point where you programmed the brain a hundred percent Exactly, because that's what I was saying.

658
00:40:04,511 --> 00:40:05,960
Speaker 1: It's a cyborg that I programmed.

659
00:40:06,463 --> 00:40:07,229
Speaker 1: I know the code.

660
00:40:07,490 --> 00:40:08,920
Speaker 1: the code does not act randomly.

661
00:40:10,342 --> 00:40:13,219
Speaker 1: The reactions it gives someone else could fall in love with it.

662
00:40:13,523 --> 00:40:16,166
Speaker 1: But yet I know Well it reacted that way.

663
00:40:16,246 --> 00:40:20,060
Speaker 1: it hugged them because it saw that their pupils were dilated by this degree and that sort of thing.

664
00:40:20,261 --> 00:40:26,851
Speaker 0: But how do you how do you explain when say there's a work of art that I may enjoy Yet the person who created that work of art.

665
00:40:26,911 --> 00:40:28,520
Speaker 0: I do not like them and that happens often.

666
00:40:28,821 --> 00:40:30,208
Speaker 1: Oh, that's very versa.

667
00:40:30,228 --> 00:40:32,540
Speaker 0: where I like someone like I said, I don't like their art.

668
00:40:32,600 --> 00:40:34,086
Speaker 1: They didn't fall in love with the person.

669
00:40:34,106 --> 00:40:36,435
Speaker 1: you fell in love with the output of the person.

670
00:40:36,495 --> 00:40:40,588
Speaker 1: what you fell in love with Was a construct that that person created.

671
00:40:41,009 --> 00:40:45,240
Speaker 1: Yep, actually and even further think about what's the uh, what's the line?

672
00:40:45,360 --> 00:40:46,671
Speaker 1: What is love versus?

673
00:40:46,731 --> 00:40:51,871
Speaker 1: I mean, I've had emotional Attachment and attraction to a lot of characters in fiction.

674
00:40:52,332 --> 00:40:54,620
Speaker 1: I've cried over people who never lived.

675
00:40:54,981 --> 00:41:00,518
Speaker 1: Yep, is that different than falling in love with something that didn't exist or only existed in someone else's mind.

676
00:41:00,558 --> 00:41:01,140
Speaker 1: What's the line?

677
00:41:02,242 --> 00:41:10,920
Speaker 0: I guess there's some sort of you know line that we sort of invent Semantically that doesn't really have a provable real space.

678
00:41:11,201 --> 00:41:13,166
Speaker 0: You know physical line that you know.

679
00:41:13,447 --> 00:41:23,497
Speaker 0: when you are attached to something enough then it suddenly becomes like, you know Undying love and hope some holy time bound to you by change that only omnipotence can bright.

680
00:41:23,577 --> 00:41:24,320
Speaker 0: and it's sort of like.

681
00:41:24,802 --> 00:41:28,640
Speaker 0: You know, no one can say exactly where the line is or whatever and whatever.

682
00:41:28,740 --> 00:41:33,560
Speaker 0: But I guess that's you know, that's what it's considered to be in in popular opinion.

683
00:41:33,921 --> 00:41:37,573
Speaker 1: But alright, so someone falls in love with the lot the got the line.

684
00:41:37,613 --> 00:41:39,379
Speaker 1: the machine I made that I wrote in basic.

685
00:41:39,660 --> 00:41:46,260
Speaker 1: now Let's say I made a machine that was a neural network, whatever and it goes in the shell style.

686
00:41:47,340 --> 00:41:54,379
Speaker 1: Effectively could pass the Turing test and as far as I could tell I could not predict its reactions a hundred percent anymore.

687
00:41:54,399 --> 00:41:58,899
Speaker 1: and Effectively as far as anyone can tell is sentient.

688
00:41:59,882 --> 00:42:01,106
Speaker 1: But it's a machine that I made.

689
00:42:01,126 --> 00:42:12,817
Speaker 0: I will what if I make a person a real person out of Atoms because I have nanotechnology and when I'm done, they're biologically identical to a you know, human being.

690
00:42:12,857 --> 00:42:14,303
Speaker 0: they're in the same species And everything.

691
00:42:14,323 --> 00:42:19,375
Speaker 0: they can even make babies one way or the other depending on the gender I make it and you fall in love with that.

692
00:42:19,395 --> 00:42:20,762
Speaker 0: It's no different I think.

693
00:42:20,862 --> 00:42:28,123
Speaker 1: what it comes down to my personal belief is that love between any two set be any two Entities.

694
00:42:28,183 --> 00:42:31,171
Speaker 1: I can't say being because what's the difference between an organic?

695
00:42:31,231 --> 00:42:31,793
Speaker 1: what like what's that?

696
00:42:31,813 --> 00:42:32,335
Speaker 1: What's a being?

697
00:42:32,375 --> 00:42:37,740
Speaker 1: but a plant is dendrophilius between any two any n entities.

698
00:42:37,740 --> 00:42:45,005
Speaker 1: I can't discriminate here any feelings of emotion between n entities of Similar levels of sentience.

699
00:42:45,607 --> 00:42:47,473
Speaker 1: I cannot find fault with them.

700
00:42:47,914 --> 00:42:49,560
Speaker 0: Yeah, it's really hard to figure out.

701
00:42:49,780 --> 00:42:50,082
Speaker 0: It's.

702
00:42:50,122 --> 00:42:53,680
Speaker 0: it's hard to say there's something wrong with anything unless someone's getting hurt.

703
00:42:53,820 --> 00:42:56,250
Speaker 0: I mean sometimes this kind of stuff.

704
00:42:56,270 --> 00:43:02,439
Speaker 0: There's someone getting hurt, you know, like One person loves someone else who isn't and they're not loved back.

705
00:43:04,740 --> 00:43:09,440
Speaker 0: Someone is in love with something and it's you know, it can't give consent cuz like an animal.

706
00:43:09,641 --> 00:43:12,980
Speaker 1: Yeah, if I love a cactus that relationship is not going to and it's not good.

707
00:43:14,905 --> 00:43:20,200
Speaker 0: Not the crushinator or even whatever robot falls in love with a person and the person doesn't you know love robots.

708
00:43:20,260 --> 00:43:22,668
Speaker 0: They love people only and they're not attracted to robot.

709
00:43:22,688 --> 00:43:24,494
Speaker 1: I think there was a tessica about that.

710
00:43:24,654 --> 00:43:32,625
Speaker 0: Yeah, mayhaps mayhaps Yes, and that the person could end up getting hurt by the crazed robot, you know Which is incredibly powerful and strong.

711
00:43:32,705 --> 00:43:35,494
Speaker 1: or maybe the robot is hurt by the person.

712
00:43:35,815 --> 00:43:37,620
Speaker 0: Maybe the robot is hurt by the person.

713
00:43:38,106 --> 00:43:38,653
Speaker 1: I guess it just.

714
00:43:38,794 --> 00:43:44,020
Speaker 1: I Cannot find fault with beings of similar sentience sharing emotional attachment.

715
00:43:44,882 --> 00:43:55,797
Speaker 1: As a result if there are sentient machines or machines that are effectively sentient and someone has feelings for it I can't look at that any differently than I look at someone having feelings for another human being.

716
00:43:55,818 --> 00:43:56,420
Speaker 0: right now.

717
00:43:56,440 --> 00:43:57,751
Speaker 0: Here's another thing to look at right?

718
00:43:57,993 --> 00:44:10,500
Speaker 0: There's a lot of basically, we you fall you biologically, you're attracted to other things in your species right, you know because you know evolution and things.

719
00:44:10,843 --> 00:44:12,700
Speaker 0: You know things that were attracted.

720
00:44:12,861 --> 00:44:26,040
Speaker 0: You know in any sort of non asexual organism right being biologically Programmed to be attracted to sexually and emotionally to things that you can procreate with is sort of an advantage.

721
00:44:26,140 --> 00:44:30,457
Speaker 0: You know, that's that's sort of how you know, it worked out, you know, if you didn't have that you'd have.

722
00:44:30,979 --> 00:44:53,877
Speaker 0: you know Like men and women not wanting each other and then they wouldn't make babies and humans wouldn't be around anymore Right now that gene or the genes that you know cause that you know are not present in everybody And you know you end up having some people who really can only you know Have these feelings toward things in their own species and some people can have it towards in their species and not.

723
00:44:53,917 --> 00:45:02,829
Speaker 0: and some of this You know stuff is you know, even have you know gender stuff going on and some of this is biological and some of it is not.

724
00:45:02,849 --> 00:45:11,887
Speaker 0: and The question might be is it good for the future of the species if we you know Take the selection pressure off of that?

725
00:45:11,987 --> 00:45:32,019
Speaker 0: and now maybe one day in the future when robots are So much better and you know than people because you just program the robot to be everything You know the perfect thing for you to love and we stop, you know We totally lose our attraction for people in the same species of you know The opposite gender for procreating and whatnot.

726
00:45:32,501 --> 00:45:41,940
Speaker 1: But what did even matter if we had full control over our genetic destiny and we just programmed ourselves or even became What if he had full control over robots but not yet full control over genetics?

727
00:45:42,642 --> 00:45:53,160
Speaker 1: See, I think the fundamental question and ain't any time this sort of issue comes up just comes down to very simply What is the seat of human consciousness because that determines the answers to a lot of these questions?

728
00:45:53,560 --> 00:45:58,516
Speaker 0: Like what about that episode of Futurama where he he's doing the robot and then everyone's doing robots?

729
00:45:58,536 --> 00:46:00,564
Speaker 1: and if everyone's doing robots And there's no more people.

730
00:46:00,725 --> 00:46:00,926
Speaker 1: Yep.

731
00:46:01,288 --> 00:46:01,589
Speaker 1: Yeah.

732
00:46:01,931 --> 00:46:03,016
Speaker 1: Yeah, that's tricky.

733
00:46:03,298 --> 00:46:10,680
Speaker 0: It is tricky And it and see that that's a situation where there could be some harm if everyone's doing robots and then we run out of people.

734
00:46:11,202 --> 00:46:11,564
Speaker 0: Oh, wow.

735
00:46:11,745 --> 00:46:13,673
Speaker 1: I realized that looking at the rest of the questions here.

736
00:46:13,694 --> 00:46:14,778
Speaker 1: We kind of answered most of them.

737
00:46:14,859 --> 00:46:15,080
Speaker 0: Did we?

738
00:46:15,402 --> 00:46:21,920
Speaker 1: Alright, alright Would we feel gratified if a machine mimicked loving us back or would we realize that it was just acting in accordance with its programming?

739
00:46:22,140 --> 00:46:24,674
Speaker 0: Well, I think that some people would and some people wouldn't.

740
00:46:25,056 --> 00:46:33,298
Speaker 1: I mean, I think Some people have a lot of difficulty Understanding how other people fanboys are a good example of this.

741
00:46:34,184 --> 00:46:47,810
Speaker 1: Running the RIT anime club, you know as the president I I had to be like the public face for the club and a lot of people would Congregate around in like the social areas of club and I had to I kind of keep the peace and talk to everyone and be Like hey you how's it going?

742
00:46:47,830 --> 00:47:08,122
Speaker 1: Hey blah blah, but Scott and all my friends could tell When I was totally blowing someone off and ignoring what they were saying But I was mimicking the right body posture in the right body language and I was doing the things that basically trick another person into Thinking that I'm engaged with them there.

743
00:47:08,182 --> 00:47:16,480
Speaker 1: there are a lot of things you can do if you want to I guess in of Influence or effect the way someone perceives the way you speak just by using body language a certain way.

744
00:47:16,861 --> 00:47:21,900
Speaker 1: It's not out of the realm that you could program a computer that did those same sorts of calculations.

745
00:47:21,960 --> 00:47:22,663
Speaker 0: But aren't we gonna?

746
00:47:22,724 --> 00:47:30,838
Speaker 0: we're gonna have to you know cross the uncanny valley of Emotion there and I think all that takes is more computing power and more time.

747
00:47:31,019 --> 00:47:43,146
Speaker 1: Yep I mean the uncanny valley is an interesting phenomenon Which I've read multiple articles asserting that the reason it exists is because things that are alien or foreign We don't really have any sort of.

748
00:47:43,166 --> 00:48:01,820
Speaker 1: we don't have to worry about because historically in the in the past of humanity Things that were very alien to us were different kinds of dangers But things that were very similar or almost normal But a little bit off often indicated disease or malformation or problems like that.

749
00:48:02,303 --> 00:48:16,179
Speaker 1: I mean I saw a lot of studies where people were sickened and disgusted by certain kinds of images and yet we're not bothered at all by other very similar kinds of images and the Images that bother them were in the uncanny valley and similar to things that cause disease

750
00:48:16,863 --> 00:48:17,085
Speaker 0: Mm-hmm.

751
00:48:18,132 --> 00:48:23,939
Speaker 1: So yeah anyway What a robot necessarily be mimicking or could it possibly begin feeling?

752
00:48:23,959 --> 00:48:36,900
Speaker 1: I I don't know what the seed of human consciousness is but I am Lee I'm about I'm 40% give or take leaning toward the idea that My intelligence is just the emergent behavior of a complex system.

753
00:48:37,020 --> 00:48:42,016
Speaker 1: And if that is the case, then robots can most definitely feel as much as I can.

754
00:48:42,036 --> 00:48:44,726
Speaker 1: Yeah, eventually There's no reason they couldn't.

755
00:48:45,348 --> 00:48:52,460
Speaker 1: there's no reason any sufficiently complex system couldn't be Self-reflective in the same way that I am especially if I give it a fusiform gyrus.

756
00:48:52,862 --> 00:49:05,779
Speaker 0: Yeah, but I guess this is sort of idea that feelings are somehow Special in some like there's some holy, you know Sac, you know, what was the word sacred sacred kind of thing?

757
00:49:06,540 --> 00:49:12,600
Speaker 0: Feelings are just chemical, you know results of the emergent, you know thing for the complex system.

758
00:49:12,760 --> 00:49:26,280
Speaker 1: I mean if that's the case because we don't I mean all we know is that I mean I feel emotions humans feel emotions And they're very powerful and it's very difficult to separate yourself From the emotions you feel and it's very difficult to clinically observe.

759
00:49:26,380 --> 00:49:36,887
Speaker 1: I mean, let's say that someday we map the brain perfectly and we're able to say without a doubt This is where every like each emotion This is how it forms and where it comes from.

760
00:49:37,288 --> 00:49:39,716
Speaker 1: and here's how look I can make a device.

761
00:49:39,917 --> 00:49:44,940
Speaker 1: you hit the button and it Makes you angry even it and you don't even know why you hit the button and it makes you happy.

762
00:49:45,402 --> 00:49:46,970
Speaker 1: We could understand it a hundred percent.

763
00:49:47,311 --> 00:49:51,499
Speaker 1: and if that sort of thing is possible I don't know how a lot of people would deal with that knowledge.

764
00:49:52,155 --> 00:49:55,009
Speaker 1: Yeah I think a lot of people wouldn't believe it because it were.

765
00:49:55,049 --> 00:50:08,934
Speaker 1: so it's very difficult to divorce yourself from your own perception of reality And kind of be self-reflective in that kind of clinical Objective way kind of like how it's very difficult for people to admit to their own inner failings to themselves.

766
00:50:09,556 --> 00:50:09,817
Speaker 0: Mm-hmm.

767
00:50:10,378 --> 00:50:12,851
Speaker 1: All right Blah blah blah blah.

768
00:50:13,356 --> 00:50:20,100
Speaker 1: if mr Levy walked in on his spouse using a robot as a sex partner would he be right to feel jealous or angry?

769
00:50:20,900 --> 00:50:38,774
Speaker 0: Well, I think there's sort of a you know, I guess another thing that's possibly biological instinctual that's been brought over over the years that you know You see, you know, we've grown into being some sort of this monogamous relationship At least humans have for the most part, you know sort of monogamous and whatnots

770
00:50:39,376 --> 00:50:40,098
Speaker 1: and I'll give us

771
00:50:40,138 --> 00:50:40,560
Speaker 0: what not.

772
00:50:41,622 --> 00:50:45,740
Speaker 0: So, you know one man one partner of some kind, you know.

773
00:50:45,760 --> 00:50:58,220
Speaker 0: And then you don't want the partner to be going with anyone else because then you feel like hey You know, they love them more than they love me, you know, you it, you know seeing something like that It's like oh you want, you know, everyone wants to have something all to themselves.

774
00:50:58,521 --> 00:51:11,595
Speaker 1: but then at the same time we have friends and I've met a lot of people in my life who who are good or bad have transcended that and are in open or Multi-faceted relationships.

775
00:51:11,918 --> 00:51:18,620
Speaker 1: and While many of them failed utterly at the same time many of them seem to be working very well.

776
00:51:18,964 --> 00:51:31,500
Speaker 0: I guess it's just you know This is sort of a more general issue outside of the robots in that if you have a relationship with someone if it's a real Relationship then, you know the terms of that relationship, you know will be like agreed upon.

777
00:51:31,580 --> 00:51:36,640
Speaker 0: And if you're not able to agree on the terms of your relationship with someone then what kind of relationship is that?

778
00:51:36,780 --> 00:51:41,300
Speaker 0: That's not much going on there, you know, it's not really gonna work out if you can't even agree on something like that.

779
00:51:41,420 --> 00:51:47,240
Speaker 0: So if one person's, you know wanting something different than the other person then you're gonna end up hurting someone.

780
00:51:47,321 --> 00:51:49,738
Speaker 0: So don't make any promises that you're not gonna keep.

781
00:51:50,761 --> 00:52:03,740
Speaker 1: Well, I think with this last question and we'll also probably end on that because we've gone on a while and I'm kind of hungry Okay, but I guess it also with this it comes down to are they using the robot as a dildo for the salsa?

782
00:52:04,261 --> 00:52:07,830
Speaker 1: Or are they using the robot for the chips or both or both?

783
00:52:08,091 --> 00:52:20,946
Speaker 1: because if someone's using being jealous of the robot if Using it purely for the salsa is like being jealous of a vibrator if you're jealous of a vibrator That's a little bit sad.

784
00:52:20,986 --> 00:52:32,219
Speaker 0: I think well, I mean, you know, you'd like, you know The chips of the salsa goes so well together that you'd like to think that you know The salsa that you made goes to the chips the best.

785
00:52:32,400 --> 00:52:45,239
Speaker 1: Well, I think there is an unrelated issue that a lot of people aren't very good at making salsa And a lot of people are very uncomfortable talking about it with possibly the people they also share chips with to the.

786
00:52:45,259 --> 00:52:54,320
Speaker 1: I Love this analogy To the point that I think a lot of people could be having a lot better sex than they currently are and I'll leave it At that.

787
00:53:00,586 --> 00:53:03,188
Speaker 1: this has been geek nights with rim and Scott special.

788
00:53:03,208 --> 00:53:05,330
Speaker 1: Thanks to DJ pretzel for the opening music.

789
00:53:06,056 --> 00:53:17,396
Speaker 0: Be sure to visit our website at www.frontroadcrew.com where you'll find show notes links our awesome forum a link to our frapper map and Links to all the RSS feeds.

790
00:53:17,817 --> 00:53:23,534
Speaker 1: we say feeds plural because geek nights airs four nights a week covering four different Brands of geekery.

791
00:53:24,016 --> 00:53:26,183
Speaker 1: Mondays are science and technology Tuesdays.

792
00:53:26,224 --> 00:53:27,990
Speaker 1: We have video games board games and RPGs.

793
00:53:28,691 --> 00:53:34,090
Speaker 1: Wednesdays are anime manga comic nights and Thursdays are the catch-alls for various rants and tomfoolery.

794
00:53:34,571 --> 00:53:46,230
Speaker 0: You can send us feedback by email to geek nights at front row crew comm or you can send audio feedback via Audio, just click the link that says send me an audio on the right side of our website.

795
00:53:46,573 --> 00:53:47,461
Speaker 1: If you like what you hear.

796
00:53:47,562 --> 00:53:51,720
Speaker 1: you can catch the last 100 episodes in iTunes or in your favorite podcatcher.

797
00:53:51,940 --> 00:53:55,050
Speaker 1: for the complete archives visit the website which has everything.

798
00:53:55,611 --> 00:54:00,547
Speaker 0: Geek nights is distributed under a Creative Commons attribution non-commercial share alike 2.5 license.

799
00:54:02,131 --> 00:54:08,169
Speaker 0: This means you can do whatever you want with it as long as you give us credit don't make money and share it in kind.

800
00:54:08,992 --> 00:54:14,426
Speaker 0: Geek nights is recorded live with no studio and no audience, but unlike those other late shows.

801
00:54:14,707 --> 00:54:16,010
Speaker 0: It's actually recorded at night.

