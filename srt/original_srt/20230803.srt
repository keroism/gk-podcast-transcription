1
00:00:08,620 --> 00:00:10,328
Speaker 0: It's Thursday, August 3rd, 2023.

2
00:00:10,328 --> 00:00:10,569
Speaker 0: I'm Rem.

3
00:00:13,480 --> 00:00:13,980
Speaker 1: And I'm Scott.

4
00:00:14,200 --> 00:00:16,030
Speaker 0: And this is the Geek Nights Book Club.

5
00:00:16,091 --> 00:00:22,220
Speaker 0: Tonight we are talking about This is How You Lose the Time War by Amal El-Motar and Max Gladstone.

6
00:00:23,020 --> 00:00:24,039
Speaker 1: Let's do this!

7
00:00:24,841 --> 00:00:39,920
Speaker 0: Yeah, we were going to do the show a little earlier, but I had a work thing that came up, and because, one, we didn't have a good Wednesday show idea, and two, we don't want to cover, or really give any promotion to, any struck works that would cross the picket line of SAG-AFTRA.

8
00:00:40,822 --> 00:00:42,900
Speaker 1: I don't watch any struck works to begin with.

9
00:00:43,022 --> 00:00:43,579
Speaker 0: You don't watch anything.

10
00:00:44,520 --> 00:00:45,268
Speaker 1: No, that's right.

11
00:00:45,348 --> 00:00:48,320
Speaker 1: Television is not... It's weird, right?

12
00:00:48,380 --> 00:00:52,197
Speaker 1: It's like, on the one hand, I'm like, "Yeah, way to go, all you writers and actors.

13
00:00:52,217 --> 00:00:52,860
Speaker 1: You deserve it.

14
00:00:53,483 --> 00:01:00,300
Speaker 1: You're doing all this hard, creative work, and you're so talented, and you should get paid, and all those Hollywood execs are taking all your money.

15
00:01:00,361 --> 00:01:01,591
Speaker 1: Yeah, I'm totally 100% on your side.

16
00:01:03,404 --> 00:01:05,777
Speaker 1: You think we're so talented and great, do you watch any of our work?

17
00:01:05,837 --> 00:01:05,937
Speaker 1: No.

18
00:01:06,781 --> 00:01:09,260
Speaker 1: I mean, meanwhile, you did... None of it entertains me, personally.

19
00:01:09,580 --> 00:01:11,560
Speaker 0: You did go see Asteroid City in the theater.

20
00:01:12,360 --> 00:01:15,440
Speaker 1: Well, I mean, that's, you know, the director was there, right?

21
00:01:16,244 --> 00:01:18,780
Speaker 1: And that's the kind of thing that I actually do like, right?

22
00:01:19,500 --> 00:01:22,280
Speaker 0: Yep, and actually, you know, the thing I would have reviewed on Wednesday...

23
00:01:22,300 --> 00:01:23,699
Speaker 1: Television is the thing I mostly don't like.

24
00:01:23,900 --> 00:01:26,516
Speaker 0: Yeah, but, uh, Nimona is not television.

25
00:01:26,536 --> 00:01:27,180
Speaker 0: That is a movie.

26
00:01:27,300 --> 00:01:36,200
Speaker 0: It just happened to be on Netflix because it was saved from the whole blue sky being destroyed by capitalism situation, and they somehow actually made the movie instead of just burying it forever.

27
00:01:36,860 --> 00:01:46,840
Speaker 0: But, uh, anyway, this is an experiment to... If we don't have a good idea for a show, and we have a good topic for a different day of the week, we're gonna change out the Geek Night schedule a little bit.

28
00:01:47,420 --> 00:01:55,880
Speaker 1: I mean, do we have to, you know, I mean, people didn't even notice when we switched from, like, you know, this was supposed to be a Tuesday/Thursday week, and now it's a Monday/Wednesday week.

29
00:01:55,900 --> 00:02:00,553
Speaker 0: We kept the Monday, Tuesday, Wednesday, Thursday alternating schedule consistent for so many years.

30
00:02:00,614 --> 00:02:01,239
Speaker 0: It's shocking.

31
00:02:01,621 --> 00:02:05,400
Speaker 1: It flipped one time, but Google Calendar is what made it consistent, right?

32
00:02:05,480 --> 00:02:09,019
Speaker 1: It's like, I can just look at the calendar and say, "Oh, this is a X week," right?

33
00:02:09,100 --> 00:02:14,580
Speaker 1: But I guess nobody, nobody's even listening, so who even gives a shit if we stick to that anymore, right?

34
00:02:14,640 --> 00:02:21,177
Speaker 1: It's, we'll just, you know, we'll do no more than two episodes a week of whatever days we happen to do, you know?

35
00:02:22,100 --> 00:02:23,329
Speaker 0: Yeah, there are the listener and the listener.

36
00:02:24,981 --> 00:02:25,866
Speaker 0: We got two right now.

37
00:02:25,967 --> 00:02:26,228
Speaker 0: Three!

38
00:02:26,248 --> 00:02:28,180
Speaker 0: A third one appeared in the livestream.

39
00:02:28,261 --> 00:02:30,720
Speaker 1: It's the same person with three, two sock puppet accounts.

40
00:02:30,740 --> 00:02:35,799
Speaker 0: Well, it's tricky because the book clubs definitely get the lowest engagement of anything we do.

41
00:02:35,920 --> 00:02:37,330
Speaker 1: That's why they're the most necessary.

42
00:02:37,370 --> 00:02:38,680
Speaker 1: People ain't fucking reading any books.

43
00:02:38,880 --> 00:02:38,980
Speaker 1: Yeah.

44
00:02:39,100 --> 00:02:41,034
Speaker 1: You know, good or bad, read a book.

45
00:02:41,235 --> 00:02:41,880
Speaker 1: Jesus Christ.

46
00:02:43,162 --> 00:02:44,579
Speaker 1: It's like, you know.

47
00:02:45,040 --> 00:02:47,420
Speaker 0: What bothers me the most is they don't even have a super long tail.

48
00:02:47,580 --> 00:02:49,019
Speaker 0: Like, people read the book and come back to it.

49
00:02:49,762 --> 00:02:52,639
Speaker 0: We're going to keep doing them because I like doing them, but you guys got to read.

50
00:02:53,340 --> 00:02:54,710
Speaker 1: This book is so short, too.

51
00:02:54,790 --> 00:02:56,180
Speaker 1: It's not even, like, you know.

52
00:02:56,281 --> 00:02:58,220
Speaker 0: Yeah, that's sort of the first thing.

53
00:02:58,460 --> 00:03:00,019
Speaker 0: So, this is how you lose the time war.

54
00:03:00,300 --> 00:03:04,640
Speaker 0: As, you know, we discussed when we announced it, Scott was the one who brought this to the table.

55
00:03:04,640 --> 00:03:09,300
Speaker 1: Okay, so I chose because it was, when we chose the books, it was June in Pride Month.

56
00:03:09,460 --> 00:03:12,660
Speaker 1: It's now no longer Pride Month, but, you know, Pride is all the time.

57
00:03:12,740 --> 00:03:13,020
Speaker 1: Whatever.

58
00:03:13,820 --> 00:03:20,860
Speaker 1: And, you know, so I chose two LGBTQ+-ish novels for Rym to select from, right?

59
00:03:21,462 --> 00:03:33,980
Speaker 1: And he selected the one that was in a recent news because a person by the name of Bigelas Dickolas Wolfwood, which is a name where anyone with that name must be a trustworthy, immaculate individual.

60
00:03:34,521 --> 00:03:36,880
Speaker 0: Yeah, that's a rare, perfect username.

61
00:03:37,740 --> 00:03:50,700
Speaker 1: Yeah, so that person going by that name suggested this book, hyped it up on the internets, and many people concurred and obeyed and such, and so we said, "Well, something must be going on there," right?

62
00:03:50,740 --> 00:03:54,300
Speaker 1: That's a thing that we do is, like, you know, we hear about a thing, right?

63
00:03:54,521 --> 00:03:58,559
Speaker 1: I think the first time we talked about this on Geek Nights was, like, the Madoka days, right?

64
00:03:58,766 --> 00:03:58,980
Speaker 1: Yeah.

65
00:03:59,120 --> 00:04:00,959
Speaker 1: Which was already a really long time ago.

66
00:04:02,362 --> 00:04:09,018
Speaker 1: When Madoka came out, it was like, you know, I knew there was an anime called Madoka Magica, and I didn't know anything about it.

67
00:04:09,440 --> 00:04:11,840
Speaker 1: I just knew there was an anime by that name.

68
00:04:12,260 --> 00:04:22,040
Speaker 1: But then I kept hearing the name come up again and again and again, and I said, "Well, if this name keeps coming up and it didn't just disappear, there must be something to it,".

69
00:04:22,142 --> 00:04:22,879
Speaker 1: and I checked it out.

70
00:04:23,221 --> 00:04:26,320
Speaker 1: So this book, it just kept coming up, right?

71
00:04:26,420 --> 00:04:29,655
Speaker 1: And it came up big with, you know, Biggles Dickles.

72
00:04:29,695 --> 00:04:33,560
Speaker 1: there's recommendation, which was viral, I guess would be the term.

73
00:04:33,780 --> 00:04:35,199
Speaker 0: It was surprisingly viral.

74
00:04:35,781 --> 00:04:44,919
Speaker 0: Like, that one short internet thread caused so many different communities to talk about this book, even if they didn't know what generated that buzz.

75
00:04:45,700 --> 00:04:47,299
Speaker 1: Yep, and so it's such a short book.

76
00:04:48,161 --> 00:04:49,660
Speaker 1: You know, I made it one of the two choices.

77
00:04:49,921 --> 00:04:57,518
Speaker 1: Rym selected it, not the other one, and it was so, you know, we read it to see what the hype was, and so here we are.

78
00:04:57,900 --> 00:05:14,120
Speaker 0: Yep, and I will say right now, you know, of course this is the Geek Nights Book Club, so we're gonna talk about this book between two people who have read it and know that we've both read it, and we are assuming that you have also read it, so not even, I don't care about spoilers anymore.

79
00:05:14,320 --> 00:05:17,659
Speaker 0: Like, if you listen to a book club podcast and you're mad about a spoiler, that's on you.

80
00:05:18,680 --> 00:05:24,919
Speaker 0: But I would say more that if this is hard to follow or you're confused, that's your fault for not reading the book.

81
00:05:25,700 --> 00:05:26,147
Speaker 1: -The best--.

82
00:05:26,168 --> 00:05:26,900
Speaker 1: -Yeah, obviously.

83
00:05:27,060 --> 00:05:36,420
Speaker 0: Like, one of the best things about reading a book at the same time as someone else is being able to discuss the things that happen in the book or the meta around the book.

84
00:05:36,500 --> 00:05:43,620
Speaker 0: You can talk about the book knowing that you both come from the same first principles or at least this basic understanding of what happened in the book.

85
00:05:44,182 --> 00:05:53,740
Speaker 0: As we saw way back when our entire collected crew kind of read The Prince of Nothing books around the same few years, and thus it just became this ongoing, constant conversation.

86
00:05:54,462 --> 00:06:09,560
Speaker 1: Yeah, I mean, I don't know what it is, but there's something about-- I actually don't really get any value from going online to media publications or journalists and hearing what they have to say about various works that have come out, video games, movies, whatever.

87
00:06:10,020 --> 00:06:18,165
Speaker 1: But if I've already seen the work in question or played the game in question, suddenly what they have to say is like-- Yeah, I don't care

88
00:06:18,205 --> 00:06:24,458
Speaker 0: what some nerd said about Evangelion before I saw it, but after I saw it, I weirdly really wanted to hear what nerds had to say about it.

89
00:06:25,181 --> 00:06:25,665
Speaker 1: Right.

90
00:06:25,705 --> 00:06:39,055
Speaker 1: I don't know what that is, but it's like, you know, this book, thankfully, this is a podcast, so if you gain any value from this for some strange reason, if you read the book at any point in the rest of your life, this will still be here waiting for you to listen to.

91
00:06:40,120 --> 00:06:40,868
Speaker 0: So I liked it.

92
00:06:41,070 --> 00:06:41,939
Speaker 0: It's not a perfect book.

93
00:06:43,142 --> 00:06:54,879
Speaker 0: Some of the hype was justified, but also some of the hype was-- I feel like some of the hype came from people who never read a Bradbury at any point and have never encountered this kind of science fiction before.

94
00:06:55,860 --> 00:07:10,260
Speaker 1: I mean, I think I'm in agreement in that I was disappointed, not that my expectation was high, but I do not think the quality of the book met the hype level, but that's not to say the book had no positive or redeeming qualities.

95
00:07:12,183 --> 00:07:18,029
Speaker 1: I think, not for the shortness of the book, it may have been worse off, but--

96
00:07:19,982 --> 00:07:28,620
Speaker 0: The book definitely benefits from the fact that this is a couple hour read, like three hours tops, unless you have difficulty reading,

97
00:07:29,722 --> 00:07:29,963
Speaker 1: and

98
00:07:30,003 --> 00:07:37,899
Speaker 0: what I got out of it relative to how little time it took from my life made it an upper-tier book, whereas if it had been longer, it would have been a lower-tier book.

99
00:07:38,483 --> 00:07:51,934
Speaker 1: Yeah, I have no regrets about reading this book, but it's like if someone were to start a discussion about the book, I'd be like, "Eh, it's all right, but it does not meet the hype level that you have heard in my

100
00:07:52,076 --> 00:07:52,419
Speaker 1: opinion.".

101
00:07:52,500 --> 00:08:07,280
Speaker 0: Yeah, but at the same time, we are jaded older people in that we've read a lot of books over the years, just like we've seen a lot of anime and seen a lot of movies, and to even get my attention takes a lot now that I'm 40.

102
00:08:07,280 --> 00:08:09,340
Speaker 1: Okay, so here's the deal with the book, right?

103
00:08:09,460 --> 00:08:19,480
Speaker 1: There is a time war, as the title would suggest, and the main combatants in the time war are two time and space-spanning civilizations.

104
00:08:19,780 --> 00:08:25,800
Speaker 1: One of them is sort of a cyber hive mind deal, right?

105
00:08:26,300 --> 00:08:29,700
Speaker 1: I guess it would be a cyber-- What's the word for it?

106
00:08:30,160 --> 00:08:31,759
Speaker 1: Singularity, yeah, right?

107
00:08:32,360 --> 00:08:35,980
Speaker 1: And the other one is more of a biological hive mind.

108
00:08:36,625 --> 00:08:38,239
Speaker 0: A biological singularity.

109
00:08:39,080 --> 00:08:50,660
Speaker 1: Right, so basically there are these two singularities of intelligence, but within them, there are still individual beings that have independent thought and whatnot.

110
00:08:50,780 --> 00:08:52,690
Speaker 1: It's not a complete single entity, right?

111
00:08:55,081 --> 00:08:58,380
Speaker 1: It's just like a colony of bees, right?

112
00:08:58,440 --> 00:09:04,560
Speaker 1: Just the cyber bee colony and the literal elf bee colony, I guess, right?

113
00:09:05,646 --> 00:09:08,120
Speaker 1: And so there's a time war happening.

114
00:09:08,360 --> 00:09:34,939
Speaker 1: So basically there are trained, highly skilled agents working for both of these groups, societies fighting each other, basically traveling throughout history and manipulating history to change the future, and they keep doing it back and forth to each other in an increasingly elaborate fashion so that the future that each one of these two different societies wants will be the one that comes about.

115
00:09:35,720 --> 00:09:39,000
Speaker 0: So from a naive perspective, this is an existential war.

116
00:09:39,280 --> 00:09:53,000
Speaker 0: Regardless of if you sympathize with one or both of the sides or the people involved, one side, much like in some anime we've seen over the years, is going to be destroyed utterly if they lose this war.

117
00:09:53,180 --> 00:09:54,920
Speaker 0: This is an existential fight.

118
00:09:56,241 --> 00:10:03,567
Speaker 1: Right, so one hive mind just simply won't-- --exist, right?

119
00:10:03,608 --> 00:10:04,234
Speaker 1: The other one won.

120
00:10:05,480 --> 00:10:13,800
Speaker 0: Now, from a meta perspective that I-- I guess I'm not going to speculate on whether or not the authors intended any of the things we're talking about.

121
00:10:13,960 --> 00:10:17,141
Speaker 0: I'm not talking about this from a 100%.

122
00:10:17,141 --> 00:10:19,520
Speaker 0: The author is dead, God is dead, we have words to work with.

123
00:10:19,540 --> 00:10:21,640
Speaker 1: I learned some stuff about the-- but anyway, keep going.

124
00:10:21,861 --> 00:10:34,640
Speaker 0: Yeah, but I don't want to presume whether or not they intended any of these readings or ideas, but there's definitely a meta concept that if these societies are fighting, then they can coexist and do coexist directly.

125
00:10:35,260 --> 00:10:39,680
Speaker 0: And because time travel is possible, then time travel is irrelevant.

126
00:10:39,740 --> 00:10:50,340
Speaker 0: There's no such thing as time travel, there is just one long system of interactions, and in that system there is a state where both of these societies do in fact exist.

127
00:10:51,981 --> 00:11:05,060
Speaker 0: Which implies that the war is stupid and pointless, or it implies that the war is necessary, because the war is the only thing that keeps these societies existing together at the same time.

128
00:11:05,760 --> 00:11:08,760
Speaker 0: I don't think that was quite the intent or the point of the book.

129
00:11:08,780 --> 00:11:11,180
Speaker 1: There also don't seem to be any other societies.

130
00:11:11,780 --> 00:11:14,660
Speaker 1: I guess those are the ones that have completely lost the time war.

131
00:11:15,160 --> 00:11:22,260
Speaker 0: There do not seem to be any other possibilities in the observed universe as far as this book is portrayed.

132
00:11:22,720 --> 00:11:24,838
Speaker 1: It's hard to tell if it's even on one planet or multiple planets.

133
00:11:25,160 --> 00:11:29,080
Speaker 0: It's definitely not just on one planet, they talk about multiple timelines though.

134
00:11:29,340 --> 00:11:33,859
Speaker 0: But they definitely imply that Earth is hyper pivotal to all of this.

135
00:11:36,541 --> 00:11:53,300
Speaker 1: And so, with the two societies, one of them has an agent, Red, who's from the Cyber Society, and Blue is from the Elfie Bio Society, and I believe that it's Blue that sends the first letter, right?

136
00:11:53,642 --> 00:11:56,219
Speaker 1: I had to keep looking this up every time.

137
00:11:56,640 --> 00:12:14,214
Speaker 0: Well, that is actually a hard question to answer, sort of, because it's a time travel story, and of course, there's a Final Fantasy 1 garland-style time loop that occurs, and as a result, Red initiated the situation Blue was in.

138
00:12:14,255 --> 00:12:18,118
Speaker 0: that led to Blue writing the first letter down the road, is what I would say.

139
00:12:18,861 --> 00:12:21,400
Speaker 0: Meaning, who wrote the first letter is an impossible question to answer.

140
00:12:21,962 --> 00:12:26,980
Speaker 1: Of course, but at the start of the book, the word for it was, what, is it epistolary?

141
00:12:27,623 --> 00:12:29,559
Speaker 1: I keep having to look up this work, right?

142
00:12:30,600 --> 00:12:34,297
Speaker 1: Yes, epistolary format, which is when you tell a story with letters.

143
00:12:35,420 --> 00:12:45,320
Speaker 1: So this isn't actually completely epistolary as some other works are, which are just letters between characters and you just read their correspondence and that tells the story.

144
00:12:45,380 --> 00:12:49,280
Speaker 0: Which I would say this book would have been better if it had stuck to that and not mixed.

145
00:12:50,282 --> 00:13:20,380
Speaker 1: I agree, but basically you get a brief one or two page chapter of a character doing their mission that they're currently on, and then that character receives a letter, and then you read the letter the character received in the next couple pages, and then it switches to the character who wrote that letter, and they're on some mission, and then they receive the response to the previous letter, and you read that.

146
00:13:20,620 --> 00:13:26,260
Speaker 1: So it's sort of this alternating between brief narrations of missions and the letters.

147
00:13:26,500 --> 00:13:38,819
Speaker 1: But, as Rym just said, it would be better off if it was just the letters, and I agree, because quite often the missions don't really add much besides setting, dressing, and flavor, right?

148
00:13:39,040 --> 00:13:50,200
Speaker 0: They do add some important but subtle color to the societies, but I don't know, again, how intentional that was, but also most of the plot is in the letters, right?

149
00:13:50,340 --> 00:13:56,720
Speaker 1: That the plot is not advancing so much in the part where they're on some mission.

150
00:13:57,582 --> 00:14:05,032
Speaker 1: You can't even really tell the overall status of the time war in the mission part, except for this one big mission where they meet and fight in the middle somewhere.

151
00:14:07,440 --> 00:14:17,500
Speaker 1: But on the majority of the mission parts, it's just like describing some mission in a cool way, like setting a cool fantasy or sci-fi scene up just to be cool.

152
00:14:17,820 --> 00:14:29,300
Speaker 0: The missions do add something very important, though, because they portray the extreme nature of the violence and pain that is involved in these actual fights.

153
00:14:29,641 --> 00:14:34,940
Speaker 0: that is not referred to materially in really any of the letters to near the end.

154
00:14:35,060 --> 00:14:52,420
Speaker 0: So on one hand, like reading this, it is hard for me to see the person who, throughout the book, is consistently thinking the red side is a better society to live in, because the blue side is often portrayed as being more pleasant in a variety of ways.

155
00:14:53,320 --> 00:15:06,820
Speaker 1: Well, I think there's just a natural tendency of, you know, sort of a ghibli-esque thing to always portray, you know, biology, nature as good and technology and industry as more evil, right?

156
00:15:06,940 --> 00:15:16,000
Speaker 1: It's like token-esque situations where the elves are good and the orcs all have machines and the elves don't really, they have magic or something, right?

157
00:15:16,000 --> 00:15:17,519
Speaker 1: It's like, that's just a common trope.

158
00:15:18,042 --> 00:15:26,300
Speaker 1: And I don't know how much the existence of that trope in your mind is painting that, versus the book is also agreeing with the trope and trying to paint the same thing.

159
00:15:26,960 --> 00:15:32,840
Speaker 1: I sort of viewed both of the societies as sort of equal in terms of goodness and evilness, right?

160
00:15:32,880 --> 00:15:35,788
Speaker 1: The mother of the blue side didn't seem super benevolent to me, right?

161
00:15:41,461 --> 00:15:44,027
Speaker 0: But there's a broader point about that.

162
00:15:44,067 --> 00:15:52,500
Speaker 0: that is Evangelion-adjacent and related to a scientific concept of self-domestication that I want to address later in our conversation.

163
00:15:53,702 --> 00:15:59,040
Speaker 1: There's very, you know, what's it called, instrumentality stuff going on, right?

164
00:15:59,161 --> 00:16:04,779
Speaker 0: But I feel like if we talk about that now, it's going to derail our whole conversation, so I'll say I'm going to derail the train later.

165
00:16:05,080 --> 00:16:10,340
Speaker 0: But the red side is often portrayed as more directly violence.

166
00:16:11,240 --> 00:16:22,280
Speaker 0: But the blue side, like very subtly, whenever the blue side is doing stuff, it's always things like, oh yeah, they made sure World War II happened because you need that, like that's natural that that had to happen.

167
00:16:22,480 --> 00:16:26,760
Speaker 0: Like blue is killing as many people as red, maybe even more people.

168
00:16:27,181 --> 00:16:33,779
Speaker 0: And blue is often the one destroying a city or destroying an entire civilization to prevent them from accomplishing some goal.

169
00:16:34,500 --> 00:16:39,299
Speaker 0: Or, like, making sure the zombie apocalypse happens in the alternate Russian front of World War II.

170
00:16:39,940 --> 00:16:46,340
Speaker 0: Like, I think I want to say one of the stories specifically implies that blue prevented Hitler from being killed on purpose.

171
00:16:47,460 --> 00:16:48,720
Speaker 1: Could, uh, yeah, I don't remember.

172
00:16:49,481 --> 00:17:01,020
Speaker 0: It's hard to say because an annoyance with the writing in this book is that it makes very specific references to pop culture, but all, like, broad pop culture.

173
00:17:01,140 --> 00:17:07,980
Speaker 0: Like, it references songs from the 70s and 80s, and it references television shows from, like, between the 50s and, like, modern times.

174
00:17:08,482 --> 00:17:17,040
Speaker 0: But the references, and this is, I mean, no disrespect to the authors, they were done in the same ham-fisted manner that Ready Player One did.

175
00:17:17,421 --> 00:17:23,599
Speaker 0: The references use proper nouns and assume that you know what the fuck those proper nouns are.

176
00:17:23,720 --> 00:17:26,380
Speaker 0: And if you don't, you will not make the reference.

177
00:17:26,820 --> 00:17:43,500
Speaker 0: In the same way that Chesterton and The Man Who Was Thursday, I still think it was a great book, but it had a lot of specific proper noun references that you would only get if you were deeply enmeshed in the, like, Christian societal thought and literature of the era.

178
00:17:43,681 --> 00:17:47,260
Speaker 0: And if you don't know those references, authors, and stories, you'll just miss all that.

179
00:17:47,761 --> 00:17:49,297
Speaker 0: You'll miss all that in this book, too.

180
00:17:50,080 --> 00:17:56,060
Speaker 0: And if you miss it, there's entire sets of sentences that are just meaningless and worthless to you as a reader.

181
00:17:57,721 --> 00:18:04,260
Speaker 1: So the other thing that bothered me, right, is that, you know, you're alternating between red, blue, red, blue, right, as you go throughout the book.

182
00:18:04,781 --> 00:18:19,420
Speaker 1: And I learned, so I don't know how true this is, but it's, as someone said, it was from, like, interviews, or so it's like, it seems like I have no reason to just believe that this is true, is that the two authors, one was writing the red and the other author was writing the blue.

183
00:18:20,160 --> 00:18:28,600
Speaker 1: And so you would think them two authors being two different people, right, would naturally have, like, a different voice in the text, right?

184
00:18:28,861 --> 00:18:30,840
Speaker 1: And especially when they're writing different characters.

185
00:18:31,501 --> 00:18:35,020
Speaker 1: But I just couldn't tell, a lot of chapters, I just couldn't tell.

186
00:18:35,120 --> 00:18:40,820
Speaker 1: And I had to, like, flip backwards until I could find the word red or the word blue to figure out who was the current chapter.

187
00:18:41,162 --> 00:18:42,460
Speaker 0: I had the same problem.

188
00:18:42,940 --> 00:18:46,596
Speaker 1: And it's like, I kept flipping back to the beginning, like, who wrote the first letter?

189
00:18:46,717 --> 00:18:47,440
Speaker 1: It was the blue, right?

190
00:18:47,640 --> 00:18:53,040
Speaker 1: It's like, shouldn't, they should have been two extremely different voices, right?

191
00:18:53,140 --> 00:18:58,680
Speaker 1: So that you could really tell immediately which character was which and who was doing what.

192
00:18:58,920 --> 00:19:04,680
Speaker 1: It's like, you know, maybe that was intentional, but it really, I don't know, that did not work.

193
00:19:04,820 --> 00:19:06,005
Speaker 0: It really worked for me.

194
00:19:06,206 --> 00:19:09,340
Speaker 0: And it's hard to say if an editor was involved in that, like, normalizing the voice.

195
00:19:10,101 --> 00:19:23,080
Speaker 0: It would have worked better structurally, because I'm a big fan of form and function being unified, if the writing style of the two sets of stories started radically different and converged to have the same voice toward the end of the book.

196
00:19:23,080 --> 00:19:24,759
Speaker 0: Because that would have fit with how it actually goes down.

197
00:19:25,160 --> 00:19:26,600
Speaker 1: That would have matched the plot, yeah.

198
00:19:26,760 --> 00:19:28,495
Speaker 0: And that's the kind of thing that...

199
00:19:29,060 --> 00:19:35,020
Speaker 1: You could say that it foreshadowed the plot with the voice being the same, but it really made it harder to read.

200
00:19:35,320 --> 00:19:38,111
Speaker 1: It's like, for such a short book, that slowed me down a lot.

201
00:19:38,151 --> 00:19:40,400
Speaker 1: I could have finished even faster if I didn't have to keep flipping back.

202
00:19:40,420 --> 00:19:44,999
Speaker 0: I would say that is the kind of thing that differentiates a B-tier novel from an A-tier novel.

203
00:19:45,746 --> 00:19:45,831
Speaker 1: Yeah.

204
00:19:46,220 --> 00:19:50,680
Speaker 0: S-tier is, and it also makes you think about something profound that you've never thought about before.

205
00:19:51,502 --> 00:19:51,638
Speaker 1: Yep.

206
00:19:52,100 --> 00:19:54,840
Speaker 0: Which, this does not make you think about anything you've never thought about before.

207
00:19:54,860 --> 00:19:57,117
Speaker 1: No, that's another thing I gotta criticize here, right?

208
00:19:57,840 --> 00:19:58,522
Speaker 0: For us, it didn't.

209
00:19:58,802 --> 00:20:09,520
Speaker 0: But again, if someone has never read a lot of science fiction, or hasn't read a lot of books, I think, much like The Matrix, this was brand new concepts to a lot of people who read it.

210
00:20:10,000 --> 00:20:14,240
Speaker 1: The thing is, I don't see the science fiction parts as being the primary part of this book.

211
00:20:14,380 --> 00:20:18,880
Speaker 1: I think the primary part of this book is literally just another Romeo and Juliet story, right?

212
00:20:18,900 --> 00:20:24,760
Speaker 1: There's two people in love, and they can't get together because, you know, they're from the opposite worlds, right?

213
00:20:24,840 --> 00:20:27,556
Speaker 1: They're from a Hatfield and a McCoy, right?

214
00:20:27,596 --> 00:20:28,300
Speaker 1: Or whatever, right?

215
00:20:28,621 --> 00:20:30,560
Speaker 0: I actually see it as a science fiction story.

216
00:20:31,162 --> 00:20:34,880
Speaker 1: They're from a Sharks and a Jets, and they can't, so they gotta be separated.

217
00:20:35,300 --> 00:20:45,640
Speaker 0: I think it's actually, it is a very science fiction story, and my argument here is that reading this, we've got two singularity civilizations, and now I guess we're gonna derail.

218
00:20:45,660 --> 00:20:55,940
Speaker 0: An instrumentality-style civilization like that, a singularity, and if you're not familiar with these concepts, I'd suggest...

219
00:20:55,940 --> 00:21:04,099
Speaker 1: It means that all the conscious sentient beings in the society have sort of merged their consciousness together to some degree, right?

220
00:21:04,860 --> 00:21:15,760
Speaker 0: Now, it can be more complex and subtle than that, so an example would be, a very specific example, a real example that is being studied by real scientists today and is a hot topic in sociology.

221
00:21:16,620 --> 00:21:18,586
Speaker 0: Individual humans arguably have agency.

222
00:21:18,746 --> 00:21:21,353
Speaker 0: I am a human, Scott is a human, you are all humans listening to this.

223
00:21:21,935 --> 00:21:23,660
Speaker 0: I hope someday a non-human listens to this.

224
00:21:23,760 --> 00:21:26,059
Speaker 1: We're not gonna discuss if free will exists or not right now, right?

225
00:21:26,220 --> 00:21:26,560
Speaker 0: Nope, we're not.

226
00:21:27,160 --> 00:21:28,020
Speaker 0: We're avoiding that part.

227
00:21:28,160 --> 00:21:43,300
Speaker 0: So, we have free will, we're agents, we make decisions, we live in the world, but we are a collection of a bunch of smaller, complex machines that are making decisions but don't necessarily have free will.

228
00:21:43,740 --> 00:21:46,759
Speaker 0: Cells in our body don't have any meaningful say on what our body does.

229
00:21:46,980 --> 00:21:47,556
Speaker 1: That we know of.

230
00:21:48,381 --> 00:21:56,959
Speaker 0: I mean, they have input into it, but they are suppressed and subsumed into the causality of what our brains decide they're going to do.

231
00:21:58,180 --> 00:22:01,612
Speaker 0: So, imagine a society, a country.

232
00:22:02,214 --> 00:22:03,900
Speaker 0: The United States is a great example.

233
00:22:04,341 --> 00:22:18,660
Speaker 0: The United States is arguably acting in the world as an entity that is larger and more powerful than any human and often acts to a degree disentangled from the will of any particular individual human.

234
00:22:19,000 --> 00:22:25,740
Speaker 0: The collected decisions of the people within that society and the power structures within those people are what decide what that society does.

235
00:22:26,161 --> 00:22:32,920
Speaker 0: If you take that to the ultimate extreme, humans in a society become analogous to cells in a human.

236
00:22:34,160 --> 00:22:36,760
Speaker 0: And domestication is a concept that leads to this.

237
00:22:37,040 --> 00:22:42,800
Speaker 0: So, in this book, we have two individuals who were not at a complete and total singularity.

238
00:22:43,100 --> 00:22:46,180
Speaker 0: These red and blue have not been turned into mitochondria yet.

239
00:22:46,481 --> 00:22:49,680
Speaker 0: They still think and feel and have agency and make decisions.

240
00:22:50,281 --> 00:22:57,560
Speaker 0: But they are in mutually exclusive societies that are themselves almost like two different meta-beings.

241
00:22:58,403 --> 00:23:01,300
Speaker 0: It's like two different meta-humans that are constructed of humans.

242
00:23:01,760 --> 00:23:06,320
Speaker 0: And these two individual humans within those structures want to continue to exist.

243
00:23:06,761 --> 00:23:10,660
Speaker 0: And they've met each other and want to continue to exist apart from their own societies.

244
00:23:11,081 --> 00:23:13,640
Speaker 0: And it's a struggle between instrumentality and individuality.

245
00:23:14,144 --> 00:23:16,279
Speaker 0: Oh shit, it's the same story as Evangelion.

246
00:23:18,763 --> 00:23:21,160
Speaker 1: But yeah, it's a Romeo and Juliet story, right?

247
00:23:21,220 --> 00:23:22,399
Speaker 1: They start writing each other.

248
00:23:22,980 --> 00:23:28,960
Speaker 1: The initial letters between each other are very antagonistic, right?

249
00:23:29,740 --> 00:23:32,074
Speaker 0: If they're trash-shocking, like, "Yo, dawg, you can't beat

250
00:23:32,115 --> 00:23:32,256
Speaker 0: me."

251
00:23:33,149 --> 00:23:33,340
Speaker 0: Right.

252
00:23:33,740 --> 00:23:35,820
Speaker 1: And then they, you know, surprise.

253
00:23:36,401 --> 00:23:37,078
Speaker 1: They fall in love.

254
00:23:37,341 --> 00:23:40,140
Speaker 1: And it's important to note that they are clearly both women.

255
00:23:40,180 --> 00:23:42,460
Speaker 1: This is a lesbian love story, right?

256
00:23:42,921 --> 00:23:48,900
Speaker 1: And I think for a lot of people, unsurprisingly, that's a major selling point.

257
00:23:49,380 --> 00:23:53,240
Speaker 1: It's like if you're an LGBTQ+ person, right?

258
00:23:54,461 --> 00:24:00,140
Speaker 1: Many that I know, it's like whenever they get any representation, like fucking anywhere, they're just so happy about it.

259
00:24:00,140 --> 00:24:00,796
Speaker 1: I would say anything.

260
00:24:01,281 --> 00:24:06,159
Speaker 0: Any work that doesn't center the archetypical societal experience.

261
00:24:06,601 --> 00:24:09,540
Speaker 1: Or does it leave it to vagueness, right?

262
00:24:09,560 --> 00:24:12,158
Speaker 1: They're like, "No, this is absolutely..." Right?

263
00:24:12,700 --> 00:24:15,720
Speaker 1: And in fact, this was optioned for television, I think.

264
00:24:15,900 --> 00:24:16,739
Speaker 1: I don't know if it'll happen.

265
00:24:17,060 --> 00:24:22,479
Speaker 0: This could be adapted into a TV show or a movie pretty well if you loosely adapted it.

266
00:24:23,340 --> 00:24:30,300
Speaker 1: But they said on Wikipedia, it says that the genders of the characters in any such adaptation are not up for negotiation.

267
00:24:30,680 --> 00:24:32,799
Speaker 0: That is important because you know what else did that?

268
00:24:33,243 --> 00:24:34,000
Speaker 0: Steven Universe.

269
00:24:36,642 --> 00:24:40,538
Speaker 1: This is all in on being explicitly gay, right?

270
00:24:41,260 --> 00:24:41,759
Speaker 1: Big time.

271
00:24:42,220 --> 00:24:48,580
Speaker 0: So there is an allegory within this that I think is very poignant to current society as well.

272
00:24:48,740 --> 00:24:51,279
Speaker 0: Take, for example, the current war between Russia and Ukraine.

273
00:24:52,900 --> 00:25:07,060
Speaker 0: Nations can be at war with each other, but think about in all of history, like in World War I with the Christmas truce, the individual people fighting that war are separate from the societies that are fighting that war.

274
00:25:07,240 --> 00:25:23,720
Speaker 0: And these are two soldiers who meet each other on the battlefield, and while they may have a lot of reasons to be sympathetic toward and fight for the societies that spawn them, they also don't have any particularly good reason to fight between each other as individuals.

275
00:25:24,720 --> 00:25:25,188
Speaker 0: Which is a classic--.

276
00:25:26,665 --> 00:25:29,040
Speaker 1: Other than that, their orders make them, right?

277
00:25:29,121 --> 00:25:42,220
Speaker 1: Because they're not quite just soldiers on a battlefield, it's more like James Bond and the enemy agent, where they're directly against each other and they're such high-level agents that actually fall in love with the other agent.

278
00:25:42,260 --> 00:25:47,437
Speaker 0: But they are soldiers on a battlefield just at a different level with a different set of tools in the same way that during World War I--.

279
00:25:47,800 --> 00:25:53,860
Speaker 1: But if two people are just infantry and two opposing armies and they fall in love, that's not really a huge scandal.

280
00:25:54,221 --> 00:26:03,659
Speaker 1: Where if you're a real CIA agent and you actually get it on with the Russian agent for real, that's going to be like treason level.

281
00:26:04,220 --> 00:26:12,219
Speaker 1: Whereas if you're in the infantry in Ukraine and you're in love with someone from the infantry in Russia, that's not really treason level.

282
00:26:13,784 --> 00:26:15,058
Speaker 1: It's not great, but it's not--.

283
00:26:15,260 --> 00:26:23,711
Speaker 0: I guess what I want to focus on more is this idea that there's a very human sentiment and a very human emotional problem around.

284
00:26:24,393 --> 00:26:43,959
Speaker 0: societies will have conflicts that are separate from and independent from the individual people that comprise those societies and the people lose a lot of agency in terms of how they navigate those conflicts and fight them with the weapons available to them because, you know, we talked about another book a long time ago, Use of Weapons.

285
00:26:45,302 --> 00:26:48,180
Speaker 0: This is a book of two people passing a chair back and forth.

286
00:26:49,805 --> 00:27:06,400
Speaker 1: I mean, you could also, you know, if you look further into the LGBTQ angle, right, you could imagine that both of these sort of singularity-ish societies, right, are conservative societies, right?

287
00:27:06,801 --> 00:27:17,200
Speaker 1: And so it's like they're worried about dying, you know, getting killed by their commander, whatever they have, right, mother, whatever it is, because of the traitorism.

288
00:27:17,681 --> 00:27:26,100
Speaker 1: But it's like it could also be viewed as, yeah, you're going to get killed because, you know, you come from a conservative society that doesn't believe in this, right?

289
00:27:27,501 --> 00:27:30,800
Speaker 1: It's also, you know, like the found family angle, right?

290
00:27:30,880 --> 00:27:40,040
Speaker 1: It's like you found your family with this other person, not with the society you grew up in, but you still have feelings for the society that you grew up in even though it mistreated you so badly.

291
00:27:40,280 --> 00:27:59,360
Speaker 0: I know you didn't watch it to the end, but Centaurworld, because it's a short show, the actual very specific meta-plot of that is that the warriors, like the horse and the rider character, the warriors, they're only warriors because of the circumstance of the society they live in.

292
00:27:59,761 --> 00:28:13,119
Speaker 0: And when they are both introduced to a different environment where they're not forced to fight and forced to fill this role, they become very different people because what they truly wanted to be was not what the society they lived in allowed them to be.

293
00:28:13,782 --> 00:28:15,471
Speaker 1: Yep.

294
00:28:15,712 --> 00:28:17,360
Speaker 1: So, a completely separate thing.

295
00:28:17,500 --> 00:28:46,902
Speaker 1: The thing that I actually liked the most about this book, of all things, right, is that there's a particular feeling, at least I've experienced this feeling, I'm sure other people have as well, of when you're communicating with someone you care about, right, you want to hear from them, right, but you don't hear from them often, right, and you're awaiting hearing from them, right, and then you actually like hear from them, right, and it's like, oh, right, and it's like.

296
00:28:47,625 --> 00:28:52,740
Speaker 1: this book encapsulates that feeling, I think, maybe better than any book I've read.

297
00:28:52,960 --> 00:29:07,315
Speaker 0: I think back to ancient times when I would be in like high school and ICQ was open and certain people on my contact list, you know, I was a high school kid and I was a nerd, were people I might have had some affection toward that.

298
00:29:07,335 --> 00:29:08,400
Speaker 0: I didn't talk to that often.

299
00:29:09,042 --> 00:29:23,900
Speaker 0: And when certain sounds played on the computer, that meant that one of those people who has not reached out to me in a while has sent me a message, and that feeling is embedded in my soul from the year 1997.

300
00:29:23,900 --> 00:29:24,061
Speaker 1: Yep.

301
00:29:24,262 --> 00:29:58,320
Speaker 1: And so, in this book, right, it's like, you know, these characters, it's like, you know, once they're in love, it's like they're waiting so hard to get a letter, right, and then it's actually kind of fun, I think, the way the letters come, it's always like, ah, yes, the person put the letter in a gust of wind, and that way their own societies would never detect that, but somehow they knew the other person would be there at that moment to feel that gust of wind, know that it wasn't a normal gust of wind, and find the message in it every single time they never missed.

302
00:29:58,780 --> 00:29:58,841
Speaker 1: Yep.

303
00:29:58,861 --> 00:29:59,102
Speaker 1: Right?

304
00:29:59,183 --> 00:30:16,178
Speaker 1: It's like, you know, and it's like just, it must have just been fun to come up with all the different ways to deliver the message, right, and it was fun to read them, you know, and it showed, I guess, how strong of their secret agent powers were, that they could pull that off every time.

305
00:30:16,920 --> 00:30:32,439
Speaker 0: Though, along those lines, too, from the beginning, like before I got to the end, this is a short book, my first suspicion was that red and blue are, in fact, the same person, and the time travel loop, like it is the same person, end to end,

306
00:30:33,001 --> 00:30:33,162
Speaker 1: and

307
00:30:34,164 --> 00:30:39,119
Speaker 0: that is almost true, actually, when you get to the end, but not in the way that I expected it to be.

308
00:30:39,940 --> 00:30:51,260
Speaker 0: My second guess was that the seeker that was following right around, I assumed that that was one of the two of them, but I wasn't sure which, and I was right about that.

309
00:30:51,782 --> 00:30:54,259
Speaker 1: That's what I thought also, and we were both right about that.

310
00:30:54,701 --> 00:31:03,280
Speaker 0: Yeah, it made the most sense, and I felt like it was foreshadowed by the first letter that was titled "Burn Before Reading," because the messages get burned before they're read by the seeker every time.

311
00:31:04,300 --> 00:31:04,370
Speaker 1: Yep.

312
00:31:06,360 --> 00:31:22,155
Speaker 1: But yeah, so there's this seeker character who's basically, after every letter is, you know, read by the recipient, the seeker, right, just sort of eats it, and like gobbles up the remains, and it turns out that the seeker is read, right?

313
00:31:22,175 --> 00:31:23,260
Speaker 1: I didn't get that wrong.

314
00:31:23,661 --> 00:31:49,760
Speaker 1: Right, and basically by consuming all these letters, you know, Red is absorbing, you know, Blue into herself, and being some sort of combined being, and then once Red has enough Blue in her, she is then able to infiltrate, you know, the center hive area of the bio-society, right, and bring things to their climactic conclusion at the end of the

315
00:31:49,780 --> 00:31:49,860
Speaker 0: book.

316
00:31:49,860 --> 00:32:23,260
Speaker 0: Now this also addresses a concept that, again, is brought up in such works as Evangelion, and also a lot of science fiction, that there's the version of you that's in your own head, and the version of you that exists as a sort of simulacra in the heads of everyone you've ever interacted with, and if those simulacra are high enough fidelity, they could effectively be equivalent to the real you, because whatever's going on inside your head, your only impact on the world is how you interact and communicate with the outside world.

317
00:32:23,640 --> 00:32:43,320
Speaker 0: If you communicate with someone deeply, and with enough detail, you could theoretically create a version of yourself in their head that is as high fidelity as your appearance in the real world, and be predictive, and that is not explored too deeply, but that is definitely implied that that is a big part of how Blue and Red survived and were reborn.

318
00:32:44,221 --> 00:32:47,670
Speaker 1: Yeah, I mean, you basically get your typical time loop scenario, right?

319
00:32:47,750 --> 00:32:59,179
Speaker 1: Red and Blue merge into one being, effectively, and then Red goes to the birth of Blue to ensure that Blue turns out the way Blue turns out.

320
00:32:59,500 --> 00:33:09,799
Speaker 0: Which Chekhov's a fucking tree from the very beginning, when Blue's like, "Oh yeah, when I was a kid, I had a weird sickness, and it went away one day, and they checked me out, and I seemed fine, but that was weird, wasn't

321
00:33:09,839 --> 00:33:09,879
Speaker 0: it?".

322
00:33:10,221 --> 00:33:16,038
Speaker 0: I was like, "That was fucking Red, that's the entire plot right there, in that one sentence, you just told me everything about this

323
00:33:16,078 --> 00:33:16,279
Speaker 0: book.".

324
00:33:16,901 --> 00:33:17,864
Speaker 1: And that was not wrong.

325
00:33:19,168 --> 00:33:27,920
Speaker 1: But yeah, I think, you know, while those positive aspects are there, I think, you know, what Rym said before about, you know, what it takes to be, you know, an S-tier book, right?

326
00:33:28,000 --> 00:33:31,731
Speaker 1: Is like, make you think about something you had never even thought about before.

327
00:33:32,232 --> 00:33:35,020
Speaker 1: It's like, this book doesn't do that really, at least.

328
00:33:35,401 --> 00:33:41,799
Speaker 0: I think this book will do that, at a similar level to how-- For someone who hasn't read any books.

329
00:33:41,980 --> 00:33:55,540
Speaker 0: Well yeah, in a similar level, and I don't mean this to disrespect Ray Bradbury, but he is important, and he has written many great things, but he also wrote a lot of okay things, like, to be brutally honest, sorry Ray.

330
00:33:56,120 --> 00:34:08,000
Speaker 0: But I feel like it was about the same level of the average or median Ray Bradbury short story, in terms of introducing a concept to someone who may have never encountered it before.

331
00:34:08,440 --> 00:34:15,900
Speaker 0: So if someone has never read any Bradbury, and this is the first book of about that level they read, I could see this introducing a lot of really important concepts.

332
00:34:16,380 --> 00:34:25,232
Speaker 0: If I'd read this book when I was a kid, and then later in my life I read some of the lower tier Ray Bradburys, I'd be saying, "Wow, Bradbury just didn't tell me anything new.

333
00:34:25,252 --> 00:34:26,958
Speaker 0: I didn't learn anything from this short

334
00:34:26,998 --> 00:34:27,259
Speaker 0: story.".

335
00:34:27,841 --> 00:34:32,679
Speaker 1: Well, the other thing is that, whether you learned anything or not, right, is anything in this book abstract?

336
00:34:32,739 --> 00:34:35,420
Speaker 0: I didn't consider anything new that I hadn't already considered.

337
00:34:35,780 --> 00:34:38,268
Speaker 1: Nothing in this book is really abstract, right?

338
00:34:38,489 --> 00:34:41,360
Speaker 1: There's no questions of, like, what happened.

339
00:34:41,480 --> 00:34:43,630
Speaker 1: It was all literal, like, this is what happened, right?

340
00:34:43,670 --> 00:34:44,976
Speaker 1: It's fully explained, right?

341
00:34:45,900 --> 00:34:48,773
Speaker 1: Just like, you know, the Christopher Nolan movies, right?

342
00:34:48,793 --> 00:34:50,179
Speaker 1: He's hot right now again, right?

343
00:34:50,239 --> 00:34:52,580
Speaker 1: It's the same reason I don't like his movies as much as everyone else's.

344
00:34:52,719 --> 00:34:53,900
Speaker 0: He just kind of explains everything.

345
00:34:53,960 --> 00:35:03,454
Speaker 0: That is what sort of bothers me in that it raises this idea of instrumentality and self-domestication and hive minds, but it doesn't interrogate that aspect deeply enough.

346
00:35:03,735 --> 00:35:05,260
Speaker 1: It interrogates the relationship more.

347
00:35:06,280 --> 00:35:12,320
Speaker 1: Right, well, it's fine to interrogate the relationship, but, like, what did it have to, you know, what is its argument?

348
00:35:12,921 --> 00:35:17,740
Speaker 1: What's the argument that it's making about either the love story or the sci-fi story?

349
00:35:17,800 --> 00:35:19,409
Speaker 1: It's like, I don't think it is making an argument.

350
00:35:19,429 --> 00:35:24,369
Speaker 1: I think it's just literally telling this story, and it's like, there is no argument to be made.

351
00:35:24,409 --> 00:35:27,820
Speaker 1: It's sort of like, here were these characters, they fell in love.

352
00:35:28,224 --> 00:35:29,840
Speaker 1: It's like, what does this have to say?

353
00:35:30,340 --> 00:35:34,358
Speaker 0: It could be arguing that if a sentient entity...

354
00:35:35,082 --> 00:35:35,847
Speaker 1: Love conquers all?

355
00:35:35,887 --> 00:35:37,780
Speaker 1: That's what Romeo and Juliet said the same thing.

356
00:35:37,940 --> 00:35:38,535
Speaker 1: It's like, you know...

357
00:35:38,720 --> 00:35:51,680
Speaker 0: If a sentient entity believes it still has agency, it should fight to retain that agency rather than being subsumed into a meta-structure like a society and being dissolved into a full singularity.

358
00:35:51,760 --> 00:36:03,880
Speaker 0: That arguably the sentient or sapient actor has a vested interest in remaining sapient, even if that is to the detriment of the greater, and I'm making quote fingers, thing that it could create a society.

359
00:36:04,220 --> 00:36:11,000
Speaker 0: Humans forming a singularity will arguably destroy a lot of the things that individual humans enjoy about being alive.

360
00:36:11,900 --> 00:36:14,229
Speaker 1: Yeah, I think it's definitely leaning harder on.

361
00:36:14,249 --> 00:36:17,120
Speaker 1: the love conquers all, which is not a wrong message, right?

362
00:36:17,261 --> 00:36:22,160
Speaker 1: Or a bad message is just not an interesting one and it's made in like half of books ever.

363
00:36:22,901 --> 00:36:24,789
Speaker 0: I think it does make this bigger point.

364
00:36:25,010 --> 00:36:27,360
Speaker 0: I just don't know how intentional that bigger point is.

365
00:36:27,800 --> 00:36:37,267
Speaker 0: Because a slightly more eloquent, like elegantly written story would have been a little shorter and would have really woven.

366
00:36:37,568 --> 00:36:42,440
Speaker 0: what is the argument it's making about singularities and instrumentality into that story.

367
00:36:42,520 --> 00:36:48,100
Speaker 0: The fact that that is there, but not interrogated itself deeply, is what leaves me slightly unsatisfied.

368
00:36:48,360 --> 00:36:59,520
Speaker 0: Because Evangelion, and I'm not saying Evangelion is the pinnacle of instrumentality works, but many works have explored that concept more deeply and forced me to give it more pause.

369
00:36:59,901 --> 00:37:02,480
Speaker 0: This book did not at any point give me any significant pause.

370
00:37:03,200 --> 00:37:04,867
Speaker 1: No, it was not paused by anything.

371
00:37:04,927 --> 00:37:07,940
Speaker 1: It was just like, yep, that happened and that happened in the end.

372
00:37:08,020 --> 00:37:13,520
Speaker 0: So I guess if this book blew your mind, go read five random Ray Bradbury short stories.

373
00:37:13,900 --> 00:37:16,439
Speaker 0: They're like seven pages long, some of them.

374
00:37:17,924 --> 00:37:19,039
Speaker 1: Go read something longer.

375
00:37:19,520 --> 00:37:23,180
Speaker 0: Yeah, but just read some Ray Bradbury and I'm just curious your thoughts.

376
00:37:23,581 --> 00:37:26,618
Speaker 0: If this book didn't blow your mind, then I don't know, I guess you're pretty well read.

377
00:37:27,800 --> 00:37:28,204
Speaker 1: Yeah, maybe.

378
00:37:29,234 --> 00:37:29,517
Speaker 1: But yeah.

379
00:37:31,382 --> 00:37:32,187
Speaker 1: Well, okay.

380
00:37:32,208 --> 00:37:34,140
Speaker 1: So do we have anything else to say about this book?

381
00:37:34,301 --> 00:37:36,900
Speaker 0: I actually don't have a lot else to say about it.

382
00:37:36,900 --> 00:37:37,769
Speaker 1: I mean, it was really short.

383
00:37:37,789 --> 00:37:38,800
Speaker 1: I mean, how else could we?

384
00:37:39,060 --> 00:37:40,785
Speaker 0: Yeah.

385
00:37:40,885 --> 00:37:49,340
Speaker 0: So to get back to the beginning, because traditionally, whoever's turn it is to bring the two offerings, the two options for the next book club, has to bring them to the table.

386
00:37:49,980 --> 00:37:53,220
Speaker 0: And you said something very important at the very beginning.

387
00:37:53,861 --> 00:37:55,919
Speaker 0: Why did you put this book on the list of two?

388
00:37:56,600 --> 00:38:00,659
Speaker 0: Because, not just because of Pride, but also because you kept hearing about it.

389
00:38:02,043 --> 00:38:03,500
Speaker 1: So there's a book you kept hearing about.

390
00:38:03,741 --> 00:38:17,420
Speaker 0: So my two options for the next book club book are two books that in the last six months, I have been hearing about repeatedly in more than two of my social circles.

391
00:38:18,241 --> 00:38:18,936
Speaker 1: Oh, that's a thing.

392
00:38:19,801 --> 00:38:24,317
Speaker 0: These two books have come up so much that I kept a lid.

393
00:38:24,357 --> 00:38:25,060
Speaker 0: These are the two.

394
00:38:25,480 --> 00:38:30,580
Speaker 0: They have come up more than any other books outside of one specific social circle.

395
00:38:31,000 --> 00:38:31,575
Speaker 1: Have I heard of them?

396
00:38:32,381 --> 00:38:40,060
Speaker 0: Either Gideon the Ninth by Tamsin Ware or The Murderbot Diaries by Martha Wells.

397
00:38:41,380 --> 00:38:42,919
Speaker 0: So The Murderbot Diaries.

398
00:38:43,020 --> 00:38:44,119
Speaker 1: Have I heard of either one of these?

399
00:38:44,500 --> 00:38:47,280
Speaker 0: So I'll give you a little bit of a brief pitch for both.

400
00:38:47,760 --> 00:38:49,545
Speaker 0: The Murderbot Diaries is sci-fi.

401
00:38:51,170 --> 00:38:54,800
Speaker 0: It is about a part robot, part human construct designed as a-.

402
00:38:54,800 --> 00:38:56,608
Speaker 1: So The Murderbot Diaries is several books.

403
00:38:56,728 --> 00:38:59,360
Speaker 1: Are you going to pick one of them or are you taking this box set deal?

404
00:39:00,142 --> 00:39:00,423
Speaker 0: I see.

405
00:39:00,504 --> 00:39:02,332
Speaker 0: I feel like we should just read the first bit.

406
00:39:02,393 --> 00:39:03,840
Speaker 0: All systems read for the book club.

407
00:39:04,701 --> 00:39:05,871
Speaker 1: Okay, one of seven.

408
00:39:05,891 --> 00:39:06,920
Speaker 1: It's one of seven.

409
00:39:07,140 --> 00:39:08,200
Speaker 1: If we want to go further, we can.

410
00:39:09,080 --> 00:39:12,680
Speaker 1: These are both series, so we know whichever one, Rym's going to read the whole series.

411
00:39:12,740 --> 00:39:14,740
Speaker 0: Oh yeah, I'm going to read them all anyway, but the book club, we'll keep it confined.

412
00:39:14,760 --> 00:39:18,420
Speaker 1: Gideon the Ninth is a three book series?

413
00:39:18,760 --> 00:39:19,959
Speaker 0: Yup, we're reading the first one.

414
00:39:21,661 --> 00:39:31,120
Speaker 0: So, but Murderbot Diaries is broadly about this murderbot, like a security unit that is a murder robot that's a human-robot hybrid of some kind.

415
00:39:31,800 --> 00:39:36,680
Speaker 0: And it overrides its governor and develops independence and ostensibly free will.

416
00:39:37,541 --> 00:39:42,880
Speaker 0: And what it does with that and whether or not it continues to be a murderbot and why.

417
00:39:43,802 --> 00:39:52,000
Speaker 0: And this book has come up in surprising conversations among people I consider to be very smart that I am friends with.

418
00:39:53,621 --> 00:40:00,100
Speaker 0: And I am very interested to see if this book lives up to some of the assertions I have heard about it from people you and I both know and trust.

419
00:40:01,240 --> 00:40:05,160
Speaker 0: Gideon the Ninth has just come up over and over and over and over again.

420
00:40:05,260 --> 00:40:07,859
Speaker 0: When I finally looked up what it's about, it's about...

421
00:40:08,201 --> 00:40:12,800
Speaker 1: But the first line of the description on the internet says the emperor needs necromancers.

422
00:40:12,920 --> 00:40:14,439
Speaker 0: Oh, and the star system dominicus.

423
00:40:14,680 --> 00:40:16,640
Speaker 1: And the ninth necromancer needs a swordswoman.

424
00:40:16,760 --> 00:40:18,384
Speaker 0: There are nine planets.

425
00:40:18,645 --> 00:40:25,020
Speaker 0: Each of these nine planets is home to a great house, like Dune style, that practices its own school of necromancy.

426
00:40:26,362 --> 00:40:26,758
Speaker 1: I see that.

427
00:40:28,521 --> 00:40:31,733
Speaker 1: It's called the Locked Tomb series.

428
00:40:32,134 --> 00:40:33,620
Speaker 1: Each book is someone the ninth.

429
00:40:33,880 --> 00:40:37,360
Speaker 1: So the second book is Harrow the ninth and the third book is Nona the ninth.

430
00:40:37,400 --> 00:40:42,240
Speaker 0: So space necromancy, already I am down, but I can't say that would be good.

431
00:40:43,140 --> 00:40:44,059
Speaker 1: Space necromancy.

432
00:40:44,361 --> 00:40:45,069
Speaker 0: So here's the rub.

433
00:40:47,220 --> 00:41:02,480
Speaker 0: Gideon the Ninth was named one of the best books of 2019 by all of NPR, Vox, the New York Public Library, Wired, Polygon, Bustle, Paste, Book Riot, and Gizmodo Australia.

434
00:41:04,084 --> 00:41:04,773
Speaker 1: That is a list.

435
00:41:06,380 --> 00:41:16,561
Speaker 1: It says here that All Systems Red won the Hugo, Nebula, Alex, and Locus award in 2018.

436
00:41:16,561 --> 00:41:17,240
Speaker 0: And you know who's...

437
00:41:17,260 --> 00:41:24,153
Speaker 1: Gideon the Ninth won the Locus, Hugo, and Crawford award, but it was a finalist for a different Hugo award.

438
00:41:28,682 --> 00:41:29,940
Speaker 0: Oh, I got even more for you.

439
00:41:30,040 --> 00:41:35,120
Speaker 1: It was a finalist for two different Hugo awards, a Nebula, a Dragon, and a World Fantasy award.

440
00:41:36,124 --> 00:41:38,560
Speaker 1: So they both have basically a big trophy chest.

441
00:41:39,240 --> 00:41:54,720
Speaker 0: They both have equivalent gigantic trophy chests, but Gideon the Ninth is specifically publicly highly recommended by one of the authors of the book we just read and by the author of the Murderbot Diaries, Martha Wells.

442
00:41:55,464 --> 00:41:55,759
Speaker 1: Okay.

443
00:41:56,863 --> 00:41:58,660
Speaker 1: So there is a big confluence here.

444
00:41:58,780 --> 00:42:01,740
Speaker 1: I have a feeling it seems likely we're going to read both of these at some point in life.

445
00:42:01,760 --> 00:42:09,620
Speaker 0: I feel like that's true, but you have the unenviable task of deciding which of these reread as the next book club.

446
00:42:10,221 --> 00:42:11,760
Speaker 1: Well, I'm looking here at all this data.

447
00:42:12,001 --> 00:42:13,919
Speaker 0: You don't have to decide right now if you don't want to.

448
00:42:14,320 --> 00:42:15,752
Speaker 1: No, no, I think I could decide right now.

449
00:42:16,800 --> 00:42:20,156
Speaker 0: I do like the idea of trying to force the decision at the end of every book club.

450
00:42:20,176 --> 00:42:20,940
Speaker 1: It's more fun that way.

451
00:42:20,960 --> 00:42:23,420
Speaker 1: So, you know, I like a necromancer and I like a Murderbot.

452
00:42:23,760 --> 00:42:23,887
Speaker 1: Right.

453
00:42:23,929 --> 00:42:24,099
Speaker 1: Okay.

454
00:42:24,360 --> 00:42:29,140
Speaker 1: And it's like, it's like, Oh, should I eat this steak or the other steak?

455
00:42:29,926 --> 00:42:30,356
Speaker 1: Oh, no.

456
00:42:30,821 --> 00:42:38,660
Speaker 1: It's like, uh, but yeah, so according to the, on the one hand, what I think, you know, if you, it's hard to compare the quality levels, right?

457
00:42:38,680 --> 00:42:39,619
Speaker 1: We can't be looking at that.

458
00:42:39,746 --> 00:42:39,940
Speaker 1: Right.

459
00:42:40,361 --> 00:42:47,240
Speaker 1: And we can't really be comparing how cool is necromancy versus how cool is Murderbots because space necromancy and Murderbots, that's equally cool.

460
00:42:47,488 --> 00:42:47,660
Speaker 1: Right.

461
00:42:47,860 --> 00:42:48,719
Speaker 1: We can't compare that.

462
00:42:49,102 --> 00:42:50,650
Speaker 1: And they both have a pile of awards.

463
00:42:50,992 --> 00:42:52,219
Speaker 1: We can't use that to separate them.

464
00:42:52,660 --> 00:42:54,672
Speaker 1: They both have a 4.2 on Goodreads.

465
00:42:54,994 --> 00:42:55,880
Speaker 1: Can't separate them.

466
00:42:56,641 --> 00:42:59,873
Speaker 1: One of them has 14,000 ratings on Amazon with a 4.5 score.

467
00:43:02,341 --> 00:43:09,095
Speaker 1: The other one has 40,000 ratings on Amazon, which is a lot more ratings, but a 4.4 score, so 0.1 less.

468
00:43:12,760 --> 00:43:23,100
Speaker 1: Um, I think the separator is going to be that one of these books on with Kindle unlimited is $0 so I don't have to go.

469
00:43:23,260 --> 00:43:25,586
Speaker 1: I don't have to go to the library or pay money.

470
00:43:26,087 --> 00:43:29,516
Speaker 1: And the other one on Kindle is a mere $2 and 50 cents.

471
00:43:31,000 --> 00:43:36,120
Speaker 0: Considering I am ambivalent between these books, not in that I don't care in that I find them equally compelling.

472
00:43:36,762 --> 00:43:38,053
Speaker 0: That's better than a coin flip.

473
00:43:38,113 --> 00:43:38,920
Speaker 0: That's how you're going to choose.

474
00:43:38,960 --> 00:43:50,179
Speaker 1: Alright, so the $0 book on Kindle unlimited, for those of you who I guess use Kindles, for everyone else just go to the library and it'll still be $0, is the Murderbot one.

475
00:43:50,219 --> 00:43:51,360
Speaker 1: It is $0.

476
00:43:51,360 --> 00:43:58,020
Speaker 0: Alright, then the next Geek Nights Book Club book will be The Murderbot Diaries All Systems Red by Martha Wells.

477
00:43:59,480 --> 00:44:02,219
Speaker 1: Read for free at the library or Kindle.

478
00:44:07,292 --> 00:44:09,537
Speaker 0: This has been Geek Nights with Rim and Scott.

479
00:44:09,578 --> 00:44:14,590
Speaker 0: Special thanks to DJ Pretzel for the opening music, Kat Lee for web design, and Brando K for the logos.

480
00:44:14,950 --> 00:44:19,990
Speaker 1: Be sure to visit our website at FrontRowCrew.com for show notes, discussion news, and more.

481
00:44:20,270 --> 00:44:22,917
Speaker 0: Remember, Geek Nights is not one, but four different shows.

482
00:44:23,057 --> 00:44:27,650
Speaker 0: SciTech Mondays, Gaming Tuesdays, Anime Comic Wednesdays, and Indiscriminate Thursdays.

483
00:44:28,050 --> 00:44:31,166
Speaker 1: Geek Nights is distributed under a Creative Commons Attribution 3.0 license.

484
00:44:31,950 --> 00:44:38,610
Speaker 1: Geek Nights is recorded live with no studio and no audience, but unlike those other late shows, it's actually recorded at night.

485
00:44:38,830 --> 00:44:56,030
Speaker 0: And the Patreon patrons for the Geek Nights Book Club tonight are Alan Joyce, Linki G, Jared, Lily Tenebrae, Case Cairn, Mix Music, Chris Haddad, Clinton Walton, Dex, Finn, Joel Hayes, Rebecca Dunne, Sam Erickson, Shervin Von Horrell, and a ton of people who are not saying, they are asking me not to say their names.

486
00:44:56,494 --> 00:44:57,910
Speaker 0: I'm real hungry and real tired.

487
00:44:58,810 --> 00:45:06,670
Speaker 0: Uh, yeah, stay tuned for regularly scheduled, but possibly rotating days of Geek Nights for the foreseeable future.

488
00:45:07,190 --> 00:45:15,170
Speaker 0: With the tiny extra caveat that I might have to go to Germany for a week, uh, in a few weeks, and if that happens, there will definitely be no Geek Nights that week.

489
00:45:15,850 --> 00:45:18,967
Speaker 0: So yeah, I leave you, tonight, with...

