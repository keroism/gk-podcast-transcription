1
00:00:08,540 --> 00:00:12,031
Speaker 1: It's Monday December 19th, 2011.

2
00:00:12,031 --> 00:00:12,513
Speaker 1: I'm Rem.

3
00:00:12,653 --> 00:00:13,134
Speaker 0: I'm Scott.

4
00:00:13,315 --> 00:00:14,659
Speaker 1: And this is Geek Nights.

5
00:00:14,719 --> 00:00:17,781
Speaker 1: Tonight, software development methodologies.

6
00:00:24,166 --> 00:00:25,246
Speaker 0: Let's do this.

7
00:00:29,929 --> 00:00:32,895
Speaker 1: While you were home being a bum, I was out shushin'.

8
00:00:34,159 --> 00:00:34,540
Speaker 0: Shushin'.

9
00:00:34,761 --> 00:00:35,142
Speaker 1: Shushin'.

10
00:00:36,145 --> 00:00:36,607
Speaker 0: That's nice.

11
00:00:36,888 --> 00:00:40,888
Speaker 1: There was actually some pretty good shushin', even though it was kind of disturbing that, you know.

12
00:00:40,908 --> 00:00:42,958
Speaker 0: How many people other than you were shushin'?

13
00:00:43,038 --> 00:00:44,384
Speaker 1: Not that many people.

14
00:00:44,445 --> 00:00:46,012
Speaker 0: I didn't think that many people would be.

15
00:00:46,293 --> 00:00:48,221
Speaker 0: There were maybe... But it was cold.

16
00:00:48,402 --> 00:00:50,772
Speaker 1: Maybe thousand people other than me at the mountain.

17
00:00:50,813 --> 00:00:51,376
Speaker 0: Oh, that's a lot.

18
00:00:51,577 --> 00:00:52,040
Speaker 1: Not really.

19
00:00:52,422 --> 00:00:53,367
Speaker 0: How many people is it usually?

20
00:00:53,508 --> 00:00:54,192
Speaker 1: A lot more than that.

21
00:00:54,212 --> 00:00:57,492
Speaker 1: There's usually lines where you have to wait like 20 minutes just to get on the lift.

22
00:00:58,135 --> 00:00:59,282
Speaker 0: Oh, but there's no line to shush.

23
00:00:59,302 --> 00:01:00,730
Speaker 0: There's just a line to get up to the top.

24
00:01:01,271 --> 00:01:02,399
Speaker 1: Yeah, why would there be a line to shush?

25
00:01:02,419 --> 00:01:02,922
Speaker 1: You just shush.

26
00:01:03,083 --> 00:01:03,949
Speaker 0: That's what I'm saying.

27
00:01:04,049 --> 00:01:06,964
Speaker 0: But, you know, people could be lined up, you know, if it's like a narrow entryway.

28
00:01:07,306 --> 00:01:09,617
Speaker 1: That's not how it works, by and large.

29
00:01:09,918 --> 00:01:11,726
Speaker 0: Is there like a line at the top, like start here?

30
00:01:11,746 --> 00:01:14,498
Speaker 1: No, there's just a mountain, and you can go in any direction.

31
00:01:14,518 --> 00:01:16,004
Speaker 1: There's like 20 different ways down.

32
00:01:16,024 --> 00:01:17,148
Speaker 1: Uh-huh.

33
00:01:17,830 --> 00:01:18,674
Speaker 1: Though the funny thing...

34
00:01:18,694 --> 00:01:22,615
Speaker 0: So you can even go down, like, in between one of the spots where you're not supposed to go.

35
00:01:22,635 --> 00:01:23,319
Speaker 0: You can.

36
00:01:23,460 --> 00:01:23,983
Speaker 1: You shouldn't.

37
00:01:24,486 --> 00:01:24,928
Speaker 1: Obviously you should.

38
00:01:24,948 --> 00:01:26,034
Speaker 1: But there are people who do.

39
00:01:26,194 --> 00:01:27,902
Speaker 1: I've done it a couple of times.

40
00:01:27,963 --> 00:01:30,072
Speaker 1: I've gone places that weren't actually trails.

41
00:01:30,533 --> 00:01:30,975
Speaker 1: What happens?

42
00:01:31,055 --> 00:01:33,121
Speaker 1: Or gone down closed trails.

43
00:01:34,466 --> 00:01:37,558
Speaker 1: You just ski and hope you don't get hurt, because if you do, they're not going to find you.

44
00:01:38,020 --> 00:01:38,422
Speaker 0: Alrighty.

45
00:01:39,447 --> 00:01:40,612
Speaker 0: Even if you scream or something?

46
00:01:41,255 --> 00:01:41,557
Speaker 1: Maybe.

47
00:01:41,637 --> 00:01:42,139
Speaker 1: I don't know.

48
00:01:42,481 --> 00:01:43,987
Speaker 0: Just if you're not in screaming condition.

49
00:01:44,349 --> 00:01:46,076
Speaker 1: Usually you go, you do that with a buddy.

50
00:01:46,096 --> 00:01:47,281
Speaker 0: A buddy system.

51
00:01:47,542 --> 00:01:47,723
Speaker 1: Yeah.

52
00:01:48,025 --> 00:01:49,270
Speaker 0: So one person will do the screaming.

53
00:01:49,450 --> 00:01:50,837
Speaker 1: But it was interesting that I'm there, right?

54
00:01:51,259 --> 00:01:53,771
Speaker 1: And there hasn't been really any snow this year.

55
00:01:53,912 --> 00:02:01,603
Speaker 1: So everything around was green and brown, except the mountain, because Hunter actually makes snow, and they made a ton of snow.

56
00:02:01,644 --> 00:02:03,310
Speaker 0: But it was cold, so the snow probably didn't melt.

57
00:02:04,071 --> 00:02:04,413
Speaker 1: No, it didn't.

58
00:02:04,433 --> 00:02:06,906
Speaker 1: They were making snow constantly the whole time I was there, too.

59
00:02:07,007 --> 00:02:08,955
Speaker 1: So feet and feet of it were just being dumped.

60
00:02:10,059 --> 00:02:11,784
Speaker 0: So there's a snowmaking machine.

61
00:02:12,487 --> 00:02:13,009
Speaker 1: Many of them.

62
00:02:13,149 --> 00:02:14,234
Speaker 0: And they spray snow.

63
00:02:14,496 --> 00:02:17,751
Speaker 1: They spray water into the air that basically turns it into snow and falls back down.

64
00:02:18,313 --> 00:02:20,819
Speaker 0: Okay, so is it just like it's snowing everywhere?

65
00:02:20,839 --> 00:02:21,982
Speaker 0: I have a video of it, in fact.

66
00:02:25,290 --> 00:02:27,946
Speaker 0: Or are there people shoveling the snow to get it on all the parts?

67
00:02:28,086 --> 00:02:29,815
Speaker 1: Oh, it's basically snowing everywhere.

68
00:02:30,097 --> 00:02:32,548
Speaker 0: So basically they spray it off the top of the mountain.

69
00:02:32,749 --> 00:02:34,196
Speaker 1: Well, no, they spray it.

70
00:02:34,216 --> 00:02:36,489
Speaker 1: Scott, Scott, they spray it at intervals all over the mountain.

71
00:02:36,509 --> 00:02:39,129
Speaker 1: If you want to get into the details of how they make snow, it's not what you're envisioning.

72
00:02:39,169 --> 00:02:40,456
Speaker 0: It's not about how they make the snow.

73
00:02:40,476 --> 00:02:43,711
Speaker 0: It's about how they get the snow, which is also how they make it.

74
00:02:43,772 --> 00:02:46,564
Speaker 1: They spray it at every individual point along the way.

75
00:02:46,965 --> 00:02:49,556
Speaker 1: There are thousands of spray nozzles all over the mountain.

76
00:02:50,782 --> 00:02:54,076
Speaker 0: I thought it was a machine that just sort of sprays it in one big spot.

77
00:02:54,277 --> 00:02:55,201
Speaker 1: No, no, no, no.

78
00:02:55,221 --> 00:02:56,908
Speaker 0: They make the snow and they pump it around.

79
00:02:56,928 --> 00:03:02,345
Speaker 1: Now they have some point places that'll make the snow for like one particular area at a time.

80
00:03:02,365 --> 00:03:08,328
Speaker 0: So the snow gets delivered at like a sprinkler system almost out of separate thingies.

81
00:03:08,509 --> 00:03:09,152
Speaker 1: Sort of, yeah.

82
00:03:09,595 --> 00:03:09,756
Speaker 1: Okay.

83
00:03:09,916 --> 00:03:10,982
Speaker 1: But there hadn't been any snow.

84
00:03:11,042 --> 00:03:13,474
Speaker 1: So the whole area around the mountain was basically brown.

85
00:03:13,835 --> 00:03:20,944
Speaker 1: And then the mountain itself had these crazy ungroomed moguls because they were basically pouring snow down and it tends to form into moguls.

86
00:03:21,828 --> 00:03:22,310
Speaker 1: It was awesome.

87
00:03:22,770 --> 00:03:23,595
Speaker 1: It was absolutely awesome.

88
00:03:23,615 --> 00:03:24,942
Speaker 0: Why aren't they like raked or something?

89
00:03:25,486 --> 00:03:28,441
Speaker 1: They do groom things, but not while they're making it because it'll just get ungroomed.

90
00:03:28,521 --> 00:03:32,479
Speaker 1: And frankly, I prefer skiing ungroomed crazy terrain.

91
00:03:33,202 --> 00:03:35,412
Speaker 0: Wouldn't you want like, what do they do for like Olympic snow?

92
00:03:35,432 --> 00:03:37,659
Speaker 1: Uh, same thing.

93
00:03:37,860 --> 00:03:39,084
Speaker 1: and or using natural snow.

94
00:03:39,787 --> 00:03:41,495
Speaker 1: And then they groom it depending on what kind of race it is.

95
00:03:41,535 --> 00:03:43,870
Speaker 1: They make like the field for the racing or the slalom or whatever.

96
00:03:44,631 --> 00:03:45,919
Speaker 1: There's some racing courses at Hunter.

97
00:03:46,080 --> 00:03:49,737
Speaker 0: It's just like you see Olympic snow and it's like oh yeah, they groom that.

98
00:03:50,220 --> 00:03:52,270
Speaker 0: It's like that's the, you know, where can you get that kind of action.

99
00:03:52,431 --> 00:03:53,333
Speaker 1: They groom that shit.

100
00:03:54,215 --> 00:03:56,882
Speaker 1: But anyway, the funny thing was there's one run.

101
00:03:57,142 --> 00:04:01,094
Speaker 1: They don't at the same time.

102
00:04:01,154 --> 00:04:03,424
Speaker 1: So they made like a set of runs you could do.

103
00:04:04,108 --> 00:04:07,804
Speaker 1: And one of them Minya Konka, which is one of my favorites anyway, or Minya Konka I guess.

104
00:04:08,909 --> 00:04:13,397
Speaker 1: I've never actually looked at how it's spelled and I'm trying to think back as to how it's spelled because it's going to make fun of you.

105
00:04:13,578 --> 00:04:17,031
Speaker 1: You're going to get, you're going to get reamed of the trails.

106
00:04:17,534 --> 00:04:21,466
Speaker 1: But uh, there it was, it looked like it was closed.

107
00:04:21,786 --> 00:04:25,502
Speaker 1: But if you skied all the way over there and look down, the sign didn't say closed.

108
00:04:25,542 --> 00:04:27,892
Speaker 1: It said warning ungroomed experts only.

109
00:04:29,035 --> 00:04:34,271
Speaker 1: So I went over there and there was maybe one other dude going down that same trail.

110
00:04:34,392 --> 00:04:36,861
Speaker 1: So I just had this whole trail to myself like all day.

111
00:04:36,881 --> 00:04:39,450
Speaker 1: It was kind of hard though.

112
00:04:40,010 --> 00:04:40,633
Speaker 0: No kidding.

113
00:04:40,814 --> 00:04:43,386
Speaker 1: In fact it was way hard, but I took a lesson.

114
00:04:43,406 --> 00:04:48,817
Speaker 0: I feel kind of confident now because you paid money for a lesson for a professional person because I was, you know, why did the professional person tell you?

115
00:04:49,018 --> 00:04:51,210
Speaker 1: Well, basically he told me what I expected.

116
00:04:51,310 --> 00:04:53,362
Speaker 1: He looked at how I skied and said, you're great.

117
00:04:53,744 --> 00:04:54,850
Speaker 1: You're on your way to be an expert.

118
00:04:54,970 --> 00:04:57,440
Speaker 1: Just keep skiing all the time.

119
00:04:57,460 --> 00:05:00,372
Speaker 1: And he showed me a couple exercises to do that I'd never thought of.

120
00:05:00,473 --> 00:05:02,845
Speaker 1: And it was actually surprising how much that helped.

121
00:05:02,865 --> 00:05:05,436
Speaker 1: He told me this thing called pizza, pizza, french fries.

122
00:05:05,758 --> 00:05:07,063
Speaker 1: He was like, yeah, right.

123
00:05:07,806 --> 00:05:13,052
Speaker 1: Actually there's a big argument that you shouldn't even teach kids that you should start them on parallel skiing right away.

124
00:05:13,072 --> 00:05:20,537
Speaker 1: And I kind of agree with that because the snowplow formation is basically dangerous and slow and stupid.

125
00:05:20,577 --> 00:05:22,504
Speaker 1: And if you go too fast, it can't stop you.

126
00:05:23,769 --> 00:05:25,840
Speaker 1: And you're more likely to have a spiral fracture.

127
00:05:25,860 --> 00:05:29,357
Speaker 1: And if you don't know what that is, imagine a fracture of bones that is spiral.

128
00:05:29,758 --> 00:05:30,822
Speaker 0: Yeah, you don't want that shit.

129
00:05:31,786 --> 00:05:34,919
Speaker 1: But you taught me this weird exercise to do.

130
00:05:34,959 --> 00:05:38,093
Speaker 1: And usually I'm like, eh, exercises, I'll just practice by skiing or whatever.

131
00:05:38,153 --> 00:05:40,384
Speaker 1: But basically I had to stand sideways.

132
00:05:40,445 --> 00:05:45,143
Speaker 1: So like if the mountain's down, I'm standing to where I'm kind of facing perpendicularly to the fall line.

133
00:05:45,925 --> 00:05:48,194
Speaker 1: And then he's like, and then change your edges.

134
00:05:48,255 --> 00:05:50,989
Speaker 1: You start sliding sideways on your skis down the mountain.

135
00:05:51,130 --> 00:05:54,286
Speaker 0: So you're looking left, but you're going down and your skis are pointing down.

136
00:05:54,306 --> 00:05:54,567
Speaker 0: Yep.

137
00:05:54,949 --> 00:06:01,617
Speaker 1: And then he's like, all right, then change your edging so that the front is falling faster than the back and then repeat.

138
00:06:01,657 --> 00:06:05,595
Speaker 1: So you kind of go like a falling leaf, like woo woo woo all the way down the mountain.

139
00:06:06,258 --> 00:06:10,316
Speaker 1: He was like, do that twice down the entire mountain and you'll be a better skier afterward.

140
00:06:10,376 --> 00:06:18,705
Speaker 1: And I did it and it hurts like a hundred percent and I can't even figure out exactly what I'm better at, but I'm better.

141
00:06:18,725 --> 00:06:19,668
Speaker 0: All right.

142
00:06:19,909 --> 00:06:22,220
Speaker 1: So do that thing if you want to get better at skiing.

143
00:06:22,462 --> 00:06:31,627
Speaker 0: You should maybe just do that thing every time you go to the mountain, like, like start off by just doing that two times and then, you know, until you can do it until you can do it without even thinking about it.

144
00:06:31,687 --> 00:06:38,683
Speaker 1: I realized that it's like DDR, like aside from exercises and things, you know, this guy, he's an expert skier and he's trying to explain like concepts of skiing.

145
00:06:39,426 --> 00:06:49,790
Speaker 1: And it's a lot like, you know, when you try to explain like a skill that you know intuitively that you learn from practice, how usually the advice you give doesn't really mean much to someone who isn't on the heads.

146
00:06:49,990 --> 00:06:50,834
Speaker 0: It's like, yeah, thanks.

147
00:06:50,874 --> 00:06:51,316
Speaker 0: I knew that.

148
00:06:51,336 --> 00:06:52,139
Speaker 0: Yep, exactly.

149
00:06:52,159 --> 00:07:06,572
Speaker 1: It just kind of reinforces this idea that for physical skills, skills of dexterity, of balance, of physicality, very little help is gained in the end from someone telling you or showing you, you really just have to do it.

150
00:07:06,612 --> 00:07:10,236
Speaker 0: Well, I think, well, obviously you have to do it, but showing definitely helps because you can watch.

151
00:07:10,256 --> 00:07:11,826
Speaker 0: To a degree, but it can only get you so far.

152
00:07:11,846 --> 00:07:21,285
Speaker 0: You have to watch and duplicate, but once you're able to duplicate and the person is watching you, it confirms you are doing it properly, then, you know, that's only step one.

153
00:07:21,346 --> 00:07:23,875
Speaker 0: Step two is repeat it now a thousand times.

154
00:07:24,115 --> 00:07:31,324
Speaker 0: That's, you know, so it just, but it does help to watch and have a person confirm that you are duplicating properly.

155
00:07:31,344 --> 00:07:41,790
Speaker 1: That was the main reason I got a lesson because, you know, I've been skiing for a few years and I'm doing like pretty expert stuff, but I, I always feel really not so confident sometimes on these hills.

156
00:07:42,351 --> 00:07:45,165
Speaker 1: So I wanted an expert to look at me and tell me if I was an idiot or not.

157
00:07:45,185 --> 00:07:47,474
Speaker 1: And apparently I'm not that much of an idiot.

158
00:07:47,795 --> 00:07:52,370
Speaker 0: All right, so, so news, news, technologies, lots of technology.

159
00:07:52,470 --> 00:07:53,213
Speaker 0: news too much.

160
00:07:53,515 --> 00:07:54,498
Speaker 0: Uh, so check this out.

161
00:07:54,579 --> 00:08:04,401
Speaker 0: in India, in India, India, people don't have a lot of money, relatively speaking, not a lot of money, but they got a lot of cell phones, cell phones, too many cell phones, almost too many cell phones and too many people.

162
00:08:04,421 --> 00:08:08,217
Speaker 0: Uh, so they want to save money on the cell phone bill.

163
00:08:08,257 --> 00:08:10,186
Speaker 0: Thankfully it doesn't cost as much as it does here.

164
00:08:10,206 --> 00:08:11,953
Speaker 0: Well, how can you do this?

165
00:08:12,314 --> 00:08:12,856
Speaker 0: real easy?

166
00:08:13,880 --> 00:08:21,554
Speaker 0: First, get one of those plans where you pay as you go and by the minute, as opposed to buying minutes upfront, like you have to do here, which is annoying too.

167
00:08:22,096 --> 00:08:26,890
Speaker 0: Let's say you want to call someone, but you don't want to pay for minutes or anything.

168
00:08:27,571 --> 00:08:34,860
Speaker 0: Call them and hang up after the first ring, they'll see your number on the caller ID and they'll call your ass back on the landline or whatever.

169
00:08:35,724 --> 00:08:37,511
Speaker 0: Well, you know, a lot of people do this.

170
00:08:37,572 --> 00:08:42,056
Speaker 0: Apparently about half of people in India have done this, uh, with their cell phones to save money.

171
00:08:42,076 --> 00:08:45,715
Speaker 1: You know, I used to do something like that when I had to get, before I had a car.

172
00:08:45,735 --> 00:08:58,294
Speaker 1: Yeah, I'd take classes at the local college and to call my mom to pick me up after school, I would basically do a collect call to the house and it would be like collect call from pick me up.

173
00:09:01,721 --> 00:09:03,104
Speaker 0: It totally works.

174
00:09:03,505 --> 00:09:05,630
Speaker 0: So, but here's something even crazier.

175
00:09:06,151 --> 00:09:13,395
Speaker 0: A lot of people out there are specifically creating automatic phone services that use missed calls.

176
00:09:13,556 --> 00:09:17,070
Speaker 0: So for example, in the US, you know, you might call Google four one one.

177
00:09:17,150 --> 00:09:17,892
Speaker 0: Does that still exist?

178
00:09:18,374 --> 00:09:19,217
Speaker 0: I have no idea.

179
00:09:19,237 --> 00:09:19,799
Speaker 1: All right.

180
00:09:20,782 --> 00:09:26,106
Speaker 0: Uh, or you might call, you know, uh, for example, I called the jury duty to find out if I had jury duty.

181
00:09:26,166 --> 00:09:29,159
Speaker 0: I don't, I'm probably not gonna, but I still have to call for the rest of the week.

182
00:09:30,223 --> 00:09:37,738
Speaker 0: Uh, and I call and I wait and I push the numbers and then eventually they, you know, I'm on hold and eventually they tell me, you know, whether it's yes or no.

183
00:09:38,803 --> 00:09:47,240
Speaker 0: Imagine if I called the jury duty and hung up and then they called my ass back on the, with the automatic system, called me back and told me based on my number.

184
00:09:47,501 --> 00:09:49,450
Speaker 1: Now, maybe though that might cost them something.

185
00:09:49,570 --> 00:10:02,320
Speaker 1: So what if instead you had a service where you call them and hang up and then they call you back and let it ring a number of times and hang up and then you have a system that knows one ring means show up to means don't.

186
00:10:03,123 --> 00:10:03,484
Speaker 0: Yeah.

187
00:10:03,565 --> 00:10:11,240
Speaker 0: But no, this is basically like there's people are setting up systems where you'll call a phone number, hang up after one ring and it'll call you back and tell you the weather.

188
00:10:11,300 --> 00:10:19,955
Speaker 0: I'll call you back and tell you the bus schedule or you know, do all kinds of other stuff so that you don't need to use your minutes and you can still get service.

189
00:10:19,995 --> 00:10:26,962
Speaker 0: And the person who has to pay is, you know, the person on the other end who has maybe a landline, it isn't paying so much.

190
00:10:27,705 --> 00:10:37,701
Speaker 0: And apparently, you know, they make an average of three dollars per customer in profits of revenue of three dollars per customer on phone service in India.

191
00:10:37,762 --> 00:10:45,790
Speaker 0: Nine hundred million accounts times three dollars is still two point seven billion dollars, but they're only making three bucks per customer.

192
00:10:46,470 --> 00:10:47,955
Speaker 0: That's not a lot.

193
00:10:48,417 --> 00:10:50,484
Speaker 0: And they would make a lot more, they said.

194
00:10:50,524 --> 00:10:54,980
Speaker 0: But half of people, you know, use this this kind of trickery.

195
00:10:55,361 --> 00:10:57,930
Speaker 0: So maybe they'll make five dollars per user instead.

196
00:10:58,210 --> 00:11:01,663
Speaker 0: Five times nine million is four and a half billion.

197
00:11:01,724 --> 00:11:07,869
Speaker 1: See, the only way instead of two point seven billion, you really want to make money off of from something like that.

198
00:11:07,890 --> 00:11:14,210
Speaker 1: You either have to use that as a kind of bundled service with a bunch of other things or no.

199
00:11:14,510 --> 00:11:15,816
Speaker 1: Eventually they'll be open source.

200
00:11:15,997 --> 00:11:19,835
Speaker 1: Everyone individually is empowered to use their own services like that.

201
00:11:19,856 --> 00:11:21,064
Speaker 0: I think it's there also because they're just.

202
00:11:21,104 --> 00:11:23,579
Speaker 0: they're not milking it and locking people in like they are here.

203
00:11:23,660 --> 00:11:24,263
Speaker 0: Yeah, exactly.

204
00:11:24,464 --> 00:11:25,530
Speaker 1: Yeah, it's an interesting.

205
00:11:25,990 --> 00:11:28,770
Speaker 1: I don't want to even call it a problem because one, I think there's nothing wrong with that.

206
00:11:28,850 --> 00:11:37,993
Speaker 1: If you are afforded charge people for calling, then if you don't want him to do this, if you were afforded something by technology and it appear, you know, it's an accepted part of the protocol.

207
00:11:38,013 --> 00:11:42,992
Speaker 1: Like, for example, I have a laptop and I say, hey, Wi-Fi, can I connect to you?

208
00:11:43,032 --> 00:11:43,957
Speaker 1: Well, I'll just go into further.

209
00:11:44,018 --> 00:11:46,671
Speaker 1: Wi-Fi says, hey, you, you want to connect to me?

210
00:11:46,691 --> 00:11:48,038
Speaker 1: And I say, yes, I want to connect to you.

211
00:11:48,078 --> 00:11:48,861
Speaker 1: And they give me Internet.

212
00:11:49,786 --> 00:11:52,800
Speaker 1: It's you know, that's not my problem if I use it.

213
00:11:53,222 --> 00:11:57,982
Speaker 1: If the other person didn't want me to use it, they shouldn't have afforded me that thing, that ability.

214
00:11:58,002 --> 00:12:01,234
Speaker 1: This is just an affordance of the way the phone system works.

215
00:12:01,937 --> 00:12:08,483
Speaker 1: And because you can exchange any information over the sideband, that could be your entire stream if you use a good encoding.

216
00:12:08,904 --> 00:12:11,294
Speaker 0: Don't offer caller ID if you didn't want this to happen.

217
00:12:11,575 --> 00:12:13,403
Speaker 1: It's very yet caller ID.

218
00:12:13,463 --> 00:12:13,724
Speaker 1: All right.

219
00:12:13,764 --> 00:12:16,416
Speaker 0: If you charge, charge people for the caller ID.

220
00:12:16,677 --> 00:12:16,899
Speaker 1: Yeah.

221
00:12:16,979 --> 00:12:17,723
Speaker 1: Which they used to.

222
00:12:17,743 --> 00:12:17,924
Speaker 1: Yeah.

223
00:12:17,964 --> 00:12:19,029
Speaker 0: You could spoof the caller ID.

224
00:12:19,350 --> 00:12:20,414
Speaker 0: I could call some service.

225
00:12:20,475 --> 00:12:26,627
Speaker 0: That's like, you know, it's like call us and hang up after two rings to get a hoe to show up and I'll dial the fake number.

226
00:12:28,891 --> 00:12:29,855
Speaker 0: And then the hoe looks.

227
00:12:30,418 --> 00:12:32,728
Speaker 1: Or I call someone and I shows up at some office.

228
00:12:32,748 --> 00:12:33,892
Speaker 1: I spoofed the caller ID.

229
00:12:33,953 --> 00:12:34,193
Speaker 1: Right.

230
00:12:34,515 --> 00:12:35,739
Speaker 1: And the caller ID is spoofed.

231
00:12:35,819 --> 00:12:37,184
Speaker 1: So I've sent a bunch of digits.

232
00:12:38,349 --> 00:12:41,301
Speaker 1: I can then have an encoding scheme to put data in those digits.

233
00:12:41,502 --> 00:12:42,045
Speaker 0: Oh, here we go.

234
00:12:42,065 --> 00:12:42,426
Speaker 0: You ready?

235
00:12:42,768 --> 00:12:44,114
Speaker 0: You spoofed caller ID to 911.

236
00:12:44,114 --> 00:12:47,451
Speaker 0: So you call the weather service and then they call 911 and tell it the weather.

237
00:12:48,575 --> 00:12:49,057
Speaker 1: That is just.

238
00:12:49,237 --> 00:12:52,630
Speaker 1: these are all just riffs on the old Chinese restaurant double take.

239
00:12:53,111 --> 00:12:53,493
Speaker 0: Yeah, I know.

240
00:12:54,396 --> 00:12:57,930
Speaker 0: I read some crazy story today that I think it was probably a FARC story.

241
00:12:58,391 --> 00:13:04,531
Speaker 0: The two guys robbed the place and then one guy ass dialed 911.

242
00:13:04,531 --> 00:13:05,998
Speaker 1: That happens kind of often.

243
00:13:06,178 --> 00:13:10,337
Speaker 0: I don't I actually sort of while that's hilarious and it could be true, I sort of don't believe it.

244
00:13:10,377 --> 00:13:12,748
Speaker 0: And I think that one guy actually wanted to turn him in.

245
00:13:13,712 --> 00:13:18,131
Speaker 0: One of the two guys wanted to, you know, like wanted to, you know, go to jail or at least, you know.

246
00:13:18,332 --> 00:13:19,095
Speaker 1: But it's hard to say.

247
00:13:19,135 --> 00:13:22,954
Speaker 0: But, you know, he didn't want to just rat out his friends straight up.

248
00:13:23,456 --> 00:13:25,989
Speaker 0: And he also couldn't convince the friend to turn himself in.

249
00:13:26,350 --> 00:13:26,451
Speaker 0: Right.

250
00:13:26,833 --> 00:13:30,733
Speaker 0: So this way, at least the friend thinks he's dumb as opposed to the friend thinking he's a rat.

251
00:13:30,914 --> 00:13:38,590
Speaker 1: Thing is, a lot of phones have emergency dialing mode, which will bypass the lock screen and simultaneously will have like 911 already pre-coded in there.

252
00:13:38,812 --> 00:13:41,170
Speaker 0: I know it is possible, but really.

253
00:13:41,370 --> 00:13:53,010
Speaker 0: But dialing 911 and then on while the 911 is dialed, talking about the crime you committed and talking about, hey, we're going to go sell the stuff at this place and then going to the place and the cops are already there.

254
00:13:53,672 --> 00:13:55,849
Speaker 0: It's a little a little too far fetched.

255
00:13:56,811 --> 00:13:57,515
Speaker 0: It's possible, though.

256
00:13:57,595 --> 00:14:00,048
Speaker 1: Of course, what is funny is that this is actually very.

257
00:14:00,088 --> 00:14:02,329
Speaker 1: this India thing is very reminiscent of the old black boxes.

258
00:14:02,771 --> 00:14:03,769
Speaker 1: You know how black boxes worked?

259
00:14:04,090 --> 00:14:04,233
Speaker 0: Yeah.

260
00:14:04,661 --> 00:14:04,865
Speaker 1: Do you?

261
00:14:06,032 --> 00:14:09,230
Speaker 0: Well, most of those boxes were just, you know, put some sound.

262
00:14:09,710 --> 00:14:10,353
Speaker 1: No, no, no, no, no.

263
00:14:10,393 --> 00:14:13,953
Speaker 1: You're thinking of red boxes and blue boxes or the I think the beige box.

264
00:14:13,974 --> 00:14:15,110
Speaker 1: The black box was different.

265
00:14:15,651 --> 00:14:29,770
Speaker 1: It would basically make the phone circuit appear as though the phone was on the hook at both ends because the billing system would not charge you for a time where one or both parties has the phone on the hook because you can't be talking.

266
00:14:30,611 --> 00:14:36,489
Speaker 1: So you'd mess with the line level, the voltage with this black box on both ends so that look like the phone was actually on the hook.

267
00:14:36,710 --> 00:14:37,113
Speaker 1: It was hung up.

268
00:14:37,576 --> 00:14:39,449
Speaker 1: And then you just keep talking through the open circuit.

269
00:14:41,191 --> 00:14:44,390
Speaker 1: It's similar to that, only actually a little bit more legit.

270
00:14:46,294 --> 00:14:47,269
Speaker 0: It's a lot more legit.

271
00:14:48,771 --> 00:14:50,990
Speaker 1: I have no problem with anyone using a side.

272
00:14:51,210 --> 00:14:52,350
Speaker 0: I don't have a problem either.

273
00:14:52,451 --> 00:14:53,465
Speaker 0: I just think it's really interesting.

274
00:14:53,566 --> 00:14:53,829
Speaker 1: Oh, yeah.

275
00:14:54,031 --> 00:14:56,390
Speaker 1: But I know there are people out there going to try to argue it's a bad thing.

276
00:14:56,910 --> 00:14:57,171
Speaker 0: Whatever.

277
00:14:57,191 --> 00:14:57,472
Speaker 0: Shut up.

278
00:14:57,773 --> 00:15:02,610
Speaker 1: So it turns out that Facebook is suing Mark Zuckerberg.

279
00:15:04,112 --> 00:15:05,630
Speaker 1: For something kind of funny.

280
00:15:05,830 --> 00:15:07,810
Speaker 0: Yeah, but it's some other guy who changed his name to Mark Zuckerberg.

281
00:15:08,030 --> 00:15:09,006
Speaker 0: So it's not their own CEO.

282
00:15:09,630 --> 00:15:09,919
Speaker 1: Some other guy.

283
00:15:11,051 --> 00:15:13,330
Speaker 1: I want to talk about this because everyone has the headlines.

284
00:15:13,510 --> 00:15:15,830
Speaker 1: People haven't actually been reading the article, I don't think so.

285
00:15:15,950 --> 00:15:16,499
Speaker 0: Some guy.

286
00:15:16,519 --> 00:15:17,129
Speaker 0: I was too lazy.

287
00:15:17,771 --> 00:15:19,250
Speaker 1: Made a store company.

288
00:15:19,755 --> 00:15:20,769
Speaker 1: I think it's based in Israel.

289
00:15:21,553 --> 00:15:23,190
Speaker 1: What it does is called the like store.

290
00:15:23,732 --> 00:15:25,950
Speaker 1: You want to buy likes for your business's website.

291
00:15:26,210 --> 00:15:27,790
Speaker 1: Three thousand five thousand ten thousand.

292
00:15:28,192 --> 00:15:30,530
Speaker 1: You pay them and they provide them nice.

293
00:15:30,691 --> 00:15:35,470
Speaker 1: They have armies of people and robots and accounts that will just like the shit out of your website.

294
00:15:35,730 --> 00:15:36,461
Speaker 1: And you pay per like.

295
00:15:36,807 --> 00:15:37,030
Speaker 0: Nice.

296
00:15:37,270 --> 00:15:38,059
Speaker 1: You have bulk discounts.

297
00:15:38,140 --> 00:15:39,050
Speaker 0: How much is it per like?

298
00:15:39,331 --> 00:15:40,490
Speaker 1: I have no idea, Penny.

299
00:15:40,630 --> 00:15:42,489
Speaker 1: This is against Facebook's terms of service.

300
00:15:43,310 --> 00:15:43,792
Speaker 0: No kidding.

301
00:15:43,972 --> 00:15:49,630
Speaker 1: So they sued the guy saying, hey, I don't know, can you sue a guy for violating the terms of service?

302
00:15:49,870 --> 00:15:54,889
Speaker 0: I mean, because he was you can you can get rid of his account, but can you sue him?

303
00:15:55,894 --> 00:15:57,309
Speaker 0: I guess they're doing it.

304
00:15:57,731 --> 00:15:58,155
Speaker 1: Well, they want.

305
00:15:58,175 --> 00:15:59,869
Speaker 1: they basically want his business shut down.

306
00:16:00,032 --> 00:16:01,190
Speaker 1: And there's all sorts of shenanigans.

307
00:16:01,472 --> 00:16:02,849
Speaker 0: I'm skipping the Israeli law.

308
00:16:04,550 --> 00:16:11,230
Speaker 1: But the funny thing is, this guy, in response to being sued, legally changed his name to Mark Zuckerberg just for publicity.

309
00:16:11,592 --> 00:16:12,260
Speaker 1: You know what?

310
00:16:12,665 --> 00:16:13,029
Speaker 0: It worked.

311
00:16:13,210 --> 00:16:14,430
Speaker 1: It appears to have worked really well.

312
00:16:15,254 --> 00:16:16,450
Speaker 1: Everyone knows about the like star.

313
00:16:16,611 --> 00:16:18,509
Speaker 1: So I went to this like star to see what the deal was.

314
00:16:18,710 --> 00:16:19,272
Speaker 0: How much of the likes?

315
00:16:20,015 --> 00:16:23,610
Speaker 1: You can buy Google plus one's YouTube views.

316
00:16:23,690 --> 00:16:25,410
Speaker 1: You can just buy YouTube views.

317
00:16:25,691 --> 00:16:25,873
Speaker 0: How much?

318
00:16:25,955 --> 00:16:26,928
Speaker 0: How much is a YouTube view?

319
00:16:27,110 --> 00:16:28,064
Speaker 1: Let's find out right now.

320
00:16:28,146 --> 00:16:28,410
Speaker 1: Let's see.

321
00:16:28,572 --> 00:16:29,949
Speaker 1: I want a real YouTube view.

322
00:16:30,612 --> 00:16:30,913
Speaker 1: All right.

323
00:16:31,174 --> 00:16:34,550
Speaker 1: I can get twenty five thousand for two hundred and thirty dollars.

324
00:16:34,670 --> 00:16:35,474
Speaker 0: That's not worth it.

325
00:16:35,534 --> 00:16:36,339
Speaker 0: That's not even close to.

326
00:16:36,379 --> 00:16:38,530
Speaker 1: I can get a thousand for twelve dollars.

327
00:16:38,790 --> 00:16:40,890
Speaker 0: No, see, that's that's an insignificant number of likes.

328
00:16:41,070 --> 00:16:42,684
Speaker 0: I've already got like one hundred thousand likes.

329
00:16:42,724 --> 00:16:43,390
Speaker 0: just rainbow dash.

330
00:16:43,430 --> 00:16:43,934
Speaker 0: Oh, my gosh.

331
00:16:44,196 --> 00:16:45,890
Speaker 0: You need you want a significant number of likes.

332
00:16:46,031 --> 00:16:48,490
Speaker 0: I need like twenty five million likes.

333
00:16:48,631 --> 00:16:50,150
Speaker 0: That's a real number of likes.

334
00:16:50,210 --> 00:16:52,069
Speaker 0: How much is twenty five million likes?

335
00:16:52,810 --> 00:16:56,970
Speaker 1: Well, twenty five million likes is much harder to get than twenty five million views.

336
00:16:56,990 --> 00:16:58,150
Speaker 0: But that's what I'm saying.

337
00:16:58,650 --> 00:17:00,689
Speaker 0: And it's like that's a. you know, it's a real number.

338
00:17:01,130 --> 00:17:05,829
Speaker 1: More importantly, this goes back into something we used to talk about more often than we do now.

339
00:17:05,910 --> 00:17:08,169
Speaker 1: But SEO scum, this is the same as SEO scum.

340
00:17:08,732 --> 00:17:12,410
Speaker 1: If you're a business and you think that this will help you, you're an idiot.

341
00:17:12,710 --> 00:17:13,272
Speaker 0: No kidding.

342
00:17:13,796 --> 00:17:16,490
Speaker 1: And it amazes me that people fall for this snake oil.

343
00:17:16,651 --> 00:17:18,250
Speaker 0: Well, it could help you a little bit, right?

344
00:17:18,411 --> 00:17:22,250
Speaker 0: If it works, if and you don't get caught and shut down your video, take it down.

345
00:17:22,590 --> 00:17:22,810
Speaker 0: Right.

346
00:17:23,333 --> 00:17:29,750
Speaker 0: Then you might actually get, for example, your video on the YouTube homepage, which will then get you actual views.

347
00:17:30,270 --> 00:17:30,391
Speaker 1: Right.

348
00:17:30,431 --> 00:17:42,330
Speaker 1: It's not that likely, though, because I cannot believe that you'll actually make it to the homepage with fake views and especially because I would not put it past Facebook and Google and anyone to perfectly let this happen.

349
00:17:42,470 --> 00:17:43,870
Speaker 1: Don't even make it against your terms of service.

350
00:17:44,332 --> 00:17:47,490
Speaker 1: And this have an algorithm that identifies these accounts doing these likes.

351
00:17:47,732 --> 00:17:48,746
Speaker 0: Yeah, just ban them.

352
00:17:48,948 --> 00:17:49,090
Speaker 1: Yeah.

353
00:17:49,270 --> 00:17:50,088
Speaker 1: Or don't count their likes.

354
00:17:50,311 --> 00:17:50,493
Speaker 0: Yeah.

355
00:17:50,614 --> 00:17:52,349
Speaker 0: And not show that video on the home page.

356
00:17:52,551 --> 00:17:52,874
Speaker 1: Yeah.

357
00:17:53,258 --> 00:17:53,520
Speaker 0: Yeah.

358
00:17:53,641 --> 00:17:54,389
Speaker 0: It totally won't work.

359
00:17:55,091 --> 00:17:58,789
Speaker 1: But it amazes me that people still fall for this stuff and that they think they need it.

360
00:17:59,250 --> 00:18:16,850
Speaker 1: And to it amazes me that people who look at sites, because I used to think that stuff like this didn't affect individual users, but people seem to be drawn to things that have a lot of Facebook likes, even though most of those things appear to have gained those likes by scams like this.

361
00:18:17,510 --> 00:18:19,109
Speaker 1: This is not the only place that sells these things.

362
00:18:19,170 --> 00:18:22,070
Speaker 0: Same people who are like obsessed with like post counts and forums.

363
00:18:22,330 --> 00:18:29,270
Speaker 0: It's like just whenever there's any number of people like crazy about making it get bigger, they have some sort of psychological hang up they can't get over.

364
00:18:29,571 --> 00:18:32,029
Speaker 0: And, you know, Farmville and everyone else takes advantage of it.

365
00:18:32,854 --> 00:18:33,850
Speaker 0: That's just all there is to it.

366
00:18:33,910 --> 00:18:34,030
Speaker 1: Yep.

367
00:18:34,571 --> 00:18:43,150
Speaker 1: Now, I don't think there's anything wrong with selling likes and I don't think there's anything wrong with a company like Facebook figuring out whose likes are fake and not counting them.

368
00:18:43,475 --> 00:18:44,409
Speaker 1: And I think that's the end of that.

369
00:18:44,873 --> 00:18:46,168
Speaker 1: I think the lawsuit is kind of silly.

370
00:18:47,853 --> 00:18:51,310
Speaker 1: And I think the guy is actually a genius for changing his name to Mark Zuckerberg.

371
00:18:51,771 --> 00:18:54,267
Speaker 0: That was definitely a move of genius right there.

372
00:18:56,452 --> 00:19:00,109
Speaker 1: And I wish everyone in this story the worst of luck, because frankly, they're all scum.

373
00:19:01,830 --> 00:19:03,630
Speaker 0: Scum versus scum, the best guy.

374
00:19:04,330 --> 00:19:07,330
Speaker 1: I do want to talk briefly about one more news item, because this has been making the rounds.

375
00:19:07,431 --> 00:19:09,650
Speaker 1: People have been in uproar lately.

376
00:19:09,850 --> 00:19:21,030
Speaker 1: There's been a lot of articles, op-eds, people complaining about how Google, partly with the advent of Google Plus and their verifications and everything, has been shutting down Gmail accounts of children.

377
00:19:21,712 --> 00:19:22,006
Speaker 1: Or people...

378
00:19:22,090 --> 00:19:23,109
Speaker 0: There's a law that says they have to.

379
00:19:23,290 --> 00:19:23,471
Speaker 0: Yeah.

380
00:19:23,532 --> 00:19:26,410
Speaker 1: So most of the articles about this basically blame Google.

381
00:19:27,135 --> 00:19:28,070
Speaker 1: It's not Google's fault.

382
00:19:28,930 --> 00:19:34,410
Speaker 1: You ever wonder why Steam and like every website in the world often will ask you, hey, when were you born?

383
00:19:34,590 --> 00:19:37,110
Speaker 0: Well, some of it's ESRB compliance for video games.

384
00:19:37,532 --> 00:19:42,490
Speaker 1: And it's also COPPA, the Childhood Online Privacy Protection Act.

385
00:19:42,650 --> 00:19:43,028
Speaker 0: That's right.

386
00:19:43,710 --> 00:19:48,050
Speaker 1: Which, one, it's an unconstitutional load of shit that I've hated from day one.

387
00:19:48,090 --> 00:19:48,949
Speaker 1: I don't think it should be a law.

388
00:19:49,330 --> 00:19:55,890
Speaker 1: It's ludicrous that we have a law like this, because what kid doesn't just say they were born on January 1st, 1900?

389
00:19:55,890 --> 00:19:56,071
Speaker 0: Yeah.

390
00:19:56,595 --> 00:19:58,610
Speaker 1: Why even make the websites go through the motion?

391
00:19:59,030 --> 00:19:59,171
Speaker 0: Yeah.

392
00:20:00,095 --> 00:20:02,950
Speaker 1: I also don't think it should be constitutional to have restrictions like that anyway.

393
00:20:03,271 --> 00:20:03,453
Speaker 0: Yep.

394
00:20:04,060 --> 00:20:04,890
Speaker 1: But I digress.

395
00:20:05,792 --> 00:20:06,810
Speaker 1: It's not Google's fault.

396
00:20:07,011 --> 00:20:09,810
Speaker 1: Google is dealing with the bullshit laws that we let get passed.

397
00:20:10,112 --> 00:20:11,390
Speaker 0: If you don't like it, get the law changed.

398
00:20:12,171 --> 00:20:16,470
Speaker 1: I disagree with that argument because our government is incapable of fixing anything at this point.

399
00:20:16,790 --> 00:20:17,170
Speaker 0: Violent revolution.

400
00:20:17,912 --> 00:20:18,990
Speaker 1: That might be the only option.

401
00:20:19,330 --> 00:20:19,696
Speaker 0: I think so.

402
00:20:20,467 --> 00:20:20,650
Speaker 0: Anyway.

403
00:20:21,431 --> 00:20:21,672
Speaker 0: Yeah.

404
00:20:22,294 --> 00:20:25,829
Speaker 0: I think, you know, a lot of people say that, you know, the last the last...

405
00:20:25,990 --> 00:20:26,777
Speaker 1: I mean, we could get in trouble.

406
00:20:26,878 --> 00:20:28,130
Speaker 1: We don't verify age.

407
00:20:28,290 --> 00:20:32,230
Speaker 1: So if if someone under the age of 13 is using our forum, we could actually get a lot of trouble.

408
00:20:33,272 --> 00:20:33,361
Speaker 0: Yeah.

409
00:20:34,270 --> 00:20:42,590
Speaker 0: You know, a lot of people say the last kind of discrimination we have to fight against is like, you know, anti-gay, anti, you know, lesbian and transgender and all that.

410
00:20:42,710 --> 00:20:52,590
Speaker 0: And that's not true to, you know, even if we, you know, somehow get it to the point where there's no more, you know, homophobes and whatnot, people are still going to be against atheists.

411
00:20:53,274 --> 00:20:54,649
Speaker 0: And that's the group that comes next.

412
00:20:55,114 --> 00:20:56,004
Speaker 0: And then even then...

413
00:20:56,490 --> 00:20:59,310
Speaker 1: Actually, that's the most distrusted group in America.

414
00:20:59,330 --> 00:21:07,930
Speaker 0: But even then, even if we somehow get it to the point where atheists are accepted, right, by, you know, the whole of society, there's still going to be age discrimination.

415
00:21:08,150 --> 00:21:11,430
Speaker 0: Age discrimination is the very last form of discrimination.

416
00:21:11,813 --> 00:21:13,470
Speaker 1: No, you're forgetting, Scott.

417
00:21:14,575 --> 00:21:14,909
Speaker 1: Furry freedom.

418
00:21:15,170 --> 00:21:16,210
Speaker 1: What about pond hopper?

419
00:21:16,650 --> 00:21:17,510
Speaker 0: That's not discrimination.

420
00:21:17,871 --> 00:21:18,390
Speaker 0: That's justified.

421
00:21:20,552 --> 00:21:22,069
Speaker 1: I wear the tanooki suit to fly.

422
00:21:22,591 --> 00:21:25,230
Speaker 0: Age discrimination is the very last form of discrimination.

423
00:21:25,270 --> 00:21:26,350
Speaker 1: I don't think it's the very last one.

424
00:21:26,430 --> 00:21:27,470
Speaker 1: What about A.I.s and robots?

425
00:21:27,510 --> 00:21:29,430
Speaker 1: They're going to get discriminated against like all fuck.

426
00:21:29,650 --> 00:21:30,530
Speaker 0: No, because they won't let you.

427
00:21:30,630 --> 00:21:31,525
Speaker 0: They'll just fucking kill you.

428
00:21:32,953 --> 00:21:34,189
Speaker 1: See, everyone says that.

429
00:21:34,590 --> 00:21:37,608
Speaker 1: No, because in what world do we make an A.I.

430
00:21:37,950 --> 00:21:39,389
Speaker 1: and then immediately give it control of nukes?

431
00:21:41,093 --> 00:21:41,519
Speaker 0: You wouldn't?

432
00:21:41,701 --> 00:21:42,228
Speaker 0: Why wouldn't you?

433
00:21:43,150 --> 00:21:44,929
Speaker 0: I trust the robot with the nukes more than just people.

434
00:21:45,850 --> 00:21:46,521
Speaker 1: That is true.

435
00:21:46,582 --> 00:21:47,090
Speaker 1: That is true.

436
00:21:47,310 --> 00:21:50,870
Speaker 1: But oh, by the way, you know what?

437
00:21:51,232 --> 00:21:54,010
Speaker 1: You're not allowed to use our forum if you're under the age of 13.

438
00:21:54,010 --> 00:21:54,106
Speaker 0: Sure.

439
00:21:54,230 --> 00:21:57,310
Speaker 1: I'm sure that'll stop all of you who are under the age of 13 from using our forum.

440
00:21:57,530 --> 00:21:57,791
Speaker 0: Great.

441
00:21:58,795 --> 00:22:06,010
Speaker 0: But yeah, age discrimination will probably won't even see a dent in age discrimination in our lifetimes or perhaps in the next century.

442
00:22:06,190 --> 00:22:10,850
Speaker 1: But Scott, what constitutes age discrimination specifically?

443
00:22:11,050 --> 00:22:19,190
Speaker 0: I mean, when you discriminate against someone simply based on the length of time that they have been alive as opposed to based on the merit of their character.

444
00:22:19,370 --> 00:22:19,570
Speaker 0: All right.

445
00:22:19,710 --> 00:22:34,372
Speaker 0: You got people who are completely dumb and incapable of thinking or driving, who are very old, perhaps 40s, 50s, yet there are like 12 year olds who are extremely capable of many, many things far more capable than people who have been on the earth far longer than them.

446
00:22:34,713 --> 00:22:43,050
Speaker 0: So discriminate against, you know, to give one person more or less rights or privileges simply based on the number of seconds since they're, you know, conception.

447
00:22:43,551 --> 00:22:45,589
Speaker 1: So I have one question for you, Scott.

448
00:22:45,873 --> 00:22:47,330
Speaker 1: Yes, I'm just going to ask you this question.

449
00:22:47,533 --> 00:22:48,509
Speaker 1: It's a loaded question.

450
00:22:48,815 --> 00:22:49,670
Speaker 0: I know heavily load.

451
00:22:49,790 --> 00:22:51,290
Speaker 0: I'm pretty sure I know the question already.

452
00:22:51,431 --> 00:22:52,669
Speaker 1: You run a company.

453
00:22:53,013 --> 00:22:53,397
Speaker 1: Yes.

454
00:22:53,499 --> 00:22:54,550
Speaker 1: You need to hire a developer.

455
00:22:54,870 --> 00:22:55,051
Speaker 1: Sure.

456
00:22:55,212 --> 00:22:59,270
Speaker 1: There are two developers who are exactly equally qualified in all regards.

457
00:22:59,570 --> 00:23:00,013
Speaker 0: Hire both.

458
00:23:00,678 --> 00:23:02,290
Speaker 0: Can never do without, you know, can't have enough.

459
00:23:02,450 --> 00:23:03,869
Speaker 1: You only have budget to hire one person.

460
00:23:04,572 --> 00:23:05,468
Speaker 1: You don't need to.

461
00:23:06,411 --> 00:23:09,830
Speaker 1: One of them is 20 and one of them is 111.

462
00:23:09,830 --> 00:23:10,212
Speaker 0: All right.

463
00:23:11,258 --> 00:23:13,230
Speaker 1: Now, which one are you going to hire?

464
00:23:14,270 --> 00:23:19,512
Speaker 1: Assuming that we have not discovered immortality and the average human lifespan is well under 111.

465
00:23:19,512 --> 00:23:20,729
Speaker 0: Well, the dude is sickly.

466
00:23:20,910 --> 00:23:21,133
Speaker 0: He was 111.

467
00:23:21,133 --> 00:23:21,619
Speaker 0: Or is he healthy?

468
00:23:22,630 --> 00:23:23,630
Speaker 0: He looks like he's going to keep going.

469
00:23:24,130 --> 00:23:25,230
Speaker 1: He looks like he's going to keep going.

470
00:23:25,330 --> 00:23:28,606
Speaker 1: But at the same time, he's not going to live past 120 because no one does.

471
00:23:30,390 --> 00:23:33,510
Speaker 0: Well, see, I'm not discriminating based on his age, discriminating based on his health.

472
00:23:33,691 --> 00:23:34,535
Speaker 0: That's completely different.

473
00:23:34,736 --> 00:23:37,270
Speaker 1: But his health is solely due to his age.

474
00:23:37,970 --> 00:23:38,656
Speaker 0: Not necessarily.

475
00:23:39,464 --> 00:23:40,069
Speaker 1: In this case, yes.

476
00:23:40,270 --> 00:23:43,270
Speaker 1: He's 100 percent healthy, except for the fact that he is aging.

477
00:23:44,292 --> 00:23:45,850
Speaker 0: Well, aging is the disease.

478
00:23:46,131 --> 00:23:52,350
Speaker 1: That if you're hiring someone, he will not be around 20 years from now, while the 20 year old, if you keep paying him, will probably still be around.

479
00:23:52,530 --> 00:23:55,390
Speaker 0: I'm not discriminating based on age, I'm discriminating based on another factor.

480
00:23:55,611 --> 00:23:56,110
Speaker 1: What other factor?

481
00:23:56,110 --> 00:23:59,190
Speaker 0: That happens to be correlated, happens to be correlated with age.

482
00:23:59,450 --> 00:24:02,490
Speaker 1: Happens to be correlated 100 percent directly, one to one.

483
00:24:02,590 --> 00:24:09,210
Speaker 0: For example, if a three year old was really good at driving, but he couldn't reach the pedals, I wouldn't let him drive.

484
00:24:09,551 --> 00:24:10,490
Speaker 0: It's, is it age discrimination?

485
00:24:11,071 --> 00:24:14,410
Speaker 0: Well, the length of his legs correlates with his age.

486
00:24:14,571 --> 00:24:17,550
Speaker 0: But it's not age discrimination because he can't reach the pedals.

487
00:24:17,991 --> 00:24:21,490
Speaker 0: So the requirement is you must be healthy and you will live a long time.

488
00:24:21,931 --> 00:24:24,570
Speaker 0: Scott, the requirement is you have to be able to reach the pedal.

489
00:24:24,770 --> 00:24:25,071
Speaker 1: All right, Scott.

490
00:24:25,092 --> 00:24:29,910
Speaker 1: So why would I ever hire someone who's 50 when I could hire someone who's similarly qualified, who's 20?

491
00:24:29,910 --> 00:24:34,090
Speaker 0: Because nobody is going to work for you for that many years.

492
00:24:34,512 --> 00:24:37,210
Speaker 0: The 50 year old dude isn't going to die in nine years.

493
00:24:37,930 --> 00:24:41,510
Speaker 0: Nine years is, you know, people work at companies for more than nine years.

494
00:24:41,952 --> 00:24:45,108
Speaker 0: You know, if you expect, you know, the 20 year old guy might work for you for 20 years.

495
00:24:45,450 --> 00:24:47,190
Speaker 0: Well, the 50 year old guy could work for you for 20 years.

496
00:24:47,330 --> 00:24:51,370
Speaker 0: Also, you know, there there's no worry of the guy's going to die tomorrow.

497
00:24:51,530 --> 00:24:59,330
Speaker 0: It may be if a 20 year old comes who's like, you know, may you know, he's fully capable of doing the job, but he's got cancer and he's going to die tomorrow.

498
00:24:59,671 --> 00:25:03,070
Speaker 0: So you're going to get a cancer guy if he's got a week to live?

499
00:25:03,970 --> 00:25:05,610
Speaker 1: Yes, but that's discriminatory.

500
00:25:06,193 --> 00:25:07,170
Speaker 0: He's got a week to live.

501
00:25:07,370 --> 00:25:09,810
Speaker 0: I'm not going to hire someone who is not even going to make it through training.

502
00:25:10,091 --> 00:25:10,372
Speaker 0: All right.

503
00:25:10,794 --> 00:25:14,890
Speaker 1: I mean, there's a guy who is more qualified than the 20 year old.

504
00:25:15,213 --> 00:25:16,249
Speaker 0: He's one hundred and nineteen.

505
00:25:17,051 --> 00:25:21,950
Speaker 1: OK, he is statistically pretty much guaranteed to die in the next six months.

506
00:25:22,531 --> 00:25:27,490
Speaker 1: OK, you know, hire him or the 18 year old might think about hiring that old guy.

507
00:25:27,651 --> 00:25:29,229
Speaker 1: You don't get that much work out of him in six months.

508
00:25:29,510 --> 00:25:32,730
Speaker 0: Well, he's probably a genius, right?

509
00:25:32,950 --> 00:25:38,350
Speaker 0: I mean, seriously, he could probably do like 10 years of work in six months.

510
00:25:39,152 --> 00:25:40,848
Speaker 0: If he's if he's better than the 20 year old.

511
00:25:47,490 --> 00:26:02,490
Speaker 1: But anyway, things of the day for the life of me, I'm almost 30 years old and this is going to sound like an old man thing, but I got fitted sheets and I basically just wad them up in a vaguely like rectangular shape.

512
00:26:02,610 --> 00:26:08,070
Speaker 1: Well, for anyone who doesn't know, shove them into the back of my linen closet to then pretend they're not there.

513
00:26:08,370 --> 00:26:12,730
Speaker 0: Fitted sheets are the ones that, you know, you put on a bed that have the the elastic strap around the bottom.

514
00:26:12,730 --> 00:26:13,573
Speaker 0: They're fitted.

515
00:26:13,653 --> 00:26:17,889
Speaker 0: They tie, you know, they stay tight on the mattress in case you're dumb and you don't know what those are.

516
00:26:18,670 --> 00:26:18,813
Speaker 1: Yeah.

517
00:26:19,077 --> 00:26:19,464
Speaker 1: So, yeah.

518
00:26:19,830 --> 00:26:20,916
Speaker 1: How the fuck do you fold those?

519
00:26:20,976 --> 00:26:22,002
Speaker 1: Well, now I know.

520
00:26:22,022 --> 00:26:23,369
Speaker 1: now I know how to fold them.

521
00:26:23,892 --> 00:26:24,918
Speaker 0: Could you actually pull it off?

522
00:26:25,200 --> 00:26:26,810
Speaker 0: I got I got it halfway through.

523
00:26:26,970 --> 00:26:29,490
Speaker 0: I've watched that shirt folding video about a thousand times.

524
00:26:29,590 --> 00:26:30,454
Speaker 0: You know, I can't fucking do it.

525
00:26:30,877 --> 00:26:33,349
Speaker 1: I folded one fitted sheet pretty close to this.

526
00:26:34,251 --> 00:26:38,490
Speaker 1: The key is if you get that trick of holding the corners, it's all about the pointy corner.

527
00:26:38,831 --> 00:26:41,230
Speaker 1: Yeah, I'm getting better at this.

528
00:26:41,310 --> 00:26:42,780
Speaker 1: This was actually life changing.

529
00:26:42,881 --> 00:26:43,928
Speaker 1: And I think you should all watch it.

530
00:26:44,390 --> 00:26:44,470
Speaker 0: Yeah.

531
00:26:45,556 --> 00:26:48,010
Speaker 0: So, you know, the game, the kids for the NES.

532
00:26:48,371 --> 00:26:49,178
Speaker 0: Yeah, that game was OK.

533
00:26:49,218 --> 00:26:50,469
Speaker 0: It's actually called MC Kids.

534
00:26:52,071 --> 00:26:52,852
Speaker 0: And yeah.

535
00:26:53,354 --> 00:26:59,750
Speaker 0: And apparently this dude named Greg is Tavares and also someone else named Dan Chang.

536
00:27:00,573 --> 00:27:01,360
Speaker 0: They made that game.

537
00:27:01,401 --> 00:27:02,369
Speaker 0: They program that shit.

538
00:27:02,931 --> 00:27:08,870
Speaker 0: And in 1992, they wrote an article in the Journal of Computer Game Design talking about how they program that shit.

539
00:27:09,614 --> 00:27:11,090
Speaker 0: And here is that article on the Internet.

540
00:27:11,150 --> 00:27:11,653
Speaker 0: And you know what?

541
00:27:11,734 --> 00:27:14,549
Speaker 0: It's pretty fascinating how they program this fucking game on NES.

542
00:27:16,071 --> 00:27:22,009
Speaker 0: So, you know, if you're actually a computer person or a game coder or anything like that.

543
00:27:23,193 --> 00:27:25,070
Speaker 0: Read this, because it's pretty fascinating.

544
00:27:25,231 --> 00:27:28,869
Speaker 0: And then on top of that, maybe you should make some NES roms or something like that.

545
00:27:29,212 --> 00:27:29,514
Speaker 0: I don't know.

546
00:27:29,938 --> 00:27:31,350
Speaker 0: Maybe mod some NES roms.

547
00:27:31,690 --> 00:27:34,057
Speaker 0: So very briefly, make Zelda D. No, please don't.

548
00:27:34,239 --> 00:27:36,566
Speaker 0: I can't even beat Zelda C. Don't make Zelda D.

549
00:27:38,791 --> 00:27:42,649
Speaker 1: Zelda D would just be you start, no sword, surrounded by blue dark nuts.

550
00:27:44,892 --> 00:27:45,882
Speaker 0: Come and stay.

551
00:27:45,922 --> 00:27:46,710
Speaker 0: Final destination.

552
00:27:47,070 --> 00:27:47,595
Speaker 1: No idea.

553
00:27:47,696 --> 00:27:49,189
Speaker 0: AIs reprogrammed, so they come right at you.

554
00:27:50,773 --> 00:27:52,105
Speaker 0: Oh, and there's a whole lake.

555
00:27:52,710 --> 00:27:57,390
Speaker 0: You're in a middle of an island and all the water around you has Zora's shooting fireballs.

556
00:27:59,433 --> 00:28:00,969
Speaker 1: You just spawn on a dark nut.

557
00:28:02,232 --> 00:28:04,649
Speaker 0: Maybe I should just make that as like a piece of art.

558
00:28:06,075 --> 00:28:06,785
Speaker 1: I prefer your...

559
00:28:07,170 --> 00:28:09,865
Speaker 0: It's like you push start and it's like, doo, doo, doo, doo, doo, doo, doo, doo, doo.

560
00:28:10,871 --> 00:28:12,010
Speaker 1: No, we should make a whole installation.

561
00:28:12,190 --> 00:28:20,550
Speaker 1: Like there'd be a nice art gallery where there's a bunch of NES games that are each of them not only impossible, but impossible to a ludicrous and surprising degree.

562
00:28:20,850 --> 00:28:22,502
Speaker 0: A Tetris that only gives pieces.

563
00:28:22,562 --> 00:28:23,630
Speaker 0: you can never finish a line.

564
00:28:25,931 --> 00:28:29,710
Speaker 1: Someone programmed bastard Tetris that is designed to give you the worst possible piece every move.

565
00:28:29,910 --> 00:28:33,910
Speaker 0: Yeah, but isn't it possible to give someone pieces that it's impossible to make a line?

566
00:28:35,412 --> 00:28:37,200
Speaker 0: If we got all S pieces?

567
00:28:37,220 --> 00:28:39,350
Speaker 0: No, because you could put them all right next to each other.

568
00:28:39,631 --> 00:28:40,550
Speaker 1: Yeah, but then there'd be all the bottom.

569
00:28:41,050 --> 00:28:41,603
Speaker 0: There would be.

570
00:28:43,412 --> 00:28:44,290
Speaker 1: Tetris is no bottom.

571
00:28:45,270 --> 00:28:48,089
Speaker 0: Just make up new pieces that are asshole pieces so you can't pos-.

572
00:28:48,973 --> 00:28:52,550
Speaker 0: So if anyone has a possibility of completing a line, make a piece that can't-.

573
00:28:52,590 --> 00:28:55,910
Speaker 1: There was that Japanese joke one that the pieces were all irregularly shaped.

574
00:28:56,251 --> 00:28:56,996
Speaker 0: Right, that's what I'm saying.

575
00:28:57,016 --> 00:29:01,930
Speaker 0: Just make up new pieces as it goes along so that any piece it gives you will not possibly make a line.

576
00:29:02,791 --> 00:29:09,329
Speaker 1: I'm talking like a Mario one that just starts you and there's just nothing but goombas and turtles everywhere and there's a pit you can't jump over right past it.

577
00:29:09,990 --> 00:29:10,065
Speaker 0: Yup.

578
00:29:10,430 --> 00:29:13,607
Speaker 1: So in the meta moment, the book club books are...

579
00:29:14,270 --> 00:29:19,550
Speaker 0: Little Prince by Antoine de Saint-Euverie and Wind, Sand, and Stars by the same person.

580
00:29:19,910 --> 00:29:21,449
Speaker 0: I'm about halfway through Wind and Sand and Stars.

581
00:29:21,591 --> 00:29:23,429
Speaker 1: I am also about halfway through Wind, Sand, and Stars.

582
00:29:23,550 --> 00:29:26,669
Speaker 0: So this book club book is probably gonna happen before the next year.

583
00:29:26,850 --> 00:29:28,630
Speaker 1: It is a fantastic book.

584
00:29:29,091 --> 00:29:29,549
Speaker 0: The best.

585
00:29:29,851 --> 00:29:31,055
Speaker 1: I'm very much enjoying it.

586
00:29:31,115 --> 00:29:35,550
Speaker 1: I really want to fly a super dangerous dodgy old plane across the desert now.

587
00:29:35,890 --> 00:29:38,021
Speaker 0: You know, these planes weren't so dodgy and old.

588
00:29:38,061 --> 00:29:39,167
Speaker 0: He wrote this thing in like the 30s.

589
00:29:39,830 --> 00:29:41,969
Speaker 1: Yeah, planes in the 30s, Scott, were dodgy.

590
00:29:43,191 --> 00:29:45,490
Speaker 0: Yeah, but it wasn't like the fucking Red Baron, alright?

591
00:29:45,911 --> 00:29:48,990
Speaker 0: No, it wasn't- It was real airplanes made of metal with engines.

592
00:29:49,330 --> 00:29:51,590
Speaker 1: Yes, it wasn't that much better than the Red Baron.

593
00:29:51,590 --> 00:29:53,290
Speaker 0: Two or four propellers on the wings.

594
00:29:53,590 --> 00:29:55,390
Speaker 1: Yeah, they were not that great, these planes.

595
00:29:55,470 --> 00:29:57,350
Speaker 0: It was a lot better than the Red Baron.

596
00:29:57,551 --> 00:30:00,249
Speaker 1: Yeah, but they were still dodgy.

597
00:30:01,470 --> 00:30:02,178
Speaker 0: Dodgier than the 747, sure.

598
00:30:03,290 --> 00:30:12,030
Speaker 1: And I know how much he talks about, "Hey, it's much better here than it was in the old days when you- In addition to worrying about the engine failing, you also have to worry about the wings falling off.

599
00:30:12,130 --> 00:30:13,203
Speaker 1: Luckily, I don't have to worry about

600
00:30:13,224 --> 00:30:13,467
Speaker 1: that.".

601
00:30:14,271 --> 00:30:17,610
Speaker 1: Except in that typhoon, he's like, "That was the one time I was worried about my wings falling

602
00:30:17,630 --> 00:30:17,690
Speaker 1: off.".

603
00:30:17,811 --> 00:30:19,167
Speaker 0: I just read the typhoon chat.

604
00:30:20,096 --> 00:30:20,548
Speaker 1: That was great.

605
00:30:20,990 --> 00:30:22,859
Speaker 0: He's just like, "Yeah, there's really no drama here.

606
00:30:22,879 --> 00:30:23,984
Speaker 0: I'm just gonna tell you what happened.

607
00:30:24,004 --> 00:30:24,707
Speaker 0: I was in a

608
00:30:24,728 --> 00:30:24,888
Speaker 0: typhoon.".

609
00:30:25,391 --> 00:30:28,250
Speaker 1: He meant not to, just to kind of, not spoil the book on the book.

610
00:30:28,270 --> 00:30:29,358
Speaker 0: Let's not ruin the book club book.

611
00:30:29,399 --> 00:30:30,850
Speaker 0: Let's continue with the better moment.

612
00:30:31,030 --> 00:30:36,290
Speaker 1: To try to trick you into reading this book, he makes a very salient point about how horror never exists in the moment.

613
00:30:36,731 --> 00:30:41,450
Speaker 1: You're never horrified in the moment of some gigantic looming catastrophe.

614
00:30:41,933 --> 00:30:43,830
Speaker 1: You're only horrified in retrospect.

615
00:30:44,714 --> 00:30:45,667
Speaker 0: Or going in.

616
00:30:46,230 --> 00:30:53,150
Speaker 1: And the people who feel horror during the event are the ones who cannot deal with the event and thus don't survive.

617
00:30:53,990 --> 00:30:54,326
Speaker 0: Courage.

618
00:30:55,201 --> 00:30:55,390
Speaker 0: Anyway.

619
00:30:56,590 --> 00:30:57,810
Speaker 0: Uh, other meta moment.

620
00:30:58,030 --> 00:31:00,308
Speaker 0: You know what's happening one week after New Year's?

621
00:31:00,630 --> 00:31:01,403
Speaker 1: I believe it is...

622
00:31:02,816 --> 00:31:03,130
Speaker 0: MAGFEST!

623
00:31:03,570 --> 00:31:03,654
Speaker 1: What?

624
00:31:04,770 --> 00:31:05,126
Speaker 1: What?

625
00:31:05,832 --> 00:31:07,390
Speaker 1: Oh my god, I'm so excited.

626
00:31:07,950 --> 00:31:13,030
Speaker 0: If you don't go to MAGFEST, stop listening to the show because you suck and you're not allowed to listen.

627
00:31:13,430 --> 00:31:16,630
Speaker 1: Dude, a good portion of the front row crew is gonna be there.

628
00:31:16,750 --> 00:31:17,529
Speaker 0: Let me change that.

629
00:31:17,590 --> 00:31:21,870
Speaker 0: If you are going to MAGFEST, do not listen to the show because you're already awesome and we can't help you.

630
00:31:21,970 --> 00:31:32,170
Speaker 0: If you are not going to MAGFEST, you are now hereby required to listen to every episode of Geek Nights Ever twice so that maybe you could maybe build up some awesomeness and be awesome enough for MAGFEST.

631
00:31:32,230 --> 00:31:36,110
Speaker 1: We are going to be on three panels, not simultaneously at MAGFEST.

632
00:31:36,210 --> 00:31:43,530
Speaker 1: We're doing our own lecture, a new one, actually an old one, Beyond Advanced Dungeons and Dragons 2nd Edition Revised.

633
00:31:45,293 --> 00:31:47,110
Speaker 1: It's beyond D&D but it's totally different panels.

634
00:31:47,350 --> 00:31:48,862
Speaker 0: My shit is fucked up so I got it.

635
00:31:50,671 --> 00:31:51,443
Speaker 0: Shoot/slice you.

636
00:31:53,974 --> 00:32:00,150
Speaker 1: We are also going to be on two discussion panels with the MAG and I guess, I don't know how many it is in the MAG anymore.

637
00:32:00,610 --> 00:32:09,530
Speaker 1: Gaming Intellectuals will be on the Moneymaking Game, which funnily has a nearly similar title to a lecture we're planning to do at PAX East, if Kahil will let us.

638
00:32:10,371 --> 00:32:15,290
Speaker 1: And we are going to be on Gamer Motivations, which is basically the discussion of the carrot in games.

639
00:32:16,472 --> 00:32:18,010
Speaker 0: What other meta is there?

640
00:32:18,050 --> 00:32:25,330
Speaker 0: You should go to the internets where we live and visit us in the places where we live on the Plus, Google and the Facebooking and the Twats.

641
00:32:25,570 --> 00:32:33,189
Speaker 1: Much more importantly, you should go to the Geek Nights Rim YouTube channel and like all that shit because not only is there good shit there...

642
00:32:33,410 --> 00:32:37,009
Speaker 0: Because you need more likes, because you don't want to pay for likes from Mark Zuckerberg.

643
00:32:37,630 --> 00:32:38,709
Speaker 1: Exactly, I want you to like it up.

644
00:32:39,010 --> 00:32:41,170
Speaker 0: We need legitimate likes guys, serious.

645
00:32:41,750 --> 00:32:45,109
Speaker 1: Of course, if you think our videos suck, you should dislike them and post about it.

646
00:32:45,690 --> 00:32:47,390
Speaker 0: Yep, that's enough.

647
00:32:47,510 --> 00:32:47,951
Speaker 0: That's enough.

648
00:32:48,593 --> 00:32:55,648
Speaker 1: So, someone on the forum posted recently, and I forget what we were talking about, and they said something like, "What do you guys think of paired

649
00:32:55,688 --> 00:32:56,309
Speaker 1: programming?".

650
00:32:56,730 --> 00:33:02,289
Speaker 1: And Scott and I looked at each other over the internet and we were like, "Simultaneously, I got shit to say about

651
00:33:02,329 --> 00:33:02,490
Speaker 1: that.".

652
00:33:04,550 --> 00:33:05,754
Speaker 0: So here's the deal, right?

653
00:33:05,794 --> 00:33:09,909
Speaker 0: When you work, in the olden days, in Henry Ford's factory, right?

654
00:33:11,271 --> 00:33:14,968
Speaker 0: Your work is pretty much do this thing over and over again, right?

655
00:33:15,992 --> 00:33:21,650
Speaker 0: And it's just, you know, do a manual labor, just like at Foxconn, you know, hit this nail, screw this screw.

656
00:33:22,211 --> 00:33:28,210
Speaker 0: So it's easily quantifiable and it's easily manageable because it's just how many can a guy do in an hour?

657
00:33:28,351 --> 00:33:29,139
Speaker 0: He gets tired.

658
00:33:29,179 --> 00:33:30,290
Speaker 0: He needs this many breaks.

659
00:33:30,675 --> 00:33:31,789
Speaker 0: We need this many people.

660
00:33:32,271 --> 00:33:35,730
Speaker 0: You know, it's an easily quantifiable and easily manageable thing.

661
00:33:36,431 --> 00:33:41,730
Speaker 0: And over decades, we have become pretty much experts at managing that sort of labor.

662
00:33:43,931 --> 00:33:48,430
Speaker 0: But when it comes to art, right, you know, you don't really manage artists.

663
00:33:48,672 --> 00:33:50,170
Speaker 0: You just sort of like, you know, authors.

664
00:33:50,350 --> 00:33:51,607
Speaker 0: It's like, how do you manage an author?

665
00:33:52,050 --> 00:33:59,430
Speaker 0: I guess someone out there is probably going to tell me I'm dumb that you do manage authors somehow, you know, but you don't manage Picasso, right?

666
00:33:59,470 --> 00:34:01,310
Speaker 0: You're not going to tell me that he needs a manager, right?

667
00:34:01,330 --> 00:34:05,090
Speaker 0: He just sort of does his arts and he makes the arts.

668
00:34:05,110 --> 00:34:09,330
Speaker 1: He was only able to do that because of reputation and having the income to be able to do it.

669
00:34:09,370 --> 00:34:11,110
Speaker 0: I'm not saying I'm not thinking about the economics of it.

670
00:34:11,130 --> 00:34:17,090
Speaker 0: I'm just saying he doesn't need some sort of structure to like, you know, his day or some procedure to follow.

671
00:34:17,330 --> 00:34:21,090
Speaker 0: He's, you know, his muse comes to him and he he makes the paintings.

672
00:34:21,449 --> 00:34:21,690
Speaker 0: Right.

673
00:34:22,993 --> 00:34:35,469
Speaker 0: But programming is always been, you know, for the past decade or two, this sort of weird in-between place where you're sort of doing a work, you know, but you're also doing an arts.

674
00:34:35,750 --> 00:34:53,969
Speaker 0: And, you know, ever since, you know, even before, you know, the Mythical Man month, people have been trying to figure out how to manage and sort of, you know, structure the work of programmers to quantify it and sort of, you know, manage it and structure it in some way.

675
00:34:54,952 --> 00:34:57,810
Speaker 0: And there are lots and lots and lots of different ideas.

676
00:34:58,671 --> 00:35:03,130
Speaker 0: And we haven't really had a lot of time to test out many of them scientifically.

677
00:35:03,371 --> 00:35:10,149
Speaker 0: Some have, some have not, you know, so we only have so much data to go on to, you know, objectively say what works and what doesn't.

678
00:35:11,150 --> 00:35:19,090
Speaker 0: So now it's not just there's a lot of people who are trying to do a lot of things that are new and there isn't a whole lot of data to say what's a good idea, what's a bad idea.

679
00:35:19,310 --> 00:35:20,670
Speaker 1: The thing is, I want to expand it a little bit.

680
00:35:20,750 --> 00:35:23,750
Speaker 1: It's not just programming because, you know, I know it's mostly software.

681
00:35:23,950 --> 00:35:33,110
Speaker 1: Yeah, but computer stuff in general, there's, you know, management in that field is also kind of a new and strange thing, especially with the advent of, you know, ticketing systems and technology.

682
00:35:33,291 --> 00:35:35,910
Speaker 1: To actually track workflow and actually do metrics on things.

683
00:35:36,990 --> 00:35:47,250
Speaker 1: And there's a lot of certifications and a lot of methodologies like Sigma and the Sigma 7, Sigma 6, whatever, or IDLE compliance, ITIL and all this stuff.

684
00:35:48,070 --> 00:35:48,291
Speaker 0: And

685
00:35:49,232 --> 00:36:10,669
Speaker 1: it's actually a very related discussion because I found in general, just to get into my opinion on all this, is that the majority of people who look to any of these to improve their process and follow them per the rules of their own systems, like I'm going to implement Scrum and they follow the rules of Scrum 100 percent, tend not to do that well.

686
00:36:12,052 --> 00:36:15,150
Speaker 0: Well, that's the thing is we don't really have any data to know who does well, right?

687
00:36:15,290 --> 00:36:19,489
Speaker 0: It's just people sort of, you know, some people do things and some people like what they came up with.

688
00:36:19,710 --> 00:36:30,170
Speaker 0: And so they continue to do it and some people don't like it and they try something else and they just do what they like, but they don't necessarily do what's best or no one really even knows what's best.

689
00:36:30,695 --> 00:36:31,669
Speaker 0: In most of the cases.

690
00:36:31,831 --> 00:36:34,230
Speaker 0: But what it comes down to is even an IT guy, right?

691
00:36:34,470 --> 00:36:41,790
Speaker 0: A software guy is even harder because in software you're doing something that has never been done before, because if it's been done before, you don't have to do it.

692
00:36:41,810 --> 00:36:44,950
Speaker 1: You can just get it unless you work for a large enterprise company.

693
00:36:45,491 --> 00:36:51,610
Speaker 0: So most of the time you're doing something new and someone's asking you even the simplest question, estimate how long this will take.

694
00:36:51,690 --> 00:36:57,270
Speaker 0: And you can sometimes estimate based on a lot of things, but they're basically saying you're about to do something that's never been done before.

695
00:36:57,351 --> 00:36:58,108
Speaker 0: How long is it going to take?

696
00:36:59,051 --> 00:37:10,550
Speaker 0: You know, and it's like I can only get so close and there's a chance that it's going to take way longer or maybe even way less than I estimated, even though I made a really good guess based on a lot of information and experience.

697
00:37:10,750 --> 00:37:20,210
Speaker 1: Now, there are a ton of, you know, scientific and I'm making quote marks, methodologies for figuring out how long stuff will take, you know, scoping and sizing of projects in software and in everything.

698
00:37:20,751 --> 00:37:24,710
Speaker 1: And they usually actually involve a good degree of math and weightings and things.

699
00:37:25,191 --> 00:37:32,190
Speaker 1: And I found that they're about as accurate as a relatively experienced person just making a gut guess.

700
00:37:32,510 --> 00:37:32,691
Speaker 1: Yeah.

701
00:37:32,811 --> 00:37:40,630
Speaker 0: And, you know, sometimes you're going to be pretty close, you know, but most of the time you're going to be like maybe a month off or something like that, depending on the size of the project.

702
00:37:40,770 --> 00:37:41,512
Speaker 0: Yeah.

703
00:37:41,532 --> 00:37:50,170
Speaker 0: And, you know, over the course of a career or at least a job you have at a company for many years, at least once you're going to be way the fuck off by a long time.

704
00:37:50,611 --> 00:37:57,850
Speaker 0: You know, there's going to be something that you thought, you know, or estimated would take a few months and takes like a year or half a year or something ridiculous like that.

705
00:37:58,010 --> 00:37:59,277
Speaker 0: It will happen at least once.

706
00:38:00,343 --> 00:38:01,450
Speaker 0: you see it happen all the time.

707
00:38:01,672 --> 00:38:03,650
Speaker 0: And worst case, you know, Duke Nukem forever.

708
00:38:04,732 --> 00:38:06,470
Speaker 0: Best case, I've never seen a best case.

709
00:38:06,530 --> 00:38:08,230
Speaker 0: Have you ever seen anyone like turn something out overnight?

710
00:38:08,350 --> 00:38:09,181
Speaker 0: They thought would take a year.

711
00:38:09,201 --> 00:38:09,809
Speaker 0: I haven't seen that.

712
00:38:10,672 --> 00:38:13,209
Speaker 1: Not a year, but I have had programmers surprise me.

713
00:38:13,770 --> 00:38:14,633
Speaker 0: Yeah.

714
00:38:14,773 --> 00:38:20,050
Speaker 0: You know, but even in IT, right, in IT, you know, you're not necessarily creating something new.

715
00:38:20,110 --> 00:38:23,890
Speaker 0: You're just sort of setting up a software or installing a thing or configuring a thing.

716
00:38:24,291 --> 00:38:26,210
Speaker 1: You are creating something new, but in a different regard.

717
00:38:26,410 --> 00:38:30,590
Speaker 1: But what you're creating that's new is all the glue between a bunch of other things.

718
00:38:30,991 --> 00:38:38,090
Speaker 1: And while those solutions are well known, the actual details of your environment make it such that what you're doing is effectively an entirely new thing.

719
00:38:38,410 --> 00:38:53,630
Speaker 1: Because nobody's actually taking like a ticketing system and a software development system and repositories and servers and software and installing them with default configurations and integrating them via UIs or defined APIs.

720
00:38:54,130 --> 00:38:54,231
Speaker 1: Right.

721
00:38:54,251 --> 00:38:57,190
Speaker 1: There's a bunch of cruft in between because you got something that's customized.

722
00:38:57,690 --> 00:38:57,891
Speaker 0: Yeah, it's.

723
00:38:58,051 --> 00:38:58,172
Speaker 0: it's.

724
00:38:58,332 --> 00:39:02,950
Speaker 0: it's a little bit a little bit easier to estimate and work things out with IT, but not much.

725
00:39:03,090 --> 00:39:05,870
Speaker 0: You know, you're always going to have like, well, how long does it take to set up exchange?

726
00:39:05,970 --> 00:39:07,147
Speaker 0: Well, about a couple of hours.

727
00:39:07,168 --> 00:39:07,289
Speaker 0: Right.

728
00:39:07,711 --> 00:39:09,850
Speaker 0: Well, you got to migrate our exchange server.

729
00:39:10,211 --> 00:39:13,090
Speaker 0: OK, there are specific things in our old exchange server.

730
00:39:13,230 --> 00:39:14,710
Speaker 0: They're going to cause you a lot of fucking trouble.

731
00:39:15,031 --> 00:39:16,650
Speaker 0: Well, now I have no fucking clue.

732
00:39:16,650 --> 00:39:17,233
Speaker 0: Here's a big example.

733
00:39:17,253 --> 00:39:20,630
Speaker 0: Maybe I'll look up that thing on Google and I'll have it in one hour extra.

734
00:39:21,131 --> 00:39:23,929
Speaker 0: Maybe it'll actually be a nightmare that requires an overnight thingy.

735
00:39:24,530 --> 00:39:26,289
Speaker 0: Maybe it requires even more work.

736
00:39:26,710 --> 00:39:32,270
Speaker 1: IT project I ever had for a real company was when I was working for ITS at RIT.

737
00:39:32,671 --> 00:39:33,144
Speaker 0: Oh, not IBM?

738
00:39:33,226 --> 00:39:33,308
Speaker 0: OK.

739
00:39:33,591 --> 00:39:34,790
Speaker 1: No, this is my first real project.

740
00:39:35,273 --> 00:39:36,590
Speaker 1: I had worked before IBM.

741
00:39:38,573 --> 00:39:40,970
Speaker 1: And actually, no, I worked there after I worked at IBM the first time anyway.

742
00:39:41,680 --> 00:39:49,470
Speaker 1: So what we had to do was migrate all the computers on RIT's faculty and administration network to Active Directory.

743
00:39:50,230 --> 00:39:51,549
Speaker 1: They weren't on the domain.

744
00:39:52,210 --> 00:39:55,610
Speaker 1: There were a bunch of like other domains around and it was kind of this hodgepodge.

745
00:39:56,170 --> 00:39:59,890
Speaker 1: Simultaneous to that, we had to migrate all of them to exchange.

746
00:40:00,711 --> 00:40:05,070
Speaker 1: Most of them had Outlook connecting to God only knows what.

747
00:40:05,410 --> 00:40:06,027
Speaker 0: Grace or Vex.

748
00:40:06,411 --> 00:40:14,610
Speaker 1: And every one of those people could not lose their like 10 years of accumulated emails.

749
00:40:14,830 --> 00:40:16,890
Speaker 0: Yeah, you can import into Exchange, export it to a file.

750
00:40:17,371 --> 00:40:18,309
Speaker 1: Oh, yeah, you say that.

751
00:40:18,651 --> 00:40:19,648
Speaker 1: OK, that is what to do.

752
00:40:20,010 --> 00:40:21,910
Speaker 1: This is why IT sizing is so difficult.

753
00:40:22,330 --> 00:40:25,429
Speaker 1: There is a pretty straightforward path to doing this.

754
00:40:26,250 --> 00:40:32,730
Speaker 1: Try doing it for more than a thousand people, each of whom have a slightly different environment.

755
00:40:33,373 --> 00:40:37,250
Speaker 1: And some of whom, in fact, almost all of whom have one thing that throws a monkey wrench into that.

756
00:40:37,630 --> 00:40:37,723
Speaker 0: Yep.

757
00:40:38,512 --> 00:40:40,890
Speaker 1: And that project took the better part of six months.

758
00:40:41,573 --> 00:40:43,409
Speaker 0: And it was a lot of people working on it.

759
00:40:43,570 --> 00:40:46,250
Speaker 0: There were just one guy, an army of guys.

760
00:40:46,430 --> 00:40:51,290
Speaker 1: I would go to an office and I'd have like 10 people with me and I'd fan them out across all these computers.

761
00:40:51,811 --> 00:40:55,070
Speaker 1: And nine of them would come back and say, oh, there's a problem.

762
00:40:57,654 --> 00:40:58,710
Speaker 1: And I'd have to do it myself.

763
00:40:58,851 --> 00:41:02,990
Speaker 1: And the number of things you would run into, like we set everyone up with these admin accounts.

764
00:41:03,110 --> 00:41:03,391
Speaker 1: Great.

765
00:41:04,093 --> 00:41:18,390
Speaker 1: Every one of them would add nine or 10 computers to the domain and then couldn't add them anymore because the accounts that were created happened to have a restriction where you could only add an account to the domain before your account was barred from adding further ones without special approval.

766
00:41:19,371 --> 00:41:21,989
Speaker 1: Nobody in the entire organization was prepared for that.

767
00:41:22,850 --> 00:41:23,091
Speaker 0: Yeah.

768
00:41:23,112 --> 00:41:23,293
Speaker 0: All right.

769
00:41:23,313 --> 00:41:26,230
Speaker 0: So let's talk about a few specific methodology thingies.

770
00:41:26,290 --> 00:41:30,810
Speaker 0: I guess the most popular one is, you know, is one that's pretty, pretty talked about frequently.

771
00:41:30,990 --> 00:41:40,069
Speaker 0: Internet is this pair programing, which is an aspect of something that was popularized by some books and some other guys who came up with it, which is extreme programing.

772
00:41:40,851 --> 00:41:46,470
Speaker 0: And, you know, basically I haven't looked too much into it because whatever.

773
00:41:46,853 --> 00:41:48,189
Speaker 1: But I have an opinion on it.

774
00:41:48,390 --> 00:41:52,750
Speaker 0: But yeah, but pretty much what it comes down to, at least the basic idea of pair programing.

775
00:41:52,950 --> 00:41:53,211
Speaker 0: Right.

776
00:41:53,271 --> 00:42:02,810
Speaker 0: Which is an aspect of extreme programing, which is extreme is that instead of sitting there and coding by yourself, you actually get two people.

777
00:42:03,312 --> 00:42:06,950
Speaker 0: One person is at the keyboard and one person is just sitting there.

778
00:42:07,731 --> 00:42:14,490
Speaker 0: And basically the person who's just sitting there says what to code and the other person types it in.

779
00:42:14,771 --> 00:42:18,290
Speaker 0: And you can sort of think together and discuss and all this stuff.

780
00:42:18,410 --> 00:42:23,390
Speaker 0: And the idea is that, you know, most of the time you spend coding is time you spend thinking.

781
00:42:23,793 --> 00:42:25,470
Speaker 0: It's not the typing isn't the bottleneck.

782
00:42:25,891 --> 00:42:34,170
Speaker 0: So even if you should actually put the slower typing person at the keyboard, you know, that way you have more time to sit and think and look.

783
00:42:34,250 --> 00:42:39,310
Speaker 0: And it's not really slowing you down with the slow typing, the thinking and figuring out what to type is where all your time is.

784
00:42:39,691 --> 00:42:44,310
Speaker 0: So if two of you work together, not only will you come up with the correct thing to type faster.

785
00:42:44,933 --> 00:42:45,194
Speaker 0: Right.

786
00:42:45,374 --> 00:42:48,930
Speaker 0: You'll both keep each other on task instead of browsing the Internet's all the time.

787
00:42:49,630 --> 00:42:56,330
Speaker 0: But on top of that, you'll have fewer bugs because you have two sets of eyes to recognize them like, aha, you missed a thing there.

788
00:42:56,430 --> 00:42:57,235
Speaker 0: Oh, I missed a thing.

789
00:42:57,417 --> 00:42:59,470
Speaker 1: Now, there's a. there's a great picture of this.

790
00:42:59,590 --> 00:43:05,670
Speaker 1: I went to the Wikipedia article on pair programing because there is one and the picture is clearly a fake one.

791
00:43:06,511 --> 00:43:09,810
Speaker 1: One of the programmers is pointing at the screen and the other one is looking.

792
00:43:09,930 --> 00:43:11,710
Speaker 1: No one ever does that in the real world.

793
00:43:11,770 --> 00:43:13,369
Speaker 0: That picture you see is a stock photo.

794
00:43:13,532 --> 00:43:13,777
Speaker 0: Yeah.

795
00:43:14,084 --> 00:43:14,248
Speaker 1: Two.

796
00:43:14,953 --> 00:43:15,750
Speaker 0: We got that b-roll.

797
00:43:16,112 --> 00:43:16,970
Speaker 1: Two in the background.

798
00:43:17,310 --> 00:43:19,450
Speaker 0: Guy pointing at a computer, one of the guy looks on, we got that b-roll.

799
00:43:19,690 --> 00:43:28,150
Speaker 1: There's actually like a proper looking scrum like clipboard, you know, the kind of like scrum tracking thing people would use.

800
00:43:28,693 --> 00:43:30,389
Speaker 1: I've never seen someone actually use it like that.

801
00:43:31,072 --> 00:43:31,233
Speaker 1: Yeah.

802
00:43:31,253 --> 00:43:33,489
Speaker 1: And three is on a Mac and he's using the mouse.

803
00:43:35,310 --> 00:43:38,681
Speaker 0: So this is one of those things where it's like, OK, some.

804
00:43:38,762 --> 00:43:41,170
Speaker 0: I do know that some people definitely do this.

805
00:43:41,271 --> 00:43:43,610
Speaker 0: I've met people who do this and they say they do it at work.

806
00:43:43,790 --> 00:43:46,049
Speaker 0: I met these people in person, never met anyone who's done it.

807
00:43:46,210 --> 00:43:48,890
Speaker 0: I've met people who say they have done it.

808
00:43:48,910 --> 00:43:54,030
Speaker 0: I've never seen a workplace in person that is doing it, but I have met people who say they do it at work every day.

809
00:43:54,070 --> 00:43:54,633
Speaker 0: That's all they do.

810
00:43:55,818 --> 00:43:58,450
Speaker 0: And, you know, they personally like it.

811
00:43:58,510 --> 00:44:09,490
Speaker 0: Do they have any evidence, actual studies and, you know, observed cases to, you know, compare it with controls against something to show that it is actually more efficient and produces less bugs?

812
00:44:10,330 --> 00:44:10,972
Speaker 0: Not really.

813
00:44:10,992 --> 00:44:19,090
Speaker 0: I mean, there's some stuff out there, but not a substantial body of, you know, work to show that this is a good way of doing things.

814
00:44:19,270 --> 00:44:23,030
Speaker 1: I have a guess, though, and I also have an environment where I think it is a very useful thing.

815
00:44:23,230 --> 00:44:23,691
Speaker 0: Yeah, but, you know,

816
00:44:23,711 --> 00:44:37,610
Speaker 1: I guess is that it only works well if the two people involved are reasonably socialized at a similar seniority and at a similar ability level, because otherwise the guy who knows more is just going to code the whole thing and the other guy is just going to kind of type it all in.

817
00:44:37,872 --> 00:44:39,169
Speaker 0: But maybe that guy will learn something.

818
00:44:39,512 --> 00:44:42,910
Speaker 1: Maybe he will, but it's probably going to slow the more senior guy down.

819
00:44:43,031 --> 00:44:45,830
Speaker 1: And I thought the whole goal of this was to make better code, not to train.

820
00:44:46,551 --> 00:44:50,510
Speaker 0: Well, maybe once in a while that guy who's not as good will notice a bug in the thing the other guy wrote.

821
00:44:50,630 --> 00:44:50,930
Speaker 0: Maybe.

822
00:44:51,231 --> 00:45:04,150
Speaker 1: But I feel like just from experience, when a more junior software engineer or IT guy is working with a senior person, they'll pretty much defer to the senior person even when the senior person is wrong for various social reasons.

823
00:45:04,451 --> 00:45:04,671
Speaker 1: Yeah.

824
00:45:05,233 --> 00:45:07,077
Speaker 0: You know, basically, you know, no, we don't.

825
00:45:07,177 --> 00:45:12,250
Speaker 0: I've never done pair program in any place, but every place I've ever worked is basically you're sitting there doing your work.

826
00:45:13,011 --> 00:45:16,610
Speaker 0: And if you have a real problem, yes, another guy, because you never were completely alone.

827
00:45:16,830 --> 00:45:22,990
Speaker 0: Yeah, I mean, my one and suddenly you can have two or maybe even three or four guys all looking at the same thing, trying to figure it out.

828
00:45:23,090 --> 00:45:28,050
Speaker 0: And, you know, usually just in the course of explaining what it is to everyone, you'll figure out what's wrong with it.

829
00:45:28,451 --> 00:45:35,030
Speaker 1: I mean, one of my senior developers will just get up and go to the other coders, be like, I'm having trouble with this and I'll just kind of huddle for five minutes and they'll go back to work.

830
00:45:35,110 --> 00:45:40,750
Speaker 0: So just because huddling is sometimes effective to solve a problem doesn't mean you should stay in the huddle the whole time.

831
00:45:41,131 --> 00:45:41,291
Speaker 0: Right.

832
00:45:41,311 --> 00:45:46,450
Speaker 0: You're playing football, you huddle up, you break and you go, you know, you do the play.

833
00:45:46,730 --> 00:45:48,450
Speaker 1: No, we should remake football to be more efficient.

834
00:45:48,590 --> 00:45:49,368
Speaker 1: It's all huddles.

835
00:45:50,050 --> 00:45:50,212
Speaker 0: Actually.

836
00:45:50,597 --> 00:45:51,650
Speaker 0: Yeah, it's all huddles.

837
00:45:52,090 --> 00:45:57,190
Speaker 0: Actually, they're thinking about if they add technology to football, they might be able to eliminate the huddle if everyone has a headset.

838
00:45:57,372 --> 00:45:58,060
Speaker 1: That'd be awesome.

839
00:45:58,182 --> 00:45:58,830
Speaker 0: It would be the awesome.

840
00:45:58,950 --> 00:46:01,897
Speaker 1: I would love to listen to that headset during the game to.

841
00:46:02,237 --> 00:46:07,810
Speaker 0: they have headsets now, but they're all encrypted and you can't listen because that means the other team will be able to listen, which ruins the whole thing.

842
00:46:08,191 --> 00:46:14,190
Speaker 0: But it does remove an aspect of the game, which is the, you know, they keep changing the number of, you know, who's in the huddles.

843
00:46:14,330 --> 00:46:18,630
Speaker 0: You don't know who's going to be on the play to sort of get the other guy to mess up his substitutions.

844
00:46:18,750 --> 00:46:26,250
Speaker 0: You bring you know, you got a slow guy in the huddle, so they let their fast guy take a rest and then you switch, which is why you're not allowed to have more than a certain number of guys.

845
00:46:26,350 --> 00:46:35,090
Speaker 1: Imagine if we had a technology, complete aside, where at the line where the ball is, there was an opaque screen.

846
00:46:35,190 --> 00:46:42,270
Speaker 1: You could walk through it, but there's no big screen would just appear every time the whistle blew and neither team could see what was going on on the other side.

847
00:46:42,690 --> 00:46:45,610
Speaker 1: And that screen disappeared the moment the hike happened.

848
00:46:45,892 --> 00:46:46,670
Speaker 0: That'd be the awesomeness.

849
00:46:46,850 --> 00:46:47,970
Speaker 1: I would I would kill.

850
00:46:48,370 --> 00:46:49,032
Speaker 0: Well, it couldn't.

851
00:46:49,133 --> 00:46:54,430
Speaker 0: No, it couldn't be at the point of the snap because then it'd be like you line up and you don't even get to see the defense.

852
00:46:54,490 --> 00:46:55,152
Speaker 0: No, no.

853
00:46:55,312 --> 00:47:02,750
Speaker 0: Part of part of part of football is seeing how the other guys line up and trying to fake the other guys out, you know, that kind of thing.

854
00:47:02,830 --> 00:47:07,390
Speaker 0: But it would be cool if it didn't go away until like the center put his hand on the ball.

855
00:47:07,732 --> 00:47:11,050
Speaker 0: And then, you know, you got to see what the other how the other team was looking.

856
00:47:11,392 --> 00:47:13,050
Speaker 0: That would be that would be a little bit more interesting.

857
00:47:13,731 --> 00:47:30,150
Speaker 1: But anyway, one place where I could see this working really well is extremely security sensitive environments like a government place where you're writing software for important spy things, because then then you're getting benefits that you don't even need science to prove that are actually better.

858
00:47:30,350 --> 00:47:30,410
Speaker 1: Yes.

859
00:47:30,430 --> 00:47:37,830
Speaker 1: For example, in order to put a backdoor in the code, you need an accomplice to simultaneously decide to do it.

860
00:47:38,091 --> 00:47:38,312
Speaker 0: Yeah.

861
00:47:38,352 --> 00:47:40,830
Speaker 0: Then dependent of passing code review, you have a special case.

862
00:47:40,951 --> 00:47:42,330
Speaker 0: You're getting a guaranteed benefit.

863
00:47:42,410 --> 00:47:44,010
Speaker 0: You don't need science to prove it's a benefit.

864
00:47:44,431 --> 00:47:50,250
Speaker 0: And it's worth even if there are other harms, it's worth it because security is so extremely important.

865
00:47:50,390 --> 00:47:59,590
Speaker 1: A special case that I don't believe and I have no evidence of this, that there are places where there will have two teams or two people code the same thing simultaneously with no communication.

866
00:48:00,431 --> 00:48:04,789
Speaker 1: And then a third person will review both of their code and then write the solution based on those two.

867
00:48:05,711 --> 00:48:09,410
Speaker 1: Again, high security, military, possibly never actually done in practice.

868
00:48:10,390 --> 00:48:10,471
Speaker 0: Yeah.

869
00:48:10,511 --> 00:48:12,050
Speaker 0: I mean, that's not a bad idea either, right?

870
00:48:12,070 --> 00:48:16,029
Speaker 0: Because then if one guy writes a backdoor, he doesn't know if his back door is actually in the product or not.

871
00:48:16,331 --> 00:48:22,109
Speaker 0: And, you know, so it's like, well, you're not even going to try to write a backdoor because someone else looks at your code before it gets in.

872
00:48:22,851 --> 00:48:24,769
Speaker 0: And, you know, you don't even know who that guy is.

873
00:48:24,890 --> 00:48:31,410
Speaker 0: So you can't be your accomplice and you don't even know if it's actually going to make it in there because someone else is doing it also.

874
00:48:32,131 --> 00:48:34,129
Speaker 0: So there's not even a point to do and it's just do your work.

875
00:48:34,533 --> 00:48:35,450
Speaker 1: So very popular.

876
00:48:35,570 --> 00:48:37,930
Speaker 1: I want to talk about is Agile, particularly Scrum.

877
00:48:38,150 --> 00:48:40,250
Speaker 0: Well, Agile, it's weird because a lot of these things.

878
00:48:40,330 --> 00:48:40,571
Speaker 0: Right.

879
00:48:40,893 --> 00:48:44,890
Speaker 0: A lot of the reason I think a lot of them are such snake oil is because they're so ill-defined.

880
00:48:44,971 --> 00:48:47,810
Speaker 0: And like, there's always going to be some guy who says, that's not Agile.

881
00:48:48,050 --> 00:48:48,716
Speaker 0: This is Agile.

882
00:48:48,776 --> 00:48:50,330
Speaker 0: I'm not Agile expert, blah, blah, blah.

883
00:48:50,532 --> 00:48:52,089
Speaker 0: And maybe, maybe that guy is.

884
00:48:52,391 --> 00:48:53,053
Speaker 0: But you know what?

885
00:48:53,915 --> 00:48:58,430
Speaker 0: I've read stuff that's like by the guy who came up with certain things and he says, I came up with it.

886
00:48:58,510 --> 00:48:59,462
Speaker 0: I'm the inventor of this thing.

887
00:48:59,523 --> 00:48:59,868
Speaker 0: And he is.

888
00:49:00,352 --> 00:49:01,769
Speaker 0: And he says, this is what the thing is.

889
00:49:02,071 --> 00:49:07,690
Speaker 0: But there'll be some other guy who's the expert on the thing, even though he didn't come up with it, who says, no, no, no, it's something different.

890
00:49:07,890 --> 00:49:17,569
Speaker 1: That's why you can't evaluate something so ephemeral or because these words, people instead you have to define like people make very specific systems based on these like Scrum.

891
00:49:18,150 --> 00:49:20,389
Speaker 1: There's some pretty particular rules about how to do Scrum.

892
00:49:20,831 --> 00:49:20,991
Speaker 1: Yeah.

893
00:49:21,011 --> 00:49:27,630
Speaker 0: It's like people came up with like these sets of rules and instructions and procedures and everyone is actually doing something different.

894
00:49:27,791 --> 00:49:30,890
Speaker 0: And a lot of people are calling it the same thing, like, oh, we're an Agile workplace.

895
00:49:31,090 --> 00:49:31,834
Speaker 0: We're an Agile workplace.

896
00:49:31,855 --> 00:49:34,450
Speaker 1: But at the same time, you go to the two workplaces and they look completely different.

897
00:49:34,610 --> 00:49:40,990
Speaker 1: And there are things like IDIL, I-T-I-L, which are extremely, excruciatingly defined in detail.

898
00:49:41,753 --> 00:49:42,036
Speaker 0: Right.

899
00:49:42,076 --> 00:49:43,590
Speaker 0: But it's sort of a no true Scotsman.

900
00:49:43,650 --> 00:49:43,791
Speaker 0: Right.

901
00:49:43,811 --> 00:49:44,657
Speaker 0: It's like we're Agile.

902
00:49:44,798 --> 00:49:46,370
Speaker 0: No, you're not really Agile.

903
00:49:46,730 --> 00:49:51,410
Speaker 1: But Scott, what about things like IDIL where there's kind of a board that decides and that is it?

904
00:49:51,751 --> 00:49:52,729
Speaker 0: Yeah, well, that's a different thing.

905
00:49:52,911 --> 00:49:53,659
Speaker 1: Yeah, that's what I was saying.

906
00:49:53,699 --> 00:49:54,568
Speaker 1: There are things like that, too.

907
00:49:55,370 --> 00:50:04,130
Speaker 1: My problem with all of these is that they all have these big graphics that remind me of what I studied at RIT in classes, unlike project management.

908
00:50:06,253 --> 00:50:08,609
Speaker 1: And they're all completely useless.

909
00:50:08,910 --> 00:50:14,590
Speaker 1: They either tell you something obvious like work on stuff, then QA it, then work on stuff.

910
00:50:15,430 --> 00:50:17,629
Speaker 1: Like, do you need a graph to explain that?

911
00:50:17,910 --> 00:50:18,929
Speaker 0: Yeah, no.

912
00:50:21,291 --> 00:50:24,850
Speaker 1: Do you need to have the thing that says plan your project before you write it?

913
00:50:25,130 --> 00:50:26,708
Speaker 1: Does someone actually need someone to tell them that?

914
00:50:28,510 --> 00:50:31,129
Speaker 1: The thing is, I kind of worry that that, in fact, is necessary.

915
00:50:31,790 --> 00:50:32,292
Speaker 0: Sometimes.

916
00:50:32,995 --> 00:50:36,550
Speaker 0: But and the thing is, a lot of people have these things on paper, but don't actually do them.

917
00:50:36,610 --> 00:50:36,831
Speaker 0: Right.

918
00:50:36,871 --> 00:50:42,270
Speaker 0: It's like we put such emphasis on like maintenance, documentation or testing or no one's test driven.

919
00:50:42,430 --> 00:50:45,090
Speaker 1: Development is never on the road.

920
00:50:45,370 --> 00:50:45,572
Speaker 0: Right.

921
00:50:45,632 --> 00:50:47,730
Speaker 0: It's like people have all these things on paper.

922
00:50:47,911 --> 00:50:48,032
Speaker 0: Right.

923
00:50:48,072 --> 00:50:51,030
Speaker 0: These procedures and stuff, they don't follow them for shit.

924
00:50:51,172 --> 00:50:52,370
Speaker 0: I have never been in a place.

925
00:50:52,491 --> 00:50:52,633
Speaker 0: Right.

926
00:50:52,936 --> 00:50:54,270
Speaker 0: A lot of the test driven development.

927
00:50:54,331 --> 00:50:55,389
Speaker 0: That's one that drives me crazy.

928
00:50:55,611 --> 00:50:55,751
Speaker 0: Right.

929
00:50:55,771 --> 00:51:00,070
Speaker 0: Because, you know, there's some cases where it's a good idea in some cases where it's a bad idea or whatever.

930
00:51:00,171 --> 00:51:03,330
Speaker 0: But it's like how many people actually have tests?

931
00:51:03,571 --> 00:51:03,872
Speaker 0: Right.

932
00:51:04,294 --> 00:51:08,530
Speaker 0: Like, you know, it's one of those things where you go online and you read articles written by people.

933
00:51:09,071 --> 00:51:09,953
Speaker 0: Here's a great example.

934
00:51:10,013 --> 00:51:15,970
Speaker 0: It's not actually of a, you know, a software development technique, but it's like, you know, a deployment.

935
00:51:16,170 --> 00:51:19,110
Speaker 0: This is a particular web software deployment technology.

936
00:51:19,531 --> 00:51:23,850
Speaker 0: And everyone, if you read articles, is like, oh, you got to be using these tools for deployment.

937
00:51:23,911 --> 00:51:24,579
Speaker 0: They're amazing.

938
00:51:24,620 --> 00:51:25,430
Speaker 0: They're amazing tools.

939
00:51:25,531 --> 00:51:26,097
Speaker 0: You got to use them.

940
00:51:26,117 --> 00:51:26,561
Speaker 0: You got to use them.

941
00:51:26,581 --> 00:51:27,107
Speaker 0: You got to use them.

942
00:51:27,208 --> 00:51:27,410
Speaker 0: Right.

943
00:51:28,070 --> 00:51:31,610
Speaker 0: So my coworker goes to a conference and everyone is like, you got to use these tools.

944
00:51:31,650 --> 00:51:33,749
Speaker 0: And I had seen a zillion articles about using these tools.

945
00:51:35,091 --> 00:51:39,010
Speaker 0: So one guy gets up in front of the thing and says, these tools are the greatest.

946
00:51:39,452 --> 00:51:39,754
Speaker 0: Right.

947
00:51:39,956 --> 00:51:41,309
Speaker 0: You know, everyone's got to use them.

948
00:51:41,592 --> 00:51:42,948
Speaker 0: Who here is using them right now?

949
00:51:43,950 --> 00:51:44,071
Speaker 0: Nobody.

950
00:51:44,475 --> 00:51:46,109
Speaker 0: Who here is planning to use them soon?

951
00:51:46,512 --> 00:51:47,409
Speaker 0: A whole bunch of people.

952
00:51:48,511 --> 00:51:56,630
Speaker 0: OK, so that same guy giving that talk, saying how those tools were great later on gives another thing like how we do it at my company.

953
00:51:56,690 --> 00:51:58,030
Speaker 1: They don't use any of those tools, do they?

954
00:51:58,150 --> 00:51:59,288
Speaker 0: He's not actually using them yet.

955
00:51:59,914 --> 00:52:01,345
Speaker 0: So, yeah, you're right.

956
00:52:01,366 --> 00:52:01,890
Speaker 1: That's the thing.

957
00:52:02,030 --> 00:52:04,910
Speaker 0: He's like, yeah, we just had of all these hacks built on the old tools.

958
00:52:05,190 --> 00:52:06,410
Speaker 1: I've dealt with a lot of this stuff.

959
00:52:06,570 --> 00:52:09,290
Speaker 1: I mean, part of my job now is managing a bunch of developers for this stuff.

960
00:52:09,350 --> 00:52:15,008
Speaker 0: A lot of people, I bet, who are emphasizing the agile's and the scrums and the test driven developments.

961
00:52:15,950 --> 00:52:16,788
Speaker 1: They're not using it.

962
00:52:16,970 --> 00:52:18,990
Speaker 1: They all think that they will be using it someday.

963
00:52:19,210 --> 00:52:24,930
Speaker 1: Every one of those people has a plan to use them, plans to do the documentation and a plan to do that.

964
00:52:25,010 --> 00:52:35,810
Speaker 1: When you said yet, that's the key, because with all these software development methodologies, everyone I have ever met who spouses them will say we are working toward implementing them.

965
00:52:35,931 --> 00:52:38,730
Speaker 1: And I've never met anyone who actually implemented them fully.

966
00:52:39,250 --> 00:52:39,990
Speaker 0: Yep, never.

967
00:52:40,750 --> 00:52:41,790
Speaker 1: Some people have gotten close, though.

968
00:52:41,850 --> 00:52:54,550
Speaker 1: And I think for some professional advice, the real key is to learn about these things and look for stuff that you think will work in your environment and pick and choose and come up with a methodology that works for your own internal environment.

969
00:52:54,812 --> 00:52:56,730
Speaker 1: And by trial and error, make it better over time.

970
00:52:57,210 --> 00:53:08,710
Speaker 1: If you try if you try to implement scrum and religiously follow it to the point that you let the rules actually drive your process and get in the way, then you're probably worse off.

971
00:53:09,131 --> 00:53:15,530
Speaker 0: That's the thing that bothers me about them the most over everything else is not necessarily, you know, they're not actually helping you.

972
00:53:15,570 --> 00:53:16,490
Speaker 0: They are actually helping you.

973
00:53:16,530 --> 00:53:17,929
Speaker 0: You don't have evidence to show they're helping you.

974
00:53:17,970 --> 00:53:28,990
Speaker 0: That doesn't really bother me as much as the fact that when you do these people concentrate so much on the procedure of work, that actually they end up doing more meta work than work.

975
00:53:29,430 --> 00:53:44,130
Speaker 0: They'll spend more time like modifying their tickets and arranging their Kanban board and, you know, having the little meetings and getting with the team and organizing the thingies and distributing the workflows and all that time.

976
00:53:44,150 --> 00:53:48,210
Speaker 0: They spend doing all that nonsense, which is supposedly going to increase the efficiency of their work.

977
00:53:48,794 --> 00:53:49,970
Speaker 0: They're just not working.

978
00:53:50,071 --> 00:53:52,689
Speaker 0: They're doing this meta work instead of doing work work.

979
00:53:53,231 --> 00:53:59,210
Speaker 0: That's like if we sat around half the day discussing how we're going to do the thing and then only spent half the day doing the thing.

980
00:53:59,671 --> 00:54:13,390
Speaker 0: If we wouldn't have had any organization or maybe only had five minutes of organization, even if without any official procedure, and then just spent all day doing the work, even if we were working less efficiently, we would probably still get more work done.

981
00:54:14,391 --> 00:54:27,090
Speaker 1: I disagree for one reason that usually it's because it takes a lot of work to set up one of these systems or to set something up in general, set up the internal infrastructure to manage products in a sort of verifiable or controlled way.

982
00:54:27,491 --> 00:54:32,850
Speaker 1: But once it's set up, if it's maintained and works, then it probably pays out dividends in the end.

983
00:54:32,950 --> 00:54:33,272
Speaker 1: It doesn't.

984
00:54:33,574 --> 00:54:35,830
Speaker 1: It's not like you have to rebuild the process for every new project.

985
00:54:36,010 --> 00:54:41,810
Speaker 0: Yeah, a lot of it depends on the size of your project, you know, because when you get more people, you need more meta work.

986
00:54:41,910 --> 00:54:45,490
Speaker 0: There's just no way to get all the people to work in concert without the meta work.

987
00:54:45,890 --> 00:54:49,530
Speaker 1: Yeah, but the thing is, you have to be smart about it and you pick and choose what parts work.

988
00:54:49,850 --> 00:55:08,210
Speaker 1: Like in idle, there's this idea of if you're categorizing the severity of a problem, like a bug comes in and you're tracking it and whatever ticketing system you use, instead of just having a priority like A, B, C, D, E or high, medium, low or whatever, it has the idea that priority is always the two dimensional matrix with two elements.

989
00:55:08,692 --> 00:55:12,030
Speaker 1: The severity or the urgency, depending on how you want to call it.

990
00:55:12,550 --> 00:55:14,110
Speaker 1: I believe the technical term is urgency, but whatever.

991
00:55:14,810 --> 00:55:17,370
Speaker 1: And the impact, like what it impacts.

992
00:55:17,870 --> 00:55:26,390
Speaker 1: So, for example, the difference between something that impacts revenue and is low priority versus something that doesn't impact revenue, but is high urgency.

993
00:55:27,111 --> 00:55:28,330
Speaker 1: The idea of separating impact from urgency.

994
00:55:28,330 --> 00:55:31,222
Speaker 0: Like, oh, my God, it crashes, but we're not actually losing any monies.

995
00:55:31,563 --> 00:55:33,230
Speaker 0: or hey, this isn't really a crash.

996
00:55:33,331 --> 00:55:34,749
Speaker 0: It's just like a weird number error.

997
00:55:34,910 --> 00:55:39,409
Speaker 0: And it's only in this tiny thing that's hardly ever used, but it is losing us a tiny amount of monies.

998
00:55:39,911 --> 00:55:48,329
Speaker 1: But the idea of separating impact from urgency and then prioritizing based on a combination of the two is a fantastic idea and everyone should do it.

999
00:55:48,671 --> 00:55:49,228
Speaker 0: It's a good idea.

1000
00:55:50,330 --> 00:55:53,250
Speaker 0: Going the rest of the way, you don't necessarily need to follow all the idle.

1001
00:55:53,511 --> 00:55:54,930
Speaker 1: Yeah, implementing all of idle.

1002
00:55:55,990 --> 00:55:58,069
Speaker 1: I wouldn't believe that anyone in the world has.

1003
00:55:58,390 --> 00:56:02,529
Speaker 0: There's probably some place they got certified and is doing it just because they wanted some bureaucracy nonsense.

1004
00:56:03,112 --> 00:56:07,290
Speaker 1: And I've studied it a lot because I've implemented aspects of it in ticketing systems.

1005
00:56:08,514 --> 00:56:12,070
Speaker 1: But spending a lot of time to define workflows and things is very important.

1006
00:56:12,390 --> 00:56:27,610
Speaker 1: The problem is people who aren't naturally good at organizing tend to fall back on these systems and tend to put a lot of effort into implementing the systems, probably more so than they should be compared to the time they should be spending on just actually getting the project going.

1007
00:56:27,791 --> 00:56:30,580
Speaker 0: Well, also, people who tend to be bad at organizing tend to really just.

1008
00:56:30,660 --> 00:56:33,690
Speaker 0: they can't stick to the system like they really want to in their minds.

1009
00:56:33,690 --> 00:56:40,050
Speaker 0: Like they have this idea, like I'm going to get an organizer and they get an organizer and they start using it and they get a to do list and they use it for about a day.

1010
00:56:40,191 --> 00:56:41,829
Speaker 0: And then they forget about it.

1011
00:56:41,890 --> 00:56:42,770
Speaker 1: Yeah, well, that's the analogy.

1012
00:56:43,214 --> 00:56:44,230
Speaker 1: I know a lot of people who do this.

1013
00:56:44,310 --> 00:56:44,815
Speaker 1: I used to do it.

1014
00:56:45,158 --> 00:56:46,370
Speaker 1: You'll need to work on some stuff.

1015
00:56:46,470 --> 00:56:49,410
Speaker 1: You're sitting at home at Saturday like, shit, I got to get some stuff done.

1016
00:56:49,810 --> 00:56:52,247
Speaker 1: So you sit down, you say, I'm going to make a list of all the things I have to do.

1017
00:56:52,991 --> 00:56:58,690
Speaker 1: And the Twilight Sparkle style, you sit there for an hour and make this exhaustive list and prioritize it.

1018
00:56:59,211 --> 00:57:01,070
Speaker 1: And then you feel like you got a bunch of work done.

1019
00:57:01,370 --> 00:57:04,950
Speaker 0: So you take a break and then you at the end of the day, you didn't get any of those things.

1020
00:57:05,270 --> 00:57:07,410
Speaker 0: Go back to the list and you spent an hour making a list.

1021
00:57:07,670 --> 00:57:08,441
Speaker 0: Congratulations.

1022
00:57:08,461 --> 00:57:09,029
Speaker 0: You made a list.

1023
00:57:09,330 --> 00:57:09,494
Speaker 0: Yep.

1024
00:57:09,740 --> 00:57:10,149
Speaker 0: Good job.

1025
00:57:10,431 --> 00:57:15,270
Speaker 1: Now, if you want to break yourself of that habit, if you make a list like that, you're not allowed to throw it away.

1026
00:57:15,571 --> 00:57:19,469
Speaker 1: You've got to leave it on your desk and look at that fucker every day and feel bad about it.

1027
00:57:19,992 --> 00:57:21,410
Speaker 1: That's the only way to break that cycle.

1028
00:57:21,752 --> 00:57:25,290
Speaker 1: The moment you say it and you make a new list, you're done.

1029
00:57:25,712 --> 00:57:26,299
Speaker 1: It's over.

1030
00:57:26,482 --> 00:57:27,009
Speaker 1: You've lost.

1031
00:57:28,634 --> 00:57:30,089
Speaker 0: But yeah, that's how these things go.

1032
00:57:30,330 --> 00:57:47,110
Speaker 0: So, you know, when someone tries to sell you on like a test driven development or an agile this or whatever, that that just sort of tells me that, you know, not necessarily that they're a bad person or that they're no good, but that they sort of, you know, easily seduced by these these ideas.

1033
00:57:47,190 --> 00:57:52,590
Speaker 0: They sort of had this naive attitude that these that these magical systems are kind of awesome.

1034
00:57:52,810 --> 00:58:03,210
Speaker 1: They're seduced by the idea that if they find some instructions on how to do X, like project management or software development, and they follow them, that it'll just work.

1035
00:58:03,730 --> 00:58:07,709
Speaker 1: Kind of like how if I follow the instructions on an Ikea thing, an Ikea thing comes out at the end.

1036
00:58:08,210 --> 00:58:14,790
Speaker 0: Yeah, it's like they have this imaginary sort of world where all their projects are managed in this beautiful structure.

1037
00:58:15,374 --> 00:58:17,430
Speaker 0: And, you know, you always test driven development.

1038
00:58:17,590 --> 00:58:22,170
Speaker 0: We're going to write before we write any code, we're going to write a test and write the code every time.

1039
00:58:22,471 --> 00:58:27,465
Speaker 0: And they believe in this like fantasy universe that they will and everything's perfectly documented.

1040
00:58:27,505 --> 00:58:29,110
Speaker 0: documentation always gets updated in the wiki.

1041
00:58:29,351 --> 00:58:31,370
Speaker 0: And they believe that that universe exists.

1042
00:58:31,390 --> 00:58:33,689
Speaker 0: They can imagine it in their minds and how great it would be.

1043
00:58:34,571 --> 00:58:41,710
Speaker 0: And they actually believe that they're going to go there and that they are going there instead of recognizing that that is a fantasy land that can never exist.

1044
00:58:42,091 --> 00:58:42,312
Speaker 1: Yup.

1045
00:58:42,753 --> 00:58:47,690
Speaker 1: You know, to quote something that gets said often, actually releasing something is a feature.

1046
00:58:48,512 --> 00:58:51,149
Speaker 1: And here's a story from my past.

1047
00:58:51,610 --> 00:59:03,990
Speaker 1: When I was a senior production engineer, my old job, I would often be approached by developers or people who would say something to the effect of we need to get this patch, whatever it is, into this production environment.

1048
00:59:05,093 --> 00:59:07,150
Speaker 1: We can't wait for a full regression test.

1049
00:59:07,270 --> 00:59:08,119
Speaker 1: It's a small patch.

1050
00:59:08,160 --> 00:59:09,029
Speaker 1: It's not that big a deal.

1051
00:59:09,710 --> 00:59:15,350
Speaker 1: And of course, I would say no, because, you know, and then I'd get overruled and I'd always be mad about that.

1052
00:59:15,450 --> 00:59:16,330
Speaker 0: Did you get it in writing?

1053
00:59:16,811 --> 00:59:18,170
Speaker 1: Oh, yeah, but I'd always get overruled.

1054
00:59:18,390 --> 00:59:23,670
Speaker 0: You just got to say you just got to get it in writing that they overruled you so that then you can have the I told you so stack.

1055
00:59:23,950 --> 00:59:28,230
Speaker 1: Let's do a Monday show on the proper means of covering one's ass in the real technical world.

1056
00:59:28,630 --> 00:59:29,281
Speaker 0: Get it in writing.

1057
00:59:29,342 --> 00:59:29,810
Speaker 0: End of story.

1058
00:59:30,090 --> 00:59:31,210
Speaker 0: Yeah, someone rang the doorbell.

1059
00:59:31,470 --> 00:59:38,790
Speaker 1: Anyway, but I used to always say things to myself like if I was in charge, you know, I wouldn't I wouldn't be the one who overrules those things.

1060
00:59:38,952 --> 00:59:40,470
Speaker 1: I would follow the process.

1061
00:59:41,070 --> 00:59:46,830
Speaker 0: I wouldn't follow the process, but I also, you know, wouldn't do certain things like letting untested grab code.

1062
00:59:47,090 --> 00:59:48,150
Speaker 1: Well, no, it's not a matter of untested.

1063
00:59:48,270 --> 00:59:59,430
Speaker 1: Imagine something that was tested by developers and was tested by QA, but the full system was not re-regression tested, even though there was a low chance of a regression anywhere else in the system.

1064
00:59:59,830 --> 01:00:08,330
Speaker 0: Well, since I know how the thing works, because I'm actually a technology person and I'm not one of those bosses who's just a boss and doesn't actually know how the shit works, I would look at the specific thing.

1065
01:00:08,910 --> 01:00:15,710
Speaker 0: And decide or I would just trust whoever was under me close most closely and not even it was also a discussion.

1066
01:00:15,850 --> 01:00:26,370
Speaker 1: But like, for example, a procedure was put in place where when code is ready to go to production, their release notes, they have to be signed by all the approvers and pretty much without fail, there'd be someone who wasn't around to sign.

1067
01:00:26,490 --> 01:00:33,829
Speaker 1: You have to roll something out anyway, and someone would overrule them, at which point, why even have the process if you're obviously going to, you know, violate it every time you have to.

1068
01:00:35,371 --> 01:00:45,970
Speaker 1: Now that I'm a manager and I deal with this stuff and I'm the boss who has to sign the overruling procedures and everything, I'm pretty much doing everything that I always used to complain about.

1069
01:00:46,353 --> 01:00:47,069
Speaker 0: Don't be doing that.

1070
01:00:47,270 --> 01:00:52,170
Speaker 1: Now, because I know better and I know that, you know, decisions I'm making are actually pretty safe.

1071
01:00:53,074 --> 01:00:53,256
Speaker 0: Yeah.

1072
01:00:53,297 --> 01:00:54,169
Speaker 0: Has anything fucked up yet?

1073
01:00:54,333 --> 01:00:54,441
Speaker 0: No.

1074
01:00:54,750 --> 01:00:57,590
Speaker 0: But when the bosses you had before made those decisions, did shit get fucked up?

1075
01:00:57,810 --> 01:00:58,150
Speaker 1: Occasionally.

1076
01:00:58,990 --> 01:00:59,234
Speaker 0: Yeah.

1077
01:00:59,254 --> 01:01:00,550
Speaker 0: So has you fucked up anything ever?

1078
01:01:01,996 --> 01:01:05,730
Speaker 1: I once choned an entire production system to be owned by Apache.

1079
01:01:06,010 --> 01:01:09,210
Speaker 0: I meant as the boss, have you, when you overruled, have you fucked it up?

1080
01:01:09,810 --> 01:01:12,590
Speaker 1: I have not yet, but I have not worked at this new company that long.

1081
01:01:12,710 --> 01:01:12,993
Speaker 0: All right.

1082
01:01:13,033 --> 01:01:14,630
Speaker 0: But you know about the technologies?

1083
01:01:14,892 --> 01:01:15,168
Speaker 0: Yeah.

1084
01:01:15,330 --> 01:01:18,110
Speaker 0: The people that were your boss before, did they know about the technologies?

1085
01:01:18,250 --> 01:01:18,418
Speaker 0: They did.

1086
01:01:18,991 --> 01:01:19,223
Speaker 0: Did they?

1087
01:01:19,514 --> 01:01:19,810
Speaker 0: They did.

1088
01:01:19,892 --> 01:01:20,427
Speaker 0: As much as you?

1089
01:01:21,651 --> 01:01:22,590
Speaker 1: Depends on what realms.

1090
01:01:22,810 --> 01:01:23,709
Speaker 0: See, here's the thing, right?

1091
01:01:23,810 --> 01:01:30,930
Speaker 0: I noticed this, this is sort of getting off topic, but I've noticed when I look at companies these days, I can sort of tell the good and the bad company.

1092
01:01:31,011 --> 01:01:31,213
Speaker 0: Right.

1093
01:01:31,516 --> 01:01:32,729
Speaker 0: Look at the company like HP.

1094
01:01:32,910 --> 01:01:33,807
Speaker 0: Who's in charge of HP?

1095
01:01:34,332 --> 01:01:35,169
Speaker 0: Just business people.

1096
01:01:35,390 --> 01:01:37,770
Speaker 0: They don't know shit about computers, technology or anything like that.

1097
01:01:37,911 --> 01:01:38,133
Speaker 0: Right.

1098
01:01:38,477 --> 01:01:39,750
Speaker 0: But look at Marriott Hotel.

1099
01:01:40,631 --> 01:01:43,950
Speaker 0: The guy just died recently, which is kind of sad because he's actually a pretty cool guy.

1100
01:01:44,530 --> 01:01:48,610
Speaker 0: The Marriott Hotel guy was like the master of hotels.

1101
01:01:48,890 --> 01:01:52,870
Speaker 0: Like dude would figure out how to fold the sheets faster and shit like that.

1102
01:01:53,111 --> 01:01:54,986
Speaker 0: You know, like he knew about hotels.

1103
01:01:56,151 --> 01:02:01,510
Speaker 0: And when you have bosses that actually know about the work that's being done, that's when the good shit happens.

1104
01:02:01,750 --> 01:02:05,810
Speaker 0: You know, Steve Jobs actually knew about computers and things.

1105
01:02:06,153 --> 01:02:07,470
Speaker 0: That's why they were successful.

1106
01:02:07,610 --> 01:02:11,750
Speaker 0: It's when the companies are run by business people who only know about monies and managing.

1107
01:02:11,770 --> 01:02:12,430
Speaker 1: But at the same time.

1108
01:02:12,670 --> 01:02:13,367
Speaker 0: When you get shit fucked up.

1109
01:02:13,570 --> 01:02:20,010
Speaker 1: You have that layer of middle management or management or executives that are pure technologists, but who don't have other skills.

1110
01:02:20,730 --> 01:02:22,230
Speaker 1: Well, obviously, well, obviously.

1111
01:02:22,350 --> 01:02:33,950
Speaker 0: But I do believe that anyone who just has normal social skills and intelligence and also, you know, the skills of whatever the job is can become the boss and they can learn to be the boss.

1112
01:02:34,311 --> 01:02:34,512
Speaker 1: Yeah.

1113
01:02:34,552 --> 01:02:37,849
Speaker 0: Couldn't if you were already a boss and that was all you could do.

1114
01:02:38,652 --> 01:02:41,370
Speaker 0: You could shit on Deborah's desk, but you couldn't know about it.

1115
01:02:41,390 --> 01:02:45,930
Speaker 1: What is one of the most common complaints about people who become senior technologists or developers?

1116
01:02:46,572 --> 01:02:49,250
Speaker 1: They get pushed toward being the boss and they don't want to be the boss.

1117
01:02:49,370 --> 01:02:50,510
Speaker 0: Well, then don't make that guy the boss.

1118
01:02:50,610 --> 01:02:58,790
Speaker 1: I'm sure there's a guy who wouldn't mind being the boss, but also I think there is a huge shortage of people who want to be the boss and are technologically skilled.

1119
01:02:59,950 --> 01:03:03,150
Speaker 0: Perhaps there's a but there's a shortage of people where technology is skilled, period.

1120
01:03:03,550 --> 01:03:04,173
Speaker 0: Yes.

1121
01:03:04,353 --> 01:03:08,450
Speaker 0: But so I'm saying that it doesn't have to be technology in a shoe factory.

1122
01:03:08,930 --> 01:03:10,409
Speaker 0: The boss should know something about shoes.

1123
01:03:10,530 --> 01:03:10,650
Speaker 0: Yeah.

1124
01:03:10,670 --> 01:03:21,630
Speaker 1: And I'm saying that in general, there's a shortage of people who know about underlying whatevers, not even just technology, who also want to be a boss and have the basic skills to be a boss.

1125
01:03:22,590 --> 01:03:22,811
Speaker 0: Yeah.

1126
01:03:22,951 --> 01:03:32,390
Speaker 0: But that doesn't mean, you know, but maybe have, you know, just keeping the current boss, whoever it may be, is better than putting in a bad boss who's only a boss and doesn't know about the thing.

1127
01:03:33,131 --> 01:03:42,150
Speaker 0: Or at the very least, right, if you're going to bring in someone who's just a boss or someone who went to business school as a manager, make them learn the thing.

1128
01:03:42,411 --> 01:03:46,430
Speaker 0: A lot of times you put that person in without even at least try.

1129
01:03:46,630 --> 01:03:51,410
Speaker 0: I mean, they're not going to become a programmer or a shoemaker or a cobbler, whatever it is that the company does.

1130
01:03:51,711 --> 01:03:52,579
Speaker 0: Maybe make towels.

1131
01:03:52,760 --> 01:03:53,849
Speaker 0: They're not going to become a weaver.

1132
01:03:54,351 --> 01:03:54,611
Speaker 0: Right.

1133
01:03:54,892 --> 01:04:00,850
Speaker 0: But at least make them learn about weaving as much as they can before making them the boss of the textile mill.

1134
01:04:01,534 --> 01:04:02,649
Speaker 0: You know, at least try.

1135
01:04:02,870 --> 01:04:02,951
Speaker 1: Yeah.

1136
01:04:02,971 --> 01:04:05,990
Speaker 0: Well, a lot of times you put these people in there who don't know about the thing.

1137
01:04:06,170 --> 01:04:09,450
Speaker 1: They went to like they got a communications degree and an MBA and now they're middle.

1138
01:04:09,550 --> 01:04:09,631
Speaker 1: Yeah.

1139
01:04:09,651 --> 01:04:10,890
Speaker 0: They're just a professional boss.

1140
01:04:10,950 --> 01:04:14,030
Speaker 0: They don't know about the thing you do and they don't care and they're not even going to try to learn it.

1141
01:04:14,110 --> 01:04:15,929
Speaker 0: They just say, get it done.

1142
01:04:16,450 --> 01:04:30,670
Speaker 1: So I guess the final moral professional advice I have, having been in all the different levels of this personally, is that you use you come up with a process that works to get whatever it is you're trying to do done.

1143
01:04:31,190 --> 01:04:46,750
Speaker 1: And the moment you start to say things like, let's implement, you know, X methodology, you know, if you can explain to another human being specifically what you think will be better after you implement it and why.

1144
01:04:47,250 --> 01:04:47,671
Speaker 1: Go for it.

1145
01:04:48,333 --> 01:04:55,330
Speaker 1: If your explanation is it'll make our process better, you're committing logical fallacies and you're not going anywhere.

1146
01:04:55,711 --> 01:04:55,852
Speaker 0: Yeah.

1147
01:04:55,912 --> 01:05:00,770
Speaker 1: And you know what about your process is going to get better and why and how it's going to make it better.

1148
01:05:01,492 --> 01:05:05,710
Speaker 0: You know, you've got to actually also get the people do it, but like aspects of scrum work really well.

1149
01:05:05,770 --> 01:05:10,870
Speaker 1: The idea of having periodic short meetings that are time constrained, where you get out.

1150
01:05:11,332 --> 01:05:11,938
Speaker 1: What did I do?

1151
01:05:12,221 --> 01:05:13,010
Speaker 1: What am I doing next?

1152
01:05:13,330 --> 01:05:14,196
Speaker 1: What is in my way?

1153
01:05:14,739 --> 01:05:16,330
Speaker 1: That concept is fantastic.

1154
01:05:16,711 --> 01:05:17,645
Speaker 0: It's an OK concept.

1155
01:05:17,686 --> 01:05:17,889
Speaker 0: Yeah.

1156
01:05:18,270 --> 01:05:22,949
Speaker 0: But maybe that, you know, you don't need to make sure everyone knows that everyone else is working on all the time.

1157
01:05:23,230 --> 01:05:26,470
Speaker 0: You're all on the same page, but it doesn't take up too much time out of the day.

1158
01:05:26,530 --> 01:05:29,130
Speaker 0: I mean, it's a common sense kind of thing, you know.

1159
01:05:29,230 --> 01:05:33,570
Speaker 0: But it's like, you know, have we done a huge study as to, you know, as opposed to what?

1160
01:05:33,991 --> 01:05:39,110
Speaker 1: Maybe you can come up with a better idea when you start worrying about who the pigs are and like actually using the jargon fully.

1161
01:05:40,231 --> 01:05:43,229
Speaker 1: Unless you can articulate how that helps you, then you shouldn't be doing it.

1162
01:05:43,773 --> 01:05:45,230
Speaker 1: Now, you might be able to articulate it.

1163
01:05:45,351 --> 01:05:47,470
Speaker 1: And, you know, those things do work in certain situations.

1164
01:05:47,591 --> 01:05:50,410
Speaker 1: But it's kind of like to talk back about skiing.

1165
01:05:51,113 --> 01:05:52,590
Speaker 1: I was looking at skis a long time ago.

1166
01:05:52,650 --> 01:05:53,655
Speaker 1: I wanted to buy some skis.

1167
01:05:53,816 --> 01:05:56,350
Speaker 1: I went to the guy and I said, what's the difference between these two skis?

1168
01:05:56,531 --> 01:05:57,529
Speaker 1: One was like double the price.

1169
01:05:57,954 --> 01:05:59,409
Speaker 1: And he was like, that one's blue.

1170
01:06:00,693 --> 01:06:02,030
Speaker 1: And I was like, no, really, what's the difference?

1171
01:06:02,110 --> 01:06:03,789
Speaker 1: And he was like, see this thing here?

1172
01:06:04,051 --> 01:06:04,495
Speaker 1: I'm like, yeah.

1173
01:06:04,516 --> 01:06:06,010
Speaker 1: He's like, it'll reduce shutter.

1174
01:06:06,374 --> 01:06:07,309
Speaker 1: And I'm like, what does that mean?

1175
01:06:07,450 --> 01:06:11,209
Speaker 1: And he said, if you can explain to me what it means, then you should buy that ski.

1176
01:06:11,630 --> 01:06:13,027
Speaker 1: Otherwise, you should buy the cheaper one.

1177
01:06:14,671 --> 01:06:15,033
Speaker 1: And you know what?

1178
01:06:15,073 --> 01:06:18,450
Speaker 1: That was the best advice I ever got for pretty much anything I've ever done.

1179
01:06:18,630 --> 01:06:19,429
Speaker 0: That guy's a bad salesman.

1180
01:06:19,450 --> 01:06:22,109
Speaker 0: He should have said the more expensive one is clearly superior.

1181
01:06:29,460 --> 01:06:31,600
Speaker 1: This has been Geek Nights with Rim and Scott.

1182
01:06:31,720 --> 01:06:36,720
Speaker 1: Special thanks to DJ Pretzel for the opening music, Cat Lee for web design and Brando K for the logos.

1183
01:06:37,120 --> 01:06:42,120
Speaker 0: Be sure to visit our website at frontrowcrew.com for show notes, discussion, news and more.

1184
01:06:42,760 --> 01:06:45,040
Speaker 1: Remember, Geek Nights is not one, but four different shows.

1185
01:06:45,320 --> 01:06:49,800
Speaker 1: Sci-Tech Mondays, Gaming Tuesdays, Anime Comic Wednesdays and Indiscriminate Thursdays.

1186
01:06:50,180 --> 01:06:53,316
Speaker 0: Geek Nights is distributed under a Creative Commons Attribution 3.0 license.

1187
01:06:54,640 --> 01:06:57,600
Speaker 0: Geek Nights is recorded live with no studio and no audience.

1188
01:06:57,860 --> 01:07:00,740
Speaker 0: But unlike those other late shows, it's actually recorded at night.

