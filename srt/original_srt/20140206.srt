1
00:00:08,940 --> 00:00:10,990
Speaker 0: It's Thursday, February 6th, 2014.

2
00:00:10,990 --> 00:00:11,332
Speaker 0: I'm Rem.

3
00:00:13,503 --> 00:00:13,795
Speaker 1: I'm Scott.

4
00:00:14,100 --> 00:00:16,839
Speaker 0: And this is Geek Nights Tonight on the Geek Nights Book Club.

5
00:00:17,461 --> 00:00:17,986
Speaker 0: I don't know.

6
00:00:18,511 --> 00:00:19,359
Speaker 0: By Gibson.

7
00:00:20,882 --> 00:00:21,400
Speaker 1: Not the guitar.

8
00:00:22,982 --> 00:00:24,019
Speaker 1: Let's do this.

9
00:00:26,384 --> 00:00:27,799
Speaker 0: I'm totally gonna hack the Gibson.

10
00:00:29,011 --> 00:00:29,239
Speaker 0: Okay.

11
00:00:31,246 --> 00:00:32,240
Speaker 1: So yeah, it's the book club.

12
00:00:32,740 --> 00:00:32,824
Speaker 1: Yeah.

13
00:00:34,020 --> 00:00:34,668
Speaker 0: It's been a while.

14
00:00:35,153 --> 00:00:35,720
Speaker 0: We've been busy.

15
00:00:36,240 --> 00:00:39,180
Speaker 1: Let's, uh, should we discuss the next book first?

16
00:00:39,220 --> 00:00:40,693
Speaker 0: Eh, we'll do a separate show talking about that.

17
00:00:40,713 --> 00:00:41,439
Speaker 0: I don't want to waste time.

18
00:00:41,660 --> 00:00:41,918
Speaker 1: Alright.

19
00:00:41,960 --> 00:00:45,580
Speaker 0: You guys are here to talk about Iduru or Idoru or Idoru.

20
00:00:45,580 --> 00:00:48,559
Speaker 1: I hope you read it because we're gonna talk a hell of a lot about it.

21
00:00:48,800 --> 00:00:53,300
Speaker 0: So guys, if you've never listened to the book club before, the point is that you've already read the book.

22
00:00:53,420 --> 00:00:54,580
Speaker 0: We're gonna assume you read it.

23
00:00:54,580 --> 00:01:01,400
Speaker 1: If you had a book club in person where you had to meet people at the library in a little room with a table and chairs, would you show up not having read the book?

24
00:01:01,704 --> 00:01:02,319
Speaker 1: No, you wouldn't.

25
00:01:02,640 --> 00:01:03,930
Speaker 0: So we're gonna assume you read it.

26
00:01:03,990 --> 00:01:05,319
Speaker 0: We're not gonna summarize the plot.

27
00:01:05,379 --> 00:01:07,379
Speaker 0: We're gonna spoil the ever-living fuck out of this book.

28
00:01:08,741 --> 00:01:12,400
Speaker 1: Uh, uh, also, we read the book and it's good, so you should read it.

29
00:01:12,620 --> 00:01:13,349
Speaker 0: Yeah, you should read it.

30
00:01:13,409 --> 00:01:14,950
Speaker 0: So if you haven't read- So that's the review.

31
00:01:14,971 --> 00:01:15,499
Speaker 1: Read this book.

32
00:01:15,720 --> 00:01:18,720
Speaker 0: If you haven't read it, read it and then come back and listen to the show.

33
00:01:19,443 --> 00:01:21,194
Speaker 1: P-positive experience reading this book.

34
00:01:21,254 --> 00:01:22,060
Speaker 1: Would read again.

35
00:01:22,581 --> 00:01:24,579
Speaker 0: A lot better than, uh, the name of the wind.

36
00:01:25,483 --> 00:01:26,454
Speaker 1: By times a zillion.

37
00:01:26,616 --> 00:01:26,920
Speaker 1: Okay.

38
00:01:28,361 --> 00:01:37,760
Speaker 1: So, uh, I just say, you know, we sometimes in the past book club episodes have or have not had news things a day, but I just so happen to have news and thing of day related to book.

39
00:01:37,882 --> 00:01:38,799
Speaker 1: So that's my new thing.

40
00:01:38,921 --> 00:01:39,203
Speaker 0: All right.

41
00:01:39,263 --> 00:01:41,580
Speaker 0: I got a news that's also related to book.

42
00:01:41,661 --> 00:01:42,639
Speaker 1: How about your thing of the day?

43
00:01:42,820 --> 00:01:44,010
Speaker 0: My thing of the day is not.

44
00:01:44,070 --> 00:01:45,159
Speaker 0: It's related to Skellington's.

45
00:01:45,380 --> 00:01:45,826
Speaker 1: Oh, you fail.

46
00:01:46,029 --> 00:01:46,820
Speaker 1: Skellington's are awesome.

47
00:01:47,122 --> 00:01:47,651
Speaker 0: Yeah, they are.

48
00:01:47,671 --> 00:01:48,179
Speaker 0: So it's okay.

49
00:01:48,460 --> 00:01:49,420
Speaker 1: So here's my news, right?

50
00:01:49,961 --> 00:01:53,060
Speaker 1: So have you ever heard of a guy named Max Martin?

51
00:01:54,340 --> 00:01:55,205
Speaker 0: Max Martin.

52
00:01:55,970 --> 00:01:57,620
Speaker 0: No, I know Miles Mayhem.

53
00:01:58,120 --> 00:01:58,699
Speaker 1: Not even close.

54
00:01:59,060 --> 00:01:59,390
Speaker 1: Max Power.

55
00:02:00,220 --> 00:02:00,301
Speaker 1: No.

56
00:02:00,764 --> 00:02:02,740
Speaker 1: So Max Martin is a dude that no one knows.

57
00:02:02,961 --> 00:02:07,480
Speaker 1: Well, not no one, but he's not a famous person that people know discography.

58
00:02:08,082 --> 00:02:08,365
Speaker 1: Yes.

59
00:02:08,848 --> 00:02:10,180
Speaker 1: So pretty much for the past.

60
00:02:10,400 --> 00:02:12,915
Speaker 0: I think I've seen this guy for the past 15 to 20 years.

61
00:02:14,121 --> 00:02:19,600
Speaker 1: This guy has basically written every almost every major hit pop song.

62
00:02:19,782 --> 00:02:20,129
Speaker 0: Wow.

63
00:02:20,170 --> 00:02:20,620
Speaker 0: You're right.

64
00:02:20,860 --> 00:02:22,217
Speaker 0: Maybe one more Oliver and he's.

65
00:02:22,541 --> 00:02:22,905
Speaker 0: Wow.

66
00:02:23,087 --> 00:02:24,380
Speaker 0: NSYNC, Backstreet Boys.

67
00:02:24,901 --> 00:02:25,203
Speaker 1: Right.

68
00:02:25,283 --> 00:02:32,820
Speaker 1: So it's like, you know, all those super popular musical groups, right, that have super hit songs that but they're not songwriters.

69
00:02:33,080 --> 00:02:37,400
Speaker 1: They're just performers, which is still, you know, people look down, tend to look down on people.

70
00:02:37,720 --> 00:02:41,160
Speaker 1: Like, I mean, there's other reasons to look down on Britney Spears or NSYNC.

71
00:02:41,501 --> 00:02:41,762
Speaker 1: Right.

72
00:02:42,064 --> 00:02:50,137
Speaker 1: But the point is, regardless of whether they can write music or have creative talent or whatever, they have a performing skill that not everyone has.

73
00:02:50,541 --> 00:02:50,882
Speaker 1: Yeah.

74
00:02:51,485 --> 00:02:54,760
Speaker 1: But you wonder where does that someone's doing the songwriting?

75
00:02:54,900 --> 00:02:55,406
Speaker 1: Who is it?

76
00:02:55,810 --> 00:02:56,579
Speaker 1: This is the guy.

77
00:02:57,062 --> 00:02:57,343
Speaker 1: Right.

78
00:02:57,704 --> 00:03:12,380
Speaker 1: So if you have some Hasune Miku type shit going on in the future, it's really the Max Martens of the world, at least until we get computers that write their own music that are going to be, you know, the real, you know, human being behind the Aideru.

79
00:03:12,820 --> 00:03:12,941
Speaker 1: Right.

80
00:03:12,961 --> 00:03:25,879
Speaker 1: So there's this huge article on Celebrity Net Worth that tells you everything you need to know about this guy who was pretty much a complete mystery to most people or still is a complete mystery to most people.

81
00:03:26,920 --> 00:03:33,196
Speaker 1: And it's pretty fascinating, like, you know, this Swedish dude's life and how he did this and why he's so good at it,

82
00:03:33,277 --> 00:03:33,619
Speaker 1: etc.,

83
00:03:33,639 --> 00:03:33,759
Speaker 1: etc.

84
00:03:34,200 --> 00:03:39,878
Speaker 1: So it's worth reading about him and perhaps even Googling him to learn more or emulating him.

85
00:03:40,401 --> 00:03:41,720
Speaker 0: That's actually pretty fascinating.

86
00:03:42,041 --> 00:03:43,440
Speaker 0: It's very relevant to what we're talking about.

87
00:03:43,681 --> 00:03:44,940
Speaker 1: It's like, no, it really was.

88
00:03:45,120 --> 00:03:48,300
Speaker 1: You think it's like anyone can write all these hit pop music.

89
00:03:48,480 --> 00:03:49,880
Speaker 1: Actually, no, only one guy can.

90
00:03:50,100 --> 00:03:50,665
Speaker 0: Well, that's the thing.

91
00:03:50,706 --> 00:03:52,119
Speaker 0: Like, look at this guy in Daft Punk.

92
00:03:52,421 --> 00:03:53,226
Speaker 0: Look at Hopsnay Miku.

93
00:03:53,266 --> 00:03:55,600
Speaker 0: Like, right now, the character is an idol.

94
00:03:55,921 --> 00:04:04,140
Speaker 0: Like, she exists in that sense, but she does not have her own agency or is creating works on her own.

95
00:04:04,260 --> 00:04:07,339
Speaker 0: There are still humans filling that character with stuff.

96
00:04:08,580 --> 00:04:13,720
Speaker 0: Eventually, humans will seed AIs that make that stuff and all these Sharon Apple things are going to happen.

97
00:04:14,585 --> 00:04:14,727
Speaker 1: Yep.

98
00:04:14,747 --> 00:04:15,920
Speaker 1: So, yeah, here's the line.

99
00:04:15,960 --> 00:04:17,057
Speaker 1: Here's the line I was looking for.

100
00:04:17,660 --> 00:04:18,345
Speaker 1: "Max Martin.

101
00:04:18,587 --> 00:04:24,972
Speaker 1: He's personally responsible for churning out more Billboard singles than Michael Jackson and Madonna

102
00:04:25,153 --> 00:04:26,017
Speaker 1: combined.".

103
00:04:30,202 --> 00:04:34,600
Speaker 0: So, my news is related only in the cyberpunk sense.

104
00:04:35,261 --> 00:04:47,100
Speaker 0: So, for those of you who haven't been following Google Glass, Google finally announced they've sold real frames, just titanium frames that'll hold prescription lenses that just connect to Google Glass and they're official.

105
00:04:47,702 --> 00:04:52,560
Speaker 0: What's funny is that they sold out of those frames immediately.

106
00:04:53,081 --> 00:04:53,399
Speaker 0: Of course.

107
00:04:53,580 --> 00:05:05,200
Speaker 0: I think they vastly underestimated the number of people with bad eyes who simultaneously bought Glass and are explorers, even though there was no way for them to use them with glasses.

108
00:05:06,080 --> 00:05:11,380
Speaker 1: You think maybe they could have just, like, you know, pretty much everyone who got Glass got it through this Glass experience.

109
00:05:12,100 --> 00:05:14,823
Speaker 1: You think they could have just been like, you know, "How's your

110
00:05:14,924 --> 00:05:15,427
Speaker 1: eyesight?"

111
00:05:15,588 --> 00:05:16,734
Speaker 1: and just, you know, counted them.

112
00:05:17,902 --> 00:05:22,659
Speaker 0: We would have lied, though, because I think everyone would have been afraid, like, if I have bad vision, they might not accept me.

113
00:05:23,020 --> 00:05:23,359
Speaker 1: Unlikely.

114
00:05:23,801 --> 00:05:25,900
Speaker 0: I don't know, because they didn't have a decision game.

115
00:05:26,642 --> 00:05:27,046
Speaker 0: I would have.

116
00:05:28,035 --> 00:05:28,580
Speaker 0: I would have lied.

117
00:05:29,062 --> 00:05:30,136
Speaker 1: You would have said, "Yeah, my eyesight's

118
00:05:30,177 --> 00:05:30,359
Speaker 1: great.".

119
00:05:30,501 --> 00:05:33,299
Speaker 0: Yes, I would have shown up to pick them up without my glasses on.

120
00:05:33,960 --> 00:05:35,379
Speaker 1: But you showed up with glasses on.

121
00:05:35,780 --> 00:05:40,839
Speaker 0: Yes, and the guy was like, he looks at me, and he kind of frowns and says, "Ah, do you need those to

122
00:05:40,879 --> 00:05:41,020
Speaker 0: see?".

123
00:05:41,121 --> 00:05:41,732
Speaker 0: And I was like, "Yep,".

124
00:05:41,752 --> 00:05:44,835
Speaker 0: and he's like, "You sure you want

125
00:05:44,876 --> 00:05:45,180
Speaker 0: Glass?"

126
00:05:45,960 --> 00:05:46,100
Speaker 0: Really?

127
00:05:46,100 --> 00:05:47,219
Speaker 1: Oh, he wanted to refund you?

128
00:05:47,681 --> 00:05:50,580
Speaker 0: Yeah, he wanted to talk me out of having Glass.

129
00:05:50,905 --> 00:05:51,139
Speaker 0: Okay.

130
00:05:51,380 --> 00:05:52,637
Speaker 0: And I was like, "I'm just going to hack something

131
00:05:52,657 --> 00:05:52,900
Speaker 0: together.".

132
00:05:52,900 --> 00:05:55,318
Speaker 0: And he's like, "Well, don't take it apart, because terms of

133
00:05:55,358 --> 00:05:55,620
Speaker 0: service.".

134
00:05:55,620 --> 00:05:58,356
Speaker 0: And I was like, "Okay, I won't violate your terms of

135
00:05:58,377 --> 00:05:58,699
Speaker 0: service.".

136
00:05:59,061 --> 00:06:00,896
Speaker 0: And I winked at him, and he looked at me like,

137
00:06:00,916 --> 00:06:00,956
Speaker 0: "Ah.".

138
00:06:01,603 --> 00:06:02,479
Speaker 0: And then he sat me down.

139
00:06:02,900 --> 00:06:04,817
Speaker 0: Of course, then he was like, "Okay, log in to your Google

140
00:06:04,837 --> 00:06:05,099
Speaker 0: account.".

141
00:06:05,441 --> 00:06:09,430
Speaker 0: So I go to mail.frontrowcrew.com, he's like, "Ah, Google

142
00:06:09,471 --> 00:06:10,016
Speaker 0: domains?".

143
00:06:11,946 --> 00:06:12,976
Speaker 0: I was like, "Bad in a

144
00:06:13,016 --> 00:06:13,400
Speaker 0: thousand.".

145
00:06:15,041 --> 00:06:17,720
Speaker 0: So yeah, Google now has legit frames.

146
00:06:18,180 --> 00:06:18,576
Speaker 0: I bought them.

147
00:06:18,880 --> 00:06:21,640
Speaker 0: I found an optician who's willing to do the thing for me.

148
00:06:23,141 --> 00:06:24,240
Speaker 0: So they're almost sold out.

149
00:06:24,641 --> 00:06:31,580
Speaker 0: I was able to get the last frame, like literally the last one, in one type, because after I bought it, it said sold out.

150
00:06:31,740 --> 00:06:33,879
Speaker 1: It said stock one, and when you went back, it reloaded.

151
00:06:34,120 --> 00:06:37,140
Speaker 0: Well, it said in stock, and after I bought it, it said out of stock.

152
00:06:37,280 --> 00:06:39,860
Speaker 1: So someone else might have gotten the last one while you were checking out.

153
00:06:40,063 --> 00:06:41,180
Speaker 0: I'm sorry I got the last one.

154
00:06:41,660 --> 00:06:43,060
Speaker 0: I can't imagine there's that much contention.

155
00:06:43,140 --> 00:06:44,660
Speaker 1: You just gotta imagine that you're special.

156
00:06:44,900 --> 00:06:50,160
Speaker 0: But I got the wrong color, which is fine, because the color's only on the inside, and my color was sold out in every type.

157
00:06:50,500 --> 00:06:53,260
Speaker 0: There's one type that's not sold out, because it's the ugly one.

158
00:06:54,040 --> 00:06:55,920
Speaker 0: You can get the ugly one right now if you want.

159
00:06:55,980 --> 00:06:56,859
Speaker 0: You can't get any other ones.

160
00:06:57,164 --> 00:06:57,260
Speaker 0: Okay.

161
00:06:58,024 --> 00:06:59,019
Speaker 1: You get the ugly one and paint it.

162
00:06:59,883 --> 00:07:01,100
Speaker 0: No, no, the shape is ugly.

163
00:07:01,240 --> 00:07:01,282
Speaker 0: Oh.

164
00:07:01,780 --> 00:07:03,140
Speaker 0: The shape is pretty bad.

165
00:07:03,321 --> 00:07:03,579
Speaker 1: Okay.

166
00:07:04,445 --> 00:07:05,479
Speaker 1: You can twist it with the pliers.

167
00:07:06,083 --> 00:07:16,080
Speaker 0: Now, I'm basically able to finally do what I've been wanting to do with glass the whole time, is not have to wear this ridiculous hack, and literally wear glass all the goddamn time.

168
00:07:16,461 --> 00:07:18,800
Speaker 0: I've been wearing it about 60% of the time lately.

169
00:07:19,101 --> 00:07:23,340
Speaker 0: I just don't wear it all the time, mostly because- Well, I take it off when I'm home, usually.

170
00:07:24,080 --> 00:07:25,660
Speaker 1: There's two reasons I don't wear it all the time.

171
00:07:25,920 --> 00:07:45,180
Speaker 1: Reason number one is that the Pebble Watch sort of is redundant with Google Glass in a lot of ways, but the Pebble Watch actually, if you count only the functionality, and not the fact that the Pebble Watch is not on your face all the time, giving it whatever, the Pebble Watch shows me every notification from my phone, period.

172
00:07:45,501 --> 00:07:46,118
Speaker 1: Every one of them.

173
00:07:46,380 --> 00:07:48,600
Speaker 0: Which is not what I want, but this isn't the show to talk about that.

174
00:07:48,660 --> 00:07:49,799
Speaker 1: Right, but Google Glass does not.

175
00:07:51,101 --> 00:07:54,179
Speaker 1: Pebble Watch also gives me all the notifications that Google Glass does.

176
00:07:55,122 --> 00:07:57,918
Speaker 1: If I have both, it's sort of like, "Bzz, bzz," and it's like, "I don't need

177
00:07:57,938 --> 00:07:58,099
Speaker 1: that."

178
00:07:58,366 --> 00:07:58,619
Speaker 1: Right?

179
00:07:59,643 --> 00:08:01,439
Speaker 1: The weather's not so good right now.

180
00:08:01,742 --> 00:08:03,800
Speaker 1: I worry about the rain and snow getting on.

181
00:08:03,800 --> 00:08:06,379
Speaker 0: That's part of the reason why I'm not wearing them every day now.

182
00:08:06,960 --> 00:08:09,260
Speaker 1: Also, the amount of time during the day that I would wear them.

183
00:08:09,400 --> 00:08:15,451
Speaker 1: If it's a day where I wake up, go to work, and come home, I'd be wearing glass for, what, an hour in the subway?

184
00:08:16,080 --> 00:08:17,060
Speaker 0: See, now, that's the difference.

185
00:08:17,260 --> 00:08:21,600
Speaker 0: This is why I think people who already wear glasses are at an advantage in the beginning.

186
00:08:22,040 --> 00:08:28,380
Speaker 0: I have to wear glasses anyway, so wearing glass instead of just glasses is no difference.

187
00:08:28,721 --> 00:08:29,500
Speaker 1: Might as well.

188
00:08:29,500 --> 00:08:31,940
Speaker 1: Wearing it when I'm at my desk in front of a computer is pointless.

189
00:08:32,220 --> 00:08:33,960
Speaker 0: See, I wear it when I'm at it in front of my computer.

190
00:08:34,120 --> 00:08:34,619
Speaker 1: What's the point?

191
00:08:34,880 --> 00:08:36,120
Speaker 0: Well, one, because why take it off?

192
00:08:36,220 --> 00:08:39,240
Speaker 0: It's the same as wearing glasses, so I just have this ability.

193
00:08:39,360 --> 00:08:42,580
Speaker 1: But all its functionality is redundant with the computer that is in front of me.

194
00:08:42,841 --> 00:08:44,179
Speaker 0: No, because it gives me notifications.

195
00:08:44,361 --> 00:08:46,480
Speaker 0: I don't just compulsively check all my shit.

196
00:08:47,481 --> 00:08:49,260
Speaker 1: I check all my shit so rapidly.

197
00:08:49,722 --> 00:08:51,860
Speaker 1: I can check all my shit multiple times a second.

198
00:08:51,880 --> 00:08:53,180
Speaker 0: Yes, and I don't do that.

199
00:08:53,342 --> 00:08:53,958
Speaker 0: I do work.

200
00:08:56,443 --> 00:08:58,080
Speaker 1: You realize I do work as well.

201
00:08:58,202 --> 00:08:58,998
Speaker 0: I know, I know.

202
00:08:59,080 --> 00:09:00,295
Speaker 1: I get the work done so fast.

203
00:09:00,821 --> 00:09:01,679
Speaker 0: It's mostly that I get up.

204
00:09:02,521 --> 00:09:02,958
Speaker 0: So I get up.

205
00:09:03,120 --> 00:09:03,979
Speaker 0: I walk around a lot.

206
00:09:04,140 --> 00:09:04,880
Speaker 0: I'm working on things.

207
00:09:05,060 --> 00:09:16,380
Speaker 1: I can reload Gmail like 10 times and read it all, all the subjects of all the emails and do work fast by the time the notification comes in the glass.

208
00:09:16,440 --> 00:09:25,120
Speaker 0: When I'm doing some work, I'll be doing work or whatever, and what glass does is while I'm sitting there at the desk, it'll pop up like any notification that matters.

209
00:09:25,580 --> 00:09:28,240
Speaker 0: It shows me only things that I would actually care about seeing live.

210
00:09:29,500 --> 00:09:30,300
Speaker 0: It doesn't show me any other shit.

211
00:09:30,300 --> 00:09:31,220
Speaker 1: I care about everything.

212
00:09:31,500 --> 00:09:32,140
Speaker 0: It doesn't show me tweets.

213
00:09:32,521 --> 00:09:33,159
Speaker 1: I can absorb.

214
00:09:33,745 --> 00:09:34,559
Speaker 0: Anyway, I digress.

215
00:09:34,800 --> 00:09:42,859
Speaker 0: My point is I will finally be able to take a step toward my gargoyle cyberpunk future because I'll be able to wear glass pretty much all the time now.

216
00:09:43,640 --> 00:09:49,378
Speaker 0: Now with my hack, the lenses I'm using are not designed to be exposed to stuff.

217
00:09:50,140 --> 00:09:53,440
Speaker 0: They're supposed to be inside of a shield because I wear them skiing.

218
00:09:54,662 --> 00:10:01,880
Speaker 0: As a result, they're not scratch resistant at all, so I have to treat these things with kid fucking gloves because they're supposed to be protected by a shield.

219
00:10:02,161 --> 00:10:03,079
Speaker 0: I'm wearing them naked and raw.

220
00:10:03,120 --> 00:10:03,720
Speaker 0: I protect the shield.

221
00:10:10,291 --> 00:10:13,050
Speaker 0: Things of the day, mine is in no way related to this book.

222
00:10:13,170 --> 00:10:13,910
Speaker 0: I just think it's awesome.

223
00:10:14,611 --> 00:10:18,310
Speaker 0: Have you ever heard of a famous picture called Student's Dream?

224
00:10:19,234 --> 00:10:19,424
Speaker 1: No.

225
00:10:19,830 --> 00:10:25,310
Speaker 1: I have no idea what you're talking about, except actually I do because you showed me the thing before the episode, but before then, I had no clue what you're talking about.

226
00:10:25,350 --> 00:10:39,349
Speaker 0: Student's Dream is a picture of someone laying on what looks like an old timey dissection table, and there's a bunch of real corpses just sort of hanging out around him, and it's super creepy looking.

227
00:10:40,130 --> 00:10:41,029
Speaker 0: Kind of a famous photo.

228
00:10:41,530 --> 00:10:48,930
Speaker 0: My thing of the day is a selection of photographs from the Burns archive of dissection photos, which sounds gross, but here's the deal.

229
00:10:48,970 --> 00:10:49,909
Speaker 0: This is why this is cool.

230
00:10:50,612 --> 00:10:59,949
Speaker 0: In the 1800s, in the early 1900s, there was sort of this rite of passage if you were going to be a doctor or a physician when you did your first dissection of a cadaver.

231
00:11:01,090 --> 00:11:06,330
Speaker 0: So students would take pictures of themselves, basically selfies with corpses.

232
00:11:06,873 --> 00:11:08,649
Speaker 0: That was like the thing that doctors did.

233
00:11:09,150 --> 00:11:16,290
Speaker 0: So these are all pictures of what looked like nerdy RIT students just like taking a selfie next to a ridiculously rotted corpse.

234
00:11:17,633 --> 00:11:17,727
Speaker 0: Okay.

235
00:11:17,911 --> 00:11:25,529
Speaker 0: Some of these corpses were probably stolen because dissection was not actually legal in a lot of places, even though it was actually pretty necessary for medical science.

236
00:11:26,831 --> 00:11:33,410
Speaker 0: So grave robbing was the thing to let doctors practice, and these pictures are kind of awesome and kind of disturbing.

237
00:11:34,532 --> 00:11:34,668
Speaker 1: Okay.

238
00:11:35,331 --> 00:11:36,729
Speaker 0: Also, I like the ones with the Skellingtons.

239
00:11:37,430 --> 00:11:40,270
Speaker 0: Like this guy just posed the skeleton wearing a top hat like hanging out with him.

240
00:11:40,611 --> 00:11:41,630
Speaker 1: Oh, those are the best pictures.

241
00:11:42,291 --> 00:11:43,830
Speaker 0: But these are real human skeletons.

242
00:11:44,210 --> 00:11:44,421
Speaker 0: Yeah.

243
00:11:45,355 --> 00:11:45,889
Speaker 1: I need one of those.

244
00:11:45,950 --> 00:11:46,350
Speaker 1: No, I don't.

245
00:11:47,352 --> 00:11:50,070
Speaker 0: I kind of want a contemplating skull.

246
00:11:51,232 --> 00:11:53,690
Speaker 0: Like a human skull, a real one, just to put on the end table.

247
00:11:53,870 --> 00:11:55,130
Speaker 0: So whenever I want to be contemplative.

248
00:11:55,250 --> 00:11:56,509
Speaker 1: How do you know who you belong to?

249
00:11:56,631 --> 00:11:57,048
Speaker 1: Don't care.

250
00:11:57,331 --> 00:11:57,807
Speaker 1: You don't care?

251
00:11:58,050 --> 00:11:59,410
Speaker 0: Because it's an empty shell now.

252
00:11:59,730 --> 00:12:00,590
Speaker 0: The human's gone.

253
00:12:01,150 --> 00:12:02,190
Speaker 1: What if it was someone you knew?

254
00:12:02,551 --> 00:12:03,909
Speaker 0: Alas ratio, I knew him.

255
00:12:04,090 --> 00:12:05,048
Speaker 1: What if it was someone you knew?

256
00:12:05,875 --> 00:12:06,610
Speaker 0: Well, I did know him.

257
00:12:06,650 --> 00:12:07,023
Speaker 0: He was the clown.

258
00:12:10,039 --> 00:12:10,250
Speaker 1: Okay.

259
00:12:10,995 --> 00:12:13,070
Speaker 0: So speaking of- Do not mail me a skull.

260
00:12:14,634 --> 00:12:15,490
Speaker 0: Just making that clear.

261
00:12:16,151 --> 00:12:19,170
Speaker 1: Speaking of Iduru, I have Iduru related thing of the day.

262
00:12:19,250 --> 00:12:20,170
Speaker 1: Here's some real idols.

263
00:12:20,450 --> 00:12:23,370
Speaker 1: I don't know if I've talked about crayon pop on the show before.

264
00:12:23,992 --> 00:12:26,010
Speaker 1: I tortured rim with them, at least shortly.

265
00:12:26,893 --> 00:12:28,710
Speaker 0: It's hard to say torture because I kind of enjoy this.

266
00:12:29,130 --> 00:12:30,710
Speaker 1: So the deal with crayon pop, right?

267
00:12:30,810 --> 00:12:34,470
Speaker 1: Is they're just another K-pop group, at least nominally, right?

268
00:12:34,650 --> 00:12:36,870
Speaker 1: You know, five pretty girls, whatever.

269
00:12:37,054 --> 00:12:37,770
Speaker 1: They're in their twenties.

270
00:12:38,150 --> 00:12:41,150
Speaker 1: They sing and dance catchy songs, just like all the other ones, right?

271
00:12:41,592 --> 00:12:51,250
Speaker 1: What sets them apart from the other K-pop groups is number one, if you look at the girl's generation, they were created by a giant company with tons of money, ultra professional.

272
00:12:51,890 --> 00:12:59,389
Speaker 1: This is basically like if we started an idol company and found some girls and tried to make a K-pop group, that's what crayon pop is.

273
00:12:59,710 --> 00:13:06,270
Speaker 1: They basically walked around the street and performed on the sidewalk, which we would do in New York until they got popular.

274
00:13:06,711 --> 00:13:09,689
Speaker 1: And they just kept trying song after song until they finally let them on TV.

275
00:13:09,790 --> 00:13:10,529
Speaker 1: Right.

276
00:13:12,114 --> 00:13:18,490
Speaker 1: But they finally got super popular when they did this one song, and they had this trademark of wearing helmets when they do this jumping song.

277
00:13:18,710 --> 00:13:20,101
Speaker 0: Scott shows me these videos and I'm like, "So what?

278
00:13:20,161 --> 00:13:20,706
Speaker 0: Hats are their

279
00:13:20,746 --> 00:13:20,968
Speaker 0: thing?".

280
00:13:21,356 --> 00:13:21,570
Speaker 1: Right.

281
00:13:21,690 --> 00:13:30,449
Speaker 1: And that sort of sets them apart from all the other K-pop groups because they wear like tracksuits and helmets as opposed to wearing like, you know, being sexy, revealing or anything like that.

282
00:13:30,530 --> 00:13:33,069
Speaker 0: You know, I know another song that was related to hats.

283
00:13:33,870 --> 00:13:34,489
Speaker 0: Hattari Dean.

284
00:13:35,438 --> 00:13:35,950
Speaker 1: It is, right?

285
00:13:36,530 --> 00:13:47,350
Speaker 1: So anyway, there's a funny video here that someone made, is they took just a performance that they did on TV of a different song, and they put subtitles on it, but the subtitles are not the right subtitles.

286
00:13:48,033 --> 00:13:49,249
Speaker 0: Oh, that genre.

287
00:13:49,650 --> 00:13:52,850
Speaker 1: That genre, where you just make up subtitles that say something else.

288
00:13:52,911 --> 00:13:53,850
Speaker 1: It's not what they're actually saying.

289
00:13:53,890 --> 00:13:57,110
Speaker 1: And the subtitles are basically like, "We're not wearing the helmets again.

290
00:13:57,330 --> 00:13:57,735
Speaker 1: Fuck you.

291
00:13:57,796 --> 00:13:58,221
Speaker 1: They're really

292
00:13:58,322 --> 00:13:58,869
Speaker 1: uncomfortable.".

293
00:14:00,652 --> 00:14:07,609
Speaker 1: So it's, you know, I think you sort of will only get the joke if you watch some of their other stuff and like understand where they came from.

294
00:14:09,254 --> 00:14:15,810
Speaker 1: But yeah, this shows that even in a world of virtual idols, you know, there is still merit in, I guess, the physical idol in some way.

295
00:14:16,371 --> 00:14:28,890
Speaker 1: And even the physical idol is still remixed and re-manifested by, you know, the, I guess, it's not the consumer, but you know, the watchers and not just the, right?

296
00:14:29,150 --> 00:14:36,290
Speaker 1: It's participatory, whether it's "Hasune Miku" or whether it's, you know, the traditional old way of doing things with real people singing and dancing.

297
00:14:36,370 --> 00:14:37,034
Speaker 0: Participatory.

298
00:14:37,075 --> 00:14:39,470
Speaker 0: There's a lot to say about that with, I don't know.

299
00:14:39,550 --> 00:14:43,250
Speaker 1: They're actually, "Crayon Pop" is actually sort of extra participatory.

300
00:14:43,490 --> 00:14:48,909
Speaker 1: Like, they get closer to their fans, like physically speaking, than other groups do.

301
00:14:49,590 --> 00:14:54,310
Speaker 1: Like, you'll see them, it's like they actually, at least seem to actually want to go meet their fans.

302
00:14:54,630 --> 00:15:00,310
Speaker 1: And like, you'll see when they're like dancing on the street, they'll let fans carry the boombox for them and stuff like that.

303
00:15:00,772 --> 00:15:01,443
Speaker 1: And it's kind of weird.

304
00:15:01,646 --> 00:15:01,870
Speaker 1: Anyway.

305
00:15:02,710 --> 00:15:04,116
Speaker 0: So, metamoment very briefly.

306
00:15:04,137 --> 00:15:07,130
Speaker 0: The next book club book will be "Wool" by Hugh Howie.

307
00:15:07,610 --> 00:15:08,108
Speaker 0: Because I've gotten...

308
00:15:08,292 --> 00:15:09,330
Speaker 1: You have like ten copies, right?

309
00:15:10,052 --> 00:15:11,230
Speaker 0: People kept giving me copies of this book.

310
00:15:11,230 --> 00:15:12,049
Speaker 1: Alright, so give me one of them.

311
00:15:12,550 --> 00:15:12,910
Speaker 1: Unrelatedly.

312
00:15:13,316 --> 00:15:13,990
Speaker 1: Or do I have one?

313
00:15:14,211 --> 00:15:14,917
Speaker 0: I'm gonna kindle it.

314
00:15:14,938 --> 00:15:16,250
Speaker 0: I don't carry books anymore.

315
00:15:16,650 --> 00:15:16,932
Speaker 1: Okay.

316
00:15:16,952 --> 00:15:19,709
Speaker 1: I'm not paying for the book that we have five free copies of.

317
00:15:20,030 --> 00:15:21,480
Speaker 0: Well, you can take one of these books then.

318
00:15:21,661 --> 00:15:22,910
Speaker 0: One of them is signed by the author.

319
00:15:23,451 --> 00:15:23,868
Speaker 0: So, I don't know.

320
00:15:24,290 --> 00:15:25,841
Speaker 0: I'm not sure who gave me that one.

321
00:15:25,921 --> 00:15:27,089
Speaker 0: If you did, thanks I guess.

322
00:15:27,431 --> 00:15:27,728
Speaker 1: Whatev.

323
00:15:28,372 --> 00:15:28,955
Speaker 0: So, we'll read it.

324
00:15:29,438 --> 00:15:31,190
Speaker 0: A lot of people speak highly about this book.

325
00:15:31,311 --> 00:15:33,570
Speaker 1: A lot of people speak highly about a lot of books.

326
00:15:33,770 --> 00:15:37,130
Speaker 0: A lot of people spoke really highly about the Kingkiller Chronicle in the name of the wind.

327
00:15:37,450 --> 00:15:37,691
Speaker 1: Sure.

328
00:15:37,891 --> 00:15:46,470
Speaker 1: Actually, I found out about that book because one of the Penny Arcade paper editions, the introduction was written by Rothfuss.

329
00:15:46,830 --> 00:15:46,916
Speaker 0: Yeah.

330
00:15:47,411 --> 00:15:47,633
Speaker 0: Yeah.

331
00:15:47,734 --> 00:15:49,170
Speaker 1: That's how I found out about that.

332
00:15:49,310 --> 00:15:52,149
Speaker 1: But, I mean, a lot of people recommend that "Ready Player One".

333
00:15:52,758 --> 00:15:53,408
Speaker 1: I read that.

334
00:15:55,131 --> 00:15:59,430
Speaker 1: I mean, it hits on all this nostalgia stuff, but it's basically the "Woo" game, the book.

335
00:15:59,651 --> 00:16:04,370
Speaker 0: Guys, read "The Prince of Nothing" and then come back to us and tell me your book is good.

336
00:16:07,110 --> 00:16:07,587
Speaker 1: Okay, so.

337
00:16:08,554 --> 00:16:08,922
Speaker 0: I don't know.

338
00:16:09,691 --> 00:16:11,230
Speaker 1: So, we're skipping all meta moments, I guess?

339
00:16:11,330 --> 00:16:12,610
Speaker 0: Yeah, videos, whatever.

340
00:16:13,090 --> 00:16:13,788
Speaker 1: Find us on the internet.

341
00:16:14,555 --> 00:16:15,529
Speaker 0: Read the other book club books.

342
00:16:16,210 --> 00:16:17,370
Speaker 0: Read the other book club books.

343
00:16:17,450 --> 00:16:17,894
Speaker 1: That's right.

344
00:16:17,934 --> 00:16:19,710
Speaker 1: There's a bunch of old book club episodes.

345
00:16:20,190 --> 00:16:30,968
Speaker 0: I read a study a week ago, two weeks ago, saying that literacy is at its level, but adults in America are reading fewer books than in, like, the last 50 years.

346
00:16:32,314 --> 00:16:33,550
Speaker 0: No one's reading books anymore.

347
00:16:33,730 --> 00:16:34,070
Speaker 0: That's right.

348
00:16:34,170 --> 00:16:34,815
Speaker 0: So, read books.

349
00:16:35,218 --> 00:16:36,690
Speaker 0: You'll be smarter than all your friends.

350
00:16:37,150 --> 00:16:41,309
Speaker 0: Then you'll start to hate your friends and they'll start to resent you, and then you'll find smarter friends.

351
00:16:41,533 --> 00:16:41,969
Speaker 1: Like us.

352
00:16:42,171 --> 00:16:43,009
Speaker 0: That's how that goes.

353
00:16:43,150 --> 00:16:43,766
Speaker 1: That's how it goes.

354
00:16:44,810 --> 00:16:48,847
Speaker 0: If I had to say one thing about Adoro, it's that it is so '90s.

355
00:16:49,751 --> 00:16:50,421
Speaker 1: It is the most '90s.

356
00:16:51,030 --> 00:16:51,984
Speaker 0: It is like, take the year.

357
00:16:52,711 --> 00:16:57,410
Speaker 1: I mean, all the cyberpunk, major cyberpunk works tend to be from the '90s, right?

358
00:16:57,450 --> 00:16:58,723
Speaker 1: The snow crashes in the early '90s.

359
00:17:00,511 --> 00:17:01,823
Speaker 1: Adoro's from the later '90s, right?

360
00:17:02,710 --> 00:17:08,810
Speaker 1: But it's like, all that shit is '90s because at that time period, it's like we had internet.

361
00:17:08,990 --> 00:17:09,824
Speaker 1: It existed, right?

362
00:17:10,230 --> 00:17:13,008
Speaker 1: We had computers, but they were so immature.

363
00:17:14,191 --> 00:17:19,849
Speaker 1: It was so early in the technology that the true future of it was mostly imaginings, right?

364
00:17:19,971 --> 00:17:25,368
Speaker 1: So you're able to, as an author, you could imagine the future of computing like, "Whoa, cyberspace, amazing," right?

365
00:17:25,651 --> 00:17:31,269
Speaker 1: And you can even see that in the lowbrow medias like Superhuman Samurai Cybersquad or VR Troopers.

366
00:17:32,231 --> 00:17:42,170
Speaker 0: Now, also remember, in this era, people used this technology, but MMORPGs, cyberspace, MUDs and MUCs, those existed.

367
00:17:42,610 --> 00:17:44,630
Speaker 0: Cyberspace existed at that time.

368
00:17:44,712 --> 00:17:45,026
Speaker 1: Barely.

369
00:17:45,390 --> 00:17:47,389
Speaker 0: But it did exist, and there were people who were involved in it.

370
00:17:47,811 --> 00:18:00,630
Speaker 0: But because those spaces were so prevalent and VR was big at the time, there was definitely this idea that cyberspace is all about hidden identities, virtual identities.

371
00:18:00,990 --> 00:18:07,650
Speaker 0: Your life in the web or the net or whatever they call it is radically different from your real person.

372
00:18:07,870 --> 00:18:08,663
Speaker 1: Goes in the shells in the '90s.

373
00:18:09,371 --> 00:18:09,591
Speaker 0: Yep.

374
00:18:10,072 --> 00:18:17,950
Speaker 0: But that was such a common, deep, unavoidable theme of all cyberpunk, of all tech writing.

375
00:18:18,270 --> 00:18:27,838
Speaker 0: Everything in the pop culture around the internet was about avatars and personas and shared spaces and cyberspaces, which really kind of died.

376
00:18:27,878 --> 00:18:31,050
Speaker 0: That whole idea is not part of the internet consciousness anymore.

377
00:18:31,210 --> 00:18:31,351
Speaker 1: Right.

378
00:18:31,371 --> 00:18:42,730
Speaker 1: Well, what happened is people took the technology that was available and so early and then extrapolated what could it be like and what they wanted it to be like, right?

379
00:18:43,351 --> 00:18:45,441
Speaker 1: And took that out into the future.

380
00:18:45,461 --> 00:18:47,029
Speaker 1: and what would happen if things, right?

381
00:18:47,571 --> 00:18:55,067
Speaker 1: And now it's developed since then and now we see the reality and the limits of technology and we're like, "Oh, this is what it actually

382
00:18:55,249 --> 00:18:55,309
Speaker 1: is.".

383
00:18:55,410 --> 00:19:00,029
Speaker 0: But at the same time, we have a lot more capabilities than were imagined even then.

384
00:19:00,350 --> 00:19:00,653
Speaker 0: Sure.

385
00:19:00,693 --> 00:19:02,950
Speaker 1: They just weren't the ones that we thought of necessarily.

386
00:19:03,250 --> 00:19:05,110
Speaker 1: Some of them are the ones we thought of and some of them aren't.

387
00:19:05,110 --> 00:19:09,110
Speaker 0: I guess what's interesting is that the ones that we thought of in the '90s are eminently possible.

388
00:19:09,270 --> 00:19:10,223
Speaker 0: It's just no one gives a shit.

389
00:19:10,527 --> 00:19:10,750
Speaker 1: Sure.

390
00:19:11,812 --> 00:19:17,790
Speaker 0: The whole idea of the shared spaces, the avatars, meet with someone in a really hyper-realistic...

391
00:19:17,850 --> 00:19:22,856
Speaker 1: Well, because the way it was imagined was that you'd jack in with goggles on your head and you'd actually see.

392
00:19:22,977 --> 00:19:25,110
Speaker 1: it would be like you're actually there for reals.

393
00:19:25,631 --> 00:19:25,893
Speaker 1: Yeah.

394
00:19:25,933 --> 00:19:29,870
Speaker 1: And you wouldn't... But actually, no, that's not how it is because that technology has not advanced that far.

395
00:19:29,970 --> 00:19:34,150
Speaker 0: So let's see what happens because that technology is coming in the next decade in a big way.

396
00:19:34,753 --> 00:19:35,235
Speaker 1: I hope so.

397
00:19:35,396 --> 00:19:35,637
Speaker 0: It is.

398
00:19:35,657 --> 00:19:38,310
Speaker 0: I mean, Oculus Rift is not a lot, but you know what?

399
00:19:38,910 --> 00:19:44,130
Speaker 0: It's the equivalent of Google Glass in the sense that it's the first consumer-level usable thing like that.

400
00:19:44,270 --> 00:19:44,553
Speaker 1: Maybe.

401
00:19:45,038 --> 00:19:46,370
Speaker 0: That stuff's coming.

402
00:19:46,930 --> 00:19:56,048
Speaker 0: But simultaneously, it's not just what we imagined the future to be based on the internet, but all these cyberpunk works are very dystopian, and they're dystopian in such a '90s way.

403
00:19:56,910 --> 00:20:02,890
Speaker 0: The example I always use, my go-to example, is the movie Strange Days, set in 1999.

404
00:20:02,890 --> 00:20:05,218
Speaker 0: It's actually very similar to the world of Aydaru.

405
00:20:06,182 --> 00:20:08,630
Speaker 0: And the dystopias are always the same.

406
00:20:09,550 --> 00:20:11,738
Speaker 0: Geopolitics kind of remains static.

407
00:20:11,778 --> 00:20:20,090
Speaker 0: Like, Russia is still this sort of Soviet thing, which it's really not anymore, but I qualify that because it's kind of going back in that direction lately.

408
00:20:21,190 --> 00:20:25,210
Speaker 0: Like, China is still this like outsourced hellhole in a lot of these dystopias.

409
00:20:25,830 --> 00:20:30,090
Speaker 0: Racial tensions are a big deal in a lot of '90s cyberpunk.

410
00:20:31,014 --> 00:20:33,965
Speaker 0: I mean, because remember, that was a big deal in '90s society.

411
00:20:34,005 --> 00:20:34,588
Speaker 0: There were riots.

412
00:20:35,890 --> 00:20:37,981
Speaker 0: Racial tensions were in the media in a big way.

413
00:20:38,082 --> 00:20:39,590
Speaker 0: Urban crime was still a problem.

414
00:20:39,690 --> 00:20:41,201
Speaker 1: In Snow Crash, they made a big deal.

415
00:20:41,241 --> 00:20:42,309
Speaker 1: Raven was a black guy.

416
00:20:43,251 --> 00:20:44,194
Speaker 1: Yep.

417
00:20:44,254 --> 00:20:49,070
Speaker 0: These cyberpunk dystopias always focused on cities become full of gangbangers.

418
00:20:49,090 --> 00:20:50,120
Speaker 1: He was the Native American guy, I forget.

419
00:20:50,140 --> 00:20:51,130
Speaker 1: It doesn't matter.

420
00:20:51,270 --> 00:20:56,509
Speaker 1: Either way, specifically he was the guy who was not the white guy or the Asian guy.

421
00:20:56,991 --> 00:21:03,862
Speaker 0: Cities were dystopian and filled with Fist of the North Star-looking bad guys running around like crazy, raping and murdering.

422
00:21:04,164 --> 00:21:05,230
Speaker 0: Look at Robocop.

423
00:21:06,470 --> 00:21:08,450
Speaker 0: Like, that's the kind of future that was envisioned.

424
00:21:08,810 --> 00:21:18,424
Speaker 0: And Aydaru is so stereotypical of '90s future dystopia that it almost feels cliche if you forget that it was written in the '90s.

425
00:21:19,170 --> 00:21:19,512
Speaker 0: Right.

426
00:21:19,593 --> 00:21:29,850
Speaker 1: This is another one of those examples where you look at... We were looking at Amazon reviews, and we think we might do this all the book clubs, but look at a few Amazon reviews for the book and discuss them and laugh at them, maybe.

427
00:21:30,571 --> 00:21:36,248
Speaker 1: But a lot of people talked about how the book is sort of cliche, and it's like, "Dude, this book invented a lot of those

428
00:21:36,288 --> 00:21:36,490
Speaker 1: cliches.".

429
00:21:37,090 --> 00:21:43,060
Speaker 1: In fact, that's the kind of book that tends to end up being a book that is famous, is a book that invents things.

430
00:21:43,101 --> 00:21:48,110
Speaker 1: Why do you think Shakespeare... That's like Shakespeare's number one reason for being so famous, because he invented all that shit.

431
00:21:48,270 --> 00:21:54,330
Speaker 0: Well, it's not that he invented them so much as he is the conscious beginning for most people who would know about those things.

432
00:21:54,491 --> 00:21:56,350
Speaker 0: He presented them for the first time.

433
00:21:56,470 --> 00:21:59,250
Speaker 1: So he gets credit for it, and it doesn't matter whether he invented it or not.

434
00:21:59,571 --> 00:22:00,819
Speaker 1: He might as well have invented it.

435
00:22:00,879 --> 00:22:02,570
Speaker 1: Like, Thomas Edison invented a light bulb.

436
00:22:02,690 --> 00:22:03,535
Speaker 1: Yeah, sure, right?

437
00:22:03,898 --> 00:22:05,024
Speaker 1: Was there light bulbs before him?

438
00:22:05,045 --> 00:22:05,789
Speaker 1: Yeah, it was the other guy.

439
00:22:07,032 --> 00:22:09,007
Speaker 1: It's like, "Okay, it doesn't

440
00:22:09,047 --> 00:22:09,269
Speaker 1: matter.".

441
00:22:09,531 --> 00:22:13,750
Speaker 1: The first light bulb that people were buying and using in their houses was Thomas Edison light bulbs.

442
00:22:14,631 --> 00:22:20,990
Speaker 0: So, most of the complaints about this book from Amazon seem to be that it's cliched, or it's complicated.

443
00:22:21,832 --> 00:22:23,089
Speaker 1: It can't be both.

444
00:22:23,951 --> 00:22:24,750
Speaker 0: I can't imagine.

445
00:22:26,611 --> 00:22:27,677
Speaker 0: God, what a waste.

446
00:22:27,738 --> 00:22:29,750
Speaker 0: Throughout the entire book, I just wanted to chuck it.

447
00:22:29,990 --> 00:22:31,289
Speaker 0: There's nothing new here.

448
00:22:32,531 --> 00:22:33,989
Speaker 1: Nothing new in this 90s book.

449
00:22:34,450 --> 00:22:35,970
Speaker 0: The plot is unoriginal and plotting.

450
00:22:36,150 --> 00:22:38,950
Speaker 0: The characters are very poorly developed, even for Gibson.

451
00:22:39,470 --> 00:22:43,050
Speaker 1: Okay, well, the characters poorly developed is somewhat true, right?

452
00:22:43,150 --> 00:22:48,010
Speaker 1: It's that he only develops the characters that really have to be developed.

453
00:22:48,593 --> 00:22:51,390
Speaker 1: And all the other characters are sort of just static through the whole book.

454
00:22:52,672 --> 00:23:00,530
Speaker 1: It's really more about the world and the plot, as opposed to any particular character growing or changing.

455
00:23:00,570 --> 00:23:03,129
Speaker 0: Well, I mean, look, the characters are all nothings.

456
00:23:03,751 --> 00:23:07,949
Speaker 0: In fact, all the main characters, everything just happens around them, and they don't actually do anything.

457
00:23:08,090 --> 00:23:16,450
Speaker 1: Yeah, the story, the plot and the conflict is all about Rez and the Aideru and the company, but you don't see that.

458
00:23:17,632 --> 00:23:26,008
Speaker 1: You're coming into this situation from really far away, from these two perspectives of Lainey and Chia, these two characters from far away.

459
00:23:27,470 --> 00:23:32,290
Speaker 1: Cyberpunk books all do this thing, or at least a lot of them do, where there's the two characters and it goes back and forth.

460
00:23:32,530 --> 00:23:34,309
Speaker 0: That might just be because a lot of it's Gibson.

461
00:23:34,510 --> 00:23:36,350
Speaker 1: Diamond Age did the same thing as Stevenson.

462
00:23:36,650 --> 00:23:38,550
Speaker 0: Yeah, Gibson and Stevenson write very similarly.

463
00:23:38,871 --> 00:23:39,810
Speaker 1: Snow Crash did the same thing.

464
00:23:40,632 --> 00:24:06,123
Speaker 1: But these two characters are coming from far away, and you're seeing things from their perspective, and those are the people who have some character development and change throughout the course of the book, and they come, they're getting closer to the situation all the time, and so it's like the real plot is happening, but you can only see what these two characters see as they get close to it, and then they pass by each other, and that's the climax of the book, and then the book ends.

465
00:24:08,031 --> 00:24:11,646
Speaker 0: Basically, all right, I found the best review, the best.

466
00:24:12,550 --> 00:24:15,930
Speaker 1: Let's make this shtick where we read only the best Amazon review.

467
00:24:16,750 --> 00:24:20,197
Speaker 0: What do you call it when you take some other people's idea and call it your own?

468
00:24:20,539 --> 00:24:21,770
Speaker 0: This is what this book is all about.

469
00:24:22,210 --> 00:24:31,449
Speaker 0: Gibson takes the Idoru theme, which is overused and abused in Japanese anime to create a story that is neither original nor interesting when compared to your average anime.

470
00:24:32,331 --> 00:24:36,558
Speaker 1: That was a valid criticism if that book came out today, but it didn't come out today.

471
00:24:36,639 --> 00:24:37,545
Speaker 1: It came out in the '90s.

472
00:24:38,792 --> 00:24:39,720
Speaker 0: This one's equally good.

473
00:24:39,780 --> 00:24:41,070
Speaker 0: Perhaps I'm not the brightest fellow.

474
00:24:41,151 --> 00:24:45,890
Speaker 0: Well, he's right on one point, but I really had no clue what Gibson was writing about.

475
00:24:46,050 --> 00:24:49,869
Speaker 0: The whole cyberpunk thing never happened, so I'll likely never--.

476
00:24:50,050 --> 00:24:55,869
Speaker 1: Okay, so the cyberpunkness of the book is usually you imagine like Snowcrasher going in cyberspace all the time, right?

477
00:24:56,010 --> 00:24:59,850
Speaker 0: Which is not actually the biggest ideas in most cyberpunk literature.

478
00:25:00,070 --> 00:25:02,510
Speaker 1: But in this, there's only a little bit of that, right?

479
00:25:02,730 --> 00:25:06,490
Speaker 1: The place is not cyberspace in general, right?

480
00:25:06,530 --> 00:25:11,217
Speaker 1: It's that sort of recreation of the-- What's it called?

481
00:25:11,318 --> 00:25:12,570
Speaker 1: The Underground City Place?

482
00:25:12,710 --> 00:25:13,376
Speaker 1: What's the name of it?

483
00:25:14,467 --> 00:25:14,790
Speaker 1: I forget.

484
00:25:15,590 --> 00:25:16,269
Speaker 0: The Walled City.

485
00:25:16,491 --> 00:25:17,029
Speaker 0: The K-File?

486
00:25:17,651 --> 00:25:19,570
Speaker 1: No, the Walled City Place, right?

487
00:25:19,712 --> 00:25:20,790
Speaker 0: Yeah, a shared K-File.

488
00:25:21,710 --> 00:25:24,302
Speaker 1: And it's like, they only go there a little bit, right?

489
00:25:27,051 --> 00:25:32,210
Speaker 1: That place and the going into cyberspace stuff is only relevant to Chia, really?

490
00:25:32,330 --> 00:25:36,890
Speaker 1: It's not really relevant to Laney, so half the book doesn't even involve that at all, right?

491
00:25:37,170 --> 00:25:40,505
Speaker 1: And it's like, for Laney, he's basically like a DVA, right?

492
00:25:42,631 --> 00:25:43,957
Speaker 1: You know what he's good at doing?

493
00:25:44,359 --> 00:25:46,550
Speaker 0: Surfing the internet and ignoring dumb shit.

494
00:25:47,210 --> 00:25:49,349
Speaker 1: Well, I think what he's actually-- you know, that is true, right?

495
00:25:50,253 --> 00:25:53,610
Speaker 1: He basically has the skill of looking at data and then understanding it, right?

496
00:25:53,710 --> 00:26:09,590
Speaker 1: And it's relevant to today, where people talk about the government collecting metadata, and it's like, if you know this fact and all these separate facts that seem unrelated, you can actually-- more information emerges when you combine them, and Laney's skill is basically seeing that, right?

497
00:26:09,910 --> 00:26:24,050
Speaker 1: So he can see, aha, this person bought tea at 2 o'clock, and this person sat down and watched this TV at 2.30, and that person's location was-- he got on that subway train at that time.

498
00:26:24,631 --> 00:26:27,210
Speaker 1: This person went and had tea with that person at their house, right?

499
00:26:27,270 --> 00:26:30,750
Speaker 1: It's like you draw the conclusions from these unrelated datas.

500
00:26:31,093 --> 00:26:31,719
Speaker 0: Yup.

501
00:26:31,799 --> 00:26:35,765
Speaker 1: Now that idea-- They come up with a fancy word for it, they're like, "Oh, he finds the NODAL

502
00:26:35,826 --> 00:26:36,228
Speaker 1: POINTS.".

503
00:26:36,630 --> 00:26:39,450
Speaker 1: It's like, yeah, no, you're basically just extracting real data from the data.

504
00:26:39,450 --> 00:26:43,489
Speaker 0: But that kind of idea was not super widespread in popular consciousness in the '90s.

505
00:26:44,510 --> 00:26:45,370
Speaker 1: No, not really.

506
00:26:45,931 --> 00:26:46,670
Speaker 0: Here's another review.

507
00:26:46,710 --> 00:26:49,090
Speaker 1: There wasn't enough data storage in the '90s to do that.

508
00:26:49,250 --> 00:26:52,070
Speaker 0: I'll point at the last dumb review, and then we'll talk more about the book.

509
00:26:52,490 --> 00:26:55,790
Speaker 0: This is a simplistic sci-fi novel more concerned with punk than futurism.

510
00:26:56,874 --> 00:27:05,690
Speaker 0: Little original or thought-provoking material passed the one seminal idea that identity and fame are fast-becoming commodities, which are created and sold.

511
00:27:06,874 --> 00:27:08,910
Speaker 0: Yeah, the '90s, that was what was happening.

512
00:27:11,512 --> 00:27:15,250
Speaker 1: Well, on the fact that it wasn't futuristic, that is true.

513
00:27:15,631 --> 00:27:26,670
Speaker 1: This book does have one problem that I notice in a lot of just sci-fi in general, anything that takes place in the future, and that many things are highly advanced.

514
00:27:26,850 --> 00:27:32,289
Speaker 1: They're going and jacking into cyberspace with their brains, going to virtual worlds, and then they have a fax machine.

515
00:27:32,551 --> 00:27:34,709
Speaker 0: Yup, so really, we don't even have fax machines.

516
00:27:35,490 --> 00:27:38,770
Speaker 1: It goes to the airport and there's a luggage carousel, and it's like, okay.

517
00:27:39,012 --> 00:27:40,189
Speaker 0: I can see the luggage carousel.

518
00:27:40,550 --> 00:27:47,110
Speaker 1: Well, I mean, yeah, today we still have luggage carousels, but if I was writing a book in the '90s, I would imagine something better than luggage carousels.

519
00:27:47,230 --> 00:27:54,430
Speaker 1: I would make sure that in every scene that I wrote, every single technology in that scene would be updated or replaced in some way.

520
00:27:54,530 --> 00:28:05,567
Speaker 1: Well, you know what it's like when you watch-- That's actually maybe a, you know, so it's like, how do you decide when you're writing a book like that which things to upgrade and which not to, because you're going to be wrong with the fax machine, and you're going to be right with the luggage

521
00:28:05,588 --> 00:28:05,770
Speaker 0: carousel.

522
00:28:05,790 --> 00:28:10,790
Speaker 0: I think it's just the blindness of your era that, for example, Total Recall.

523
00:28:10,950 --> 00:28:12,110
Speaker 1: Your editor should see that shit, though.

524
00:28:12,150 --> 00:28:14,270
Speaker 0: Maybe, but Total Recall, though, you'll be blind to this stuff.

525
00:28:14,370 --> 00:28:18,869
Speaker 0: They think, oh, it's a dystopian future where there's ads everywhere, so let's put screens everywhere with ads on them.

526
00:28:19,231 --> 00:28:24,890
Speaker 0: So the screens are all these giant CRTs hanging everywhere in a future with space travel.

527
00:28:25,670 --> 00:28:32,850
Speaker 1: Like, no one thought flat panels, no one thought-- Well, actually, Total Recall had some flat screens, like the one in his wall in his bedroom.

528
00:28:33,090 --> 00:28:37,230
Speaker 0: Yeah, but it also had a lot of huge CRTs hanging out just like everywhere.

529
00:28:37,530 --> 00:28:37,985
Speaker 0: It did indeed.

530
00:28:38,770 --> 00:28:48,029
Speaker 0: Or like, well, in this book, what really stood out was that the book didn't really at any point seem to consider the idea that wireless communication would exist.

531
00:28:49,852 --> 00:28:53,848
Speaker 0: They're like, everything's wired, even though the data being transferred is not that much.

532
00:28:54,710 --> 00:28:59,249
Speaker 0: And two, they seem to be focused-- Like, there's a lot of IR being used.

533
00:29:00,210 --> 00:29:02,610
Speaker 0: Remote controls are mentioned at multiple points.

534
00:29:03,091 --> 00:29:04,489
Speaker 0: IR remote controls.

535
00:29:05,391 --> 00:29:09,690
Speaker 0: Like, those are the two things that stood out the most to me in terms of the technology being disparate.

536
00:29:10,690 --> 00:29:13,030
Speaker 1: All right, let's talk about what actually happens in the frickin' book, right?

537
00:29:13,110 --> 00:29:19,510
Speaker 0: All right, so I think the book is-- The whole "he wants to date an idol" thing is really-- It's like the difference engine.

538
00:29:19,650 --> 00:29:23,090
Speaker 0: It's just a canard to bring up all these ideas and see what's going on.

539
00:29:23,150 --> 00:29:27,350
Speaker 0: I think the book's about fandom, it's about fame, and it's about AI.

540
00:29:28,570 --> 00:29:31,607
Speaker 1: Well, it's also about the information, right?

541
00:29:32,190 --> 00:29:37,090
Speaker 1: It's like the real thing that happens is not that he wants to marry the idol, right?

542
00:29:37,230 --> 00:29:46,843
Speaker 1: It's that he's able to get at the truth because it was created by all the information of all the fans, right?

543
00:29:49,630 --> 00:29:55,930
Speaker 1: Networking all the-- Just like in "Ghost in the Shell," where he networks all the dudes in his pachinko parlor, right?

544
00:29:56,713 --> 00:30:00,090
Speaker 1: It's like, where did the idol's intelligence come from?

545
00:30:00,150 --> 00:30:06,530
Speaker 1: The idol's intelligence came from all the things that all of the fans of the idol did on the internet together.

546
00:30:06,650 --> 00:30:14,823
Speaker 1: It's like you combine all the fan forums and all the fan arts and the fan everythings together, and that gave life to the virtual idol.

547
00:30:18,293 --> 00:30:24,510
Speaker 1: That's even more Hatsune Miku than just-- Sharon Apple doesn't even have that aspect at all, right?

548
00:30:24,890 --> 00:30:27,305
Speaker 1: It's even so accurate because that's--.

549
00:30:28,371 --> 00:30:36,650
Speaker 0: Well, I said AI because really there's this point that information is the only thing that actually matters or exists in some senses.

550
00:30:37,231 --> 00:30:40,962
Speaker 0: Information is its own plane of existence, and that AIs arise--.

551
00:30:41,143 --> 00:30:58,570
Speaker 0: Remember, they mentioned a couple of times that she is the epitome of desire, that the idol is the epitome of desire, fans desire her, res desires, people desire her, and I think the turning point for an active AI, or what makes this interesting, is when that turns into the thing itself now having desire.

552
00:30:58,770 --> 00:31:02,269
Speaker 0: That's the collective, reflective desire of all the things desiring it.

553
00:31:04,453 --> 00:31:13,535
Speaker 0: But the book's about fandom, too, because notice it's kind of a side point that doesn't require any of this cyberpunk stuff at all, that she is a fan.

554
00:31:13,978 --> 00:31:15,730
Speaker 0: A lot of you kids are fans of things.

555
00:31:16,413 --> 00:31:18,349
Speaker 0: Some of you, or at least one of you, is a fan of us.

556
00:31:19,791 --> 00:31:24,650
Speaker 0: Your image of us is a carefully constructed media image.

557
00:31:24,730 --> 00:31:27,268
Speaker 0: You have a flat data set of us.

558
00:31:28,632 --> 00:31:36,550
Speaker 0: The us you think of is not quite the us that we really are, so your perceptions of us are very much colored by being a fan.

559
00:31:36,690 --> 00:31:40,537
Speaker 0: And notice how Chia, as soon as she meets the real Rez-- He's not a bad guy.

560
00:31:40,557 --> 00:31:41,869
Speaker 0: He's kind of a chill guy.

561
00:31:42,330 --> 00:31:50,710
Speaker 0: But in that moment, when she sees the three-dimensional view, when she gets more information about him, suddenly she's not a fan anymore.

562
00:31:51,452 --> 00:31:57,190
Speaker 0: She has seen beyond the curtain, and is in this whole new plane of information and existence.

563
00:31:58,211 --> 00:31:59,910
Speaker 0: It's no longer a central part of her life.

564
00:32:00,272 --> 00:32:03,670
Speaker 0: It's almost kind of an adolescent story on the side.

565
00:32:03,911 --> 00:32:05,889
Speaker 0: She sort of grows up just by experiencing all of this.

566
00:32:06,650 --> 00:32:09,235
Speaker 1: Well, it's also interesting, right, is that the plot is about.

567
00:32:09,617 --> 00:32:12,430
Speaker 1: Rez wants to marry this idol, right?

568
00:32:12,970 --> 00:32:14,800
Speaker 1: And it's like, why does it have to be that, right?

569
00:32:17,652 --> 00:32:20,130
Speaker 1: It's sort of what's happening is the thing that can never happen.

570
00:32:21,252 --> 00:32:24,850
Speaker 1: The idol is basically the combination of all the fans together.

571
00:32:25,450 --> 00:32:26,358
Speaker 1: Granted, intelligence.

572
00:32:26,398 --> 00:32:27,709
Speaker 1: He's marrying all the fans.

573
00:32:28,164 --> 00:32:28,330
Speaker 1: Yeah.

574
00:32:28,610 --> 00:32:28,833
Speaker 1: Right?

575
00:32:29,198 --> 00:32:30,050
Speaker 1: Think about it that way.

576
00:32:30,210 --> 00:32:34,410
Speaker 1: It's like the one thing that never happens, the famous person marrying a fan, right?

577
00:32:34,790 --> 00:32:37,069
Speaker 1: It's like, no, he's actually marrying every fan at once.

578
00:32:38,210 --> 00:32:44,510
Speaker 0: But notice how the fan that has the true picture has a very different view and is not a part of that flash mob.

579
00:32:45,092 --> 00:32:46,488
Speaker 0: Doesn't even tell people about it.

580
00:32:46,839 --> 00:32:46,989
Speaker 1: Nope.

581
00:32:47,310 --> 00:32:49,390
Speaker 0: Just kind of stays away, fades back.

582
00:32:49,690 --> 00:32:54,707
Speaker 0: I love that little point that Rez says he's going to come and talk to her later and thank her, and then he just never fucking shows up.

583
00:32:55,635 --> 00:32:56,259
Speaker 0: I like that bit.

584
00:32:56,400 --> 00:32:57,849
Speaker 0: He just completely forgot she existed.

585
00:32:58,230 --> 00:32:58,354
Speaker 0: Mm-hmm.

586
00:33:00,492 --> 00:33:09,569
Speaker 0: But in terms of Chia as an adolescent story, notice how Gibson uses, whenever we see things from her perspective, she doesn't know stuff.

587
00:33:09,959 --> 00:33:10,110
Speaker 1: Nope.

588
00:33:10,672 --> 00:33:12,890
Speaker 0: She's very well written as a dumb punk kid.

589
00:33:13,612 --> 00:33:16,830
Speaker 0: She just doesn't know stuff at all, and she describes things.

590
00:33:16,970 --> 00:33:24,549
Speaker 0: She keeps describing the lady next to her on the plane drinking that carrot juice with the celery sticking out of it, or the tomato juice with the celery sticking out of it.

591
00:33:24,851 --> 00:33:27,130
Speaker 0: Not really putting together that those are Bloody Marys.

592
00:33:27,210 --> 00:33:27,710
Speaker 0: It's alcohol.

593
00:33:28,332 --> 00:33:29,349
Speaker 0: She's getting herself drunk.

594
00:33:30,696 --> 00:33:31,950
Speaker 0: She just glosses over all this.

595
00:33:31,970 --> 00:33:32,709
Speaker 0: She doesn't know history.

596
00:33:33,090 --> 00:33:37,590
Speaker 0: She doesn't know much about the Soviet Union or politics or anything.

597
00:33:37,670 --> 00:33:38,070
Speaker 1: She knows about Rez.

598
00:33:38,510 --> 00:33:39,409
Speaker 0: It's all she knows about.

599
00:33:40,732 --> 00:33:42,710
Speaker 0: But it's written from a very naive perspective.

600
00:33:43,351 --> 00:33:49,470
Speaker 0: And he's also making this point about how youth culture increasingly has access to information and yet at the same time doesn't care.

601
00:33:49,932 --> 00:34:02,110
Speaker 0: Because remember there's that little anecdote where she's talking about how the two meshbacks in her class were fighting over whether you draw the crooked ends of the cross that the teachers always yell at them about the right way or not.

602
00:34:02,271 --> 00:34:02,908
Speaker 0: Obviously Nazis.

603
00:34:04,470 --> 00:34:05,650
Speaker 0: Obviously Swastika.

604
00:34:06,070 --> 00:34:08,509
Speaker 0: She has no idea what that is.

605
00:34:08,909 --> 00:34:19,070
Speaker 1: Right, because he's imagining this in a future, and he's sort of being like, you know, yeah, in the future, World War II will have been even longer ago than it is now, right?

606
00:34:19,130 --> 00:34:20,688
Speaker 1: You think kids now don't know history.

607
00:34:20,851 --> 00:34:22,690
Speaker 1: Kids then are really not going to know history.

608
00:34:22,909 --> 00:34:31,330
Speaker 0: But that scene also had a funny moment where then she says something about it's like when they would build those stun guns out of disposable cameras and shock each other.

609
00:34:31,550 --> 00:34:31,870
Speaker 0: Like, really?

610
00:34:32,670 --> 00:34:37,170
Speaker 0: Disposable film cameras with flashes still exist in this far future?

611
00:34:38,630 --> 00:34:39,170
Speaker 1: Fax machines.

612
00:34:39,949 --> 00:34:40,786
Speaker 0: Fax machines.

613
00:34:41,851 --> 00:34:43,969
Speaker 0: Well, probably still exist because our laws are so out of date.

614
00:34:44,931 --> 00:34:46,409
Speaker 1: So, tell you about Laney, right?

615
00:34:46,469 --> 00:34:50,710
Speaker 1: So Laney worked for this company that was basically the shitty newspaper.

616
00:34:51,440 --> 00:34:52,029
Speaker 1: Or the TMZ.

617
00:34:52,511 --> 00:35:00,670
Speaker 0: It's almost like TMZ New York Post, but the biggest newspaper in the world, because people only care about vapid entertainment in this dystopian future.

618
00:35:01,391 --> 00:35:06,750
Speaker 0: It's obvious that that commoditized fame is everything, and it's all manufactured.

619
00:35:07,892 --> 00:35:10,269
Speaker 0: But at the same time, true fame shines through.

620
00:35:11,656 --> 00:35:12,049
Speaker 0: Somehow.

621
00:35:14,912 --> 00:35:20,470
Speaker 1: But he leaves because the conflicts, the boss, I guess?

622
00:35:20,751 --> 00:35:24,109
Speaker 0: Also, his personal conflict over letting that girl kill herself.

623
00:35:24,590 --> 00:35:24,731
Speaker 1: Right.

624
00:35:24,852 --> 00:35:26,970
Speaker 1: Oh, so let's talk about the girl that killed herself, right?

625
00:35:27,130 --> 00:35:28,558
Speaker 1: So, he goes into his information.

626
00:35:30,850 --> 00:35:32,290
Speaker 1: He sees that this thing is going to happen.

627
00:35:32,690 --> 00:35:35,310
Speaker 1: He goes to try to do something about it, right?

628
00:35:35,410 --> 00:35:38,569
Speaker 0: But he doesn't tell any-- He goes personally to do it.

629
00:35:38,810 --> 00:35:43,090
Speaker 0: He kind of acts like the stalker weirdo that everyone's afraid he might be.

630
00:35:43,550 --> 00:35:43,752
Speaker 1: Yeah.

631
00:35:43,793 --> 00:35:45,290
Speaker 1: Well, I mean, if you have that ability, right?

632
00:35:45,390 --> 00:35:48,067
Speaker 1: I mean, that's something that we have to deal with today.

633
00:35:48,731 --> 00:35:51,850
Speaker 1: It's like, yeah, I'm going to look up information about things on the internet.

634
00:35:52,031 --> 00:35:54,350
Speaker 1: At what point am I a stalker weirdo, right?

635
00:35:54,490 --> 00:35:56,628
Speaker 1: It's like, you know, I don't know.

636
00:35:56,990 --> 00:36:04,550
Speaker 0: Yeah, but at the same time, remember, he, in the book, has this power because of a weird drug test done on him as a kid in the orphanage.

637
00:36:05,273 --> 00:36:06,349
Speaker 1: Oh, yeah, that's just sort of silly.

638
00:36:06,710 --> 00:36:11,370
Speaker 0: But at the same time, the danger is that that drug makes you a psychotic stalker.

639
00:36:11,910 --> 00:36:12,010
Speaker 1: Yeah.

640
00:36:12,590 --> 00:36:17,369
Speaker 1: But you could argue-- Apparently, he's the one guy who didn't become the psychotic stalker from the drug, and all the other people did.

641
00:36:17,611 --> 00:36:27,510
Speaker 0: Maybe there's this more subtle point there that having the ability to see that information-- Remember, this is a world before I could just go to Google and get all that kind of metadata myself.

642
00:36:28,030 --> 00:36:30,390
Speaker 0: We have Laney powers now just because of technology.

643
00:36:30,734 --> 00:36:31,188
Speaker 0: All of us do.

644
00:36:31,870 --> 00:36:36,009
Speaker 0: Back then, and when this book was written and in the world of this book, normal people cannot do that.

645
00:36:36,630 --> 00:36:38,788
Speaker 0: The only person who can do that is Laney.

646
00:36:39,750 --> 00:36:44,530
Speaker 0: So maybe it's having that ability alone makes you a stalker.

647
00:36:45,255 --> 00:36:47,070
Speaker 0: It guarantees you'll become a stalker.

648
00:36:47,190 --> 00:36:54,509
Speaker 0: And even Laney, who is not as far gone and not as fucked up as all the other people who use this drug, he's still kind of a weirdo stalker.

649
00:36:55,650 --> 00:36:56,966
Speaker 1: But I guess since he's the only one--.

650
00:36:57,270 --> 00:37:04,270
Speaker 1: Imagine if one person had an iPhone that could Google, went back in time, and they still had somehow modern internet and could Google, right?

651
00:37:04,652 --> 00:37:05,969
Speaker 1: You're going to fucking hire that person.

652
00:37:06,452 --> 00:37:06,586
Speaker 0: Yep.

653
00:37:07,150 --> 00:37:07,395
Speaker 1: Right?

654
00:37:07,579 --> 00:37:11,390
Speaker 1: Even though-- Even though he doesn't do-- That person would have such a vast power.

655
00:37:11,591 --> 00:37:19,870
Speaker 1: Like if I just took my iPhone back to the '90s and somehow it still had an internet connection to today, discounting things like Back to the Future lottery ticket winning.

656
00:37:19,950 --> 00:37:23,330
Speaker 0: Yeah, just like Wikipedia knowledge for dates up to that point.

657
00:37:23,590 --> 00:37:34,350
Speaker 1: Yeah, it's like-- I would be so powerful, it would be hard not to do evil things just from human nature unless I was fucking Dalai Lama or some shit, right?

658
00:37:34,492 --> 00:37:35,529
Speaker 1: It would be so easy.

659
00:37:36,210 --> 00:37:40,009
Speaker 0: It's good to know you're on the shit list of "If you get dark powers, destroy

660
00:37:40,049 --> 00:37:40,150
Speaker 0: you.".

661
00:37:40,312 --> 00:37:40,807
Speaker 1: Right, yeah.

662
00:37:41,430 --> 00:37:43,429
Speaker 1: If I get dark powers, you won't be able to destroy me.

663
00:37:43,730 --> 00:37:45,648
Speaker 0: I'm of the camp of "Use dark powers to do

664
00:37:45,668 --> 00:37:45,849
Speaker 0: good.".

665
00:37:45,910 --> 00:37:49,409
Speaker 1: Strike me down and I will become more powerful than you can possibly be.

666
00:37:50,052 --> 00:37:50,203
Speaker 1: Okay.

667
00:37:55,152 --> 00:37:55,320
Speaker 1: Okay.

668
00:37:56,340 --> 00:38:00,540
Speaker 0: So, was it just me or was the Russian mob really kind of funny and derpy?

669
00:38:00,780 --> 00:38:03,859
Speaker 1: Like, it's not just-- Well, they were fighting against funny and derpy, too.

670
00:38:04,100 --> 00:38:04,831
Speaker 1: I mean, what's his name?

671
00:38:04,892 --> 00:38:05,420
Speaker 1: The strong guy?

672
00:38:06,383 --> 00:38:07,960
Speaker 0: Oh, he is the best, Blackwell.

673
00:38:08,360 --> 00:38:09,094
Speaker 0: Of course.

674
00:38:09,114 --> 00:38:09,440
Speaker 1: Oh, yeah, right?

675
00:38:09,500 --> 00:38:12,660
Speaker 1: So, it's like, Blackwell is already kind of funny, right?

676
00:38:12,660 --> 00:38:14,200
Speaker 1: He's awesome and funny, though, right?

677
00:38:14,240 --> 00:38:23,300
Speaker 1: He's just, you know, the stereotypical gigantic badass dude who's, you know-- Super graceful and-- But he wasn't just, you know, this dumb muscle.

678
00:38:23,501 --> 00:38:29,059
Speaker 1: It's like they took the smart guy and the muscle guy and they put him in the same body, right?

679
00:38:29,641 --> 00:38:33,780
Speaker 1: And that sort of makes it a really interesting and awesome character to root for or whatever.

680
00:38:34,000 --> 00:38:37,120
Speaker 0: Yeah, but he's also ruthless, but in this very calculating and kind of loyal way.

681
00:38:37,241 --> 00:38:38,675
Speaker 1: But it's like you sort of need, right?

682
00:38:39,320 --> 00:38:45,666
Speaker 1: If you're going to have this-- He's not comic relief because he's not, you know, like slapstick, but he's like enjoyable.

683
00:38:45,707 --> 00:38:48,100
Speaker 1: Like, you smile when he's there, right?

684
00:38:48,240 --> 00:38:50,019
Speaker 0: The Russian mafia guys are kind of like that, too.

685
00:38:50,120 --> 00:38:55,180
Speaker 1: Right, you need that kind of, you know-- You can't have that guy fighting a serious enemy, right?

686
00:38:55,580 --> 00:39:04,079
Speaker 1: That's why you'll have like in an action movie, there'll be the-- You know, the main character will be more serious and the slapstick guy is like the guy waiting for Bruce Willis in the car, right?

687
00:39:04,623 --> 00:39:07,240
Speaker 1: And it's like Bruce Willis can't fight a silly enemy.

688
00:39:07,340 --> 00:39:08,859
Speaker 1: He's got to fight the serious enemy.

689
00:39:09,180 --> 00:39:09,624
Speaker 1: And so, right?

690
00:39:09,644 --> 00:39:11,700
Speaker 1: So you have to match up the guy against the right enemy.

691
00:39:11,780 --> 00:39:15,200
Speaker 1: So you need that Russian mafia enemies there to fight against Blackwell.

692
00:39:16,020 --> 00:39:17,180
Speaker 1: So you match up correctly.

693
00:39:17,820 --> 00:39:25,260
Speaker 0: So look at how not just the main characters, but basically every character in the story doesn't have access to all the information.

694
00:39:26,001 --> 00:39:27,320
Speaker 0: And as a result-- Neither does the reader.

695
00:39:27,460 --> 00:39:30,520
Speaker 1: I mean, we have more than most because we're getting two angles at least.

696
00:39:30,680 --> 00:39:31,880
Speaker 1: At least two angles, right?

697
00:39:32,322 --> 00:39:36,480
Speaker 1: But we're still, you know, we're basically adding those two together to find our own--.

698
00:39:36,480 --> 00:39:37,760
Speaker 0: But notice how the story does this.

699
00:39:37,920 --> 00:39:46,400
Speaker 0: Basically, every chapter, the character has some fundamental question that's basically answered by the other character's perspective in the next chapter.

700
00:39:46,680 --> 00:39:46,760
Speaker 0: Yep.

701
00:39:46,880 --> 00:39:49,359
Speaker 0: So as a reader, we get all the answers ongoing.

702
00:39:49,500 --> 00:39:50,627
Speaker 0: It's like, "I wonder what that's about.

703
00:39:50,888 --> 00:39:51,472
Speaker 0: Next chapter.

704
00:39:51,593 --> 00:39:52,639
Speaker 0: Oh, that's exactly what that's

705
00:39:52,659 --> 00:39:52,780
Speaker 0: about.".

706
00:39:52,820 --> 00:39:56,580
Speaker 1: Well, like I said, we're seeing our own nodal point in the book, right?

707
00:39:56,620 --> 00:39:58,660
Speaker 1: The nodal point in The Love Hotel, eventually.

708
00:39:58,901 --> 00:40:08,519
Speaker 0: But notice how the characters, every character, except the idol herself, does not see fucking anything and doesn't fucking do anything.

709
00:40:09,769 --> 00:40:09,940
Speaker 0: Nope.

710
00:40:10,180 --> 00:40:15,040
Speaker 0: They're just kind of bumping around in the dark, bumping into stuff until eventually things work out.

711
00:40:15,380 --> 00:40:23,480
Speaker 0: And only at the very end when Laney gets all the information and that kind of dumb explanation of how he sees it, which I think was not really well written.

712
00:40:23,601 --> 00:40:23,763
Speaker 0: No.

713
00:40:23,784 --> 00:40:24,980
Speaker 1: It was a little weird.

714
00:40:25,121 --> 00:40:29,459
Speaker 0: It was like trying to describe what hacking in the movie Hackers looks like.

715
00:40:30,900 --> 00:40:33,077
Speaker 0: But only then did he figure it all out.

716
00:40:33,780 --> 00:40:36,000
Speaker 0: But we have that power today with Google.

717
00:40:36,500 --> 00:40:36,580
Speaker 0: Yep.

718
00:40:36,820 --> 00:40:39,300
Speaker 0: But the book gives you that power while reading it.

719
00:40:39,640 --> 00:40:43,600
Speaker 0: You learn every answer along the way just because you can see from multiple perspectives.

720
00:40:45,201 --> 00:40:46,340
Speaker 1: It's so meta, right?

721
00:40:46,440 --> 00:40:51,155
Speaker 1: It's about a guy who finds nodal points, but while you're reading the book, the book is you finding a nodal point.

722
00:40:51,236 --> 00:40:51,700
Speaker 1: Oh my gosh.

723
00:40:52,860 --> 00:40:53,073
Speaker 0: Oh my gosh.

724
00:40:53,561 --> 00:41:05,020
Speaker 0: Really, the joy of this book is in all the tiny little details because either they're really anachronistic, like the situation with Russia is just kind of outdated and silly, but there's little details about nanotech.

725
00:41:05,280 --> 00:41:10,080
Speaker 0: Nanotech is not a big part of the book other than it's kind of the next step for the story.

726
00:41:10,964 --> 00:41:11,559
Speaker 0: That's the goal.

727
00:41:11,861 --> 00:41:15,920
Speaker 0: Obviously, they wanted the nanotech to build a city like the shared kill file in the real world.

728
00:41:16,000 --> 00:41:17,160
Speaker 1: But they still have fax machines.

729
00:41:17,340 --> 00:41:19,500
Speaker 1: They can't just nano build a piece of paper on the other side.

730
00:41:19,661 --> 00:41:23,680
Speaker 0: But there's that little point about how nanotechnology is extremely illegal.

731
00:41:25,160 --> 00:41:29,560
Speaker 1: And that makes sense because self-replicating- It seems to also be the most powerful thing, right?

732
00:41:29,640 --> 00:41:32,540
Speaker 1: It's like, yeah, with this little thing, you can build a whole fucking city.

733
00:41:33,200 --> 00:41:36,820
Speaker 1: Well, that's basically like, you know, that's a ridiculously powerful thing.

734
00:41:36,980 --> 00:41:41,700
Speaker 0: Or remember in Diamond Age, the seeds that could do that on their own were ridiculously dangerous.

735
00:41:42,160 --> 00:41:42,229
Speaker 1: Yep.

736
00:41:43,240 --> 00:41:45,860
Speaker 1: I mean, yeah, I'll just plant this motherfucker in New York.

737
00:41:46,022 --> 00:41:46,151
Speaker 1: Oops.

738
00:41:46,720 --> 00:41:47,220
Speaker 0: You know what's funny?

739
00:41:47,803 --> 00:41:48,059
Speaker 1: Double city.

740
00:41:48,080 --> 00:41:50,260
Speaker 0: Because I'm reading yet another culture book.

741
00:41:50,380 --> 00:41:59,480
Speaker 0: I'm reading a service detail, and there's a whole idea of smatter and smatter infections or smatter swarms or self-homogenizing swarms is the term.

742
00:41:59,560 --> 00:42:06,000
Speaker 0: It's the idea that in the galaxy periodically, out of nowhere or out of somewhere, a homogenizing swarm will just appear.

743
00:42:06,140 --> 00:42:08,640
Speaker 0: And it's nanobots that are trying to make more of themselves.

744
00:42:09,701 --> 00:42:16,259
Speaker 0: Either they came out of a civilization that fucked up and destroyed itself with nanotech, which happens kind of often just out in the galaxy.

745
00:42:16,340 --> 00:42:18,560
Speaker 1: Like, if you count the whole universe, yeah, you're going to find those.

746
00:42:18,760 --> 00:42:21,175
Speaker 0: Yeah, like every day, somewhere, some planet goes, "Up,

747
00:42:21,215 --> 00:42:21,618
Speaker 0: Gregu!"

748
00:42:22,683 --> 00:42:24,420
Speaker 0: And they call them smatter infestations.

749
00:42:24,700 --> 00:42:28,319
Speaker 0: And every now and then, they flare up in different parts of the galaxy, and the culture goes and deals with them.

750
00:42:29,100 --> 00:42:30,399
Speaker 0: So it's kind of like that.

751
00:42:31,241 --> 00:42:38,360
Speaker 0: A nanotech device of the scale that's discussed in this book would be more powerful than the most powerful nuclear weapons.

752
00:42:39,383 --> 00:42:40,300
Speaker 1: I mean, think about it.

753
00:42:40,842 --> 00:42:44,420
Speaker 1: You could build an orbital with that motherfucker if you programmed it, right?

754
00:42:45,082 --> 00:42:46,558
Speaker 0: Space doesn't seem to be a big deal in this.

755
00:42:47,720 --> 00:42:48,379
Speaker 0: Not a lot of space.

756
00:42:49,420 --> 00:42:51,540
Speaker 1: I mean, they don't even really talk about satellites or anything.

757
00:42:51,660 --> 00:42:52,900
Speaker 1: I don't know how their net's working.

758
00:42:53,340 --> 00:42:56,800
Speaker 0: Well, the net appears to be sort of pseudo-mythological.

759
00:42:57,520 --> 00:42:59,308
Speaker 0: Like, Zona Rosa had that knife.

760
00:42:59,408 --> 00:43:05,420
Speaker 0: that was actually an application that was super illegal, and people build houses inside of other people's websites.

761
00:43:05,620 --> 00:43:10,800
Speaker 1: Yeah, they make a big deal also about the computer, I guess her deck or computer.

762
00:43:10,840 --> 00:43:12,290
Speaker 0: Oh, her sandbenders?

763
00:43:12,310 --> 00:43:13,900
Speaker 0: The artisanal computer made by Indians?

764
00:43:14,001 --> 00:43:15,612
Speaker 1: She's basically got a hippie computer.

765
00:43:15,834 --> 00:43:16,639
Speaker 1: It's made by hippies.

766
00:43:18,102 --> 00:43:20,960
Speaker 1: It's a computer from Whole Foods and not a computer from Newegg.

767
00:43:21,560 --> 00:43:30,014
Speaker 0: Computers have gotten to the point, and you see this in some more current science fiction, seems to get to this point where young people use technology.

768
00:43:30,054 --> 00:43:33,839
Speaker 0: that's so far beyond understanding that it is kind of mystical to them.

769
00:43:37,362 --> 00:43:39,614
Speaker 0: I'm trying to think of a good example of this offhand.

770
00:43:39,956 --> 00:43:40,700
Speaker 0: I'll think of one later.

771
00:43:41,304 --> 00:43:46,780
Speaker 1: But it's interesting how you imagine a world where it's like, her software is completely different from everyone else's software, right?

772
00:43:46,800 --> 00:43:51,460
Speaker 1: It's like the sandbender software is like, "Whoa, it's totally different," and they don't use the same stuff as everyone else.

773
00:43:51,640 --> 00:43:55,459
Speaker 1: And it's like, in the real world, it's like you got three choices.

774
00:43:56,000 --> 00:43:56,117
Speaker 0: Yeah.

775
00:43:57,162 --> 00:44:00,340
Speaker 1: It's like, maybe that's Linux, but no, not even.

776
00:44:00,740 --> 00:44:03,340
Speaker 0: Oh, yeah, that was David Bowie, guys, if you didn't notice.

777
00:44:03,808 --> 00:44:04,080
Speaker 0: Oh, really?

778
00:44:04,120 --> 00:44:04,640
Speaker 0: In the sandbenders.

779
00:44:05,008 --> 00:44:05,198
Speaker 0: No.

780
00:44:05,520 --> 00:44:07,719
Speaker 0: Yeah, I don't think a lot of kids know who David Bowie is.

781
00:44:07,860 --> 00:44:08,368
Speaker 1: Because this was '90s.

782
00:44:09,267 --> 00:44:09,480
Speaker 0: Yeah.

783
00:44:09,500 --> 00:44:09,827
Speaker 1: '90s, guys.

784
00:44:12,144 --> 00:44:12,919
Speaker 0: The music man.

785
00:44:13,420 --> 00:44:13,660
Speaker 1: Labyrinth.

786
00:44:18,764 --> 00:44:26,240
Speaker 0: I mean, this book is actually really simple, really straightforward, and it brings up kind of interesting, obvious ideas.

787
00:44:26,321 --> 00:44:35,680
Speaker 0: If you ignore the kind of broken anachronisms and remember that it was written in the '90s, it's about fame, it's about AI, it's about information, it's about having Google.

788
00:44:37,380 --> 00:44:40,740
Speaker 1: It's kind of, right, sometimes it's not exciting to read.

789
00:44:41,020 --> 00:44:45,320
Speaker 1: It's like, this thing was way more exciting to read when none of these things happened yet.

790
00:44:45,547 --> 00:44:45,680
Speaker 1: Yeah.

791
00:44:45,845 --> 00:44:45,980
Speaker 1: Right?

792
00:44:46,260 --> 00:44:52,097
Speaker 1: It's like, if you watch Ghost in the Shell, it's still exciting because it's like, "Yeah, I want my cyborg body, and we've been waiting for the cyborg bodies for a

793
00:44:52,137 --> 00:44:52,399
Speaker 1: while.".

794
00:44:52,543 --> 00:44:52,758
Speaker 1: Yup.

795
00:44:53,001 --> 00:44:55,220
Speaker 1: And we have some, but no, not even close.

796
00:44:56,201 --> 00:44:58,215
Speaker 1: But yeah, reading something that's like, "Oh, my God, what if we had

797
00:44:58,255 --> 00:44:58,540
Speaker 1: Google?".

798
00:44:58,540 --> 00:44:59,171
Speaker 1: And it's like, "I have

799
00:44:59,191 --> 00:44:59,578
Speaker 1: Google's.".

800
00:45:00,280 --> 00:45:00,480
Speaker 1: Right?

801
00:45:00,640 --> 00:45:08,240
Speaker 0: So some of the excitement is lost, some of the pure- But remember, 1996, The Realm, the first graphical MMORPG launched that year.

802
00:45:08,400 --> 00:45:08,535
Speaker 1: Right.

803
00:45:08,940 --> 00:45:25,250
Speaker 1: So it's lacking some of that surface-level excitement stuff, but as long as you keep it in perspective, right, of the time it was written, there's a lot to see here because there really weren't two- I mean, it's not like Snow Crash, where like, "Yeah, it was the

804
00:45:25,312 --> 00:45:25,618
Speaker 1: first.".

805
00:45:25,821 --> 00:45:30,788
Speaker 1: But yeah, a lot of these particular ideas in here were the first time.

806
00:45:30,828 --> 00:45:33,240
Speaker 1: you see them in a major popular novel.

807
00:45:33,441 --> 00:45:45,240
Speaker 0: I'd say this book overall has a 50%, it's batting 500 in terms of how much of what it predicted is real or progressing in that direction for real.

808
00:45:45,960 --> 00:45:52,460
Speaker 0: Like, the information stuff, the fandom and fame and culture stuff is going in that direction, but then aspects of it are not.

809
00:45:53,262 --> 00:46:02,959
Speaker 0: Like, the sort of dystopian burb clave, ads everywhere, media has literally gone to shit, it hasn't really happened yet.

810
00:46:03,143 --> 00:46:03,205
Speaker 1: No.

811
00:46:04,160 --> 00:46:05,240
Speaker 0: Like, we're not on that path.

812
00:46:05,904 --> 00:46:06,859
Speaker 0: Most media is like that.

813
00:46:06,980 --> 00:46:08,299
Speaker 1: There are aspects of that that exist.

814
00:46:08,680 --> 00:46:10,540
Speaker 0: But we haven't gone off the deep end.

815
00:46:10,660 --> 00:46:15,620
Speaker 0: Actually, I think the percentage of that type of media is holding pretty constant over the decades.

816
00:46:16,040 --> 00:46:17,959
Speaker 1: Yeah, I think, you know, wait for the old people to die.

817
00:46:18,320 --> 00:46:18,410
Speaker 1: Yeah.

818
00:46:20,220 --> 00:46:23,520
Speaker 1: But yeah, it's still worth reading, right?

819
00:46:23,881 --> 00:46:31,480
Speaker 1: And it's not just the cyberpunk technology aspect, right, but the culture of fame and idleness aspect.

820
00:46:31,760 --> 00:46:36,160
Speaker 0: So I guess think of it more- Don't think that it's just Sharon Apple or whatever.

821
00:46:36,300 --> 00:46:37,079
Speaker 0: Think of it more like that.

822
00:46:37,560 --> 00:46:45,200
Speaker 0: This is about information, metadata, and the future of fame and what fame is and if fame matters.

823
00:46:50,490 --> 00:46:52,630
Speaker 0: This has been Geek Nights with Rim and Scott.

824
00:46:52,830 --> 00:46:57,750
Speaker 0: Special thanks to DJ Pretzel for the opening music, Kat Lee for web design, and Brando K for the logos.

825
00:46:58,150 --> 00:47:03,150
Speaker 1: Be sure to visit our website at frontrowcrew.com for show notes, discussion news, and more.

826
00:47:03,450 --> 00:47:06,090
Speaker 0: Remember, Geek Nights is not one, but four different shows.

827
00:47:06,251 --> 00:47:10,829
Speaker 0: Sci-Tech Mondays, Gaming Tuesdays, Anime Comic Wednesdays, and Indiscriminate Thursdays.

828
00:47:11,290 --> 00:47:14,366
Speaker 1: Geek Nights is distributed under a Creative Commons Attribution 3.0 license.

829
00:47:15,670 --> 00:47:18,650
Speaker 1: Geek Nights is recorded live with no studio and no audience.

830
00:47:18,930 --> 00:47:21,790
Speaker 1: But unlike those other late shows, it's actually recorded at night.

