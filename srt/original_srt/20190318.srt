1
00:00:08,700 --> 00:00:12,432
Speaker 1: It's Monday March 18th 2019.

2
00:00:12,432 --> 00:00:13,457
Speaker 1: I'm rim.

3
00:00:13,658 --> 00:00:15,910
Speaker 1: I'm Scott and this is geek nights tonight.

4
00:00:16,550 --> 00:00:20,689
Speaker 1: Algorithmic content curation and why it keeps recommending Nazi shit to your kids.

5
00:00:22,071 --> 00:00:28,364
Speaker 0: Let's do this All right, so yeah, this is podcast I've been listening to.

6
00:00:28,485 --> 00:00:33,520
Speaker 0: you know, I don't listen to too many podcasts But I added one recently called the war on cars.

7
00:00:34,961 --> 00:00:36,967
Speaker 1: That's a very Scott podcast.

8
00:00:37,067 --> 00:00:41,180
Speaker 0: three New York Viking people talking about how shit cars are.

9
00:00:42,013 --> 00:00:45,008
Speaker 1: Yeah Having rented and driven a car recently.

10
00:00:45,028 --> 00:00:50,413
Speaker 0: Yeah, so the thing is that every episode of the show I've listened to has been great except for two.

11
00:00:50,514 --> 00:01:07,343
Speaker 0: the first one Was one where they talked about self-driving cars and everything they said was right except they just have a more Pessimistic outlook and they sort of assumed the worst-case scenario for self-driving cars where I tend to assume a better-case scenario For self-driving cars.

12
00:01:07,363 --> 00:01:09,569
Speaker 0: I assume a pretty good.

13
00:01:09,589 --> 00:01:19,998
Speaker 0: They're basically like assuming like some company will own the cause and and You know, you'll buy one and like who says you'll buy one It's like, you know that they have these assumptions about how it's gonna be right.

14
00:01:20,119 --> 00:01:21,665
Speaker 1: anyway I mean, I don't I don't want any.

15
00:01:21,705 --> 00:01:23,352
Speaker 1: I don't mean to own a car even if there's.

16
00:01:23,894 --> 00:01:27,546
Speaker 0: I have different assumptions about how it's But the point is the current episode.

17
00:01:27,746 --> 00:01:33,403
Speaker 0: their most recent one was simultaneously the best and worst podcast episode I've ever heard.

18
00:01:33,423 --> 00:01:39,112
Speaker 0: Ooh, they interviewed the surviving dude from NPR's car talk.

19
00:01:39,495 --> 00:01:50,979
Speaker 0: Whoa Whoa, that was my face second favorite radio show and revealed that the the dead guy and to some extent the living guy Actually hated cars.

20
00:01:52,045 --> 00:01:53,419
Speaker 1: You know, that sounds about right.

21
00:01:54,242 --> 00:01:57,632
Speaker 1: You know thinking back to the way they talked about cars and it was fantastic.

22
00:01:57,853 --> 00:02:00,280
Speaker 0: the problem is this particular podcast episode.

23
00:02:00,381 --> 00:02:01,311
Speaker 0: They interviewed this guy.

24
00:02:01,331 --> 00:02:04,600
Speaker 0: Uh They did not play the interview.

25
00:02:05,162 --> 00:02:14,446
Speaker 0: they played like a single sentence from the interview of him saying something and then Basically spent like five minutes Commenting on his comment.

26
00:02:14,868 --> 00:02:23,862
Speaker 0: What watch like if I took an email interview Covered out one sentence and wrote three paragraphs after it cut out one sentence and but three paragraphs after it and no point in the Podcast.

27
00:02:23,883 --> 00:02:26,780
Speaker 0: did they play the interview and now I want to punch all of them in the face.

28
00:02:26,820 --> 00:02:28,228
Speaker 0: Just play the fucking interview.

29
00:02:28,489 --> 00:02:30,520
Speaker 1: Jesus Christ is oh my god.

30
00:02:30,781 --> 00:02:31,222
Speaker 1: Is this?

31
00:02:31,502 --> 00:02:34,851
Speaker 0: if you interview someone you can comment on it like after.

32
00:02:34,871 --> 00:02:38,220
Speaker 1: so Scott is what have you just play the fucking interview?

33
00:02:38,580 --> 00:02:39,563
Speaker 0: Is this what happens?

34
00:02:39,604 --> 00:02:40,988
Speaker 0: you can edit it, but just play it.

35
00:02:41,128 --> 00:02:44,679
Speaker 1: when we're at the stage of content creation where?

36
00:02:45,520 --> 00:02:51,680
Speaker 1: Successful relatively large content creators don't know the basics of like radio production and journalism.

37
00:02:52,224 --> 00:02:56,945
Speaker 1: So as a result, they do things like that Like a room.

38
00:02:56,965 --> 00:03:01,300
Speaker 0: is that just what I guess is actually, you know, I don't is somewhat professionally produced.

39
00:03:02,301 --> 00:03:03,144
Speaker 0: You know, it sounds great.

40
00:03:03,446 --> 00:03:07,160
Speaker 1: Well, yeah, but you can hire someone really cheap to make a podcast sound great.

41
00:03:07,703 --> 00:03:09,271
Speaker 0: Yeah, I mean, I don't I don't think they do.

42
00:03:09,552 --> 00:03:10,075
Speaker 0: they're not like.

43
00:03:10,095 --> 00:03:11,060
Speaker 0: they're not one of those podcasts.

44
00:03:11,140 --> 00:03:13,148
Speaker 0: It's done at a radio station, but they sound like they are.

45
00:03:13,530 --> 00:03:16,705
Speaker 0: Oh, but at the point is just play the fucking interview Jesus Christ.

46
00:03:16,765 --> 00:03:17,551
Speaker 1: Oh my god.

47
00:03:17,672 --> 00:03:21,880
Speaker 0: I have such a low tolerance If you interview someone all I want to hear is what the interview.

48
00:03:22,544 --> 00:03:24,940
Speaker 1: I mean the only podcast I listen to at all these days.

49
00:03:24,960 --> 00:03:27,580
Speaker 0: I imagine if we had like interview with so-and-so on geek night.

50
00:03:27,600 --> 00:03:31,200
Speaker 0: So we played like five sentences from the interview and spent the rest of the time talking.

51
00:03:31,602 --> 00:03:33,010
Speaker 1: I feel like we should do that.

52
00:03:33,070 --> 00:03:34,960
Speaker 0: That's literally what they did in this episode.

53
00:03:35,040 --> 00:03:44,475
Speaker 1: I mean that's even worse than baby's first mistake of get someone on a show to interview and spend most of the time talking at them instead of Asking them questions and listening to them there.

54
00:03:44,535 --> 00:03:45,360
Speaker 0: You want to hear that first?

55
00:03:45,380 --> 00:03:46,688
Speaker 0: You've heard to us talk enough right?

56
00:03:46,728 --> 00:03:48,720
Speaker 0: every fucking episode you want to hear the other person talk.

57
00:03:48,861 --> 00:04:00,685
Speaker 0: yeah, the best interview the best interviewer is someone who gets the other person to talk and talk a lot and say good stuff and then when that person stops talking they ask the question that All you got to do right?

58
00:04:00,705 --> 00:04:09,716
Speaker 0: when you're interviewing your goal is it is not to do anything except say words that catalyze the other person into talking more and better.

59
00:04:09,998 --> 00:04:21,024
Speaker 1: unless Your interview is a buzz-altering of the person you're interviewing Mmm, like if you've cornered some anti-vaxxer Do you be like children?

60
00:04:21,245 --> 00:04:25,880
Speaker 0: even then to a large extent your job is still to make them make a fool of themselves by talk.

61
00:04:26,121 --> 00:04:27,968
Speaker 0: Ah, I want to get them to talk.

62
00:04:28,269 --> 00:04:28,891
Speaker 1: Here's the difference.

63
00:04:29,132 --> 00:04:29,654
Speaker 1: Are you good?

64
00:04:29,935 --> 00:04:31,140
Speaker 1: You know, are you know burning wheel?

65
00:04:31,280 --> 00:04:34,139
Speaker 1: You're not gonna rebut because you're interviewing someone to get them to talk.

66
00:04:34,441 --> 00:04:37,320
Speaker 1: But are you making are you doing something to get them to talk?

67
00:04:37,441 --> 00:04:40,160
Speaker 1: Are you just taking the insight action over and over again?

68
00:04:40,220 --> 00:04:42,106
Speaker 0: You don't rebut by firing at them.

69
00:04:42,146 --> 00:04:46,700
Speaker 0: you rebut by laying there a path before them which includes a spiky pit trap.

70
00:04:47,000 --> 00:04:48,866
Speaker 1: Yep, they're gonna say about.

71
00:04:48,886 --> 00:04:49,748
Speaker 1: they're gonna say something.

72
00:04:49,788 --> 00:04:57,179
Speaker 0: you just need to talk enough to make them walk forward into that pit trap Get out of it and then turn around and walk right back into it again.

73
00:04:57,401 --> 00:04:57,946
Speaker 1: I mean these days.

74
00:04:57,986 --> 00:05:06,586
Speaker 1: the only podcast I can even Dane listening to unless someone else puts them on like casually like when I'm on my own are like NPR like professional ones.

75
00:05:06,787 --> 00:05:11,039
Speaker 0: this finally war on cars podcast sounds like an NPR podcast only it's not.

76
00:05:11,360 --> 00:05:14,849
Speaker 1: well It sounds like they might have some baby's first mistake problems based.

77
00:05:14,969 --> 00:05:15,691
Speaker 1: I can't listen.

78
00:05:16,253 --> 00:05:17,616
Speaker 1: Did you listen to the whole episode?

79
00:05:17,637 --> 00:05:20,588
Speaker 0: I Was hoping the interview would eventually start.

80
00:05:20,990 --> 00:05:21,975
Speaker 1: see there was your false.

81
00:05:22,015 --> 00:05:26,179
Speaker 1: Hope I didn't know I. uh, I have a much dimmer view of podcasting.

82
00:05:26,862 --> 00:05:31,240
Speaker 0: But anyway, listen to all the episodes of that show except for the most recent one where the interview the car tuck.

83
00:05:32,221 --> 00:05:33,005
Speaker 1: So I got to save this.

84
00:05:33,066 --> 00:05:41,279
Speaker 0: my only opening bit is as you might have recalled a while on a Thursday There's best one was the one where they reviewed the Super Bowl commercials and pointed out all the evils of car culture present in them.

85
00:05:41,841 --> 00:05:42,524
Speaker 1: No, all right.

86
00:05:42,705 --> 00:05:44,914
Speaker 1: I'm glad they're singularly focused on hitting cars.

87
00:05:44,994 --> 00:05:45,416
Speaker 1: It was really.

88
00:05:45,436 --> 00:05:46,440
Speaker 0: it was a really good episode.

89
00:05:46,480 --> 00:05:47,365
Speaker 1: They should get you on the show.

90
00:05:47,385 --> 00:05:48,692
Speaker 1: I feel like you'd be their star witness.

91
00:05:50,120 --> 00:05:51,668
Speaker 0: I Wouldn't have anything to say that they don't know.

92
00:05:51,749 --> 00:05:55,526
Speaker 1: Yeah, I just got emailing me like you're gonna get this guy Scott the gig night's guy.

93
00:05:55,727 --> 00:05:57,695
Speaker 1: just trust me get this guy on the show.

94
00:05:58,057 --> 00:06:00,657
Speaker 1: He hates cars Possibly more than either of you.

95
00:06:02,763 --> 00:06:11,270
Speaker 1: So, uh Well, I'll save the full story of this for when we do our next Thursday episode Which is called water in the ceiling, but I have an update.

96
00:06:11,812 --> 00:06:18,790
Speaker 1: my I now have a brand new bespoke door Bathroom made custom to my apartment.

97
00:06:18,890 --> 00:06:19,774
Speaker 0: It was more.

98
00:06:19,795 --> 00:06:20,980
Speaker 0: He's not happy about the door.

99
00:06:21,040 --> 00:06:23,594
Speaker 0: He's happy about the opportunity to use the word bespoke.

100
00:06:23,734 --> 00:06:24,679
Speaker 1: I use that word a lot.

101
00:06:26,080 --> 00:06:33,261
Speaker 1: But the People doing the work, you know I was working from home and they were doing the work and I was sitting here and they come in there and he's kind of Giggling.

102
00:06:33,281 --> 00:06:38,419
Speaker 1: he's like, uh, I assume you want to keep the poop sign cuz I forgot the poop sign is there.

103
00:06:40,022 --> 00:06:42,739
Speaker 1: So the poop sign was affixed permanently to the dull door.

104
00:06:43,481 --> 00:06:49,883
Speaker 1: So I had to carefully remove the poop sign without damaging it so I can put it on the new door as soon as I get The door painted.

105
00:06:50,385 --> 00:06:58,900
Speaker 1: so the poop sign is safe and we'll have a new home at pooping eye level Right in front of my toilet and the full story of this will be on our next Thursday episode of geek.

106
00:06:59,041 --> 00:07:00,350
Speaker 0: So the poop sign is a piece of metal.

107
00:07:00,370 --> 00:07:01,860
Speaker 0: I feel like it's not going anywhere, right?

108
00:07:02,000 --> 00:07:06,420
Speaker 1: You could clean it those little splatter on it slightly bent because it was very difficult to get off the door.

109
00:07:06,580 --> 00:07:09,817
Speaker 0: The thing is about the poop sign is that it's always been attached with adhesive.

110
00:07:10,099 --> 00:07:20,620
Speaker 0: Yep I feel like what you should do is you should perhaps Mount the poop sign onto something or perhaps attach a hook or something else to the back of it So that it may be mounted in a non adhesive fashion.

111
00:07:20,821 --> 00:07:24,634
Speaker 1: But I want it to be fixed and have no movement or flutter at whatsoever.

112
00:07:24,694 --> 00:07:29,171
Speaker 0: cuz bathroom doors get open and closed a lot Yeah, but you can find some way of mounting it.

113
00:07:29,191 --> 00:07:30,880
Speaker 0: Oh, no, I know the way to manage does not involve.

114
00:07:31,061 --> 00:07:32,586
Speaker 1: You know why it's not with adhesive.

115
00:07:32,907 --> 00:07:35,214
Speaker 1: That was the adhesive that came with the poop sign.

116
00:07:36,277 --> 00:07:41,055
Speaker 0: I have evidence In that on the back of the poop sign are two sets of adhesive.

117
00:07:41,296 --> 00:07:41,960
Speaker 1: Oh, you're right.

118
00:07:42,120 --> 00:07:44,529
Speaker 1: So there I replace it with a second adhesive.

119
00:07:44,749 --> 00:07:46,254
Speaker 0: I Phoenix righted you objection.

120
00:07:46,656 --> 00:07:50,449
Speaker 0: Ah, oh my god Presented the evidence immediately.

121
00:07:50,489 --> 00:07:51,434
Speaker 1: Hey, so I do have.

122
00:07:51,474 --> 00:07:58,780
Speaker 1: the real solution though There's that there is the 3m adhesive that is solid but has this tiny little tab.

123
00:07:58,840 --> 00:08:02,155
Speaker 1: You can reach in there and pull on and if you pull on it, it just lets go.

124
00:08:02,175 --> 00:08:06,169
Speaker 1: Mm-hmm completely That's how I hold all these hooks around the studio.

125
00:08:06,210 --> 00:08:07,073
Speaker 0: It's called the command hook.

126
00:08:07,374 --> 00:08:11,025
Speaker 1: Yeah, so I'm gonna use that That adhesive on here.

127
00:08:11,046 --> 00:08:15,496
Speaker 1: Mm-hmm, and then I can remove it without this trouble ten years from now And I have to replace the door again.

128
00:08:17,005 --> 00:08:17,519
Speaker 1: Poop sign.

129
00:08:20,031 --> 00:08:21,477
Speaker 1: But anyway, I have a thing of the day.

130
00:08:21,517 --> 00:08:22,220
Speaker 1: I'll say for later.

131
00:08:22,260 --> 00:08:28,804
Speaker 1: That is this lawyer who watches Media and comments on like how accurate the lawyer stuff is.

132
00:08:28,825 --> 00:08:29,990
Speaker 0: you watch his law and order and shit.

133
00:08:30,331 --> 00:08:33,323
Speaker 1: Oh, yes, and I don't care about any of that but a while ago.

134
00:08:33,383 --> 00:08:35,190
Speaker 1: He did it's always sunny in Philadelphia.

135
00:08:35,874 --> 00:08:36,859
Speaker 0: Which are lawyers in that?

136
00:08:37,280 --> 00:08:38,969
Speaker 1: Uh, yeah, there's multiple courtroom scenes.

137
00:08:39,211 --> 00:08:42,322
Speaker 1: Okay, and that is some of the funniest shit I've ever seen.

138
00:08:42,764 --> 00:08:44,169
Speaker 1: but someone got him.

139
00:08:44,571 --> 00:08:49,950
Speaker 1: He's an anime fan and someone told him Phoenix Wright exists and he watched episode of Phoenix Wright the anime.

140
00:08:50,231 --> 00:08:59,667
Speaker 1: Yeah, oh no, but he came in being like, I don't know anything about the Japanese legal system So I'm just gonna treat this like it's the US legal system and the rest of this episode is him going.

141
00:08:59,747 --> 00:09:00,309
Speaker 1: Oh my fucking.

142
00:09:00,430 --> 00:09:04,063
Speaker 1: oh I hope Japan isn't like this.

143
00:09:04,385 --> 00:09:06,293
Speaker 0: good lord Japan.

144
00:09:06,353 --> 00:09:11,260
Speaker 0: the thing is Japan is more like that than Japan isn't like that But it's more like that than it should.

145
00:09:11,280 --> 00:09:13,714
Speaker 0: it's enough like that to make him go Like I was.

146
00:09:13,775 --> 00:09:20,824
Speaker 0: one email and be like buddy says this guy if you don't know about this guy I thought I've been following him on social media for many years called Jake Adelstein.

147
00:09:20,924 --> 00:09:24,028
Speaker 0: Yeah, I follow him because He's Jews.

148
00:09:25,211 --> 00:09:28,021
Speaker 0: It was like into Japanese stuff and lives in Japan.

149
00:09:28,061 --> 00:09:32,621
Speaker 0: and he wrote a book about the Yakuza and he wrote a recent book Called Tokyo vice.

150
00:09:33,023 --> 00:09:37,135
Speaker 0: and he wrote a recent book What's it called the devil.

151
00:09:37,395 --> 00:09:38,659
Speaker 0: pay the devil in Bitcoin?

152
00:09:39,100 --> 00:09:39,863
Speaker 0: He wrote a book, right?

153
00:09:40,063 --> 00:09:40,906
Speaker 0: He's a really cool dude.

154
00:09:41,006 --> 00:09:47,950
Speaker 0: Anyway, uh But I think he recently tweeted that like back in the day when he was just a cub reporter in Japan.

155
00:09:48,493 --> 00:09:53,417
Speaker 0: He would go to the the the court or whatever every day and say hey Were there any not guilties?

156
00:09:53,437 --> 00:09:54,402
Speaker 0: because they were so rare.

157
00:09:54,503 --> 00:09:55,690
Speaker 0: any one of them would have been news.

158
00:09:56,373 --> 00:10:02,617
Speaker 0: He went and asked for not guilties like every day to make sure All right, so we got some tech news.

159
00:10:03,039 --> 00:10:03,661
Speaker 1: It's Monday.

160
00:10:03,681 --> 00:10:05,468
Speaker 1: I think Scott's news is first.

161
00:10:05,609 --> 00:10:07,395
Speaker 0: Yes It's a big deal.

162
00:10:07,535 --> 00:10:17,501
Speaker 0: It's the weekend and you know, I'm sitting around my apartment like you do And looking for something to watch like you do and I hope the twitch Habit I have studiously avoided for a long time now.

163
00:10:17,622 --> 00:10:22,339
Speaker 0: and of course in this house of Scott There are so many layers of ad block happening.

164
00:10:22,359 --> 00:10:23,262
Speaker 0: There is the pie hole.

165
00:10:23,584 --> 00:10:30,156
Speaker 0: there is you block origin There is so there is every reasonable ad block Deployment technology.

166
00:10:30,196 --> 00:10:32,268
Speaker 1: you see an ad in the Scott household.

167
00:10:32,368 --> 00:10:35,338
Speaker 1: that is Where you turn around kids?

168
00:10:35,920 --> 00:10:36,823
Speaker 0: Look at the magic.

169
00:10:37,184 --> 00:10:38,750
Speaker 0: It's like finding a rat in the kitchen.

170
00:10:38,830 --> 00:10:39,975
Speaker 0: How the hell did you get it here?

171
00:10:40,357 --> 00:10:42,145
Speaker 1: No, it's like finding a raccoon in the kitchen.

172
00:10:42,185 --> 00:10:43,310
Speaker 1: Like where did you come from?

173
00:10:44,110 --> 00:10:47,248
Speaker 0: It's like when I open the balcony door and a fly comes in and I get my fly swatter.

174
00:10:47,268 --> 00:10:54,151
Speaker 0: Yep Anyway, so I turn on Twitch where I never see an ad and a fucking ad comes up and I'm like what the fuck is This?

175
00:10:54,532 --> 00:10:55,596
Speaker 0: yeah, why I mean like?

176
00:10:55,636 --> 00:10:59,870
Speaker 0: sometimes I see an ad because it's one of those ones like the streamer put it in their stream.

177
00:10:59,890 --> 00:11:06,963
Speaker 0: Yeah, I happens a lot of times during eSports tournaments But this was an actual twitch pre-roll ad.

178
00:11:07,224 --> 00:11:09,170
Speaker 0: the stream was happening and I was not seeing it.

179
00:11:09,210 --> 00:11:10,428
Speaker 0: I'm like, what the fuck is this?

180
00:11:11,070 --> 00:11:16,710
Speaker 0: Why am I seeing this shit and I go and I search and sure enough the top post on the you block origin?

181
00:11:17,351 --> 00:11:19,019
Speaker 1: Reddit already voted the hell up.

182
00:11:19,461 --> 00:11:21,430
Speaker 0: I think twitch just changed their ad system.

183
00:11:21,490 --> 00:11:44,370
Speaker 0: It seems that twitch has changed their ad system in such a way that the ads are somehow like in the real stream With some kind of new technology and the only way to block them is to either pay for twitch turbo which is nine bucks a month because remember twitch prime doesn't block it anymore or to Subscribe to that particular twitch channel and twitch prime only lets you do that to one channel per month.

184
00:11:45,611 --> 00:11:51,965
Speaker 0: Otherwise, you got to pay whatever the streamer is charging if it's even if you do my channel I'm not even a twitch affiliate or whatever.

185
00:11:52,005 --> 00:11:53,875
Speaker 0: It's called Twitch partner.

186
00:11:54,035 --> 00:11:55,681
Speaker 0: you can't subscribe to my twitch channel.

187
00:11:55,721 --> 00:11:57,970
Speaker 0: You're just gonna see ads on it if I stream there.

188
00:11:59,010 --> 00:12:04,074
Speaker 0: So I'm paying for YouTube red because I watch a lot more a premium YouTube premium I pay.

189
00:12:04,295 --> 00:12:07,610
Speaker 0: I watch a lot more YouTube than I watch twitch so I'm gonna still pay for that.

190
00:12:07,710 --> 00:12:08,776
Speaker 1: I know most you block ads.

191
00:12:08,816 --> 00:12:21,610
Speaker 1: it also includes way more than you get from because four fifths of the Revenue that the geek nights like my youtube channel gets is from YouTube premium people who are watching our content.

192
00:12:21,792 --> 00:12:23,670
Speaker 1: Yeah, the ads are like the last fifth.

193
00:12:23,850 --> 00:12:29,630
Speaker 0: So I'm gonna be probably streaming for now on YouTube only cuz I don't want anyone to have to see ads to see my stream.

194
00:12:30,473 --> 00:12:33,684
Speaker 0: And also I'm probably watching a lot less twitch in general.

195
00:12:33,925 --> 00:12:37,134
Speaker 0: I'll only be watching like, you know Much much less.

196
00:12:37,335 --> 00:12:38,881
Speaker 1: I mean, I honestly like I'm gonna have.

197
00:12:38,942 --> 00:12:44,289
Speaker 0: instead what I'm gonna do is watch a lot more Crunchyroll and Netflix that I fucking pay for and don't watch enough of.

198
00:12:44,349 --> 00:12:55,552
Speaker 1: yeah Because once the cost of paying for something like twitch starts to approach the cost of like crunchyroll Which one provides more content, yes good Streams.

199
00:12:55,593 --> 00:12:57,783
Speaker 0: if I'm gonna sit down to watch some autocross fuck it.

200
00:12:57,803 --> 00:12:58,607
Speaker 0: I'll just play some autocross.

201
00:12:59,009 --> 00:13:00,937
Speaker 1: Yep I mean, it's kind of like my.

202
00:13:00,957 --> 00:13:02,443
Speaker 1: my strategy lately has been.

203
00:13:02,463 --> 00:13:04,170
Speaker 0: I hope I don't watch twitch.

204
00:13:04,571 --> 00:13:09,990
Speaker 1: I will watch like the YouTube video of the good twitch stream later because I won't see ads in YouTube.

205
00:13:10,090 --> 00:13:12,241
Speaker 1: I would never watch something live on twitch.

206
00:13:12,542 --> 00:13:17,930
Speaker 0: My hope is that the Streamers will notice that their viewer counts going down.

207
00:13:18,030 --> 00:13:21,509
Speaker 0: I don't think it will be big enough, but hopefully it's big enough that impacts the streamers.

208
00:13:21,690 --> 00:13:28,437
Speaker 1: Well, it's interesting because I feel like there is a heavy overlap between people who care about video game streams And people who know about ad blocking.

209
00:13:28,457 --> 00:13:35,829
Speaker 0: this would actually be less of a problem if twitch made one change And that is because basically subscriber to someone's twitch channel is five dollars a month.

210
00:13:36,532 --> 00:13:39,100
Speaker 0: That's a lot of money for one person.

211
00:13:39,541 --> 00:13:42,370
Speaker 0: if it was it should be 50 set but a dollar a month.

212
00:13:42,993 --> 00:13:45,850
Speaker 0: I would actually probably subscribe to five twitch channels easily.

213
00:13:46,011 --> 00:13:48,089
Speaker 0: Yeah, right but for five dollars a month.

214
00:13:48,451 --> 00:13:54,250
Speaker 0: I'm subscribing to like the AG the AGDQ channel the one month that AGDQ is happening.

215
00:13:54,511 --> 00:13:58,927
Speaker 1: Ah, but AGDQ is if you wait like until later that day.

216
00:13:58,987 --> 00:14:04,475
Speaker 0: It's just on YouTube Yeah, but sometimes you like to watch it live and also they donate that money to the charity It doesn't go to.

217
00:14:04,596 --> 00:14:05,944
Speaker 1: I can just donate money to them.

218
00:14:06,146 --> 00:14:06,810
Speaker 0: I do that also.

219
00:14:07,131 --> 00:14:12,673
Speaker 0: It's just an extra five bucks to make the viewing easier and then you can make your donation five dollars less Even it out.

220
00:14:12,914 --> 00:14:18,070
Speaker 0: No, yeah, whatever but yeah, and then I'll use my free twitch prime on like one person.

221
00:14:18,254 --> 00:14:18,646
Speaker 0: But that's it.

222
00:14:18,770 --> 00:14:27,338
Speaker 1: It'll be interesting to see where this all goes because up until now every time there's been an escalation in the ad wars The ad blockers have always won.

223
00:14:27,358 --> 00:14:27,779
Speaker 1: Yep.

224
00:14:28,141 --> 00:14:36,888
Speaker 0: This is there are ways feels hard to beat though the pie hole can't beat it because it's a DNS based blocker and It would have to just block all of twitch DNS for that to work.

225
00:14:38,373 --> 00:14:44,950
Speaker 1: I would be happy with adblock where I'm watching the twitch stream and it's gonna show me the ad in stream.

226
00:14:45,493 --> 00:14:54,470
Speaker 1: If my ad blocker just blanked the video out Put a little banner that says there's some ad playing and just showed me cat videos instead until the ad was done.

227
00:14:54,672 --> 00:14:57,817
Speaker 0: That would be fine, too But it doesn't do that.

228
00:14:58,199 --> 00:15:01,510
Speaker 1: I know but I'm saying that I don't even care that I lose the time.

229
00:15:01,711 --> 00:15:04,963
Speaker 1: I just don't want to see the ad ever under any circumstances.

230
00:15:05,003 --> 00:15:05,223
Speaker 0: Yes.

231
00:15:05,565 --> 00:15:08,917
Speaker 0: However, it is disappointing though It's like I would be happy with what you just said.

232
00:15:08,957 --> 00:15:09,741
Speaker 0: That's perfectly fine.

233
00:15:09,781 --> 00:15:12,009
Speaker 0: Just blocking the ad is priority one by far.

234
00:15:12,831 --> 00:15:19,650
Speaker 0: But it is kind of upsetting on twitch in particular because on twitch when there is an ad there are things happening behind me.

235
00:15:19,871 --> 00:15:20,274
Speaker 1: I miss it.

236
00:15:20,576 --> 00:15:23,694
Speaker 0: Usually most of the time on a normal stream It's the streamer.

237
00:15:23,714 --> 00:15:28,250
Speaker 0: has you know pushed a button to play an ad to make money and gone to the back.

238
00:15:28,290 --> 00:15:28,853
Speaker 0: Well, I can you do.

239
00:15:28,893 --> 00:15:29,917
Speaker 0: you're not missing much.

240
00:15:30,078 --> 00:15:32,690
Speaker 0: if you're watching eSports, you could be missing something.

241
00:15:32,690 --> 00:15:35,245
Speaker 1: I can push this button right now and make an ad play for all of you.

242
00:15:35,507 --> 00:15:37,435
Speaker 0: Don't do that I'll be mad.

243
00:15:37,696 --> 00:15:38,821
Speaker 1: I could though do not?

244
00:15:39,503 --> 00:15:40,507
Speaker 1: I there was a long time ago.

245
00:15:40,547 --> 00:15:41,110
Speaker 1: We're at a PAX.

246
00:15:41,975 --> 00:15:43,868
Speaker 1: I was actually responsible for pushing that button.

247
00:15:44,592 --> 00:15:48,650
Speaker 1: All right for the like the PAX YouTube live stream for Square Enix and stuff.

248
00:15:48,770 --> 00:15:52,889
Speaker 1: I had to push the button on a schedule and it felt real dirty every time I clicked it.

249
00:15:53,090 --> 00:15:53,956
Speaker 1: That was a long time ago.

250
00:15:54,278 --> 00:16:04,189
Speaker 1: Anyway, so yeah, but We've never encountered the situation yet where the ad blocker the nerds are using no longer works.

251
00:16:04,752 --> 00:16:07,890
Speaker 1: Hopefully it will work soon like ad blocks still work on YouTube.

252
00:16:08,591 --> 00:16:11,970
Speaker 1: Like I pay for the fancy YouTube, but ad block works.

253
00:16:12,030 --> 00:16:19,079
Speaker 1: I actually don't know if it does or not because I always logged it does because I'm not logged into my Personal YouTube account on the HT PC.

254
00:16:19,360 --> 00:16:20,686
Speaker 1: Okay, cuz it's in a public room.

255
00:16:20,726 --> 00:16:25,118
Speaker 1: Like I don't want to risk that I might like something Someone might do something.

256
00:16:25,159 --> 00:16:25,943
Speaker 1: It's a full YouTube.

257
00:16:25,963 --> 00:16:29,969
Speaker 1: like it's a Google account Mmm, I don't want to have to log into it every time I use the HT PC.

258
00:16:30,616 --> 00:16:33,168
Speaker 1: So we have like this dummy throwaway Constantly like that.

259
00:16:33,692 --> 00:16:38,530
Speaker 1: Well, yeah, cuz you don't have people just like sitting at your HT PC when you're might not even be in the room.

260
00:16:38,590 --> 00:16:40,115
Speaker 1: They're in attention, I guess.

261
00:16:40,396 --> 00:16:42,242
Speaker 1: Yeah, it's a more public situation.

262
00:16:42,262 --> 00:16:42,724
Speaker 0: people come over.

263
00:16:42,744 --> 00:16:44,570
Speaker 0: I'm not exactly watching the keyboard.

264
00:16:45,992 --> 00:16:48,781
Speaker 0: I guess you could go and like some garbage videos.

265
00:16:48,841 --> 00:16:51,268
Speaker 1: I could go and send you send people emails from your account.

266
00:16:51,288 --> 00:16:51,730
Speaker 1: Okay?

267
00:16:52,532 --> 00:16:56,260
Speaker 1: So in some other news Apparently Scott didn't know this was happening.

268
00:16:56,280 --> 00:16:58,450
Speaker 0: I knew I knew something was happening.

269
00:16:58,510 --> 00:16:59,615
Speaker 0: I just didn't know the full extent.

270
00:16:59,635 --> 00:17:02,829
Speaker 1: I said I want to make the 737 story my news and Scott was like why?

271
00:17:03,150 --> 00:17:03,820
Speaker 1: That's not a big deal.

272
00:17:03,921 --> 00:17:04,530
Speaker 1: And I was like what?

273
00:17:05,511 --> 00:17:06,314
Speaker 0: That's not what I said.

274
00:17:06,334 --> 00:17:09,710
Speaker 0: I said, oh, I don't know why that people are going so crazy about this.

275
00:17:09,851 --> 00:17:10,535
Speaker 0: It's just a plane.

276
00:17:10,575 --> 00:17:11,762
Speaker 0: that's like messed up or something.

277
00:17:12,105 --> 00:17:12,950
Speaker 0: I didn't read the news.

278
00:17:13,030 --> 00:17:14,435
Speaker 0: I just saw a bunch of headlines about it.

279
00:17:14,474 --> 00:17:18,750
Speaker 1: And so you didn't realize that one the 737 max is a pretty brand new plane.

280
00:17:19,911 --> 00:17:21,055
Speaker 0: Okay - I figured it was.

281
00:17:21,215 --> 00:17:22,983
Speaker 0: I thought it was like a mod of the 737 because 737 is an old plane.

282
00:17:25,392 --> 00:17:29,067
Speaker 1: So mod of the 737. what you just said is interesting.

283
00:17:29,087 --> 00:17:29,870
Speaker 1: we'll get back to that.

284
00:17:30,030 --> 00:17:31,696
Speaker 0: Okay, I'm gonna explain this plenty of it.

285
00:17:31,957 --> 00:17:33,081
Speaker 0: that happens all the time right?

286
00:17:33,101 --> 00:17:51,450
Speaker 1: this a 380 a 380 a that's the thing that planes do yeah, and That sometimes means the mod is an entirely new plane Like okay an f-18 Hornet versus like the more the other f-18 Hornet like the enhanced one Basically a completely different feel less disingenuous, right?

287
00:17:51,490 --> 00:17:59,624
Speaker 0: It's like if you make a car and it's a completely new car You shouldn't keep calling it like, you know, if I make a completely new car I shouldn't keep calling it the Ford Taurus if it's not.

288
00:17:59,765 --> 00:18:00,610
Speaker 1: Ah, but what's the right?

289
00:18:01,830 --> 00:18:04,480
Speaker 1: Between an f-16 ABC or D at the same time?

290
00:18:04,521 --> 00:18:15,844
Speaker 1: if I make a for a car and call it the Ford Taurus a it Shouldn't be a completely different car like f-18 versus the super like the Hornet versus the Super Hornet is like a completely different plane Situation even though they have the their origin in the same.

291
00:18:15,965 --> 00:18:17,090
Speaker 0: I will give a pass.

292
00:18:17,852 --> 00:18:25,290
Speaker 0: I'm not super okay with it But I will give a pass to the addition of the word super because Mario Brothers and Super Mario Brothers are nothing alike true

293
00:18:25,390 --> 00:18:29,470
Speaker 1: But they share a common origin and a lot of common like control schemes

294
00:18:29,691 --> 00:18:32,069
Speaker 0: Do they share as much as the f-18 Hornet and Super Hornet?

295
00:18:33,873 --> 00:18:46,187
Speaker 1: Yeah, maybe That gets complicated in a hurry sure and full disclosure I know a lot more about the f-16 and if I talk too much about the f-18 Certain people who listen to the show are gonna come up into my ass about it.

296
00:18:46,207 --> 00:18:51,364
Speaker 0: I Would have to guess if you put them into photos and I had to pick one you could.

297
00:18:51,765 --> 00:18:53,070
Speaker 1: I think you could pick which one.

298
00:18:53,331 --> 00:18:55,338
Speaker 1: Maybe the Super Hornet has more shit on it.

299
00:18:55,739 --> 00:18:58,570
Speaker 1: Okay, that's you look at the Super Hornet like a. wow that has a.

300
00:19:00,056 --> 00:19:05,496
Speaker 0: I can't even give you like the the names of like different Valkyries and Macross except for like two.

301
00:19:05,938 --> 00:19:11,415
Speaker 1: I could from pictures tell the difference between f14 f15 f16 f18 Yeah, f22 f35.

302
00:19:11,495 --> 00:19:13,062
Speaker 0: I could make educated guesses.

303
00:19:13,564 --> 00:19:14,288
Speaker 1: You could tell the f1.

304
00:19:14,308 --> 00:19:17,618
Speaker 0: so F1 17 I can do b2 I can wait.

305
00:19:17,658 --> 00:19:18,641
Speaker 1: said you get a guess is what.

306
00:19:19,243 --> 00:19:20,667
Speaker 1: what's any difference between an f14 and f15?

307
00:19:24,630 --> 00:19:29,040
Speaker 1: Bigger Faster between an f14 and literally any other plane I mentioned.

308
00:19:30,063 --> 00:19:30,404
Speaker 0: I don't know.

309
00:19:30,765 --> 00:19:32,650
Speaker 0: Okay older cuz it's a lower number.

310
00:19:33,553 --> 00:19:37,629
Speaker 1: Uh, yeah, you're technically correct Said educated guess.

311
00:19:38,711 --> 00:19:40,178
Speaker 1: Anyway, here's the deal.

312
00:19:40,780 --> 00:19:49,770
Speaker 1: So the 737 max is Pretty Fundamentally different from a 737 in some ways and that it uses much larger engines.

313
00:19:50,131 --> 00:19:52,680
Speaker 1: So the engines had to be moved on the wings.

314
00:19:53,042 --> 00:20:00,382
Speaker 1: So the flight profile is More different than an effort 737 than you might expect.

315
00:20:00,682 --> 00:20:03,450
Speaker 1: Okay, it's designed to be much more fuel-efficient.

316
00:20:03,792 --> 00:20:06,890
Speaker 0: That's kind of why even with bigger engines is more fuel-efficient.

317
00:20:07,151 --> 00:20:14,725
Speaker 0: Uh, yeah, generally big right they run at lower rpm or whatever that you measure for jet engines base There's more to it than a jet engines don't have rpm.

318
00:20:14,745 --> 00:20:15,409
Speaker 0: Do they or do they?

319
00:20:16,310 --> 00:20:17,620
Speaker 1: Baby, I mean they do.

320
00:20:17,962 --> 00:20:24,948
Speaker 1: Okay, basically It's easier to make a larger jet engine more efficient fuel wise for reasons.

321
00:20:25,169 --> 00:20:27,759
Speaker 1: Okay There's a lot of reasons why that's the case.

322
00:20:27,880 --> 00:20:30,210
Speaker 0: I know as little as I know about regular engines.

323
00:20:30,551 --> 00:20:31,858
Speaker 0: I know that's about jet hitch.

324
00:20:32,039 --> 00:20:32,561
Speaker 1: I'm going.

325
00:20:32,722 --> 00:20:34,210
Speaker 1: so my knowledge is going off.

326
00:20:34,330 --> 00:20:37,184
Speaker 0: I know the fundamental theory of how a jet engine works and that's it.

327
00:20:37,586 --> 00:20:42,743
Speaker 1: I went to Starbase which was this like Air Force recruitment program.

328
00:20:42,763 --> 00:20:52,436
Speaker 1: when I was a kid at the Air National Guard base I learned all I learned like a scary lot about like fighter jets and like Military nonsense around planes.

329
00:20:53,058 --> 00:20:57,130
Speaker 1: and then I am a nerd who cared a lot about the f-16 Falcon in particular.

330
00:20:57,976 --> 00:20:59,650
Speaker 1: That's pretty much the extent of my knowledge.

331
00:21:01,194 --> 00:21:11,117
Speaker 1: But anyway, so this is a new plane that is based on the hull and like the systems of a 737 It has a system in it called MCAS.

332
00:21:11,519 --> 00:21:12,200
Speaker 0: What's that stand for?

333
00:21:12,341 --> 00:21:15,028
Speaker 1: Maneuvering Characteristics Augmentation System.

334
00:21:15,309 --> 00:21:18,350
Speaker 0: Okay Yeah, that's like something from a Gundam anime.

335
00:21:18,591 --> 00:21:30,313
Speaker 1: So basically modern planes are mostly fly-by-wire like yeah, you move the stick this it is not pneumatically directly moving a control surface somewhere because that ship sailed a long time ago don't say.

336
00:21:30,654 --> 00:21:38,890
Speaker 1: the reason why I'm obsessed with the f-16 is because it was like The modern fly-by-wire system like that the I've flown a real f-16 simulator.

337
00:21:38,990 --> 00:21:42,785
Speaker 1: The control arm is like off to the side and it's fully fly-by-wire.

338
00:21:42,805 --> 00:21:46,304
Speaker 1: It's fucking crazy and weird Because the computer has to fly the plane.

339
00:21:46,908 --> 00:21:49,516
Speaker 1: So Airliners are the same way.

340
00:21:49,577 --> 00:21:51,024
Speaker 1: There's a lot of systems at play.

341
00:21:51,447 --> 00:21:56,020
Speaker 1: MCAS Effectively does a bunch of things to make.

342
00:21:56,060 --> 00:22:13,110
Speaker 1: the 737 max that has bigger engines and a higher danger of stalling And different flight characteristics at low speed and during certain situations feel like a regular 737. so pilots don't have to be like completely retrained on this new plane.

343
00:22:13,511 --> 00:22:19,107
Speaker 1: Someone who can fly a 737 can read the documentation and then ostensibly fly a 737 max.

344
00:22:19,147 --> 00:22:20,250
Speaker 1: It'll feel pretty much the same.

345
00:22:20,290 --> 00:22:20,993
Speaker 0: Yeah, I never really.

346
00:22:21,053 --> 00:22:28,150
Speaker 0: I mean I figured you know, it's like flying is obviously, you know Something you have to train a lot for and spend a lot of hours learning.

347
00:22:28,591 --> 00:22:38,846
Speaker 0: But I sort of had the idea that like hey if you can fly like, you know one plane one commercial jet You can fly another commercial jet without having to learn too much different their systems.

348
00:22:38,966 --> 00:22:40,940
Speaker 0: I can drive a car I've never driven before.

349
00:22:41,081 --> 00:22:42,812
Speaker 0: pretty much immediately They will.

350
00:22:42,873 --> 00:22:45,842
Speaker 0: you have to do some work to fly a different plane, but how much really?

351
00:22:45,922 --> 00:22:48,510
Speaker 1: they will have many complex systems and characteristics.

352
00:22:48,510 --> 00:22:49,859
Speaker 1: It'll often be very different.

353
00:22:50,462 --> 00:22:57,390
Speaker 1: things like speeds Like the way to get out of certain kinds of situations might be radically different.

354
00:22:57,953 --> 00:23:02,594
Speaker 1: Like no this plane if it gets into this situation You got a nose down hard.

355
00:23:03,176 --> 00:23:08,430
Speaker 1: that might be very counterintuitive to another plane that has a different characteristic in that particular situation.

356
00:23:08,651 --> 00:23:14,770
Speaker 1: Interesting, so and I'm skipping a lot because this could be a whole show and if I go deeper I'm gonna get something wrong.

357
00:23:15,051 --> 00:23:16,296
Speaker 0: Yeah, you probably already got something.

358
00:23:16,336 --> 00:23:17,901
Speaker 1: I probably already gotten some minor things wrong.

359
00:23:18,082 --> 00:23:18,745
Speaker 1: So here's the deal.

360
00:23:19,387 --> 00:23:27,494
Speaker 1: this system Was not well publicized to the people who were trained in the 737 or in our flying 737 maxes.

361
00:23:27,795 --> 00:23:32,368
Speaker 1: assuming they will behave similarly to the 737 as they flown before they will behave similar.

362
00:23:32,589 --> 00:23:45,018
Speaker 1: similarly This system will actually take control of the stick in a certain situation and bring the nose down Automatically, okay to avoid a stall.

363
00:23:45,560 --> 00:23:47,446
Speaker 1: there appears to be a bug in this system.

364
00:23:47,466 --> 00:23:48,710
Speaker 1: Oops where?

365
00:23:49,511 --> 00:24:01,305
Speaker 1: During takeoff or shortly after takeoff It will think that the plane is entering this dangerous stall condition that is only a problem on the max and not on a regular 737 and then start nosing down.

366
00:24:01,325 --> 00:24:16,386
Speaker 1: if The pilot and co-pilot the flight crew don't know that the system will automatically fucking do this on its own And will override you They'll pull the stick up because the planes nosing down.

367
00:24:16,406 --> 00:24:24,288
Speaker 1: That's not good Assuming that like the previous system their input were all will supersede any automated system.

368
00:24:24,428 --> 00:24:25,290
Speaker 1: in this situation.

369
00:24:25,992 --> 00:24:28,017
Speaker 1: The MCAS will then say oh shit.

370
00:24:28,037 --> 00:24:30,424
Speaker 1: The pilots fighting me nose down more.

371
00:24:30,564 --> 00:24:32,689
Speaker 1: Fuck you and the plane will just crash.

372
00:24:33,811 --> 00:24:38,068
Speaker 1: Okay, the procedure is to disable this system and take control of the plane.

373
00:24:38,088 --> 00:24:38,670
Speaker 0: that makes sense.

374
00:24:40,192 --> 00:24:42,524
Speaker 1: Best I can tell and this is the topic.

375
00:24:42,604 --> 00:24:43,690
Speaker 1: you can read the details.

376
00:24:45,351 --> 00:24:51,367
Speaker 1: This change was not well documented for pilots and This might be an utter fucking shit show.

377
00:24:52,333 --> 00:24:53,257
Speaker 1: This is killed there.

378
00:24:53,277 --> 00:24:55,808
Speaker 1: There have been two full fatality hull losses.

379
00:24:55,869 --> 00:24:57,476
Speaker 0: in short I only knew about one of them.

380
00:24:57,777 --> 00:25:00,670
Speaker 1: Yeah, cuz you don't read the news or know anything about the real world at all.

381
00:25:00,871 --> 00:25:04,609
Speaker 0: I just go past the headline and I only read what I actually seems like it matters to me.

382
00:25:04,770 --> 00:25:13,782
Speaker 0: So to 737, but whatever that doesn't seem to matter to Scott to brand new 737 max has had complete hull losses that killed everyone aboard.

383
00:25:13,842 --> 00:25:15,066
Speaker 1: That's a big goddamn deal.

384
00:25:15,387 --> 00:25:22,330
Speaker 1: I mean one is a big deal I didn't know is - so you can read the stories because this is all developing about like the whole this.

385
00:25:22,672 --> 00:25:23,617
Speaker 1: This is a big deal.

386
00:25:23,677 --> 00:25:24,703
Speaker 0: That is my main thing.

387
00:25:24,763 --> 00:25:25,929
Speaker 0: Is that yet again?

388
00:25:26,271 --> 00:25:34,170
Speaker 0: I can guarantee you what should happen if there was justice in the world Is that the executives at Boeing should all go to jail forever for murdering all those people?

389
00:25:34,550 --> 00:25:41,801
Speaker 0: Including all the way down to whoever is responsible, you know the whole chain But no one will go to jail even though they are mass murderers.

390
00:25:42,242 --> 00:25:44,188
Speaker 1: This is escalating rapidly.

391
00:25:44,229 --> 00:25:47,330
Speaker 0: negligence So, let's see doesn't need to be a life sentence.

392
00:25:47,431 --> 00:25:50,550
Speaker 1: But you know, here's why this is important for technology.

393
00:25:50,651 --> 00:25:53,746
Speaker 0: Meanwhile, some guy robbed the convenience stores in jail for a long time because I want to.

394
00:25:53,766 --> 00:25:54,712
Speaker 1: I don't want to make this the whole Show.

395
00:25:54,732 --> 00:25:55,522
Speaker 1: I want to get into the main bed.

396
00:25:55,542 --> 00:25:58,075
Speaker 1: There are two Technology things that happen here.

397
00:25:58,115 --> 00:25:59,439
Speaker 1: They're very important one.

398
00:25:59,459 --> 00:26:00,925
Speaker 1: This is there act 25 all over again.

399
00:26:03,234 --> 00:26:03,820
Speaker 1: Do you know what there are?

400
00:26:03,820 --> 00:26:03,901
Speaker 1: 25 is?

401
00:26:05,331 --> 00:26:09,010
Speaker 0: Google and there are 25 and then trying to act like he's smart because he knows about there.

402
00:26:09,010 --> 00:26:09,673
Speaker 0: I know a lot about.

403
00:26:09,713 --> 00:26:11,201
Speaker 1: there are 25 because I studied it.

404
00:26:11,281 --> 00:26:13,030
Speaker 0: Yeah listeners don't know what it is either.

405
00:26:13,391 --> 00:26:16,061
Speaker 1: I'll bet some listeners know some most don't.

406
00:26:16,362 --> 00:26:18,730
Speaker 1: so there are 25 long story short.

407
00:26:19,311 --> 00:26:20,875
Speaker 0: I'll just go find something.

408
00:26:20,895 --> 00:26:21,356
Speaker 0: I know about that.

409
00:26:21,396 --> 00:26:21,697
Speaker 0: You don't?

410
00:26:21,857 --> 00:26:26,229
Speaker 1: there are 25. software controls a radiation therapy machine.

411
00:26:26,851 --> 00:26:29,137
Speaker 1: Oh bug and software fucking kills people.

412
00:26:29,237 --> 00:26:29,959
Speaker 0: just give some cancer.

413
00:26:30,100 --> 00:26:30,340
Speaker 1: Yep.

414
00:26:30,601 --> 00:26:31,604
Speaker 1: Wait, what burns them?

415
00:26:31,644 --> 00:26:34,050
Speaker 1: shoots them with a deadly radiation laser.

416
00:26:34,453 --> 00:26:34,917
Speaker 1: You know what?

417
00:26:34,958 --> 00:26:35,825
Speaker 0: This is actually relevant.

418
00:26:35,885 --> 00:26:36,430
Speaker 0: I was watching.

419
00:26:37,551 --> 00:26:38,254
Speaker 0: My mom wants it.

420
00:26:38,275 --> 00:26:39,641
Speaker 0: My mom loves James Bond, right?

421
00:26:39,681 --> 00:26:42,440
Speaker 0: Yeah, but there's a James Bond exhibit in the city She wants to go to whoo.

422
00:26:43,230 --> 00:26:45,760
Speaker 0: Emily Amanda has not seen enough James Bond really.

423
00:26:46,162 --> 00:26:48,049
Speaker 0: Oh never even a Sean Connery James Bond at all.

424
00:26:48,471 --> 00:26:50,860
Speaker 1: Oh, so dude, here's the quiz the fundamental question.

425
00:26:51,161 --> 00:26:53,690
Speaker 1: Do you even tell her Lazenby exists or you just skip that one?

426
00:26:53,770 --> 00:26:54,274
Speaker 0: I'm just saying so.

427
00:26:54,315 --> 00:26:54,658
Speaker 0: he was.

428
00:26:54,738 --> 00:27:00,389
Speaker 0: I like that one to be watch Thunderball yesterday and the scene in which James Bond is getting therapy because he just got beat up.

429
00:27:00,591 --> 00:27:07,696
Speaker 0: yeah, he's in like a health spa resort and The she gets put on like this, you know Obviously not good.

430
00:27:07,897 --> 00:27:08,358
Speaker 0: machine.

431
00:27:08,619 --> 00:27:11,810
Speaker 0: that like basically shakes you to sort of stretch out your spine a little bit, right?

432
00:27:12,030 --> 00:27:16,770
Speaker 0: Yeah, and the bad guy comes in and cranks it up to the max which is super dangerous and it's gonna kill him.

433
00:27:16,915 --> 00:27:19,170
Speaker 0: Yeah And my question is why does a marital therapy?

434
00:27:19,270 --> 00:27:24,387
Speaker 0: Machine even have a setting to go that high to where that why would you would never put it on that setting?

435
00:27:24,828 --> 00:27:29,770
Speaker 0: and I was Thinking and my the thing that immediately came to mind is like yeah you go to the dentist x-ray.

436
00:27:30,333 --> 00:27:34,974
Speaker 0: It doesn't have a setting to where you could like aim it at someone and kill it like it doesn't Option.

437
00:27:35,176 --> 00:27:41,265
Speaker 0: Well, I mean it did way back in the day But like a lot of a modern one does not have the setting of zap.

438
00:27:41,285 --> 00:27:42,850
Speaker 0: someone with x-rays until they have cancer.

439
00:27:43,051 --> 00:27:44,017
Speaker 0: It's just not an option.

440
00:27:44,118 --> 00:27:44,802
Speaker 1: Oh Scott.

441
00:27:45,063 --> 00:27:45,929
Speaker 1: How do you think?

442
00:27:47,230 --> 00:27:54,990
Speaker 0: radiation therapy machines generate their radiation Isn't there just like a piece of uranium in there and then it opens up a little field and then it zaps.

443
00:27:55,050 --> 00:27:56,217
Speaker 0: So they're all.

444
00:27:56,559 --> 00:27:57,323
Speaker 1: they're all different.

445
00:27:57,343 --> 00:27:58,490
Speaker 1: There's a lot of different ways to do.

446
00:27:58,550 --> 00:28:05,345
Speaker 0: It's like there's a radioactive thing in there and some of them Yeah some of them also have like tubes cuz like, you know old fancy electric like cool those glass tubes.

447
00:28:05,365 --> 00:28:08,238
Speaker 0: you zap electricity through them and Then they zap x-rays out everywhere.

448
00:28:08,640 --> 00:28:09,706
Speaker 0: You could just make one of those.

449
00:28:09,807 --> 00:28:10,189
Speaker 0: It's aimed.

450
00:28:11,551 --> 00:28:13,677
Speaker 1: There's a bunch of modern and smaller and better.

451
00:28:14,018 --> 00:28:22,937
Speaker 1: but the Boeing thing and the therac 25 thing share something very much in common software changes that affect the real world.

452
00:28:23,659 --> 00:28:26,329
Speaker 1: if design chitily will fucking kill people.

453
00:28:26,349 --> 00:28:38,470
Speaker 1: and Computer science and software engineering the world over continues to largely ignore this kind of programming treating programming more like traditional engineering in certain situations.

454
00:28:38,851 --> 00:28:45,549
Speaker 0: I think that the the people who are the best at programming are not necessarily working on You know these sorts of things.

455
00:28:46,051 --> 00:28:54,330
Speaker 0: So if you're not familiar is not as someone who is a programmer who has had plenty of opportunities to go work on say software for medical devices.

456
00:28:55,212 --> 00:28:58,410
Speaker 0: That is not a thing you desirable to go work on.

457
00:28:59,212 --> 00:29:05,730
Speaker 0: I'm sure there are smart people working on those things somewhere But most of the smartest people are working on stupid shit like social networks.

458
00:29:06,332 --> 00:29:11,668
Speaker 1: So the other thing that happens is that traditionally like with this is the internet.

459
00:29:11,688 --> 00:29:13,393
Speaker 1: governments governance right the u.s.

460
00:29:13,413 --> 00:29:15,259
Speaker 1: For a long time set the state like the u.s.

461
00:29:15,299 --> 00:29:23,730
Speaker 1: Would regulate something and the rest of the world with either follow suit or Ignore us and we would basically win by default like that's how things have generally gone with the internet.

462
00:29:24,373 --> 00:29:28,990
Speaker 1: The same has been true for a lot of things and one of those things is aviation regulation.

463
00:29:29,910 --> 00:29:37,350
Speaker 1: Until this incident for basically all of modern history the entire world looked to the FAA for things like should this plane be grounded?

464
00:29:38,251 --> 00:29:40,358
Speaker 1: After the first hull loss the FAA didn't do anything.

465
00:29:41,080 --> 00:29:44,049
Speaker 1: after the second hull loss the FAA also didn't do anything.

466
00:29:44,752 --> 00:29:49,529
Speaker 1: The Chinese equivalent of the FAA said fuck it these planes are grounded in China.

467
00:29:50,554 --> 00:30:01,708
Speaker 1: Europe and the rest of the world said we're doing what China did And the FAA still refused to ground them probably because of some combination of corruption and incompetence.

468
00:30:01,728 --> 00:30:05,640
Speaker 1: and What happened because of this disaster?

469
00:30:06,202 --> 00:30:08,089
Speaker 1: is that as of now?

470
00:30:08,910 --> 00:30:18,702
Speaker 1: The FAA basically lost its credibility as like the guiding light of aviation regulation Around the world and the EU and China have already come in to fill that.

471
00:30:19,144 --> 00:30:21,050
Speaker 1: I don't know if that can ever be repaired.

472
00:30:21,652 --> 00:30:26,170
Speaker 1: I think we I think the US just lost control of aviation regulation.

473
00:30:27,051 --> 00:30:35,649
Speaker 1: For the foreseeable future and for the lives of anyone alive today like that was a fundamental She see change that will have drastic ramifications for the time to come.

474
00:30:36,414 --> 00:30:44,390
Speaker 1: Okay, just like with the internet No one cares what the US thinks about the internet anywhere because their FCC has very similar problems now to the FAA.

475
00:30:45,592 --> 00:30:47,587
Speaker 1: So yeah, you can read more about that.

476
00:30:48,612 --> 00:30:58,935
Speaker 1: That's plenty of news, I think we should just get right into Things of the day.

477
00:30:58,975 --> 00:30:59,376
Speaker 1: what he got.

478
00:30:59,898 --> 00:31:03,330
Speaker 0: so this looks like it's about Mario maker protection about programming.

479
00:31:03,976 --> 00:31:05,570
Speaker 1: Oh, I saw this video, but I didn't watch it yet.

480
00:31:05,690 --> 00:31:08,261
Speaker 0: So this video is kind of long, so I'm just gonna explain it to you.

481
00:31:08,281 --> 00:31:09,306
Speaker 0: real simple like right.

482
00:31:09,948 --> 00:31:23,511
Speaker 0: so Basically they have a situation where you want to trigger certain events to happen in your Mario level right and That would otherwise be impossible to trigger, but they found out this bug To where?

483
00:31:23,551 --> 00:31:28,910
Speaker 0: basically if you have two pal blocks and then a bullet bill gun on top of the two pal blocks all

484
00:31:28,930 --> 00:31:30,436
Speaker 1: right This is already very specific,

485
00:31:30,677 --> 00:31:36,390
Speaker 0: and they're on one of those like tracks that goes up and down You know like the kind you would normally have a moving platform on a line.

486
00:31:36,450 --> 00:31:37,513
Speaker 0: Yeah, right so you.

487
00:31:37,694 --> 00:31:39,459
Speaker 0: so basically they go up and down right.

488
00:31:40,583 --> 00:31:42,849
Speaker 0: if normally that is like when you set that up.

489
00:31:43,291 --> 00:31:44,957
Speaker 0: It's a. it's like a global object.

490
00:31:45,419 --> 00:31:53,030
Speaker 0: and that global object like spawns is when the screen spawns And is always there even if it's not on screen all right, so you don't to see it right.

491
00:31:53,771 --> 00:31:56,421
Speaker 0: And the thing is even though that's his global object.

492
00:31:56,923 --> 00:32:02,698
Speaker 0: What can happen is if Any sort of lag in the game happens.

493
00:32:03,400 --> 00:32:06,789
Speaker 0: so for example touching a checkpoint taking damage?

494
00:32:08,051 --> 00:32:12,024
Speaker 0: Picking up a mushroom those things Mario goes doot doot doot or like you right.

495
00:32:12,225 --> 00:32:20,950
Speaker 0: these certain lag causing events Will cause the the second pal block and the bullet bill gun to separate by a few pixels.

496
00:32:21,251 --> 00:32:23,541
Speaker 1: Oh, I see a little gap there to separate.

497
00:32:23,582 --> 00:32:25,470
Speaker 0: It's called the big gap the giant gap.

498
00:32:25,550 --> 00:32:29,770
Speaker 0: It's called the giant gap because the guy who discovered it his internet name includes the word giant.

499
00:32:30,493 --> 00:32:31,697
Speaker 0: It's not actually a gap.

500
00:32:31,798 --> 00:32:33,043
Speaker 0: It's not actually a big gap.

501
00:32:33,123 --> 00:32:33,886
Speaker 0: It's a gap.

502
00:32:33,926 --> 00:32:34,770
Speaker 0: that was you know the same way.

503
00:32:34,910 --> 00:32:39,550
Speaker 0: I need giant gasps like how kaizo block isn't is about the guy who yeah named kaizo.

504
00:32:39,590 --> 00:32:49,796
Speaker 0: It's a giant gap because anyway it causes the top two things like become separated right and then Disappear bounce away, whatever.

505
00:32:49,816 --> 00:33:24,005
Speaker 0: so now you can basically set up your Mario maker level such that if Mario you know takes damage touches a checkpoint or gets a mushroom you can now trigger a cascade of events Right because that pal block and that bullet bill gun that now fly away Right from their their original position can trigger p-switches Or all kinds of make make bat push bad guys into the scene do all sorts of crazy shit And is a really fascinating way of programming.

506
00:33:24,025 --> 00:33:34,439
Speaker 0: you know using You know Mario maker and also this guy's channel is full of all kinds of stuff like they made turn-based games in Mario maker All sorts of nonsense.

507
00:33:34,740 --> 00:33:39,780
Speaker 0: so check out the whole channel, but this video in particular You don't have to watch because I just explained it to you.

508
00:33:40,021 --> 00:33:50,491
Speaker 1: this reminds me a lot of something I haven't used as my thing of the day yet where someone figured out why there's this one mole playing rough in one specific spot in all of earthbound and It's.

509
00:33:50,913 --> 00:34:01,419
Speaker 1: it's a very similar discussion about how important this one encounter is in the game, but I'll save that for another time because my thing of the day is Something that our friend chase would love.

510
00:34:01,801 --> 00:34:04,754
Speaker 1: I got a video tearing this thing down Scott.

511
00:34:04,774 --> 00:34:06,287
Speaker 1: what is the best way to cook a hot dog?

512
00:34:06,991 --> 00:34:07,916
Speaker 0: Mr.. Cook a hot dog?

513
00:34:07,936 --> 00:34:09,041
Speaker 0: yeah fire all right.

514
00:34:09,061 --> 00:34:10,126
Speaker 1: so on a fire in a grill?

515
00:34:10,487 --> 00:34:14,254
Speaker 0: no no no I mean like you put the hot dog on a stick and you put okay So in a fire.

516
00:34:14,797 --> 00:34:17,309
Speaker 1: so would number two be like on a grill with fire under it.

517
00:34:17,670 --> 00:34:18,313
Speaker 0: That's not.

518
00:34:18,373 --> 00:34:19,074
Speaker 0: that's not a bad way.

519
00:34:19,136 --> 00:34:19,878
Speaker 0: You could do a lot worse.

520
00:34:19,978 --> 00:34:21,203
Speaker 1: Yep number three.

521
00:34:21,264 --> 00:34:22,849
Speaker 1: I guess would then be just boiling water.

522
00:34:23,650 --> 00:34:24,717
Speaker 0: Boiling water is really bad.

523
00:34:24,879 --> 00:34:25,603
Speaker 0: I'm sure you could there.

524
00:34:25,784 --> 00:34:28,790
Speaker 0: I'm sure the boiler I guess there must be a lot of ways better.

525
00:34:29,152 --> 00:34:29,757
Speaker 0: You know what I don't.

526
00:34:29,797 --> 00:34:31,250
Speaker 0: actually you know what's better than boiling water.

527
00:34:31,310 --> 00:34:33,708
Speaker 0: It's not a good way, but it's better than boiling water.

528
00:34:33,728 --> 00:34:37,610
Speaker 0: now Just toaster of it on the highest setting yeah, put it on a piece of tinfoil in there.

529
00:34:37,812 --> 00:34:39,509
Speaker 0: I do that when I'm really lazy.

530
00:34:40,051 --> 00:34:46,570
Speaker 1: So what if I told you that there was a way in the 60s to cook hot dogs in an entirely novel way?

531
00:34:46,610 --> 00:34:48,010
Speaker 1: And this shit is horrifying.

532
00:34:48,989 --> 00:34:54,504
Speaker 1: The presto hotdogger would just put mains voltage through the hot dog.

533
00:34:54,524 --> 00:34:54,945
Speaker 0: That'll work.

534
00:34:55,366 --> 00:34:56,850
Speaker 1: Yes, it does work.

535
00:34:57,932 --> 00:35:00,785
Speaker 1: This is a device where it's a little dangerous.

536
00:35:00,805 --> 00:35:03,013
Speaker 0: Uh yeah It'll work.

537
00:35:03,355 --> 00:35:04,460
Speaker 1: Crazy dangerous.

538
00:35:04,500 --> 00:35:05,283
Speaker 0: Totally works though.

539
00:35:05,404 --> 00:35:09,117
Speaker 1: This is like those Asian In a lot of countries like in Southeast Asia.

540
00:35:09,137 --> 00:35:11,105
Speaker 0: It's a little fire hazard, but you know it works.

541
00:35:11,567 --> 00:35:18,130
Speaker 1: Or like in the Philippines Like you'll you'll have instead of a hot water heater You just have a shower head with like just current running through it.

542
00:35:18,170 --> 00:35:20,381
Speaker 0: There's plenty of other ways to cook the hot dog.

543
00:35:20,401 --> 00:35:21,829
Speaker 0: You like take a welding torch to it.

544
00:35:22,412 --> 00:35:26,109
Speaker 1: It's like yeah, so this was basically this will cook a hot dog in 60 seconds.

545
00:35:26,410 --> 00:35:27,857
Speaker 1: You can put a bunch of hot dogs in it.

546
00:35:27,897 --> 00:35:30,489
Speaker 0: Takes that I figured it would do like instantly like electric chair like pshh.

547
00:35:30,610 --> 00:35:36,107
Speaker 1: Well it takes 60 seconds because it's six hot dogs, and you only got 120 volts.

548
00:35:36,127 --> 00:35:42,743
Speaker 1: and However much amperage comes out of a wall outlet in the US in 1967.

549
00:35:42,743 --> 00:35:44,889
Speaker 0: What if you use the the dryer outlet with the?

550
00:35:45,872 --> 00:35:47,277
Speaker 0: So the power pump.

551
00:35:47,357 --> 00:35:51,270
Speaker 1: My thing of the day is not that the presto hotdogger exists as ridiculous as this is.

552
00:35:51,391 --> 00:35:52,560
Speaker 0: I thought that that would be the thing of the day.

553
00:35:52,600 --> 00:35:56,370
Speaker 1: My thing of the day is big Clive Demonstrating the hotdogger because he got one.

554
00:35:56,530 --> 00:36:00,845
Speaker 1: Oh, no, and then he puts it in a 220 line to see what happens.

555
00:36:01,045 --> 00:36:04,970
Speaker 0: Oh, no, that's an exact thing I just suggested without even knowing that's what was gonna happen.

556
00:36:05,050 --> 00:36:10,690
Speaker 1: There are only two possibilities either it cooks the hot dogs twice as fast or the hot dogs explode.

557
00:36:11,431 --> 00:36:12,890
Speaker 0: I'm not gonna spoil it please.

558
00:36:13,831 --> 00:36:16,681
Speaker 1: So the video is called turbo charging a 120 volt presto hotdogger on 250 volts.

559
00:36:22,927 --> 00:36:27,705
Speaker 1: In The meta moment the geek night's book club book was 2001 a space odyssey.

560
00:36:27,725 --> 00:36:28,669
Speaker 1: we talked about it.

561
00:36:28,749 --> 00:36:29,792
Speaker 0: finally What's the new book?

562
00:36:29,953 --> 00:36:34,810
Speaker 1: I got to finally make my argument that hell and the leopard are the same goddamn thing.

563
00:36:34,951 --> 00:36:36,749
Speaker 1: Okay, did you watch the movie again?

564
00:36:37,250 --> 00:36:38,636
Speaker 1: No, I'm gonna watch the movie again soon.

565
00:36:38,656 --> 00:36:40,786
Speaker 1: Okay, cuz I haven't seen the movie since I was in.

566
00:36:40,806 --> 00:36:44,359
Speaker 1: I Think either fifth grade or sixth grade too long.

567
00:36:44,499 --> 00:36:45,984
Speaker 1: It's been a long time.

568
00:36:46,004 --> 00:36:47,630
Speaker 1: I gotta watch the movie again.

569
00:36:47,991 --> 00:37:01,222
Speaker 1: Maybe I'll watch it on the train to Zenk icon this weekend because geek nights will be live at Zenk icon this weekend doing three panels on Saturday the secret guide to running panels on Saturday Not so long after that the 40 table.

570
00:37:01,242 --> 00:37:02,510
Speaker 1: take on tabletop games.

571
00:37:02,510 --> 00:37:06,464
Speaker 1: You must play and on Sunday morning play dirty to win.

572
00:37:06,544 --> 00:37:14,609
Speaker 0: and while rim is at Zenk icon I will be preparing a panel for PAX East which is the week after that the real harm of game.

573
00:37:15,111 --> 00:37:16,670
Speaker 1: Oh shit, it's gonna be a good panel.

574
00:37:16,771 --> 00:37:18,923
Speaker 1: I found a tweet about some shit Google's doing.

575
00:37:18,943 --> 00:37:20,050
Speaker 1: that we got to include in the panel.

576
00:37:20,695 --> 00:37:22,289
Speaker 1: Did you make a presentation at least yet?

577
00:37:23,290 --> 00:37:26,988
Speaker 0: I made a Google Doc that it was now easily going to be made into a person.

578
00:37:27,029 --> 00:37:33,829
Speaker 1: Scott I'm just saying I wrote the entire nostalgia versus game design panel four days before we did it.

579
00:37:33,929 --> 00:37:34,915
Speaker 0: Oh good I'm way ahead of you good.

580
00:37:35,036 --> 00:37:37,210
Speaker 0: All right, so my Google Doc is waiting.

581
00:37:37,990 --> 00:37:43,155
Speaker 1: I'm curious to see how well how you put this panel together because I got I got some content I got to give you.

582
00:37:43,175 --> 00:37:45,010
Speaker 0: Oh give it to me cuz I make the slides.

583
00:37:45,050 --> 00:37:46,575
Speaker 0: I've already put together most of the panel.

584
00:37:47,197 --> 00:37:51,150
Speaker 1: also Google that remember I pay for a Google or an Adobe stock account.

585
00:37:51,271 --> 00:37:53,701
Speaker 1: So I can make slides that are 100% copyright free.

586
00:37:53,722 --> 00:37:57,863
Speaker 0: All right Well, I usually you know, I'll make all the slides without photos.

587
00:37:57,883 --> 00:37:59,050
Speaker 0: Yeah, we'll just start filming it.

588
00:37:59,070 --> 00:38:00,359
Speaker 1: Let me know when you start making those.

589
00:38:00,419 --> 00:38:01,989
Speaker 1: I'll start filling in like good images.

590
00:38:02,794 --> 00:38:05,568
Speaker 1: If we need images because I pay for this I'm gonna use it.

591
00:38:07,674 --> 00:38:12,801
Speaker 1: So beyond that after PAX East We have no conventions until PAX West.

592
00:38:12,901 --> 00:38:13,424
Speaker 0: It's summer.

593
00:38:13,444 --> 00:38:13,966
Speaker 0: go outside.

594
00:38:14,147 --> 00:38:14,710
Speaker 1: Oh my god.

595
00:38:15,873 --> 00:38:18,409
Speaker 1: We used to go to a lot of cons in the summer, but we don't anymore.

596
00:38:19,591 --> 00:38:21,502
Speaker 1: But I haven't picked the new booklet book yet.

597
00:38:21,945 --> 00:38:22,810
Speaker 1: This is your last chance.

598
00:38:23,453 --> 00:38:24,177
Speaker 1: you either have.

599
00:38:24,459 --> 00:38:38,480
Speaker 1: I'm either gonna pick nine Fox Gambit or Troy gambit or ten Fox game or Troy Dennings pages of pain, which is a licensed planescape novel That I read once a long time ago.

600
00:38:38,500 --> 00:38:40,350
Speaker 1: Okay, it's gonna be one of the two.

601
00:38:40,450 --> 00:38:46,802
Speaker 0: Yeah, you gotta tell me I can tell you this though if you pick pages of pain I will also pick a bad fantasy novel.

602
00:38:46,842 --> 00:38:47,546
Speaker 0: I read when I was young.

603
00:38:47,727 --> 00:38:48,150
Speaker 0: That's fine.

604
00:38:48,812 --> 00:38:54,210
Speaker 1: I'm all about reading bad novels as a kid so I can just look on my past self with shame.

605
00:38:56,282 --> 00:39:05,069
Speaker 1: But interestingly Multiple listeners have already coming out telling me to not pick nine Fox Gambit because they're afraid of it.

606
00:39:05,612 --> 00:39:09,730
Speaker 1: But so far all the things they've said about it just make me want to read it more.

607
00:39:09,991 --> 00:39:19,383
Speaker 1: Oh, no, so they're like, oh, it's too dense and full of like ridiculous like what like the prince of nothing like, okay Throw the proper noun gobbledygook at me.

608
00:39:19,464 --> 00:39:20,289
Speaker 1: My body is ready.

609
00:39:21,691 --> 00:39:26,750
Speaker 1: Linear algebra something something sure the gnosis the gnosis man.

610
00:39:27,471 --> 00:39:28,615
Speaker 0: So yeah, what do you see?

611
00:39:29,358 --> 00:39:30,642
Speaker 1: We'll be judging anime soon.

612
00:39:31,024 --> 00:39:32,690
Speaker 1: I'm doing some work to get gig nights presents.

613
00:39:32,690 --> 00:39:36,930
Speaker 0: You tell the judging anime might be a week late again cuz we got a bunch of convention.

614
00:39:38,011 --> 00:39:45,725
Speaker 1: Yep after PAX East is when all the other content will start up again because We got nothing to do but bike around in the Sun after that.

615
00:39:45,745 --> 00:39:46,087
Speaker 1: Mm-hmm.

616
00:39:47,352 --> 00:39:54,717
Speaker 1: so this is becoming a much more serious problem recently than it was in the past, but We haven't actually talked about this.

617
00:39:54,757 --> 00:39:56,784
Speaker 1: We've talked about some related items, but here's the deal.

618
00:39:57,747 --> 00:40:11,749
Speaker 1: in the modern world there's a bunch of platforms that have content hosted on them and Their entire business model is centered on the idea that People who are not them make content that is on that platform and they monetize that content in some way.

619
00:40:12,311 --> 00:40:17,288
Speaker 0: Because hosting your own content on the internet is far too difficult for the vast majority of people.

620
00:40:17,408 --> 00:40:18,893
Speaker 1: now, dude It's too difficult for us.

621
00:40:19,154 --> 00:40:29,342
Speaker 1: We can host we're like on our own effectively by paying people to like provided Podcasts and our website but YouTube live streaming video.

622
00:40:29,382 --> 00:40:34,453
Speaker 1: this shit would not be on anywhere in the internet Dude, I just can't pay for it I can't.

623
00:40:34,634 --> 00:40:39,919
Speaker 0: we could tell their people can't even host a blog without Someone hosting like making a website like blog spot for them.

624
00:40:40,059 --> 00:40:46,550
Speaker 1: I could host this stuff if we had like four listeners Anyway, so we could use bit torrent.

625
00:40:46,731 --> 00:40:49,340
Speaker 1: Yeah, no one would listen, but this applies to a lot of things.

626
00:40:49,360 --> 00:40:58,210
Speaker 1: this applies to like YouTube and it applies to like Twitch But it also applies to things like Amazon where other people sell stuff on Amazon.

627
00:40:58,631 --> 00:41:02,748
Speaker 1: Amazon just provides the platform for people to buy that stuff and they take a cut.

628
00:41:03,170 --> 00:41:15,116
Speaker 1: now They're also dipping into selling stuff direct app stores instead of going to a website and downloading the XE Yep, so this is a. this is a big common primary part of the modern internet.

629
00:41:15,437 --> 00:41:23,590
Speaker 1: ostensibly it might have replaced a lot of a web 2.0 was supposed to be and made the Internet much more consumer oriented and there's a whole other can of worms there.

630
00:41:23,770 --> 00:41:27,317
Speaker 1: This is a big primary reality of the modern internet.

631
00:41:27,838 --> 00:41:36,910
Speaker 1: the problem is Thus the content sets are so big that I'm not saying it's impossible to curate it with humans.

632
00:41:37,271 --> 00:41:42,730
Speaker 1: I'm saying no one is willing to put the effort and money forth to curate this with humans.

633
00:41:43,372 --> 00:41:45,079
Speaker 1: It is not part of their business model.

634
00:41:45,119 --> 00:41:45,942
Speaker 1: I mean listen.

635
00:41:46,183 --> 00:41:47,889
Speaker 0: I couldn't even sort my mp3s.

636
00:41:49,092 --> 00:41:49,735
Speaker 1: I still haven't.

637
00:41:49,795 --> 00:41:55,532
Speaker 1: I have that same same directory, but I've been copying 1994.

638
00:41:55,532 --> 00:41:58,326
Speaker 0: imagine if your job is to sort through YouTube videos.

639
00:41:58,346 --> 00:42:03,430
Speaker 0: look at the people whose job It was to like flag content on Facebook who went crazy because they're seeing all that garbage content.

640
00:42:03,490 --> 00:42:07,667
Speaker 1: Have any of you read that expose of what it's like to be a Facebook content moderator like.

641
00:42:08,109 --> 00:42:10,497
Speaker 0: it's like It's like a third-party outsourced place.

642
00:42:10,517 --> 00:42:11,661
Speaker 0: It's like the worst job ever.

643
00:42:11,681 --> 00:42:20,268
Speaker 0: you get clinical depression like they Sit in a building of an Arizona or some shit reading the worst of the internet all fucking day.

644
00:42:20,429 --> 00:42:31,185
Speaker 0: just in Trying to you know figure out not only do you have to look at all that garbage, but you have to like Carefully know what's which stuff is okay on the Facebook guidelines and which stuff isn't.

645
00:42:31,205 --> 00:42:35,809
Speaker 0: you can't just use your own common sense And if you mess up even like a few times you like lose your job.

646
00:42:35,930 --> 00:42:38,770
Speaker 0: So it's super high pressure, and you're looking at all this garbage content.

647
00:42:38,890 --> 00:42:42,324
Speaker 1: You're looking at the worst the internet has to offer at any given day.

648
00:42:42,485 --> 00:42:44,635
Speaker 0: Yeah, it's not good times Your brain.

649
00:42:44,716 --> 00:42:51,516
Speaker 1: so the even if we were even if like Companies committed to having human curation There is a human toll.

650
00:42:51,837 --> 00:42:52,438
Speaker 1: that is.

651
00:42:52,779 --> 00:42:55,667
Speaker 0: even South Park had the episode that showed like all the like.

652
00:42:55,708 --> 00:42:58,222
Speaker 0: you know they showed Kids in like a foreign country.

653
00:42:58,242 --> 00:43:15,789
Speaker 1: you know moderating The year I was the like deputy manager of the packs like live streaming team the people who would literally sit during packs and Moderate and curate the twitch comments on our live streams like I saw some shit.

654
00:43:16,653 --> 00:43:18,603
Speaker 1: That was really depressing to do.

655
00:43:18,623 --> 00:43:22,178
Speaker 1: I Was blocking people so fast it was.

656
00:43:22,679 --> 00:43:30,085
Speaker 1: it was actually like honestly disturbing to deal with that And that was just for a few hours for a couple of nights once text only.

657
00:43:30,426 --> 00:43:31,690
Speaker 1: yeah text only.

658
00:43:32,154 --> 00:43:33,890
Speaker 1: I saw some shit that I can't forget.

659
00:43:34,758 --> 00:43:41,650
Speaker 1: So all that aside We have moved on to the idea like most companies have algorithmic ways to curate content.

660
00:43:41,690 --> 00:43:42,071
Speaker 0: now We're not.

661
00:43:42,131 --> 00:43:46,003
Speaker 0: this has worked really well for example for blocking spam in your email.

662
00:43:46,083 --> 00:43:48,390
Speaker 0: Yeah curate your emails now.

663
00:43:48,651 --> 00:43:49,413
Speaker 1: Here's the problem.

664
00:43:49,714 --> 00:43:58,510
Speaker 1: the reason it works for spam blocking and emails is that one as a society we all agreed We'd rather miss a legit email than ever see spam again.

665
00:43:58,671 --> 00:44:02,930
Speaker 0: Yeah, I look at my spam folder like whenever I remember to once in a while just to double-check.

666
00:44:03,632 --> 00:44:04,776
Speaker 0: I see some stuff in there.

667
00:44:05,077 --> 00:44:14,726
Speaker 0: usually it's like a newsletter that I tried to unsubscribe to and failed or An email from someone weird yep, but it's a real person, but you know what.

668
00:44:14,787 --> 00:44:15,770
Speaker 1: even then I'm willing.

669
00:44:16,153 --> 00:44:16,537
Speaker 0: I don't get.

670
00:44:16,617 --> 00:44:21,889
Speaker 1: I don't care like with phone calls I don't get spam phone calls cuz I'm willing just not ever answer my phone again.

671
00:44:22,170 --> 00:44:29,190
Speaker 1: Yeah, like I just a white list only anyway, but who mod the people who monetize email.

672
00:44:30,213 --> 00:44:35,883
Speaker 1: They are served by You not seeing spam because they don't get a cut of the spam.

673
00:44:35,923 --> 00:44:36,886
Speaker 1: the spam just angers you.

674
00:44:36,906 --> 00:44:37,709
Speaker 1: you lose their service.

675
00:44:37,749 --> 00:44:40,827
Speaker 1: less Mmm, but with say YouTube is a good example.

676
00:44:40,847 --> 00:44:42,675
Speaker 1: with YouTube How does YouTube make money?

677
00:44:42,935 --> 00:44:47,008
Speaker 1: YouTube makes more money if you watch more videos.

678
00:44:47,109 --> 00:44:47,329
Speaker 0: yep?

679
00:44:47,790 --> 00:44:51,613
Speaker 1: Just the more hours you watch content the more money They make mm-hmm.

680
00:44:51,934 --> 00:44:57,010
Speaker 1: so they have incentive to get you an individual user to watch as much YouTube as possible.

681
00:44:57,597 --> 00:44:58,345
Speaker 1: So how do they do this?

682
00:44:58,406 --> 00:44:58,669
Speaker 1: they use?

683
00:44:58,850 --> 00:45:07,339
Speaker 1: Algorithms to look at you and try to figure out based on the stuff this person likes and the videos They've watched and what other people like them like.

684
00:45:07,881 --> 00:45:10,970
Speaker 1: what video could we recommend right after they finish this watching this video?

685
00:45:11,550 --> 00:45:13,689
Speaker 1: To where they'll just keep watching forever right?

686
00:45:13,709 --> 00:45:14,151
Speaker 0: yeah They don't.

687
00:45:14,211 --> 00:45:16,737
Speaker 0: they tune this algorithm a court right.

688
00:45:16,778 --> 00:45:21,430
Speaker 0: the the the gmail spam algorithm is tuned to be like all right.

689
00:45:22,051 --> 00:45:25,702
Speaker 0: Only show this person real emails and not spam emails right.

690
00:45:25,742 --> 00:45:29,112
Speaker 0: we want to you know get the garbage emails in the trash as much As possible.

691
00:45:29,393 --> 00:45:31,661
Speaker 0: the YouTube recommendation algorithm is tuned.

692
00:45:32,042 --> 00:45:34,350
Speaker 0: make this person watch as much YouTube as possible.

693
00:45:34,450 --> 00:45:41,750
Speaker 0: It's not tuned to make this person as happy as possible or make this person as good as possible or anything like that.

694
00:45:41,890 --> 00:45:50,867
Speaker 0: It's just make this person watch as much YouTube as we can get them to watch make them stay on the site And now that such it exceeds in doing what it says it wants to do.

695
00:45:51,089 --> 00:45:55,909
Speaker 1: now Let's skip the other problem that just came up from this.

696
00:45:55,929 --> 00:46:02,005
Speaker 1: if You design something like that on one hand you are providing a stream of content.

697
00:46:02,106 --> 00:46:05,213
Speaker 1: if like say it works perfectly the algorithm is 100% accurate.

698
00:46:05,634 --> 00:46:13,915
Speaker 1: I watched some ridiculous like Sonic the Hedgehog Neil, Sisorega matchup, and then it immediately recommends some weird Garfield he-man mashup.

699
00:46:13,975 --> 00:46:16,763
Speaker 1: like it 100% knows what rim wants to see next.

700
00:46:16,863 --> 00:46:19,490
Speaker 0: yeah, that's great right definitely where he wants to see.

701
00:46:20,531 --> 00:46:30,490
Speaker 1: But is that not also creating a highly addictive stream of content That could cause addictive behaviors in someone like rim?

702
00:46:31,112 --> 00:46:36,090
Speaker 1: What's the difference between designing a game that people play a lot because they like it and designing a game that people play a lot?

703
00:46:36,290 --> 00:46:37,088
Speaker 1: Because they're addicted to it?

704
00:46:37,351 --> 00:46:40,224
Speaker 1: And is it different if you design the thing to addict people in the first place?

705
00:46:40,586 --> 00:46:41,470
Speaker 1: same can of worms.

706
00:46:41,911 --> 00:46:47,732
Speaker 0: There's a big can of worms around the word addiction to right cuz like addicted to a video game isn't the same as being addicted To heroin.

707
00:46:48,133 --> 00:46:48,694
Speaker 1: ah though.

708
00:46:48,714 --> 00:46:49,516
Speaker 1: They're.

709
00:46:49,596 --> 00:46:53,626
Speaker 1: they're clinically shockingly similar, but also not well.

710
00:46:53,846 --> 00:47:00,368
Speaker 1: the way that they're not is Interesting because the physical heroin addiction is actually way less dangerous than most people realize.

711
00:47:01,413 --> 00:47:04,226
Speaker 1: It's easier to get off a hair, and then they get off a say alcohol.

712
00:47:04,567 --> 00:47:04,949
Speaker 0: That's true.

713
00:47:06,412 --> 00:47:11,790
Speaker 1: But anyway, I want to skip that conversation of what if the algorithms actually worked perfectly.

714
00:47:11,870 --> 00:47:15,782
Speaker 1: It's still a problem because the algorithms don't work perfectly.

715
00:47:15,802 --> 00:47:21,315
Speaker 1: the garbage the algorithms are causing Specific real harms.

716
00:47:21,596 --> 00:47:24,305
Speaker 1: that arguably led to that massive shooting in New Zealand.

717
00:47:24,425 --> 00:47:25,388
Speaker 1: right it just happened.

718
00:47:25,629 --> 00:47:30,951
Speaker 0: so the One major problem is the way that most of them work including the ones that are like Amazon You.

719
00:47:30,991 --> 00:47:31,955
Speaker 0: this is what you should buy.

720
00:47:31,975 --> 00:47:32,557
Speaker 0: is they?

721
00:47:32,577 --> 00:47:36,731
Speaker 0: just look at what other people who do the same things as you also did Right?

722
00:47:36,791 --> 00:47:43,593
Speaker 0: so you know if I watch a lot of kpop videos, and I just watched one and that video I just watched.

723
00:47:43,633 --> 00:47:44,557
Speaker 0: it looks at the says all right.

724
00:47:44,777 --> 00:47:48,150
Speaker 0: who else watched similar videos to Scott and also watch this video?

725
00:47:48,190 --> 00:47:49,629
Speaker 0: He just watched all right.

726
00:47:49,951 --> 00:47:54,122
Speaker 0: What video did a lot of those people watch that Scott hasn't seen yet.

727
00:47:54,363 --> 00:47:56,930
Speaker 0: oop this one like almost everyone who watches the first?

728
00:47:57,050 --> 00:48:00,285
Speaker 0: Video Scott just watched also watch this, but Scott didn't watch it.

729
00:48:00,305 --> 00:48:01,732
Speaker 0: yet there you go Right.

730
00:48:02,154 --> 00:48:13,646
Speaker 0: so the problem is is if you hang in a community Say a video game community, and you watch some Mario video And it just turns out that there is a large community of Mario people who are also.

731
00:48:13,727 --> 00:48:14,650
Speaker 0: I don't know Nazis.

732
00:48:15,534 --> 00:48:21,563
Speaker 0: Then the Mario video will at the end suggest to you hey You know there's a lot of Mario people out there who are Nazis.

733
00:48:21,583 --> 00:48:26,155
Speaker 0: you should check out this Nazi shit and This one you might say.

734
00:48:26,717 --> 00:48:29,265
Speaker 1: why would so many Mario fans be into Nazis?

735
00:48:29,285 --> 00:48:31,090
Speaker 1: well you saw a gamergate right the out there.

736
00:48:31,230 --> 00:48:31,752
Speaker 1: It's a problem.

737
00:48:31,873 --> 00:48:36,370
Speaker 0: algorithm can't actually tell what's in the content of the video at really much at all.

738
00:48:36,491 --> 00:48:37,398
Speaker 0: It's mostly just.

739
00:48:37,761 --> 00:48:38,829
Speaker 0: this is a video ID.

740
00:48:39,030 --> 00:48:40,416
Speaker 0: This is also a video ID.

741
00:48:40,456 --> 00:48:43,690
Speaker 0: the correlation between the viewership of both of these videos is high.

742
00:48:44,233 --> 00:48:47,509
Speaker 0: Someone has watched video a. I will recommend video B. I don't know what's in them.

743
00:48:47,750 --> 00:48:50,338
Speaker 1: This is why if you watch it is blind.

744
00:48:50,539 --> 00:49:12,170
Speaker 1: any video on the internet about like a recent movie Anything that gets like Nazis and Gomer Gators and all the shitlords active For various reasons those people tend to be the kinds of people who watch a lot of YouTube videos So they tend their tastes tend to be over represented and overlap heavily with other non shithead non Nazi people.

745
00:49:12,613 --> 00:49:17,156
Speaker 1: But if you watch any content stream on YouTube It's only a few videos before.

746
00:49:17,477 --> 00:49:19,463
Speaker 1: you get like some Jordan Peterson nonsense.

747
00:49:19,663 --> 00:49:21,248
Speaker 1: you get some anti-feminist nonsense.

748
00:49:21,268 --> 00:49:23,478
Speaker 1: you get straight-up Nazi recruitment video right.

749
00:49:23,498 --> 00:49:31,910
Speaker 0: there are lots of cases where for example Maybe you are really into gardening right and you go find some nice gardening videos.

750
00:49:32,031 --> 00:49:38,927
Speaker 0: Well, it just so happens that on the internet They're a large part of the community for gardening are people who want to grow their own food because they're all like.

751
00:49:39,208 --> 00:49:40,734
Speaker 1: you know You're going with this.

752
00:49:40,794 --> 00:49:42,320
Speaker 0: I have specific examples of this.

753
00:49:42,380 --> 00:49:48,082
Speaker 0: they're all like hippie-dippie right and they're you know They're all into like clean eating and some other nonsense.

754
00:49:48,384 --> 00:49:49,890
Speaker 0: Oh, and they're also anti-vax people.

755
00:49:49,970 --> 00:49:59,035
Speaker 0: So you just looked up your innocent gardening because you wanted your flower to grow and by the way vaccines will kill your children, so Conspiracy type.

756
00:49:59,075 --> 00:50:06,405
Speaker 1: people who arguably have their own mental disorders Tend to go down YouTube rabbit holes and further reinforce this.

757
00:50:06,425 --> 00:50:20,542
Speaker 1: so YouTube Tends to just funnel people toward a relatively small number of Extremely toxic rabbit holes and then just keep them there forever Because that generates a lot of controversy and a lot of views.

758
00:50:20,884 --> 00:50:30,630
Speaker 1: and the algorithm says wow Those white kids started watching a lot more Mario videos and a lot of Mario adjacent videos and here's Hitler, right?

759
00:50:30,790 --> 00:50:35,090
Speaker 0: So the thing is like we said having humans do this is not is not perfect.

760
00:50:35,431 --> 00:50:37,038
Speaker 0: Having algorithms do is even worse.

761
00:50:37,560 --> 00:50:40,030
Speaker 0: and the thing is there is a solution to this.

762
00:50:40,090 --> 00:50:45,290
Speaker 0: That's sort of obvious, but no one really implements it and if they do they do it reluctantly.

763
00:50:45,290 --> 00:50:48,530
Speaker 1: I'm curious what you think because I have a lot of ideas about how to handle right?

764
00:50:48,650 --> 00:50:50,741
Speaker 0: Well, I mean, it's not nothing's ever gonna be perfect perfect.

765
00:50:50,782 --> 00:50:52,350
Speaker 0: But the thing is it's like.

766
00:50:54,384 --> 00:50:54,550
Speaker 0: You know.

767
00:50:54,610 --> 00:51:00,272
Speaker 0: You can't handle tons and tons of content with just human beings and there is the human cost for those human beings who would be Doing it.

768
00:51:00,353 --> 00:51:00,574
Speaker 0: Yep.

769
00:51:00,856 --> 00:51:03,490
Speaker 0: The algorithm is clearly fuck not gonna do it, right?

770
00:51:03,871 --> 00:51:08,267
Speaker 0: You need some sort of combination of the to a human wielding an algorithm.

771
00:51:08,347 --> 00:51:11,657
Speaker 0: Yes, right Editorial input into an algorithm.

772
00:51:11,697 --> 00:51:23,580
Speaker 0: So it's like, okay listen YouTube algorithm, you know I see that, you know, these people have watched this but seriously just like no Nazis ever right seriously No anti-vax shit ever doesn't matter what other people watch.

773
00:51:23,821 --> 00:51:25,628
Speaker 0: just don't recommend this to anyone ever.

774
00:51:25,688 --> 00:51:27,413
Speaker 0: just you know This whole swath.

775
00:51:27,453 --> 00:51:32,126
Speaker 0: just get it out of here, right some editorial human input into the algorithm.

776
00:51:32,427 --> 00:51:41,533
Speaker 0: that will sort of you know Carve things up in a mostly as good as we can way constantly work on improving it all the time Right.

777
00:51:41,854 --> 00:51:46,272
Speaker 0: So hopefully, you know, you won't have bad shit like this happen Now.

778
00:51:46,333 --> 00:51:49,370
Speaker 0: the reason so most companies are willing to do this?

779
00:51:49,410 --> 00:51:51,198
Speaker 0: Well, no, there are cases where they do this.

780
00:51:51,238 --> 00:51:53,328
Speaker 0: For example, they do it on Google search.

781
00:51:53,669 --> 00:51:55,497
Speaker 0: true Right, Google search does this.

782
00:51:55,758 --> 00:51:58,770
Speaker 0: they just do it as little as possible, right?

783
00:51:59,071 --> 00:52:06,104
Speaker 0: When people are searching for like do stuff and Nazi stuff was coming up They like they went in and they put in a fix for that.

784
00:52:06,245 --> 00:52:07,430
Speaker 0: It's like they can do it.

785
00:52:07,771 --> 00:52:16,364
Speaker 0: It's like they're just really hesitant to do it because they believe in algorithms They have like its philosophy of not interfering of being fair with the algorithm.

786
00:52:16,424 --> 00:52:18,270
Speaker 0: I think other people have the opposite flow.

787
00:52:18,370 --> 00:52:21,077
Speaker 0: No one has this mixed middle philosophy.

788
00:52:21,097 --> 00:52:23,885
Speaker 1: I think it's more nuanced and more insidious than that.

789
00:52:23,945 --> 00:52:31,667
Speaker 1: I think part of the problem is that These platforms not so much regular old Google search because who Google searches for things anymore.

790
00:52:31,707 --> 00:52:32,430
Speaker 1: They type into good.

791
00:52:32,690 --> 00:52:35,584
Speaker 1: I think most people type into Google just to get the first link.

792
00:52:35,865 --> 00:52:44,930
Speaker 1: Yeah, but the the monetization models of these platforms Kind of don't want to turn away revenue.

793
00:52:45,492 --> 00:52:46,374
Speaker 1: They want them they.

794
00:52:46,575 --> 00:53:06,590
Speaker 1: I think they want the shitheads and Nazis to keep using the platform and just not cause Advertisers to stop advertising on the rest of the platform Mmm, I think they don't want to turn away audience and every time they exhibit editorial control It'll cause quote-unquote controversy and they'll lose some percentage of the people who would use their platform.

795
00:53:07,352 --> 00:53:13,570
Speaker 1: And they'll also now have set a precedent to where when some other group complains they now have editorial control.

796
00:53:13,731 --> 00:53:16,049
Speaker 1: It opens up to potential legal liability and all sorts of stuff.

797
00:53:16,512 --> 00:53:19,830
Speaker 1: There's a lot of reasons why they don't want to exhibit editorial control.

798
00:53:20,251 --> 00:53:25,508
Speaker 1: They'd rather be able to play in the platform and only react as opposed to be proactive.

799
00:53:25,528 --> 00:53:30,909
Speaker 0: the platform That'd be like if you know, you're at a party at my house and some Nazis came over and you blame my house.

800
00:53:31,231 --> 00:53:32,797
Speaker 0: Yep, it's like not my house's fault.

801
00:53:32,858 --> 00:53:35,449
Speaker 0: It's like you decide who comes to your party and not it's your house.

802
00:53:36,011 --> 00:53:37,377
Speaker 0: It's not the house's fault.

803
00:53:37,618 --> 00:53:38,643
Speaker 0: if Nazis are in there.

804
00:53:38,663 --> 00:53:40,350
Speaker 0: That's because you're a Nazi sympathize.

805
00:53:40,450 --> 00:53:43,620
Speaker 1: Twitter will not just say white supremacy is banned.

806
00:53:44,021 --> 00:53:44,743
Speaker 1: They just won't do it.

807
00:53:44,924 --> 00:53:45,405
Speaker 0: They can.

808
00:53:45,606 --> 00:53:46,849
Speaker 1: they could trivially say it.

809
00:53:47,371 --> 00:53:48,796
Speaker 1: They could also trivially enforce it.

810
00:53:49,097 --> 00:53:50,703
Speaker 1: they refuse to that.

811
00:53:50,984 --> 00:53:52,690
Speaker 1: we disagree on the first principle.

812
00:53:53,132 --> 00:53:55,382
Speaker 1: They tend to these tech companies tell you what's like.

813
00:53:55,422 --> 00:53:57,210
Speaker 0: we believe in free speech, right?

814
00:53:57,450 --> 00:54:03,370
Speaker 0: The thing is free speech means the government coming in and saying white supremacist talk is not okay.

815
00:54:03,551 --> 00:54:09,066
Speaker 0: I actually don't want anyone to go to jail purely for say waving a Nazi flag.

816
00:54:09,086 --> 00:54:10,350
Speaker 0: That should not put you in jail.

817
00:54:10,834 --> 00:54:11,864
Speaker 0: It might get you beat up.

818
00:54:11,884 --> 00:54:12,450
Speaker 0: That's okay.

819
00:54:13,675 --> 00:54:18,112
Speaker 0: Right doing you know, if you if you then, you know act on any of your Nazi beliefs Yeah, you should be.

820
00:54:18,433 --> 00:54:20,741
Speaker 1: you know, waving the flag in so many.

821
00:54:21,042 --> 00:54:25,876
Speaker 1: if the thing you're doing can be construed as a threat Yeah Which often it can be could be.

822
00:54:26,217 --> 00:54:33,285
Speaker 0: but purely just waving a flag that happens to be a flag of evil Should not get you in trouble with the government.

823
00:54:33,607 --> 00:54:42,429
Speaker 0: First Amendment I believe in that but it should get you banned from my house then from any place That's private place where anyone has the power to kick you out of.

824
00:54:42,932 --> 00:54:46,650
Speaker 0: Basically, you should be confined to your own home because nobody will allow you into their home.

825
00:54:46,912 --> 00:54:47,979
Speaker 0: You can't do it in the grocery store.

826
00:54:47,999 --> 00:54:48,342
Speaker 0: Go sir.

827
00:54:48,362 --> 00:54:49,470
Speaker 0: Kicks you out, right?

828
00:54:49,910 --> 00:54:52,065
Speaker 1: Well, I'm gonna take a very more direct approach here can't?

829
00:54:52,145 --> 00:54:52,286
Speaker 0: can't?

830
00:54:52,306 --> 00:54:59,151
Speaker 0: go on Twitter These slippery throw private places that have the absolute right to decide what can't get a job because no one has no one has to hire You.

831
00:54:59,171 --> 00:55:00,255
Speaker 0: it's not a protected class.

832
00:55:00,275 --> 00:55:04,450
Speaker 1: a slippery slope here can be pretty narrowly defined to not be a slippery slope.

833
00:55:04,952 --> 00:55:15,869
Speaker 1: You could just say a very small list of certain fascist white supremacist misogynist and hateful ideologies are just banned from these private platforms and That could be the end of the slope.

834
00:55:16,694 --> 00:55:19,690
Speaker 1: Let all the other shitty stuff just happen and get dealt with.

835
00:55:20,791 --> 00:55:21,435
Speaker 0: Pudges a goat.

836
00:55:21,475 --> 00:55:22,600
Speaker 0: see it's like all right.

837
00:55:22,621 --> 00:55:23,947
Speaker 0: They put up a goat.

838
00:55:23,987 --> 00:55:24,430
Speaker 0: see again.

839
00:55:24,570 --> 00:55:28,330
Speaker 0: You're gonna take a guess, you know, at least it wasn't a swastika.

840
00:55:28,852 --> 00:55:43,216
Speaker 1: yep, but the algorithms because of this laissez-faire approach are Basically funneling red like radicalizing content for these very narrow and very violent ideologies into the minds of children like.

841
00:55:43,537 --> 00:55:48,027
Speaker 1: PewDiePie is honestly a white supremacist advocate who is probably tainted a generation.

842
00:55:48,047 --> 00:56:00,379
Speaker 1: hmm and This is only going to continue until the platforms take a stand as we saw with the simplest example Alex Jones that crazy guy Dangerous person cause dangerous things to happen.

843
00:56:00,600 --> 00:56:01,001
Speaker 0: nut job.

844
00:56:01,362 --> 00:56:05,677
Speaker 1: when Twitter and Facebook and YouTube banned him He basically disappeared overnight.

845
00:56:06,039 --> 00:56:07,023
Speaker 1: You didn't I'm sure.

846
00:56:07,043 --> 00:56:08,429
Speaker 0: his fans are still all into him.

847
00:56:08,991 --> 00:56:12,540
Speaker 1: Well, what seems to has happened is his hardest core.

848
00:56:12,580 --> 00:56:16,330
Speaker 1: crazy fans followed him to like whatever den of like shittiness.

849
00:56:16,431 --> 00:56:20,720
Speaker 1: His content is on now But the vast majority of his audience disappeared.

850
00:56:20,760 --> 00:56:23,650
Speaker 1: because really is people don't know how to use the internet that well.

851
00:56:24,071 --> 00:56:30,350
Speaker 1: They lack object permanence and especially the kinds of people who fall for this kind of conspiracy nut job nonsense.

852
00:56:31,192 --> 00:56:33,017
Speaker 1: Not that good at searching for stuff.

853
00:56:33,378 --> 00:56:43,529
Speaker 1: if you take these people off of a very small number of highly used platforms They disappear from the hearts and minds of most people and they lose their monetization stream.

854
00:56:44,574 --> 00:56:44,754
Speaker 1: They.

855
00:56:44,835 --> 00:56:48,330
Speaker 1: it basically ends them without the government having to get involved.

856
00:56:48,691 --> 00:56:56,536
Speaker 1: All you need is for YouTube Facebook Twitter and maybe like two other platforms to agree to ban like Specific fascist stuff.

857
00:56:57,219 --> 00:56:59,570
Speaker 1: and they disappear from most of the internet, right?

858
00:56:59,670 --> 00:57:14,292
Speaker 0: The internet itself in the web allows anyone with access and enough money to turn on a computer and host it Right get an IP address to publish any content They want to the internet and there's nothing you can do to stop them really and there shouldn't be really anything you do to Stop them.

859
00:57:14,493 --> 00:57:17,270
Speaker 0: Yeah, this is child porn or something like that, right?

860
00:57:18,472 --> 00:57:23,033
Speaker 0: But the thing is is actually quite a high bar to actually do that It's not.

861
00:57:23,194 --> 00:57:25,142
Speaker 0: most people are not capable of doing that.

862
00:57:25,302 --> 00:57:26,467
Speaker 0: They need some sort of help.

863
00:57:26,507 --> 00:57:27,190
Speaker 0: They need a YouTube.

864
00:57:27,411 --> 00:57:30,249
Speaker 0: Otherwise, you know, they would never be able to post a comment.

865
00:57:30,731 --> 00:57:47,170
Speaker 0: Anyway, they need this bar crossed for them by someone else and thus these organizations these social networks or whatever You want to call them platforms, you know YouTube Facebook Twitter Reddit all these right are simply Helping people get over that bar.

866
00:57:47,772 --> 00:57:50,423
Speaker 0: Right, and if you they didn't help those you'll get over that bar.

867
00:57:50,463 --> 00:57:52,050
Speaker 0: Those people would be on the other side.

868
00:57:52,933 --> 00:57:56,868
Speaker 0: So stop helping people over who suck only good people on this side.

869
00:57:57,129 --> 00:58:03,369
Speaker 1: Yep It's a pretty easy trivial stance to make and the only people you're actually gonna anger are Nazis.

870
00:58:04,834 --> 00:58:10,758
Speaker 0: so And your and your investors who are probably Nazis.

871
00:58:10,899 --> 00:58:11,280
Speaker 1: Yep.

872
00:58:11,761 --> 00:58:19,810
Speaker 0: Well like Twitter is a particularly wealthy and probably white supremacist VC investors I assume they're all white Silicon Valley douchebags.

873
00:58:19,910 --> 00:58:31,807
Speaker 1: Twitter is such a weird specific example because Twitter seems to go out of its way to protect white supremacists on the platform like Beyond what would be coincidence and it's really bothering me.

874
00:58:31,827 --> 00:58:58,360
Speaker 1: Mmm like if policies tend to get enforced more against people calling Nazis out than actual Nazis and And Twitter I think relies too much on a lot of the traffic on Twitter is Nazis and if you kick them out Twitter's metrics go way down in a hurry and Twitter can make money but can't make VC money and I feel like there's a really perverse Incentive there to keep the Nazis on the platform for the controversy.

875
00:58:58,360 --> 00:59:03,200
Speaker 0: The biggest problem is you've always we want to leave Twitter and people keep trying to make other Twitter's that are just fine.

876
00:59:03,521 --> 00:59:11,952
Speaker 1: Those Twitter's always fall into two categories either one not good enough yet for people to migrate to en masse or two They were created by the people who are banned from.

877
00:59:11,992 --> 00:59:19,300
Speaker 0: there are actually some good Non-twitters that have been around and people just can't go to migrate because you can't get everyone to leave all at once.

878
00:59:19,481 --> 00:59:20,385
Speaker 0: Yep, you got to get it.

879
00:59:20,445 --> 00:59:22,757
Speaker 0: It's like if I just go alone and bring a few friends with me.

880
00:59:22,777 --> 00:59:23,460
Speaker 0: That's not good enough.

881
00:59:23,540 --> 00:59:28,737
Speaker 0: It's like I'm there because the other good people are still there and they're not leaving so I can't leave.

882
00:59:28,877 --> 00:59:32,280
Speaker 0: and if they do leave It's like we need everyone to get up and go all together.

883
00:59:32,360 --> 00:59:42,437
Speaker 1: Yep, but it's even worse than that because I use Twitter not just as a social media network which is the primary way I use it, but I also use it as a Content distribution platform to a broader audience of people.

884
00:59:42,457 --> 00:59:44,586
Speaker 1: Mm-hmm If I just like chat with my.

885
00:59:44,606 --> 00:59:44,948
Speaker 0: I want to.

886
00:59:45,008 --> 00:59:47,940
Speaker 0: I would delete my Facebook except we got like a geek nights page there.

887
00:59:49,262 --> 00:59:50,567
Speaker 1: No, I don't have a Facebook.

888
00:59:50,587 --> 00:59:51,189
Speaker 0: I gotta keep my.

889
00:59:51,309 --> 00:59:53,336
Speaker 0: I gotta keep my that geek night's Facebook page up.

890
00:59:53,818 --> 00:59:56,546
Speaker 0: Yep Someone looks at it.

891
00:59:57,209 --> 00:59:58,777
Speaker 1: All right, it's been over an hour and I'm hungry.

892
00:59:58,797 --> 00:59:59,440
Speaker 1: Let's just stop here.

893
01:00:05,814 --> 01:00:08,340
Speaker 1: This has been geek nights with rim and Scott special.

894
01:00:08,400 --> 01:00:13,180
Speaker 1: Thanks to DJ pretzel for the opening music cat leave for web design and Brando K for the logos.

895
01:00:13,461 --> 01:00:15,428
Speaker 0: Be sure to visit our website at front row.

896
01:00:15,468 --> 01:00:18,480
Speaker 0: crew calm for show notes discussion news and more.

897
01:00:18,760 --> 01:00:26,160
Speaker 1: Remember geek nights is not one but four different shows sci-tech Mondays gaming Tuesdays and make comic Wednesdays and indiscriminate Thursdays.

898
01:00:26,521 --> 01:00:29,695
Speaker 0: Geek nights is distributed under a Creative Commons attribution 3.0 license.

899
01:00:30,961 --> 01:00:34,050
Speaker 0: Geeknights is recorded live with no studio and no audience.

900
01:00:34,231 --> 01:00:35,695
Speaker 0: But unlike those other late shows.

901
01:00:35,836 --> 01:00:37,140
Speaker 0: It's actually recorded at night.

902
01:00:40,361 --> 01:01:00,773
Speaker 1: And the patreon patrons for this non algorithmically curated list of people or this episode of geek nights Remember that I only ever do this in one take and some of you have been messing with me lately looking at you Chris Thomas rhyme or Han and Anyway without any further ado the patrons Craig Oliver Alan Joyce, Heidi McNichol Just like a dude guy chart obviously linkagey Jennifer Hitchcock.

903
01:01:00,793 --> 01:01:01,095
Speaker 1: Chris made.

904
01:01:01,115 --> 01:01:01,899
Speaker 1: give my state a calm.

905
01:01:01,919 --> 01:01:05,975
Speaker 1: J Bad scooter lonely Roberto Kingsley Shawn Yeager Matthew Smith Nicholas Brando, mr.

906
01:01:05,995 --> 01:01:06,176
Speaker 1: Strong.

907
01:01:06,196 --> 01:01:14,551
Speaker 1: distraction for two one creations Chris Thomas rhyme or Han and Shervin von Horrell reori Rochelle Montanona super boy sailor Vista Joe sure Joe star Clinton Walton.

908
01:01:14,652 --> 01:01:19,657
Speaker 1: written from New Zealand Ryan parent Robenlander Finn Daniel revenue Sean Klein Chris rhyme er and Thomas.

909
01:01:19,879 --> 01:01:19,980
Speaker 1: on.

910
01:01:20,722 --> 01:01:23,051
Speaker 1: Like I said, I'll see you guys at Zen Chi con.

911
01:01:23,231 --> 01:01:25,740
Speaker 1: I'll be there pretty much just Saturday in part of Sunday.

912
01:01:25,882 --> 01:01:26,939
Speaker 1: But you see the schedule.

913
01:01:27,985 --> 01:01:29,360
Speaker 1: Yeah, pexy's is gonna be awesome.

914
01:01:29,541 --> 01:01:33,160
Speaker 1: I will probably be hanging out in forcing in maine theater at night, but you never know.

915
01:01:33,441 --> 01:01:35,048
Speaker 1: I might get an interesting or different ship.

916
01:01:35,470 --> 01:01:37,398
Speaker 1: But now I leave you with.

917
01:01:40,033 --> 01:01:40,939
Speaker 0: I'm your dad.

918
01:01:42,042 --> 01:01:44,599
Speaker 0: Better like it cuz I'm your new dad.

919
01:01:45,384 --> 01:01:46,571
Speaker 0: You're gonna like it.

920
01:01:46,651 --> 01:01:47,919
Speaker 0: Your old dad is out.

921
01:01:50,257 --> 01:01:53,736
Speaker 0: The new dad is in No appointments.

922
01:01:53,856 --> 01:01:59,218
Speaker 0: I keep office hours for five to seven Tuesdays and Thursdays.

923
01:01:59,358 --> 01:02:00,523
Speaker 0: be there on time.

924
01:02:00,543 --> 01:02:02,410
Speaker 0: I'm your new dad.

925
01:02:03,114 --> 01:02:04,300
Speaker 0: You better like it.

926
01:02:04,763 --> 01:02:05,829
Speaker 0: I'm your new dad.

927
01:02:08,364 --> 01:02:09,878
Speaker 0: It's your shit together.

928
01:02:11,905 --> 01:02:15,585
Speaker 0: Now cut your hair Now.

929
01:02:15,625 --> 01:02:17,297
Speaker 0: don't care if you're a man or a woman.

930
01:02:19,142 --> 01:02:21,550
Speaker 0: Don't care if you're a boy or your girl.

931
01:02:21,590 --> 01:02:22,393
Speaker 0: cut your hair.

932
01:02:22,955 --> 01:02:24,160
Speaker 0: cut your hair off.

933
01:02:25,203 --> 01:02:26,065
Speaker 0: I'm your dad.

934
01:02:26,507 --> 01:02:28,071
Speaker 0: Feel your skin back.

935
01:02:28,532 --> 01:02:29,636
Speaker 0: It feels bad.

936
01:02:30,237 --> 01:02:31,140
Speaker 0: I am your father.

937
01:02:32,543 --> 01:02:34,678
Speaker 0: You need to learn not to bother.

938
01:02:36,581 --> 01:02:37,884
Speaker 0: I got a recliner.

939
01:02:37,904 --> 01:02:39,628
Speaker 0: It's pretty good.

940
01:02:39,668 --> 01:02:43,878
Speaker 0: I got the money to buy it from your college fund.

941
01:02:44,058 --> 01:02:44,860
Speaker 0: I am your dad.

