1
00:00:08,700 --> 00:00:12,693
Speaker 1: It's Monday August 31st 2020.

2
00:00:12,693 --> 00:00:13,134
Speaker 1: I'm rim.

3
00:00:13,195 --> 00:00:15,703
Speaker 1: I'm Scott and this is geek nights tonight.

4
00:00:15,723 --> 00:00:17,509
Speaker 1: We are talking about biometrics.

5
00:00:18,752 --> 00:00:19,462
Speaker 0: Let's do this.

6
00:00:21,213 --> 00:00:26,036
Speaker 1: it's uh, it's a tough time right now because Right around now.

7
00:00:26,056 --> 00:00:35,326
Speaker 1: I mean year by year and all varies a little bit way to either be in Seattle About to fly to Seattle like this is the pecs time.

8
00:00:35,748 --> 00:00:36,410
Speaker 0: It's pretty rare.

9
00:00:36,470 --> 00:00:40,188
Speaker 0: You're gonna get a geek night's episode in August 31st, right like.

10
00:00:40,329 --> 00:00:43,848
Speaker 0: probably You may be next year, but probably not the year after.

11
00:00:43,888 --> 00:00:58,159
Speaker 1: hopefully This is when like all my calendar invites that I set to myself for like go to packs do things prepare slides Like they're all popping up in my feed up until this point the quarantine for all the trouble, you know it's not the best time like.

12
00:00:58,220 --> 00:01:07,150
Speaker 1: I'd rather not have to be quarantined, but We haven't actually missed that many major Conventions or events because the summer is actually usually kind of our downtime.

13
00:01:07,972 --> 00:01:21,646
Speaker 1: But we're now hitting the period where we would normally go to a major convention every month for like five months in a row sometimes multiple in a month and this is the point where I'm actually going to not have that happen.

14
00:01:21,686 --> 00:01:33,485
Speaker 0: for the first time in since 2008 Yeah, we pretty much been doing the same You know, not, you know daily routine has changed and things like that.

15
00:01:33,625 --> 00:01:41,325
Speaker 0: obviously but our Annual schedule, you know zoomed out the macro schedule has been pretty much the same for about ten years.

16
00:01:41,345 --> 00:01:42,649
Speaker 0: Yeah until now.

17
00:01:42,809 --> 00:01:44,401
Speaker 0: so There you go.

18
00:01:44,421 --> 00:01:52,876
Speaker 1: Yep I'd like I had a dream the other night where I was just like We were on our way to PAX West and then I was like, oh shit What hotel are we in?

19
00:01:53,117 --> 00:01:57,715
Speaker 1: and I couldn't remember and I didn't know what hotel we booked because we don't have a hotel We're not going to PAX West.

20
00:01:58,438 --> 00:02:00,204
Speaker 1: I was like, I'm in the Sheridan or the Red Lion.

21
00:02:00,485 --> 00:02:01,790
Speaker 1: Red Lion doesn't even exist anymore.

22
00:02:01,851 --> 00:02:02,638
Speaker 1: What's going on?

23
00:02:03,284 --> 00:02:03,930
Speaker 0: It's the motif.

24
00:02:05,191 --> 00:02:07,740
Speaker 0: We're in the one that has the new PAX tabletop in it.

25
00:02:07,780 --> 00:02:08,763
Speaker 1: That's where we usually are.

26
00:02:08,782 --> 00:02:10,208
Speaker 0: That's what I have.

27
00:02:10,369 --> 00:02:11,354
Speaker 0: one year We've been in it.

28
00:02:11,575 --> 00:02:11,917
Speaker 0: Yep.

29
00:02:12,480 --> 00:02:15,840
Speaker 1: That's where we would probably be again Probably yes.

30
00:02:16,467 --> 00:02:16,690
Speaker 1: Yeah.

31
00:02:16,790 --> 00:02:22,025
Speaker 1: So now now it's the weird time where there are things I'm missing that I would normally be doing.

32
00:02:22,065 --> 00:02:26,254
Speaker 1: that are big things that are like Milestones of the year.

33
00:02:26,334 --> 00:02:28,942
Speaker 1: PAX always ends summer for me and now there's no PAX.

34
00:02:29,383 --> 00:02:38,610
Speaker 0: So either summer's gonna go on forever, which I'll take that Okay Yeah, but you know, I mean, it's just people have to get ready.

35
00:02:39,131 --> 00:02:43,585
Speaker 0: I mean, even though it's been many months already, I think you know, it's like, okay.

36
00:02:43,746 --> 00:02:44,548
Speaker 0: Everything's different.

37
00:02:44,588 --> 00:02:55,762
Speaker 0: now People have to accept that like yeah On the other side is not gonna be going back to what you had before Not for a long time.

38
00:02:55,822 --> 00:02:56,667
Speaker 0: At least I don't know.

39
00:02:56,727 --> 00:02:58,114
Speaker 0: there isn't Like.

40
00:02:58,174 --> 00:03:09,232
Speaker 0: some things will probably be able to return to the what they were right But the point is is that it's not like, you know, let's say we get past the virus and get past fascism somehow in 2020.

41
00:03:09,232 --> 00:03:10,282
Speaker 1: Oh, yeah, it's not like.

42
00:03:10,343 --> 00:03:11,050
Speaker 1: oh everything's fixed.

43
00:03:11,050 --> 00:03:16,458
Speaker 0: 2022 is not gonna suddenly look like 2018 new or 24 or 2014 or you know any of the years of the past 10 years, right?

44
00:03:20,450 --> 00:03:20,912
Speaker 0: It's gonna be.

45
00:03:21,113 --> 00:03:22,218
Speaker 0: it's gonna be a different look.

46
00:03:22,459 --> 00:03:22,861
Speaker 0: Yeah, right.

47
00:03:23,082 --> 00:03:24,809
Speaker 0: You don't go get a makeover and come out.

48
00:03:25,151 --> 00:03:34,608
Speaker 0: It's like oh, I'm getting a makeover right now, you know, looking bad looking good changing things up You know, whatever you don't come out on the other side looking exactly the same as you went in.

49
00:03:36,930 --> 00:03:38,616
Speaker 0: Like that doesn't happen.

50
00:03:38,997 --> 00:03:48,568
Speaker 1: Yep, some things whatever whatever your life situation is except that now yep, especially because where there's a long haul in the u.s.

51
00:03:48,629 --> 00:03:53,824
Speaker 1: So Even like vaccines and things like there aren't gonna be a lot of cons next year.

52
00:03:53,945 --> 00:03:55,430
Speaker 0: If any we'll see.

53
00:03:56,198 --> 00:03:57,170
Speaker 1: Yeah, we'll see how it all goes.

54
00:03:57,511 --> 00:04:03,570
Speaker 1: But there is a lot of tech news and we got to keep milking this Apple story because it's just growing and growing and stuff.

55
00:04:04,412 --> 00:04:13,583
Speaker 0: So the first thing I got to say about the Apple story is obviously this brewing has only was sort of started at that Congressional hearing and only went up since right.

56
00:04:14,145 --> 00:04:18,707
Speaker 0: and I got to say well Apple is obviously none of the companies involved here.

57
00:04:18,767 --> 00:04:19,350
Speaker 0: good by the way.

58
00:04:19,390 --> 00:04:22,459
Speaker 1: Yeah, nobody's nobody like clearly the right one.

59
00:04:22,679 --> 00:04:24,665
Speaker 0: This is this is a bad guy battle here.

60
00:04:24,685 --> 00:04:29,248
Speaker 0: This is like, you know, dr Doom and you know Lex Luthor punching it out.

61
00:04:30,654 --> 00:04:39,490
Speaker 0: but the point is is that You know of all those four companies that were at that hearing right your Google your Facebook.

62
00:04:40,054 --> 00:04:42,590
Speaker 0: Right your Amazon and your Apple, right?

63
00:04:44,570 --> 00:04:50,310
Speaker 0: Apple is getting the the most blows here in the immediate aftermath, right?

64
00:04:51,274 --> 00:04:52,288
Speaker 0: And why is that?

65
00:04:52,870 --> 00:04:55,550
Speaker 0: Number one Apple has the most money of all those companies.

66
00:04:55,971 --> 00:05:00,986
Speaker 0: What's Apple's I think as the biggest market cap ever in history of any company something some trillion.

67
00:05:01,286 --> 00:05:11,550
Speaker 1: the entire like u.s Tech sector is bigger than many world like global regional economies right now Which let's not get into how the stock market doesn't reflect reality.

68
00:05:11,610 --> 00:05:13,820
Speaker 1: but anyway, Apple got a lot of wealth and capital.

69
00:05:13,940 --> 00:05:18,488
Speaker 0: Apple Apple is big right and also, right.

70
00:05:19,339 --> 00:05:28,170
Speaker 0: Apple is philosophically At least on paper right the enemy of those other three companies, right?

71
00:05:28,210 --> 00:05:31,109
Speaker 0: If you look at the four companies in the box, right?

72
00:05:32,710 --> 00:05:36,888
Speaker 0: Apple is the one where the customer is the customer.

73
00:05:36,908 --> 00:05:39,357
Speaker 1: Yeah Which doesn't always mean you're the right.

74
00:05:39,417 --> 00:05:42,248
Speaker 1: good guy like Amazon treats the customer on a pedestal.

75
00:05:42,308 --> 00:05:43,754
Speaker 0: get a row I was gonna say right.

76
00:05:43,894 --> 00:05:47,468
Speaker 0: so a Google and Facebook the customer is the product right.

77
00:05:47,910 --> 00:06:02,410
Speaker 0: on Amazon the customer is sort of the customer right but what Amazon does is they Exploit others in service of the customer while also taking the customers data to help it better exploit others.

78
00:06:03,092 --> 00:06:08,110
Speaker 0: Apple right serves the customer but sees itself as a luxury service.

79
00:06:08,491 --> 00:06:09,514
Speaker 0: So who do they exploit?

80
00:06:10,036 --> 00:06:10,939
Speaker 0: also the customer.

81
00:06:10,959 --> 00:06:11,842
Speaker 0: by making them pay.

82
00:06:11,882 --> 00:06:14,470
Speaker 0: they make everyone they work with pay, right?

83
00:06:14,770 --> 00:06:22,310
Speaker 0: It's like, you know instead of you know, taking your data and selling it or spying on you or any of those things, right?

84
00:06:22,670 --> 00:06:23,916
Speaker 0: We're just gonna make everyone pay.

85
00:06:23,976 --> 00:06:26,930
Speaker 0: developers pay customers overpay for my RAM.

86
00:06:27,456 --> 00:06:28,509
Speaker 0: everyone pay money.

87
00:06:29,197 --> 00:06:44,570
Speaker 0: right and You know will treat the customer nicely, but they don't treat anyone else nice just the cover That's and so because of that right that aligns the Google's and Facebook's of the world, you know against Apple.

88
00:06:44,751 --> 00:06:50,270
Speaker 0: Yeah, right, especially since they have to operate on Apple's platform, right?

89
00:06:50,510 --> 00:06:51,333
Speaker 0: So like I why does?

90
00:06:51,454 --> 00:06:54,426
Speaker 1: Apple's platform is not the majority is not a monopoly.

91
00:06:54,446 --> 00:06:57,970
Speaker 1: there are other platform Forms for smartphones and tablets and everything.

92
00:06:58,472 --> 00:07:04,673
Speaker 1: but Apple basically has complete control over people who are fully into their Ecosystem.

93
00:07:05,134 --> 00:07:10,480
Speaker 1: and the reality of the world is it's not easy for most people to switch ecosystems.

94
00:07:11,328 --> 00:07:17,001
Speaker 0: no but if you think about it, right Apple doesn't Depend on Amazon.

95
00:07:17,162 --> 00:07:22,625
Speaker 0: It's like they might use some Oz Computers or Google cloud compute or Microsoft Azure or stuff like that.

96
00:07:22,705 --> 00:07:24,010
Speaker 0: They don't have those resources.

97
00:07:24,171 --> 00:07:25,801
Speaker 0: I've heard like iCloud is hosted on those.

98
00:07:25,841 --> 00:07:33,010
Speaker 0: possibly it's unknown But I've definitely heard stories that Apple hosts their iCloud on other clouds, but they're not dependent.

99
00:07:33,090 --> 00:07:34,096
Speaker 0: They could just switch that up.

100
00:07:34,136 --> 00:07:34,940
Speaker 0: They can do their own.

101
00:07:34,981 --> 00:07:35,242
Speaker 0: They don't.

102
00:07:35,322 --> 00:07:36,629
Speaker 0: they're not dependent on that, right?

103
00:07:37,870 --> 00:07:46,470
Speaker 0: But so like no one has a hold on Apple No one can make Apple do anything that they don't want to do right, but Google's got to put Google Maps at iOS.

104
00:07:47,390 --> 00:07:50,805
Speaker 0: Facebook's app is the numbers like the number one way to use Facebook.

105
00:07:50,925 --> 00:08:00,749
Speaker 0: It's got to be on iOS If if Apple kicks Facebook out of the App Store Completely like the default Facebook app or the Facebook Messenger app or the Instagram app.

106
00:08:01,171 --> 00:08:06,389
Speaker 0: It's like some people would leave iOS to go get an Android phone to get the Facebook app.

107
00:08:06,670 --> 00:08:11,610
Speaker 1: I think a lot of people would use this as an excuse to say I guess I can't log into my Facebook account ever again.

108
00:08:11,630 --> 00:08:18,378
Speaker 0: Oh, right But Facebook would be totally but Huge, it's true.

109
00:08:18,438 --> 00:08:20,370
Speaker 1: I feel like to be real like real about it.

110
00:08:20,470 --> 00:08:31,589
Speaker 1: I think Facebook would lose basically all of its non Dangerously crazy users and all of its young users and all that would be left would be like you and on conspiracies and anti-vaxxers.

111
00:08:34,134 --> 00:08:40,164
Speaker 0: The point is is that Apple's got a hold on the other people they don't have and they got nothing on Apple.

112
00:08:40,184 --> 00:08:41,429
Speaker 0: So that's why the battle rages.

113
00:08:41,551 --> 00:08:43,806
Speaker 0: Okay, so what's the latest developments in the battle?

114
00:08:43,846 --> 00:08:44,289
Speaker 0: So first?

115
00:08:45,191 --> 00:08:48,290
Speaker 0: There was some shenanigans in with Apple's review process.

116
00:08:49,091 --> 00:08:59,273
Speaker 0: Someone reviewing the WordPress app basically misunderstood it and misunderstood work the difference between WordPress the software and wordpress.com the site and There was some tussle.

117
00:08:59,354 --> 00:09:01,520
Speaker 0: and then Apple said oops are bad and fixed it.

118
00:09:01,721 --> 00:09:04,790
Speaker 0: Yeah, so that's just a poor timing on.

119
00:09:05,771 --> 00:09:25,752
Speaker 0: You know something that happens relatively often in the Apple, you know App Store approval process Especially and it goes unnoticed when it happens to smaller apps of Apple not understanding the what the app is and getting their own policies wrong because they've got a whole team of people doing reviews who aren't necessarily Even

120
00:09:25,893 --> 00:09:26,575
Speaker 1: arguably.

121
00:09:26,695 --> 00:09:39,116
Speaker 1: I've seen people make an argument that sometimes what Apple has done to them is Be purposefully obtuse as an excuse to not let an app in where there's some other reason they don't want that have to be in the store.

122
00:09:39,766 --> 00:09:45,889
Speaker 0: sure so the It's just bad timing for them to get exposed on that thing.

123
00:09:46,212 --> 00:09:56,770
Speaker 0: So what they've done is they now Apple came out I think today and they were like, okay, we got a new thing for our approval our App Store approval process, right?

124
00:09:57,010 --> 00:10:00,810
Speaker 0: So they are making some effort to at least look better or do better.

125
00:10:01,512 --> 00:10:08,290
Speaker 0: And what they're doing the changes they've made are that a if you're making just a bug fix patch like a small patch, right?

126
00:10:09,031 --> 00:10:10,180
Speaker 0: They're just gonna let it go.

127
00:10:10,200 --> 00:10:21,293
Speaker 0: if your apps already approved Right without holding you up and then if they happen to find something in your bug fix patch That they don't like that is not approved They'll get.

128
00:10:21,333 --> 00:10:38,472
Speaker 0: they'll let your app stay up and basically make you fix it in your next, you know, your next go Right, so they're not gonna like because there's been a lot of times where people had bug fixes and they got held up or it's Like they're just fixing a bug and suddenly their apps out of the store and they're afraid to fix their bugs because you know Yeah,

129
00:10:38,794 --> 00:10:41,109
Speaker 1: but a lot of that still resolve revolves around.

130
00:10:41,531 --> 00:10:46,050
Speaker 1: What are the parameters where upon Apple will kick you out or force you to pay them the vig?

131
00:10:46,890 --> 00:10:49,845
Speaker 0: So the second the second thing is they changed it.

132
00:10:49,965 --> 00:10:58,650
Speaker 0: So There is now some sort of appeals a better appeals process or an unappeals process where there previously was none or whatever.

133
00:10:58,832 --> 00:11:06,274
Speaker 0: So if you've got something That happened to you and you're not happy with the ruling you can appeal better I guess than before.

134
00:11:06,314 --> 00:11:06,716
Speaker 0: we'll see.

135
00:11:06,917 --> 00:11:12,141
Speaker 0: we'll wait for people to actually put in appeals and see what happens to them to figure out how well that's working.

136
00:11:12,704 --> 00:11:16,350
Speaker 0: and the third thing is What was the third thing?

137
00:11:16,610 --> 00:11:17,032
Speaker 1: Oh, so there was.

138
00:11:17,052 --> 00:11:24,900
Speaker 0: they're going to take suggestions and like input from develop Apple developers Into what the rules should and should not be.

139
00:11:24,960 --> 00:11:28,450
Speaker 0: so basically you can comment to Apple and say hey this rules bullshit.

140
00:11:28,550 --> 00:11:29,414
Speaker 0: This rule is good.

141
00:11:29,454 --> 00:11:31,283
Speaker 0: You should add this really should remove that rule.

142
00:11:31,584 --> 00:11:32,709
Speaker 0: This rule is not clear, etc.

143
00:11:33,131 --> 00:11:37,888
Speaker 1: What if they just see how that goes that are all just don't charge 30% for in-app purchase, right?

144
00:11:38,209 --> 00:11:38,350
Speaker 0: Right?

145
00:11:38,411 --> 00:11:39,489
Speaker 0: We'll see how that works, right?

146
00:11:40,570 --> 00:11:41,614
Speaker 0: So the in-app purchases.

147
00:11:41,654 --> 00:11:44,062
Speaker 0: so stories in that front and that front right.

148
00:11:44,122 --> 00:11:50,261
Speaker 0: Facebook tried to put in a notice in their app To let users know that Apple was taking a 30% cut.

149
00:11:50,381 --> 00:11:54,312
Speaker 0: Yeah, and that they could go to Facebook.

150
00:11:54,332 --> 00:12:00,029
Speaker 0: they could go pay somewhere else and not through the app and deny Apple that money and pay the same price.

151
00:12:01,271 --> 00:12:05,784
Speaker 0: Right and Apple was like no you can't tell users irrelevant information.

152
00:12:05,824 --> 00:12:07,930
Speaker 1: Yeah quote irrelevant information.

153
00:12:08,070 --> 00:12:12,222
Speaker 1: That is clearly a clause to let Apple quash anything.

154
00:12:12,242 --> 00:12:12,844
Speaker 1: They don't like that.

155
00:12:12,884 --> 00:12:14,830
Speaker 1: Anyone says in an app during the payment, right?

156
00:12:15,050 --> 00:12:16,695
Speaker 0: That's a definitely an ambiguous rule.

157
00:12:16,755 --> 00:12:24,963
Speaker 0: I'm sure you could go and find tons of apps with irrelevant information in them in their you eyes That are approved and Apple doesn't give a crap.

158
00:12:24,983 --> 00:12:38,534
Speaker 0: That's definitely a vague arbitrarily, you know ambiguously Non-consistently enforced rule that Apple has in there so that for situations like this they can you know Have a rule.

159
00:12:38,574 --> 00:12:39,619
Speaker 0: it's like oh, okay.

160
00:12:39,660 --> 00:12:40,403
Speaker 0: We don't allow.

161
00:12:40,423 --> 00:12:41,850
Speaker 0: you know this right?

162
00:12:41,850 --> 00:12:42,373
Speaker 1: This is just

163
00:12:42,413 --> 00:12:56,170
Speaker 0: like because this is just like all those laws that say Black people can't vote without actually writing down black people can't vote and you write something else like oh, yeah You can only register to vote on a Tuesday in the middle of the day in this part of town.

164
00:12:56,314 --> 00:12:56,790
Speaker 1: You know what else?

165
00:12:57,431 --> 00:12:59,098
Speaker 0: Where there's a bunch of white people with guns.

166
00:12:59,158 --> 00:13:01,730
Speaker 1: there were a bunch of fights and there are still fights about.

167
00:13:02,434 --> 00:13:05,050
Speaker 1: When can companies of various types?

168
00:13:05,790 --> 00:13:09,850
Speaker 1: Include taxes and fees that they have to pay to other entities in their prices?

169
00:13:09,950 --> 00:13:12,580
Speaker 1: They show you versus when do they have to be added after the fact?

170
00:13:12,640 --> 00:13:18,703
Speaker 1: like some places there are laws that say you can't include the sales tax in a price you publish because they?

171
00:13:18,843 --> 00:13:30,570
Speaker 1: the sales tax has to be Calculated after the fact to avoid the kinds of optics problems that state and local governments Don't want to deal with like weird laws and weird rules happen all the time.

172
00:13:30,971 --> 00:13:45,090
Speaker 1: I remember as a kid Cedar Point the rollercoaster park got a special exemption from the state of Ohio to still collect sales tax But not say that they were collecting it and just include it in their prices, which was not allowed anywhere else in the States.

173
00:13:46,511 --> 00:13:49,681
Speaker 1: Kind of like how some companies can say oh, we're charging you this fee.

174
00:13:49,882 --> 00:13:52,330
Speaker 0: That sounds like not equal protection under the law to me.

175
00:13:52,531 --> 00:13:54,610
Speaker 1: Yeah, well they applied it at like a county level.

176
00:13:54,710 --> 00:13:59,329
Speaker 0: We're like Sandusky County has an example sounds like not equal protection under the law.

177
00:13:59,349 --> 00:13:59,570
Speaker 0: to me.

178
00:14:00,254 --> 00:14:02,649
Speaker 1: That equaled protection probably doesn't apply to a case like that.

179
00:14:02,991 --> 00:14:10,330
Speaker 0: I mean, I know what the equal protection legally means right and that obviously Can arbitrarily regulate right commerce?

180
00:14:10,850 --> 00:14:12,055
Speaker 0: I know that that is our.

181
00:14:12,276 --> 00:14:17,169
Speaker 0: that is legal under the law as written and as you know enforced in the United States.

182
00:14:17,491 --> 00:14:21,165
Speaker 0: But in principle the same laws should apply to everyone everywhere.

183
00:14:21,546 --> 00:14:24,338
Speaker 0: and that's a case where it's like Oh, I live in a different place different law.

184
00:14:24,358 --> 00:14:28,357
Speaker 0: All right, it's like oh, I'm in the next town over a different law I make more money.

185
00:14:28,377 --> 00:14:30,430
Speaker 0: I'm allowed to trade these stocks, right?

186
00:14:30,550 --> 00:14:32,476
Speaker 0: I'm a I'm an accredited investor.

187
00:14:32,556 --> 00:14:38,473
Speaker 0: different laws for me, right and I I see all of those as in principle you know not.

188
00:14:38,734 --> 00:14:46,543
Speaker 1: what I'm getting here is this is this is more the question of Providing that information is harmful to Apple's brand.

189
00:14:46,824 --> 00:14:56,170
Speaker 1: but the information is true But Apple is banning this information from being shared in a place where it would be relevant by claiming it's irrelevant.

190
00:14:56,712 --> 00:15:01,366
Speaker 1: This is this is a battle that has never been resolved pretty much anywhere right?

191
00:15:01,426 --> 00:15:05,097
Speaker 0: the second battle that's going on Obviously the fortnight one the big one right.

192
00:15:05,579 --> 00:15:15,449
Speaker 0: the current status is that on iOS you can still play fortnight But the developer account has been suspended so you can't download fortnight, but if you've already got it, you've already got it.

193
00:15:15,931 --> 00:15:22,070
Speaker 0: So what that means is all the iOS fortnight players are stuck in the previous season of fortnight.

194
00:15:23,033 --> 00:15:28,030
Speaker 1: I know enough about the kids to know that that basically means they don't have fortnight and are not getting updates.

195
00:15:28,452 --> 00:15:36,968
Speaker 0: So it's sort of like a whole bunch of people playing Counter-strike source and then everyone else on all the other platform is playing counter-strike.

196
00:15:37,008 --> 00:15:41,644
Speaker 0: go right, they all got the update but iOS isn't gonna get the updates for now.

197
00:15:41,684 --> 00:15:54,249
Speaker 0: and but the the situation involving The unreal engine is still that you know if you're making games with unreal engine you can still get them on iOS.

198
00:15:54,269 --> 00:15:56,849
Speaker 0: just epic Itself can't get their games out right yeah.

199
00:15:57,692 --> 00:16:04,195
Speaker 0: So the argument that I want to make that I haven't seen anyone make right which seems really straightforward to me Which is why I don't know.

200
00:16:04,536 --> 00:16:10,821
Speaker 0: there must be some reason that clearly that explains Why me not a lawyer or expert in any way has thought of this.

201
00:16:11,202 --> 00:16:14,735
Speaker 0: yet corporate lawyers paid lots of money have not thought of It or at least not said it.

202
00:16:14,775 --> 00:16:17,628
Speaker 0: there must be some reason because this seems so obvious.

203
00:16:17,749 --> 00:16:17,929
Speaker 0: right.

204
00:16:18,775 --> 00:16:30,229
Speaker 0: The Bose basic thing we learned about antitrust I even knew this as a kid from the Microsoft case was that if you got a monopoly in one area You can't use it to help yourself win and take over another market.

205
00:16:30,289 --> 00:16:35,545
Speaker 0: Yeah Microsoft had monopoly on operating systems for peace, but already here's the problem.

206
00:16:35,585 --> 00:16:36,348
Speaker 1: What's the market?

207
00:16:36,428 --> 00:16:36,950
Speaker 1: is the market?

208
00:16:37,370 --> 00:16:37,852
Speaker 0: I'll hold on.

209
00:16:37,892 --> 00:16:39,076
Speaker 0: I got you I got no.

210
00:16:39,096 --> 00:16:40,360
Speaker 0: no no I got you right.

211
00:16:40,660 --> 00:16:45,074
Speaker 0: you can't use that to wedge yourself in and take over In the browser department.

212
00:16:45,214 --> 00:16:47,602
Speaker 0: right that's what Microsoft got called out on right.

213
00:16:48,143 --> 00:16:50,029
Speaker 0: so it seems pretty obvious to me.

214
00:16:50,612 --> 00:17:00,130
Speaker 0: Right this whole 30% App Store thing that's going on right Instead of framing it as everyone has is like Apple taking a cut of your apps, right?

215
00:17:00,950 --> 00:17:01,996
Speaker 0: But it actually is.

216
00:17:02,720 --> 00:17:09,798
Speaker 0: is Apple is wedging out PayPal stripe Right payment cut Google pay.

217
00:17:10,199 --> 00:17:11,864
Speaker 0: right you cannot use.

218
00:17:11,984 --> 00:17:15,296
Speaker 0: if you've got an app in the Apple App Store You cannot sell.

219
00:17:15,617 --> 00:17:17,605
Speaker 0: let's say you got a game that sells coins.

220
00:17:17,685 --> 00:17:18,710
Speaker 1: I see where you're going with this.

221
00:17:18,790 --> 00:17:19,794
Speaker 0: Here's that you can't use.

222
00:17:20,035 --> 00:17:24,010
Speaker 0: you can't use PayPal to sell your coins in your game on the Apple App Store.

223
00:17:24,150 --> 00:17:25,414
Speaker 0: You must use Apple pay.

224
00:17:25,655 --> 00:17:29,265
Speaker 1: so if you go to a restaurant they can be like cash only.

225
00:17:29,406 --> 00:17:42,229
Speaker 1: or we only accept Amex that's true, but the And arguably Might be monopolies because in that County there aren't in the other rows of that type.

226
00:17:42,952 --> 00:17:55,836
Speaker 0: But that restaurant is not itself have a its own Restaurant pay and it does not control a significant portion of the restaurant market, but that Monopoly, what is the market?

227
00:17:55,916 --> 00:17:56,477
Speaker 1: is the market?

228
00:17:56,818 --> 00:18:00,810
Speaker 0: iPhone users or smart visa visa could not buy.

229
00:18:02,278 --> 00:18:09,470
Speaker 0: if visa bought Several fast-food chains and made it so the only way to buy food at them is a visa that might fly.

230
00:18:09,570 --> 00:18:10,619
Speaker 1: I actually that might.

231
00:18:10,700 --> 00:18:12,993
Speaker 1: they might win that one Maybe.

232
00:18:13,314 --> 00:18:18,270
Speaker 0: but like imagine if McDonald's and like they had a but they have to have a monopoly on fast food, right?

233
00:18:18,871 --> 00:18:28,950
Speaker 0: so burger King and Taco Bell and McDonald's and Chipotle and Wendy's and every single almost every single fast food like more than half of it is owned by visa.

234
00:18:29,977 --> 00:18:31,710
Speaker 1: Get the money from because Apple has Apple pay.

235
00:18:31,830 --> 00:18:36,330
Speaker 1: But you still inject money into the Apple pay system from something else like a credit card.

236
00:18:36,410 --> 00:18:39,139
Speaker 0: The point is I want to see right that.

237
00:18:39,320 --> 00:18:56,653
Speaker 0: I think that you know, we should see PayPal stripe and all those payment processors should be the ones Complaining about Apple saying hey Developers want to you like our payment platforms But they can't use them in the Apple and their apps their native apps in the Apple App Store Right.

238
00:18:56,774 --> 00:18:59,710
Speaker 0: Apple is pushing us out with their antitrust, right?

239
00:19:00,071 --> 00:19:04,970
Speaker 1: I don't want to fly though because I think this is this is Apple running a store?

240
00:19:06,690 --> 00:19:12,347
Speaker 1: Stores can use whatever payment things they would like to use but it's not.

241
00:19:12,428 --> 00:19:16,702
Speaker 0: you're not paying You know, you're not buying the thing from Apple.

242
00:19:16,723 --> 00:19:21,763
Speaker 0: You're buying the thing from the developer Yeah, but you're buying it for it to be a store Apple run marketplace.

243
00:19:22,124 --> 00:19:30,230
Speaker 0: for it to be a store Apple would have to buy the app from the app developer and then Amazon goes straight past their sales and they take a cut.

244
00:19:31,637 --> 00:19:39,294
Speaker 0: Yeah, okay You can't pay with a lot of not anything though River.

245
00:19:39,394 --> 00:19:42,448
Speaker 1: oh, you can't use rim Co to pay that payment process Apple.

246
00:19:42,588 --> 00:19:46,703
Speaker 0: if Amazon said the only way to buy anything on Amazon is with an Amazon credit card.

247
00:19:46,743 --> 00:19:47,666
Speaker 0: I think that would be a little.

248
00:19:47,686 --> 00:19:54,330
Speaker 1: ah Amazon there's a much better claim that they have a near monopoly on like online purchase, but they don't do that.

249
00:19:54,411 --> 00:19:57,395
Speaker 0: You can use any old can use discover Processor.

250
00:19:57,416 --> 00:20:05,939
Speaker 1: they're not taking a payment processing fee They're taking a. you're using our platform to host your app to download the app the infrastructure everything Like this is a can mark what

251
00:20:05,979 --> 00:20:13,225
Speaker 0: they take what they're taking that fee on all Payments and they're making you process all payments through them and not it's

252
00:20:13,286 --> 00:20:18,070
Speaker 1: for the purpose of them Collecting the cut that you have to agree to to sell stuff in their marketplace.

253
00:20:18,151 --> 00:20:31,710
Speaker 0: You're welcome to not sell stuff in their marketplace But I think because it's as a side effect if it's you know anti-competitive against other payment processing Companies that could force Apple to adopt a different model, right?

254
00:20:34,252 --> 00:20:41,172
Speaker 1: Apple could trivially say you can pay with any payment processor, but we take 30%.

255
00:20:41,172 --> 00:20:42,319
Speaker 0: How would they do that?

256
00:20:42,660 --> 00:20:44,390
Speaker 0: How would that be technologically possible?

257
00:20:44,651 --> 00:20:45,474
Speaker 1: They've got paid.

258
00:20:45,754 --> 00:20:49,989
Speaker 0: they my money is going from me directly to PayPal and then to the app.

259
00:20:50,551 --> 00:20:50,913
Speaker 0: What they're?

260
00:20:50,933 --> 00:20:53,850
Speaker 0: how is Apple gonna reach in if you're in our store?

261
00:20:54,210 --> 00:21:02,369
Speaker 1: You can't directly sell stuff without going through our cash register Which actually is very common in farmers markets and art fairs and all sorts of things.

262
00:21:03,013 --> 00:21:05,246
Speaker 0: No, it's still you know, there's something going on there.

263
00:21:05,306 --> 00:21:11,530
Speaker 1: Yeah, I'm saying You that Apple has a monopoly except over people who choose to use Apple technology.

264
00:21:11,811 --> 00:21:22,569
Speaker 0: But there's an argument you could make over the fact that you saw if you're a developer Right, it's like even though a lot of people use Android it's been shown, you know, numerically right.

265
00:21:22,609 --> 00:21:30,510
Speaker 0: then Yeah You don't really make money selling like a game in the Android Google Play Store as much as you make money selling it on the Apple Store.

266
00:21:30,993 --> 00:21:32,059
Speaker 0: It's like you sorta.

267
00:21:32,280 --> 00:21:39,269
Speaker 0: if you want to make money selling mobile apps It's like yeah, the Apple App Store is where people pay for things the Google Play Store not so much.

268
00:21:40,112 --> 00:21:43,082
Speaker 0: And that also has the sideloading thing going on there too, right?

269
00:21:43,122 --> 00:21:43,503
Speaker 0: There's no.

270
00:21:44,166 --> 00:21:53,514
Speaker 1: but is any amount of money Acceptable for the owner of the marketplace to extract from the system for the purpose of providing the marketplace which costs money to provide Right.

271
00:21:53,594 --> 00:21:56,690
Speaker 0: Oh, I'd say like let's say you get to mark two farmers markets in town, right?

272
00:21:56,770 --> 00:21:58,720
Speaker 0: And in one of them all the farmers make bank.

273
00:21:58,982 --> 00:22:01,714
Speaker 0: for some reason that has all the customers Right that pay.

274
00:22:02,115 --> 00:22:08,160
Speaker 0: the other one has a lot of foot traffic, but for some reason no one buys anything there Right or very little.

275
00:22:08,503 --> 00:22:14,033
Speaker 0: and it's like They go to the big farmers market starts to crack down and do evil shit and they're like We don't have a monopoly.

276
00:22:14,073 --> 00:22:14,375
Speaker 0: look at that.

277
00:22:14,415 --> 00:22:17,729
Speaker 0: others farm farmers market and the farmers like we don't make any money in that market.

278
00:22:19,070 --> 00:22:23,041
Speaker 1: There's also the problem of do the users care or not.

279
00:22:23,222 --> 00:22:26,050
Speaker 1: Most people who don't play fortnight don't give a shit.

280
00:22:27,431 --> 00:22:29,383
Speaker 0: Well for a fortnight for now, but there's a lot.

281
00:22:29,403 --> 00:22:30,450
Speaker 0: there's a lot going on, right?

282
00:22:30,690 --> 00:22:32,140
Speaker 1: Oh, yeah, but I'm saying that I did.

283
00:22:32,200 --> 00:22:35,874
Speaker 1: I think it'll be very difficult for Anyone to win against.

284
00:22:35,955 --> 00:22:37,139
Speaker 0: it's just it's just.

285
00:22:37,299 --> 00:22:40,470
Speaker 0: I mean, yeah, it's just an angle right that it's not been discussed, right?

286
00:22:40,891 --> 00:22:43,562
Speaker 0: It's like, you know, I'm throwing on my armchair analysis.

287
00:22:43,582 --> 00:22:43,944
Speaker 1: It's not like.

288
00:22:43,984 --> 00:22:45,008
Speaker 1: I have special knowledge here.

289
00:22:45,691 --> 00:22:46,073
Speaker 0: I didn't say.

290
00:22:46,113 --> 00:22:49,830
Speaker 0: it seems like, you know, it seems like they're wedging out the payment processors, right?

291
00:22:49,950 --> 00:22:51,969
Speaker 0: You gotta use Apple pay you anything else?

292
00:22:52,210 --> 00:22:54,850
Speaker 1: I think that's a side effect like they don't care about the payment processors.

293
00:22:54,971 --> 00:22:57,583
Speaker 1: Their only goal is if your thing is in our store.

294
00:22:57,623 --> 00:22:59,070
Speaker 1: We want to cut of anything you bring.

295
00:22:59,732 --> 00:23:04,985
Speaker 0: Well, I think what Apple actually believes is that you know is actually what they say Apple is.

296
00:23:05,365 --> 00:23:08,494
Speaker 0: they they're very good at saying What they believe right?

297
00:23:08,514 --> 00:23:12,527
Speaker 0: So they say it's like yeah, we want you to use Apple pay because it's more secure.

298
00:23:12,828 --> 00:23:15,519
Speaker 0: It's safer It's a better experience for the customer.

299
00:23:15,861 --> 00:23:17,970
Speaker 0: right and all those things are kind of true, right?

300
00:23:18,292 --> 00:23:26,626
Speaker 0: And that's why they don't want you know PayPal in the App Store or whatever because it's like yeah There's some shenanigans suddenly Apple customers getting screwed over because something PayPal did right?

301
00:23:26,646 --> 00:23:27,910
Speaker 0: They don't want that, right?

302
00:23:28,151 --> 00:23:33,986
Speaker 0: But the side effect is you may or may not sort of be antitrusting out those competitors who aren't.

303
00:23:34,186 --> 00:23:38,290
Speaker 1: but if that were a Real argument they would just let you use any payment processor.

304
00:23:38,872 --> 00:23:39,394
Speaker 1: But they.

305
00:23:39,855 --> 00:23:44,310
Speaker 1: the rule is you still have to pay Apple 30% of any transactions that happen in their store.

306
00:23:44,914 --> 00:23:46,870
Speaker 0: But then you could just hide the transactions from Apple.

307
00:23:47,352 --> 00:23:51,170
Speaker 1: But hiding the transactions is how Apple will then say you violated our rules and kick you out.

308
00:23:51,230 --> 00:23:53,187
Speaker 0: And how could you how could they know you hid them you hit them?

309
00:23:54,012 --> 00:23:54,715
Speaker 1: By going.

310
00:23:54,735 --> 00:23:56,783
Speaker 1: if someone could download the app and try it.

311
00:23:57,004 --> 00:24:01,262
Speaker 0: if I pay money to as I'm saying Technologically if I paid a PayPal you got an app.

312
00:24:01,604 --> 00:24:02,830
Speaker 0: I buy coins in your app.

313
00:24:02,890 --> 00:24:03,160
Speaker 1: Yeah, right.

314
00:24:03,450 --> 00:24:04,769
Speaker 1: So I go to the with PayPal.

315
00:24:05,172 --> 00:24:10,032
Speaker 0: Apple has no way to know how much money I gave you or that I even gave you money but that was part of my Terms of service.

316
00:24:10,073 --> 00:24:14,130
Speaker 1: you got to pay me 30% of all those transactions or I kick everyone lies and pays you nothing.

317
00:24:14,492 --> 00:24:15,539
Speaker 1: Yeah, then they kick them all out.

318
00:24:15,660 --> 00:24:16,445
Speaker 1: That's what would happen.

319
00:24:16,807 --> 00:24:17,129
Speaker 1: That's how.

320
00:24:18,752 --> 00:24:19,476
Speaker 0: How would they know?

321
00:24:19,557 --> 00:24:21,910
Speaker 0: you just say everyone would just say no one paid me.

322
00:24:22,918 --> 00:24:33,643
Speaker 1: In situations like this Usually what happens is the company that suspects the problem will approach the companies that are the biggest likely offenders Demand an audit and if they don't comply kick them out of their marketplace.

323
00:24:33,985 --> 00:24:35,370
Speaker 0: pretty sure Apple would rather.

324
00:24:35,671 --> 00:24:38,382
Speaker 0: You know, it's a big difference between Apple having to do that.

325
00:24:38,523 --> 00:24:38,804
Speaker 0: Also.

326
00:24:38,884 --> 00:24:44,182
Speaker 1: All I ever do is have an And say oh look I can buy stuff through PayPal here.

327
00:24:44,202 --> 00:24:46,089
Speaker 1: And if I do that, I will buy something.

328
00:24:46,109 --> 00:24:46,290
Speaker 1: now.

329
00:24:46,894 --> 00:24:49,631
Speaker 1: Look that company did not give us a 30%.

330
00:24:49,631 --> 00:24:59,698
Speaker 0: The point is Apple having to do that to every single app and the billions of zillions of apps in the App Store and audit all of them versus Automatically collecting 30% without having to do anything.

331
00:25:00,440 --> 00:25:04,290
Speaker 1: I guess is Apple obligated to create an in-app purchase ecosystem or not?

332
00:25:06,431 --> 00:25:08,424
Speaker 1: They could just say no in-app purchases fuck you.

333
00:25:08,444 --> 00:25:09,932
Speaker 0: and They could.

334
00:25:09,972 --> 00:25:13,043
Speaker 0: they could say no app on the App Store is allowed to have in-app purchases.

335
00:25:13,103 --> 00:25:18,896
Speaker 0: then they themselves would lose a shit ton of money because Everyone would lose money.

336
00:25:19,137 --> 00:25:22,010
Speaker 1: Yeah, because really is most people don't actually buy or install.

337
00:25:22,030 --> 00:25:24,932
Speaker 0: But it's not just the you know, it's not just the in-app purchases It's also.

338
00:25:24,952 --> 00:25:26,177
Speaker 0: you buy a $10 app.

339
00:25:26,459 --> 00:25:29,170
Speaker 0: seven dollars goes to the developer three dollars goes to Apple.

340
00:25:29,310 --> 00:25:36,290
Speaker 0: Yeah, and even if the app has no in-app purchases after the initial $10, but the other thing is what if here's a hypothetical?

341
00:25:36,570 --> 00:25:45,534
Speaker 1: What if without taking a significant chunk of all the in-app purchases the App Store itself is infeasible won't make enough money and Bet?

342
00:25:45,555 --> 00:25:48,049
Speaker 1: the way for them to make money would just be to scale it back.

343
00:25:48,652 --> 00:25:52,490
Speaker 1: Do less reviews of products let less things in just make it shittier.

344
00:25:54,032 --> 00:25:57,469
Speaker 1: Like there's a lot of negative outcomes for everyone involved that could happen here.

345
00:25:58,055 --> 00:26:00,641
Speaker 0: They could just have a different Model for it.

346
00:26:00,702 --> 00:26:04,058
Speaker 0: that makes sense like hey You want to list an app in the App Store.

347
00:26:04,238 --> 00:26:10,730
Speaker 0: if the app collects money is a freak because already if you have a free App right they all you have to do is pay to be an Apple developer.

348
00:26:10,811 --> 00:26:13,670
Speaker 0: Yep, and then you can put your free all many free apps as you want, right?

349
00:26:13,810 --> 00:26:16,922
Speaker 1: But most people only make free apps because they won't have in-app purchase.

350
00:26:17,002 --> 00:26:20,394
Speaker 0: obviously most most apps in the App Store are free Which is what Apple also says.

351
00:26:21,057 --> 00:26:24,129
Speaker 0: but if anyone makes an app that is not free in any way.

352
00:26:24,511 --> 00:26:24,792
Speaker 0: Right?

353
00:26:25,133 --> 00:26:29,670
Speaker 0: then you have to pay Apple a flat fee to list the app the listing fee.

354
00:26:29,710 --> 00:26:33,102
Speaker 1: I don't think that would make enough money for Apple to even bother continuing with the marketplace.

355
00:26:33,463 --> 00:26:35,209
Speaker 0: the app stores exist to sell.

356
00:26:35,229 --> 00:26:37,639
Speaker 0: they Didn't even have the App Store in the first iPhone.

357
00:26:37,679 --> 00:26:42,943
Speaker 0: the existence of the App Store makes Apple its money Via making people want to buy an iPhone.

358
00:26:42,963 --> 00:26:43,526
Speaker 0: They should know.

359
00:26:43,606 --> 00:26:51,110
Speaker 0: I'm actually clear We don't have data to show if that is the fact that they the fact that they make the 30% is Actually, it's like heart following the horse situation.

360
00:26:51,190 --> 00:26:58,358
Speaker 1: Oh, but I would argue that that 30 that that 30% is probably critical and was probably though I don't know part of their business plan all along.

361
00:26:58,839 --> 00:27:00,706
Speaker 0: No, no, no, I'm pretty it feels to me.

362
00:27:00,746 --> 00:27:04,145
Speaker 0: I mean I was there alive at that time.

363
00:27:04,811 --> 00:27:16,310
Speaker 0: That was a very different market - yeah Apple definitely I felt like at the beginning Caved in and a mate allowed the native apps by third-party developers, which they didn't want to do originally.

364
00:27:16,852 --> 00:27:22,370
Speaker 0: They allowed it, you know with the intention that aha this will make people want to buy iPhones.

365
00:27:22,972 --> 00:27:26,467
Speaker 0: Right the and the App Store is just a way to get people to buy.

366
00:27:26,507 --> 00:27:28,896
Speaker 0: you know to make You know the phone desirable.

367
00:27:29,278 --> 00:27:32,610
Speaker 0: and then it's like oh actually we're not making money on selling phones.

368
00:27:32,730 --> 00:27:36,544
Speaker 0: People are just keeping their phones for a long time not upgrading them so much.

369
00:27:37,086 --> 00:27:38,070
Speaker 0: We'll make our money on that.

370
00:27:38,150 --> 00:27:39,940
Speaker 0: Oh, but the App Store look how much money it's making.

371
00:27:39,960 --> 00:27:40,141
Speaker 0: All right.

372
00:27:40,161 --> 00:27:43,495
Speaker 1: Well, that's the money is I guess Yeah, but there's there's sort of the final.

373
00:27:43,856 --> 00:27:48,210
Speaker 1: the real problem is still capitalism in that many problems always capital.

374
00:27:48,210 --> 00:28:04,003
Speaker 1: But I'm saying many things like this Often what can happen in a market is the rent seekers are Actually using that rent to provide the service or to make it worthwhile to the people that own that company to bother provide Collecting plenty of extra rent.

375
00:28:04,023 --> 00:28:06,635
Speaker 0: They could easily Charge way less rent.

376
00:28:06,816 --> 00:28:09,670
Speaker 1: Ah, but if that would make them less profits, why bother?

377
00:28:09,910 --> 00:28:11,089
Speaker 1: Why not just shut it all down?

378
00:28:11,410 --> 00:28:11,651
Speaker 1: Like there's.

379
00:28:11,792 --> 00:28:15,870
Speaker 0: there might be a because you're pretty because you're at least pretending to be less evil than the competitors.

380
00:28:16,172 --> 00:28:22,585
Speaker 1: Ah, but fiduciary duty you are beholden to your shareholders To do the right thing for them not for society.

381
00:28:22,705 --> 00:28:23,609
Speaker 0: They're already worth it.

382
00:28:23,770 --> 00:28:25,641
Speaker 0: You already have the most valuable stock there is.

383
00:28:25,661 --> 00:28:27,190
Speaker 0: I think you're doing well, right?

384
00:28:27,631 --> 00:28:37,525
Speaker 1: But I'm just saying there's a. there are many things that if you strip away the monetization that late Capitalism has sort of thrust into those markets those products would just disappear in time.

385
00:28:37,565 --> 00:28:45,052
Speaker 0: that logic by that logic Why doesn't an Apple shareholder complain and say hey, well, you should be charging 50% not 30?

386
00:28:45,052 --> 00:28:52,710
Speaker 1: They do all the times shareholders Oftentimes activist shareholders will try to buy enough shares to force the company to be even more evil.

387
00:28:53,192 --> 00:28:54,276
Speaker 1: That is the thing that happens.

388
00:28:54,417 --> 00:29:06,590
Speaker 1: so if they don't have to listen to those even more evil shareholders they only don't have to listen to those more evil shareholders because smarter institutional investors hold on to enough of the stock to have enough of a majority.

389
00:29:07,832 --> 00:29:15,890
Speaker 0: Is that if you if you can fend off a guy who says you should be charged in 50 instead of 30 Then you can fend off a guy who says you should be charged at 30 instead of 10?

390
00:29:15,890 --> 00:29:23,087
Speaker 0: Maybe not because sometimes like if the profits aren't high gonna ask a judge to chart to determine the correct number You should be charging?

391
00:29:23,471 --> 00:29:25,242
Speaker 0: Well me that what you're doing is legal in the first.

392
00:29:25,323 --> 00:29:30,390
Speaker 1: now what it comes down to more Is that the company could just redirect strategically entirely?

393
00:29:32,031 --> 00:29:37,710
Speaker 1: If something is not worth the hassle to maintain a high squeeze rate of the profits from that area.

394
00:29:38,614 --> 00:29:39,540
Speaker 1: Also a lot of things like.

395
00:29:39,781 --> 00:29:41,310
Speaker 1: here's a good example Facebook sucks.

396
00:29:41,410 --> 00:29:42,092
Speaker 1: Facebook is evil.

397
00:29:42,132 --> 00:29:47,348
Speaker 1: Facebook probably harmed America and the world in irreparable ways and Facebook should be destroyed.

398
00:29:47,769 --> 00:29:56,370
Speaker 1: However nothing else Has the access that Facebook has especially in local hyper local even rural communities.

399
00:29:56,791 --> 00:30:05,507
Speaker 1: So a lot of like left-wing activists organized on Facebook because without that tool There is no other way to reach a certain subset of the population.

400
00:30:05,527 --> 00:30:06,090
Speaker 1: They need to reach.

401
00:30:07,092 --> 00:30:11,590
Speaker 0: What do you do about that when the thing that's realize it because it's it's an essential tool.

402
00:30:12,295 --> 00:30:16,879
Speaker 1: Ah, but there's a there gets even thornier problem Utility if you have the national social network.

403
00:30:16,959 --> 00:30:20,170
Speaker 1: that could also get real bad in a hurry for a whole different set of reasons.

404
00:30:20,951 --> 00:30:23,022
Speaker 0: That's a you know, that's the old.

405
00:30:23,102 --> 00:30:27,141
Speaker 0: that's what you know, right-wing people say Oh, if the government owns it, then it's not free the the.

406
00:30:27,321 --> 00:30:29,350
Speaker 0: if the government owns the printing press they will print.

407
00:30:29,370 --> 00:30:31,659
Speaker 1: But would you trust our current government?

408
00:30:31,739 --> 00:30:34,228
Speaker 1: Would you trust our current government with the social network?

409
00:30:37,594 --> 00:30:38,182
Speaker 0: No, yeah.

410
00:30:38,506 --> 00:30:41,256
Speaker 0: hence The point is like Twitter.

411
00:30:41,296 --> 00:30:45,409
Speaker 1: Twitter is irreplaceable and Twitter also needs to be replaced because it's dangerous and broken.

412
00:30:46,432 --> 00:30:50,163
Speaker 1: Mmm, there's no way to make a competitor to it in capitalism that could possibly succeed.

413
00:30:50,183 --> 00:30:52,570
Speaker 1: In fact Twitter itself can't succeed.

414
00:30:54,713 --> 00:30:56,661
Speaker 1: What you gonna do so in some other news.

415
00:30:56,741 --> 00:30:59,191
Speaker 0: this is a very real go with news We're not.

416
00:30:59,211 --> 00:31:00,515
Speaker 0: that news wasn't one more news.

417
00:31:00,555 --> 00:31:05,069
Speaker 1: We can skip some of the other light ones, but this one is very tech news.

418
00:31:06,271 --> 00:31:07,916
Speaker 1: This everyone kept talking to me about.

419
00:31:07,937 --> 00:31:09,080
Speaker 1: this is a very rim news.

420
00:31:09,783 --> 00:31:11,750
Speaker 1: this chrome feature and the DNS thing.

421
00:31:12,611 --> 00:31:14,201
Speaker 1: Okay, I think we actually talk.

422
00:31:14,362 --> 00:31:15,650
Speaker 0: Oh, we didn't talk about this.

423
00:31:15,750 --> 00:31:16,293
Speaker 0: So about this?

424
00:31:16,313 --> 00:31:20,370
Speaker 1: there is a thing that ISPs do that is evil and I think should be made illegal.

425
00:31:20,992 --> 00:31:23,200
Speaker 1: Where the DNS server they give you.

426
00:31:23,260 --> 00:31:30,319
Speaker 1: if you're not a smart tech person who knows how to avoid this If you type if you miss type a URL They'll take you to some other site.

427
00:31:30,580 --> 00:31:32,330
Speaker 1: They'll give you a DNS result to that.

428
00:31:32,471 --> 00:31:34,923
Speaker 1: Anyway, that takes some spam site, right?

429
00:31:34,943 --> 00:31:38,390
Speaker 0: So you type into your browser Com which doesn't exist.

430
00:31:38,490 --> 00:31:47,490
Speaker 0: No one's registered that domain or pointed it anywhere and what you should get as a response from the DNS server's system Right is no such domain NX, right?

431
00:31:48,790 --> 00:31:49,634
Speaker 1: But there's this.

432
00:31:49,714 --> 00:31:50,718
Speaker 1: this system is a hierarchy.

433
00:31:50,779 --> 00:31:54,959
Speaker 0: It works this way for you're supposed to get an NX which is yeah You typed in a non-existent domain.

434
00:31:55,019 --> 00:32:03,410
Speaker 0: It does not register the DNS system but instead your ISP will send you an IP address and say hey Here's the I or C name or whatever.

435
00:32:03,490 --> 00:32:06,580
Speaker 0: Here's the address of that of that domain root.com.

436
00:32:07,061 --> 00:32:11,056
Speaker 0: and you end up at a website that is run by Verizon or who knows.

437
00:32:11,278 --> 00:32:13,530
Speaker 1: usually it has some ads on it, right?

438
00:32:13,770 --> 00:32:23,747
Speaker 0: Usually it's got ads and search results or stuff and that your ISP is making money on that and tracking you and learning about you And such and such and they should not be allowed to do that.

439
00:32:25,511 --> 00:32:34,406
Speaker 1: Yep, so chrome chromium had a pretty good feature where cleverly It's a way to detect if the environment you're in is do it.

440
00:32:34,427 --> 00:32:35,170
Speaker 1: There's a lot more details.

441
00:32:35,190 --> 00:32:37,169
Speaker 1: I'm gonna skip because this is a news that I don't want to go deep.

442
00:32:37,451 --> 00:32:48,830
Speaker 1: There's a whole bunch of stuff about corporate domains and private DNS that I'm just gonna skip but basically What it does is it'll make up three random domains with like random top-level domains like bit of it a dot bit of that

443
00:32:49,351 --> 00:32:56,830
Speaker 0: Right almost guaranteed that none of them will be real and registered so that when it looks for them It should see an X's, right?

444
00:32:57,091 --> 00:33:07,643
Speaker 0: And if it happens to accidentally pick a real one the odds of there being like, you know more than two out of three Not and coming back with like a specific IP address.

445
00:33:07,964 --> 00:33:09,570
Speaker 0: not right not likely.

446
00:33:10,052 --> 00:33:11,640
Speaker 0: So that way they can find out if you're.

447
00:33:11,660 --> 00:33:13,850
Speaker 0: you turn out you open your chrome browser and it's like aha.

448
00:33:13,950 --> 00:33:17,930
Speaker 0: They know immediately if your ISP is shady or not and can act accordingly.

449
00:33:18,191 --> 00:33:23,970
Speaker 1: So that'll actually work pretty well to detect if you are like using a hijacking shitty DNS like pretty good way.

450
00:33:24,291 --> 00:33:35,484
Speaker 1: And then the browser can change its behavior when you make a typo or type something that probably isn't a domain name Into your like URL bar because the world decided that search and URLs are basically the same thing.

451
00:33:35,524 --> 00:33:38,292
Speaker 1: now welcome to the your 2020.

452
00:33:38,292 --> 00:33:42,628
Speaker 1: Yes, I have thoughts about that both that are nuanced that are beyond the scope of the show.

453
00:33:43,913 --> 00:33:47,908
Speaker 1: But I lament the fact that DNS is not the strict tree hierarchy that it used to be.

454
00:33:48,984 --> 00:33:52,894
Speaker 1: so the problem is Those requests.

455
00:33:53,757 --> 00:34:05,895
Speaker 1: if the bride if the ISP is not doing something evil will basically go all the way up to the top of DNS and end up asking the Official hard coded.

456
00:34:06,176 --> 00:34:09,143
Speaker 1: there aren't that many of them root servers of DNS.

457
00:34:09,405 --> 00:34:11,389
Speaker 1: Hey, what the fuck is this top-level domain?

458
00:34:12,330 --> 00:34:19,650
Speaker 1: Yep, and since this feature was launched Chromium has basically been D do s-ing the root of the entire DNS system.

459
00:34:20,911 --> 00:34:21,813
Speaker 1: There's good graphs here.

460
00:34:22,255 --> 00:34:36,824
Speaker 1: this kind of thing happens kind of often because people who come up with a very clever feature Don't fully understand the ramifications of how that feature will interact with Existing structures on the internet like DNS or and people are just it's.

461
00:34:36,844 --> 00:34:45,052
Speaker 0: just if you write code for something like chromium And it gets deployed you have to realize your code is running on an enormous number of computers around the world Right?

462
00:34:45,433 --> 00:34:51,210
Speaker 0: so things that don't matter or work perfectly in your local test right your test framework everything works great.

463
00:34:51,610 --> 00:34:52,774
Speaker 0: You do not you do not.

464
00:34:52,995 --> 00:34:57,408
Speaker 0: there's no way for you to test the ramifications of your code running on.

465
00:34:57,649 --> 00:35:05,241
Speaker 1: you know every Windows PC yeah, or most of them and That's something that people who write code actually really need to think about.

466
00:35:05,341 --> 00:35:18,630
Speaker 1: but usually the person writing any particular piece of code Doesn't necessarily have that broad and classical understanding of all the possible ramifications And the people deciding about the features may not like they may assume that the engineers will work these things out.

467
00:35:18,991 --> 00:35:21,640
Speaker 1: There's not a good way to handle this right?

468
00:35:21,660 --> 00:35:23,366
Speaker 0: you're also only thinking about.

469
00:35:23,747 --> 00:35:27,605
Speaker 0: you know your Computers whatever you're working on right my you know.

470
00:35:27,625 --> 00:35:32,878
Speaker 0: when I code at work I'm thinking about our work computers And I'm thinking about our users and their computers.

471
00:35:33,259 --> 00:35:40,529
Speaker 0: right if there's some side effect for computers far away somewhere else I'm not thinking about those too much if I'm not directly interacting with them.

472
00:35:41,071 --> 00:35:50,110
Speaker 0: But code on a computer somewhere it could affect code on computers everywhere and All the software of the world is not just one monolith that is written by one person.

473
00:35:50,416 --> 00:36:06,005
Speaker 1: but I would say the real solution to this problem like the only reason chromium even added a feature like this is to try to get around a real problem of people's DNS servers Hijacking things they type in to serve them ads or otherwise spy on them.

474
00:36:06,607 --> 00:36:08,213
Speaker 0: yep that Really.

475
00:36:08,233 --> 00:36:12,690
Speaker 1: there is no technological solution to that problem short of nationalizing DNS.

476
00:36:12,971 --> 00:36:15,018
Speaker 0: I think there is a solution to that problem.

477
00:36:15,961 --> 00:36:16,824
Speaker 0: I think the solution.

478
00:36:16,844 --> 00:36:18,268
Speaker 0: I think regulation is the solution.

479
00:36:18,650 --> 00:36:19,573
Speaker 0: well That is one solution.

480
00:36:19,594 --> 00:36:21,723
Speaker 0: I think the operating system should do something about it.

481
00:36:22,205 --> 00:36:22,426
Speaker 0: right?

482
00:36:22,506 --> 00:36:23,430
Speaker 0: the operating systems.

483
00:36:23,731 --> 00:36:25,577
Speaker 0: You know OS X and Windows right.

484
00:36:25,938 --> 00:36:33,019
Speaker 0: there's no reason that they couldn't just not X. when they do DHCP Right they could a right.

485
00:36:33,199 --> 00:36:37,170
Speaker 0: they could collect right figure out which ISPs are good and bad.

486
00:36:37,631 --> 00:36:40,303
Speaker 0: They could figure out when you install the OS or turn the computer on.

487
00:36:40,343 --> 00:36:50,130
Speaker 1: they can figure out which Goes down a lot of the same paths that the solution We just talked about goes down, and then they clever solution at scale that may have unforeseen consequences.

488
00:36:50,231 --> 00:36:50,694
Speaker 0: But it won't.

489
00:36:50,815 --> 00:36:52,730
Speaker 0: it won't be pinging random things.

490
00:36:52,830 --> 00:36:57,010
Speaker 0: They'll just build pretty quickly a database of which ISPs are good or bad.

491
00:36:57,391 --> 00:37:03,470
Speaker 1: You know look at what gathering data on what URLs people are typing in on their like operating system level.

492
00:37:03,893 --> 00:37:05,929
Speaker 1: No people would know not at all with that.

493
00:37:06,151 --> 00:37:10,170
Speaker 0: They just look at your DHCP, and then they would say okay these you know.

494
00:37:10,210 --> 00:37:12,137
Speaker 1: How do they know which I which which?

495
00:37:12,157 --> 00:37:15,790
Speaker 1: DNS servers are bad especially if these are all ten dots inside of ISP.

496
00:37:16,011 --> 00:37:19,290
Speaker 0: Can I know if you just type if you just type like IP config at a Windows computer?

497
00:37:19,430 --> 00:37:21,721
Speaker 0: You can just see which ISP you have right.

498
00:37:21,841 --> 00:37:22,123
Speaker 0: It's like.

499
00:37:22,263 --> 00:37:23,610
Speaker 0: Oh, it's routing through.

500
00:37:23,891 --> 00:37:31,896
Speaker 0: I do not want my operating system making decisions based on the information I have configured in my network settings.

501
00:37:32,237 --> 00:37:38,782
Speaker 0: No not something that you if you configure something in your network settings, but I can DHCP use the DNS server pointed to that.

502
00:37:38,802 --> 00:37:41,110
Speaker 1: don't ask question fault the default DHCP?

503
00:37:41,552 --> 00:37:45,010
Speaker 0: No, if you put if you type in a DNS server, that's what you're using right.

504
00:37:45,272 --> 00:37:48,030
Speaker 0: I'm saying 99% of people who don't type in anything.

505
00:37:48,070 --> 00:37:50,530
Speaker 0: They just turn their computer on it don't touch the networking settings.

506
00:37:50,570 --> 00:37:51,834
Speaker 0: Oh, I'm saying you should still.

507
00:37:51,874 --> 00:37:56,550
Speaker 1: the operating system should still be obligated to trust whatever DNS ever comes back in that DHCP request.

508
00:37:57,373 --> 00:38:01,647
Speaker 0: I'm saying it should only do that if you tell it to or if you're not on one of the.

509
00:38:01,728 --> 00:38:03,334
Speaker 0: if you're on Some sort of.

510
00:38:03,395 --> 00:38:06,570
Speaker 0: you know public ISP windows should never on a pay.

511
00:38:07,652 --> 00:38:07,973
Speaker 1: I'm on.

512
00:38:07,993 --> 00:38:09,780
Speaker 1: that is a bad solution to this.

513
00:38:09,820 --> 00:38:18,650
Speaker 0: if you're on if you're on spectrum or FiOS or something and it's a known evil ISP it should switch your DNS server to be like Microsoft's DNS server.

514
00:38:18,690 --> 00:38:20,797
Speaker 1: Yeah, that that would lead to an antitrust.

515
00:38:20,897 --> 00:38:24,208
Speaker 1: Microsoft is hijacking your DNS request to their own private servers.

516
00:38:24,349 --> 00:38:26,357
Speaker 0: Microsoft Sends you to Google's DNS server.

517
00:38:26,578 --> 00:38:27,341
Speaker 0: It's not antitrust.

518
00:38:27,361 --> 00:38:28,386
Speaker 0: They're sending you to someone else.

519
00:38:28,486 --> 00:38:29,330
Speaker 0: Just someone that they trust.

520
00:38:29,551 --> 00:38:30,397
Speaker 1: Yeah, who did that?

521
00:38:30,981 --> 00:38:32,170
Speaker 0: That is a terrible idea.

522
00:38:32,712 --> 00:38:36,610
Speaker 1: It's a great idea that that idea is very similar to the idea chromium has.

523
00:38:37,290 --> 00:38:44,296
Speaker 1: that that is putting the logic to solve a problem way too low in the stack and making a lot of Assumptions for something that's going to be deployed.

524
00:38:44,316 --> 00:38:45,120
Speaker 0: It's not gonna.

525
00:38:45,341 --> 00:38:47,670
Speaker 0: it's not gonna make a zillion DNS requests that are unnecessary.

526
00:38:47,931 --> 00:38:51,062
Speaker 1: I can imagine a lot of unforeseen consequences of that.

527
00:38:51,082 --> 00:38:53,270
Speaker 1: I can imagine a lot of difficult to troubleshoot problems.

528
00:38:53,553 --> 00:38:54,910
Speaker 1: I can imagine a lot of corporate networks.

529
00:38:55,673 --> 00:38:58,465
Speaker 0: I don't think a corporate network wouldn't have.

530
00:38:58,585 --> 00:38:59,690
Speaker 1: what if I want to go to those?

531
00:38:59,870 --> 00:39:02,639
Speaker 1: What if I want to use my ISP DNS?

532
00:39:03,101 --> 00:39:04,225
Speaker 1: I don't care about the hijacking.

533
00:39:04,626 --> 00:39:08,102
Speaker 1: don't decide for me Don't don't send my request to Google.

534
00:39:08,122 --> 00:39:12,786
Speaker 0: I don't trust Google too bad If you're if your only argument is the one that's in favor of the evil thing.

535
00:39:12,806 --> 00:39:13,590
Speaker 0: We're trying to eliminate.

536
00:39:13,630 --> 00:39:17,870
Speaker 1: No, I'm saying the operating systems network stack should be pure and specific.

537
00:39:17,971 --> 00:39:20,189
Speaker 1: Don't overload your bullshit business logic into it.

538
00:39:20,471 --> 00:39:28,537
Speaker 1: The network stack should not look at the ISP you connected to and make a judgment about whether or not to overwrite the DNS Setting that came back in a DHCP packet.

539
00:39:29,179 --> 00:39:29,781
Speaker 0: I think it should.

540
00:39:30,423 --> 00:39:34,682
Speaker 1: I think that is a terrible idea And I think the right solution is a great idea.

541
00:39:34,702 --> 00:39:36,130
Speaker 0: It's much better than the chromium idea.

542
00:39:36,210 --> 00:39:39,730
Speaker 1: Actually, I think the chromium one is a better solution because that's a piece of software.

543
00:39:39,850 --> 00:39:40,934
Speaker 1: It's not the chromium ones.

544
00:39:40,954 --> 00:39:43,341
Speaker 0: got to make all kinds of requests right and nonsense.

545
00:39:43,362 --> 00:39:45,910
Speaker 1: Yes, but it doesn't mess with your network stack settings.

546
00:39:47,273 --> 00:39:48,743
Speaker 1: What you propose will just lead.

547
00:39:48,783 --> 00:39:49,890
Speaker 0: this is actually even better.

548
00:39:50,090 --> 00:39:51,133
Speaker 0: This is actually.

549
00:39:51,474 --> 00:39:53,500
Speaker 0: it's actually would actually solve more problems.

550
00:39:53,560 --> 00:39:58,674
Speaker 0: because how many problems in non browsers are caused by Having shitty DNS?

551
00:39:58,714 --> 00:40:00,820
Speaker 0: that sends you to weird things on bad domains.

552
00:40:01,081 --> 00:40:04,350
Speaker 0: Now all your other apps would suddenly have good DNS operating system-wide.

553
00:40:05,450 --> 00:40:09,741
Speaker 0: Yeah, I'd still think that if only instead of only chromium having good DNS.

554
00:40:09,882 --> 00:40:16,884
Speaker 1: Yeah, the problem is - I don't want anyone One to change what the network stack of the computer is.

555
00:40:16,944 --> 00:40:17,285
Speaker 1: they should.

556
00:40:17,325 --> 00:40:17,887
Speaker 0: they're cheap.

557
00:40:18,088 --> 00:40:18,690
Speaker 0: you're changing.

558
00:40:18,871 --> 00:40:21,310
Speaker 0: You are a person who's gonna type in your own DNS.

559
00:40:21,310 --> 00:40:22,536
Speaker 0: For you nothing would happen.

560
00:40:22,577 --> 00:40:32,090
Speaker 0: I Yeah, if there I am only assuming that if you're some customer who's on spectrum and you've never changed your network settings

561
00:40:32,210 --> 00:40:35,280
Speaker 1: I don't want Windows to make any decision based on what ISP

562
00:40:35,381 --> 00:40:38,592
Speaker 0: you don't but you know what it's better for a vast majority of People

563
00:40:38,712 --> 00:40:42,488
Speaker 1: actually probably not most people are probably fine with those spam things because they just don't.

564
00:40:43,090 --> 00:40:44,015
Speaker 0: Just don't know better.

565
00:40:44,055 --> 00:40:45,181
Speaker 0: You'd be helping them out.

566
00:40:45,623 --> 00:40:49,864
Speaker 1: Yeah, even though I don't want them I don't want a low-level systems to solve higher order problems.

567
00:40:49,904 --> 00:40:51,210
Speaker 1: That is a recipe for disaster.

568
00:40:51,290 --> 00:40:52,777
Speaker 0: That is it's not a low answer.

569
00:40:52,838 --> 00:40:55,209
Speaker 0: solving it on the problem on the level that it is.

570
00:40:56,294 --> 00:40:59,174
Speaker 1: If you want to frame it that way That's their set.

571
00:40:59,194 --> 00:41:07,838
Speaker 0: your ISP is setting your DNS IP the IP address of your DNS server to a bad DNS server We're gonna set it to a good one solving the problem right at the spot where it's caused.

572
00:41:07,939 --> 00:41:18,558
Speaker 1: I think a better solution would just to be to have a law saying that DNS servers that are used in public in public ISPs Cannot return results that are not.

573
00:41:18,880 --> 00:41:19,602
Speaker 0: I don't think.

574
00:41:19,622 --> 00:41:21,570
Speaker 0: you know, you're not gonna get a lot of that law ever.

575
00:41:22,443 --> 00:41:26,150
Speaker 1: I mean We're not gonna do that law is more feasible than anything you proposed.

576
00:41:26,230 --> 00:41:29,330
Speaker 1: Like if you have you proposed what you just said to Microsoft you'd be laughed out of the room.

577
00:41:29,852 --> 00:41:30,414
Speaker 0: I don't think so.

578
00:41:30,434 --> 00:41:33,286
Speaker 0: I think so they might be like, ooh, I think that would be a terrible idea.

579
00:41:33,627 --> 00:41:34,270
Speaker 0: Google liked it.

580
00:41:35,196 --> 00:41:38,261
Speaker 1: Google Trying to get you to use their DNS servers.

581
00:41:38,281 --> 00:41:40,069
Speaker 1: They can collect a shit ton of data from you.

582
00:41:41,472 --> 00:41:44,029
Speaker 0: Actually, I don't know if the Google public DNS actually collects.

583
00:41:45,091 --> 00:41:46,255
Speaker 0: Think it doesn't collect users.

584
00:41:46,395 --> 00:41:47,900
Speaker 0: It doesn't collect users specific data.

585
00:41:47,960 --> 00:41:50,990
Speaker 1: No, but it collects what the crux what URLs are being queried.

586
00:41:51,070 --> 00:41:51,672
Speaker 1: That's a huge.

587
00:41:51,793 --> 00:41:53,037
Speaker 0: Yeah, they're looking at like.

588
00:41:53,078 --> 00:41:53,720
Speaker 0: yeah, they're looking at like.

589
00:41:53,780 --> 00:41:56,390
Speaker 0: who is which you are domains are the most queried and stuff.

590
00:41:56,430 --> 00:41:58,070
Speaker 1: Yeah, it also does have enough metadata.

591
00:41:58,210 --> 00:41:58,331
Speaker 1: Like.

592
00:41:58,371 --> 00:42:02,326
Speaker 1: there's enough metadata there to figure out who's doing what pretty easily if they want it to.

593
00:42:02,366 --> 00:42:02,486
Speaker 0: yeah.

594
00:42:02,547 --> 00:42:04,575
Speaker 0: Yeah What are you gonna use?

595
00:42:04,655 --> 00:42:05,559
Speaker 0: open DNS law?

596
00:42:05,579 --> 00:42:08,190
Speaker 0: Yeah, that's all that's broken in a different worse way.

597
00:42:08,210 --> 00:42:15,934
Speaker 1: I guess my thinking is DNS and DHCP should be sacrosanct relatively straightforward Specifications.

598
00:42:16,175 --> 00:42:17,641
Speaker 1: that made so some people.

599
00:42:18,002 --> 00:42:22,561
Speaker 0: it forced me if people are using a non Sarcosynct DNS forced them to use a sarcosynct one.

600
00:42:22,882 --> 00:42:24,750
Speaker 1: No because Google's not a sacrosanct one.

601
00:42:27,231 --> 00:42:28,338
Speaker 0: Here's the is way you could do it.

602
00:42:28,358 --> 00:42:36,467
Speaker 0: you could effectively make a list of known DNS servers that are evil and just block them all and be like not a lot right.

603
00:42:36,747 --> 00:42:39,298
Speaker 1: and then most people's Windows Boxes just wouldn't work and they wouldn't know why.

604
00:42:40,002 --> 00:42:46,987
Speaker 0: no because they would say hey You know your ISP is DNS server is on a list of banned DNS servers that behaves.

605
00:42:47,047 --> 00:42:48,030
Speaker 1: and remember Netflix.

606
00:42:48,853 --> 00:42:50,398
Speaker 1: Hey your eyes sucks.

607
00:42:50,438 --> 00:42:53,650
Speaker 1: complain about it and how that didn't solve any problems and just confused people.

608
00:42:54,731 --> 00:42:59,030
Speaker 0: Yeah, I'm just saying yeah, you know if you're if you're so, you know picky, right?

609
00:43:00,271 --> 00:43:08,154
Speaker 1: I'm just saying as a general piece of advice don't try to solve high order problems in low Level systems.

610
00:43:08,214 --> 00:43:09,118
Speaker 1: that is I'm sorry.

611
00:43:09,621 --> 00:43:11,610
Speaker 0: I see it as I'm solving the problem where it is.

612
00:43:11,670 --> 00:43:15,183
Speaker 0: It's a problem of your DNS server IP address being set to a shitty one.

613
00:43:15,224 --> 00:43:16,227
Speaker 0: I'm gonna set it to a good one.

614
00:43:16,569 --> 00:43:16,850
Speaker 1: Okay?

615
00:43:17,571 --> 00:43:29,945
Speaker 1: Anyway, the last thing we're not gonna talk about this in depth, but his little piece of news, uh Don't buy Elon Musk's brain implant and put no one's buying the brain and people want to.

616
00:43:30,346 --> 00:43:30,827
Speaker 1: people are.

617
00:43:31,248 --> 00:43:36,303
Speaker 0: people are in Just those are just sock puppet accounts or people that Ellen must give drugs to.

618
00:43:36,584 --> 00:43:46,963
Speaker 1: I think there are people who want this and I All I will say, you know That's a self-solving problem.

619
00:43:47,406 --> 00:44:01,889
Speaker 0: brain Brain interfaces should not be used until there are not mega corpse making them pretty much Until I can you know put together my own brain implant in my house Like I way I've put together a PC in my house.

620
00:44:02,090 --> 00:44:02,753
Speaker 0: Yeah, right.

621
00:44:02,934 --> 00:44:09,909
Speaker 0: and so you have a cyberpunk shop shop down in the corner next to the digital tattoo shop Zero, I see through anything, right?

622
00:44:10,711 --> 00:44:12,156
Speaker 0: Don't go and get it any don't?

623
00:44:12,176 --> 00:44:12,297
Speaker 0: like?

624
00:44:12,879 --> 00:44:18,779
Speaker 0: I always said that I'm not gonna get brain implant 1.0 I'll probably get 2.0 or maybe even 3.0.

625
00:44:18,779 --> 00:44:22,250
Speaker 0: But if Ellen Musk is making the brain implant, I'm not getting a million point.

626
00:44:22,250 --> 00:44:24,228
Speaker 0: Oh, yeah, I'm not getting two million point.

627
00:44:24,268 --> 00:44:33,304
Speaker 0: Oh but anyway things Of the day.

628
00:44:33,585 --> 00:44:35,170
Speaker 0: so shit, what was my thing of the day?

629
00:44:35,631 --> 00:44:36,353
Speaker 1: I'll do mine first.

630
00:44:36,574 --> 00:44:38,600
Speaker 1: so this is a pretty cool article.

631
00:44:38,921 --> 00:44:39,242
Speaker 1: I'm not.

632
00:44:40,125 --> 00:44:44,500
Speaker 1: it is plausible, but I'm not going to say that it's true, but it may like it made the rounds news was talking about.

633
00:44:44,621 --> 00:44:47,715
Speaker 1: It's an interesting story, but it's basically the story.

634
00:44:47,735 --> 00:45:10,620
Speaker 1: It was published recently of Someone who claims to have worked at Apple and in the course of working for them helped probably the CIA make special iPods that had Hardware and software in them that could collect and hide data but appeared from all outward investigation to be a normal iPod

635
00:45:11,542 --> 00:45:11,662
Speaker 0: Right.

636
00:45:11,682 --> 00:45:19,220
Speaker 0: Well what the actual story is more like people from the the government right the doe which is already like that's nuclear stuff.

637
00:45:19,922 --> 00:45:21,427
Speaker 0: Apple didn't give permission for this.

638
00:45:21,447 --> 00:45:23,011
Speaker 0: They probably wouldn't have ever right.

639
00:45:23,031 --> 00:45:29,160
Speaker 0: these people basically snuck into getting jobs at Apple Developed it while working at Apple and then disappeared.

640
00:45:29,582 --> 00:45:30,788
Speaker 1: Yeah, but we're told like there was.

641
00:45:30,868 --> 00:45:31,873
Speaker 1: like you read the story like.

642
00:45:31,893 --> 00:45:42,799
Speaker 1: I'm not gonna read this story to you but it basically tells the story of how this thing supposedly went down and There's a lot of plausible stuff in here and it's an interesting fascinating story, right?

643
00:45:43,060 --> 00:45:45,794
Speaker 0: We obviously can't prove that true or false, right?

644
00:45:45,814 --> 00:45:47,020
Speaker 0: There's no way to do that, right?

645
00:45:47,220 --> 00:45:48,784
Speaker 0: Apple can't even prove it true or false.

646
00:45:48,844 --> 00:45:51,812
Speaker 0: probably right, but it seems true.

647
00:45:51,832 --> 00:45:55,941
Speaker 0: ish enough right to at least be worth Mentioning.

648
00:45:56,523 --> 00:46:01,000
Speaker 1: it's all yep, and it's also like in terms of the details like worst case.

649
00:46:01,122 --> 00:46:11,698
Speaker 1: It's just a really good story But the details are tracking with what I like just based on my own professional experience What I would need in a product like that.

650
00:46:12,423 --> 00:46:13,450
Speaker 1: Like how would you do it?

651
00:46:13,490 --> 00:46:14,860
Speaker 1: Like the details are pretty specific.

652
00:46:14,920 --> 00:46:22,473
Speaker 1: So whoever wrote the story, even if it's false put a lot of thought into What would such a device actually need to be like in the real world?

653
00:46:22,915 --> 00:46:23,095
Speaker 0: Yep.

654
00:46:23,497 --> 00:46:26,467
Speaker 0: It's basically like Either if like if it's.

655
00:46:26,668 --> 00:46:28,014
Speaker 0: if it's true that it's true.

656
00:46:28,034 --> 00:46:40,919
Speaker 0: if it's not true Someone did so much work writing this to make it, you know So as as you know believable and plausible as possible and that itself is worthy of giving them a read.

657
00:46:41,509 --> 00:46:44,548
Speaker 1: Yep the only thing I don't think is plausible is the.

658
00:46:44,849 --> 00:46:51,860
Speaker 1: the article speculates about what they were trying to spy on and I don't think it was a Geiger counter.

659
00:46:52,281 --> 00:46:52,442
Speaker 1: Like.

660
00:46:52,904 --> 00:47:02,880
Speaker 1: I can think of a lot of other SIG in type things that someone would want to do with a device like that To smuggle data in and out of a place possibly from sensors a Geiger counter.

661
00:47:02,980 --> 00:47:06,915
Speaker 1: I think there were better ways to handle that but who knows I'm sure it's like.

662
00:47:06,935 --> 00:47:11,773
Speaker 0: I'm sure the government already had Plenty of you know, tiny hidden Geiger counter things.

663
00:47:11,793 --> 00:47:13,540
Speaker 0: Yeah, I wouldn't need an iPod one.

664
00:47:13,761 --> 00:47:24,384
Speaker 1: Remember the key to an iPod is whatever it is hide in plain sight with a device that can be inspected pretty thoroughly and still not return anything like any like Deviant result.

665
00:47:24,404 --> 00:47:25,869
Speaker 1: that would require further investigation.

666
00:47:26,531 --> 00:47:27,615
Speaker 1: Yep, you find some yup.

667
00:47:27,695 --> 00:47:28,197
Speaker 0: It's an iPod.

668
00:47:29,362 --> 00:47:37,191
Speaker 1: Yeah, like and if I hide a tiny like micro micro SD card Somewhere on my body there are a lot of ways someone could find that.

669
00:47:37,492 --> 00:47:42,140
Speaker 1: but if someone finds my iPod because I handed it to Them that's a very different situation.

670
00:47:42,901 --> 00:47:52,178
Speaker 0: Yep, anyway, so my thing of the day is this little cute website Lord of the Manor dot IO and it's a little tiny Sim City ish kind of game right.

671
00:47:52,218 --> 00:47:56,732
Speaker 0: you Collect some resources by building like you build like a little forest hut and the.

672
00:47:56,933 --> 00:47:59,360
Speaker 0: then it starts chopping the wood in the nearby area.

673
00:47:59,681 --> 00:48:00,405
Speaker 0: Then you get wood.

674
00:48:00,646 --> 00:48:03,820
Speaker 0: then you can use the will to build the wood to build other buildings, right?

675
00:48:03,940 --> 00:48:04,462
Speaker 0: Etc.

676
00:48:04,784 --> 00:48:08,200
Speaker 0: The only buildings you can't build are the residential buildings that house your population.

677
00:48:08,522 --> 00:48:09,426
Speaker 0: They just sort of appear.

678
00:48:09,487 --> 00:48:10,552
Speaker 0: naturally as your.

679
00:48:10,934 --> 00:48:17,840
Speaker 0: you know domain Increases in quality, you know houses will appear and upgrade and it's just a cute little sim game.

680
00:48:17,920 --> 00:48:19,549
Speaker 0: It's not like the greatest game.

681
00:48:19,609 --> 00:48:23,688
Speaker 0: It's not gonna occupy you for a long time Right, but it's thing of the day.

682
00:48:23,768 --> 00:48:26,560
Speaker 0: because look someone made this in a browser.

683
00:48:26,881 --> 00:48:29,875
Speaker 0: It runs in your browser and it's like it's this nice.

684
00:48:29,915 --> 00:48:30,879
Speaker 0: They're still working on it.

685
00:48:31,221 --> 00:48:35,940
Speaker 0: It's it's super speedy and responsive and it's like it could have been like a desktop app.

686
00:48:36,000 --> 00:48:36,663
Speaker 0: You wouldn't even know.

687
00:48:36,723 --> 00:48:38,491
Speaker 0: it's like wow, you did this in the in the web.

688
00:48:38,571 --> 00:48:40,339
Speaker 0: It's like that's pretty freaking impressive.

689
00:48:40,399 --> 00:48:41,607
Speaker 0: Wow Good job.

690
00:48:41,627 --> 00:48:43,780
Speaker 0: I Played it.

691
00:48:43,820 --> 00:48:51,520
Speaker 0: It only took me like hardly any time to upgrade everything to the max and get a huge pile of gold and jewelry and pretty much every resource available.

692
00:48:53,242 --> 00:48:57,697
Speaker 0: So, you know, it's not gonna occupy your Time too much.

693
00:48:58,842 --> 00:48:59,725
Speaker 1: I'm poking at it right now.

694
00:48:59,966 --> 00:49:00,147
Speaker 1: Yeah.

695
00:49:00,187 --> 00:49:02,216
Speaker 0: Yeah, it's a really good UI considering.

696
00:49:02,237 --> 00:49:02,719
Speaker 0: Oh, I can.

697
00:49:02,759 --> 00:49:05,430
Speaker 1: it is You know what it does, you know what makes me really pleased with this.

698
00:49:05,510 --> 00:49:07,438
Speaker 1: I can zoom out to an appropriate level.

699
00:49:07,538 --> 00:49:08,040
Speaker 1: so many games.

700
00:49:08,040 --> 00:49:09,185
Speaker 1: Yeah, let me zoom out far enough.

701
00:49:09,326 --> 00:49:10,029
Speaker 0: That's what I'm saying.

702
00:49:10,049 --> 00:49:12,700
Speaker 0: Like you zoom in and zoom out with the scroll wheel super smooth.

703
00:49:12,881 --> 00:49:14,948
Speaker 0: So, yeah, it's it's pretty pretty damn good.

704
00:49:15,008 --> 00:49:15,450
Speaker 0: gives you some.

705
00:49:15,530 --> 00:49:18,140
Speaker 0: you know, Euro board game kind of feels a little bit, right?

706
00:49:19,041 --> 00:49:21,088
Speaker 0: But I think mostly it's just kind of inspiring.

707
00:49:21,148 --> 00:49:32,179
Speaker 0: It's like yeah, you know imagine taking the async Websockets technology of like a jackbox or an adil a 18xx games and combining it with this kind of UI.

708
00:49:32,501 --> 00:49:35,452
Speaker 0: That's the kind of game that you can make on the web right now.

709
00:49:35,472 --> 00:49:37,420
Speaker 0: Not too not too much difficulty.

710
00:49:38,887 --> 00:49:39,417
Speaker 0: You should try it.

711
00:49:39,601 --> 00:49:50,633
Speaker 1: Yeah In the minute moment as we've said we'll be live on September 4th coming up real soon at the crunchyroll Expo With Jojo anime by its cover and also oh, that's sooner than I thought that's.

712
00:49:50,673 --> 00:49:52,418
Speaker 0: that's in Friday September 18th.

713
00:49:53,040 --> 00:49:54,306
Speaker 1: Where is the finish line?

714
00:49:54,567 --> 00:49:56,294
Speaker 1: brand new lecture for our packs?

715
00:49:56,596 --> 00:49:58,303
Speaker 1: We got some magfest stuff we're working on.

716
00:49:58,926 --> 00:50:03,528
Speaker 1: we might be making our first ever appearance at magwest because It's all for sure.

717
00:50:03,548 --> 00:50:05,040
Speaker 0: You don't have to go we don't have to go there.

718
00:50:05,060 --> 00:50:11,334
Speaker 0: Yeah If there's any conventions far away Like magwest that we normally wouldn't go to ever because it's too far not worth it.

719
00:50:11,735 --> 00:50:12,698
Speaker 0: We can go there now.

720
00:50:12,858 --> 00:50:15,838
Speaker 1: So Yeah, you know stay tuned on all that.

721
00:50:16,441 --> 00:50:22,479
Speaker 1: Otherwise like type geek nights into Google and find our stuff and hang out in our discord and watch our live streams.

722
00:50:22,560 --> 00:50:23,928
Speaker 1: and We got videos.

723
00:50:23,948 --> 00:50:24,432
Speaker 1: We got stuff.

724
00:50:24,492 --> 00:50:24,956
Speaker 1: We're streaming.

725
00:50:24,977 --> 00:50:32,633
Speaker 1: We're hanging out We're doing things during the quarantine and as winter comes we got to do more and more stuff indoors And we might be making more and more content.

726
00:50:32,653 --> 00:50:33,459
Speaker 1: Cuz what else are we gonna do?

727
00:50:34,580 --> 00:50:39,277
Speaker 0: Yep Yeah, and I might maybe we should read the book club book tale again.

728
00:50:39,297 --> 00:50:39,900
Speaker 0: G at some point.

729
00:50:40,026 --> 00:50:44,651
Speaker 1: Yep I'm trying to figure out at what point would I have enough free time to read books.

730
00:50:44,732 --> 00:50:47,500
Speaker 0: cuz without community read some comic books yesterday.

731
00:50:47,781 --> 00:50:55,883
Speaker 1: Well, like we keep saying without a commute like I don't have a lot of time to read because I keep saying this because I Think it's important for people to internalize The core.

732
00:50:55,923 --> 00:51:02,769
Speaker 1: the kovat crisis does not mean you have to be like more Productive in your hobbies or your pursuits.

733
00:51:02,889 --> 00:51:05,579
Speaker 1: Most people don't actually have any more free time now.

734
00:51:05,880 --> 00:51:06,322
Speaker 1: They're just for.

735
00:51:06,362 --> 00:51:07,405
Speaker 0: historically did.

736
00:51:07,445 --> 00:51:12,400
Speaker 0: did previous pandemics were during the flu epidemic to the people who survived and didn't get the flu?

737
00:51:12,521 --> 00:51:15,840
Speaker 0: Did they suddenly do a whole bunch of great stuff because they were at home all the time?

738
00:51:15,900 --> 00:51:16,984
Speaker 0: Yeah, do I do?

739
00:51:17,065 --> 00:51:19,213
Speaker 0: unemployed people have a lot of productivity?

740
00:51:19,273 --> 00:51:21,060
Speaker 0: No, I can tell you the last time I was unemployed.

741
00:51:22,482 --> 00:51:26,459
Speaker 1: I remember you what you you went from zero to 100 miles an hour at find new job.

742
00:51:27,384 --> 00:51:29,879
Speaker 1: Yeah, like every waking hour into finding a better job.

743
00:51:30,462 --> 00:51:34,820
Speaker 1: Not every waking hour, but I really put in like a work week worth of finding a better job.

744
00:51:34,987 --> 00:51:37,527
Speaker 0: Yeah I tried to stream like, you know some.

745
00:51:37,547 --> 00:51:40,718
Speaker 0: you stream maybe like once or twice or something in those days.

746
00:51:40,758 --> 00:51:41,400
Speaker 0: cuz that's the time.

747
00:51:41,420 --> 00:51:42,022
Speaker 0: it Was right.

748
00:51:42,082 --> 00:51:44,633
Speaker 0: There's a different time you understand like the mid-2000s.

749
00:51:44,713 --> 00:51:46,420
Speaker 0: I was unemployed for like a few weeks.

750
00:51:46,440 --> 00:51:52,780
Speaker 0: Yeah, it was just like, you know Well, I'm gonna do a whole while I'm sitting here and I'm not looking for a job.

751
00:51:52,800 --> 00:51:53,880
Speaker 0: I'm gonna do all kinds of shit.

752
00:51:54,382 --> 00:51:57,594
Speaker 0: I did only a little bit of shit about as much as the little bit of shit.

753
00:51:57,634 --> 00:51:58,698
Speaker 0: I'm doing now, right?

754
00:51:59,059 --> 00:52:03,077
Speaker 0: So That's you know, if you're doing a little bit of extra shit, that's good enough.

755
00:52:03,097 --> 00:52:03,620
Speaker 0: That's what you're getting.

756
00:52:03,660 --> 00:52:12,000
Speaker 1: Yeah, like I'm spending a lot of time like I decided I'm gonna try to get like way ripped Like I'm working out a lot, but that takes away time from all the other things I could be doing.

757
00:52:12,120 --> 00:52:13,005
Speaker 1: I don't have more free time.

758
00:52:13,286 --> 00:52:16,020
Speaker 1: So just do not fall for the illusion of free time during this.

759
00:52:16,602 --> 00:52:18,350
Speaker 1: You don't actually have more free time.

760
00:52:18,370 --> 00:52:20,600
Speaker 1: You just have less options to spend that free time.

761
00:52:23,740 --> 00:52:30,780
Speaker 1: So we actually talked for almost an hour already And the listener actually just pointed out another classic.

762
00:52:31,141 --> 00:52:38,447
Speaker 1: This is like an old-school gig nights ribbon Scott argue through the news for 45 minutes and then are too hungry to do the main Bit, is that what the show is?

763
00:52:38,869 --> 00:52:43,927
Speaker 0: cuz let's talk about some biometric of some kind You know, let's do the highest level of like.

764
00:52:44,468 --> 00:52:45,631
Speaker 1: what are biometrics?

765
00:52:45,772 --> 00:52:47,115
Speaker 1: and like the ramifications.

766
00:52:47,135 --> 00:52:53,400
Speaker 0: so when people talk about biometrics They're usually talking about biometric authentication, which is stuff like fingerprint sensor.

767
00:52:53,560 --> 00:53:00,967
Speaker 0: You know Apple face ID some sort of system where you're using your iris detector in a movie But those exist.

768
00:53:01,048 --> 00:53:09,106
Speaker 0: kind of you know where you're trying to prove who you are to your computer to log in or prove who you are to the Computers that it opens the doors.

769
00:53:09,126 --> 00:53:09,949
Speaker 0: you can go in the office.

770
00:53:09,969 --> 00:53:16,391
Speaker 1: and that is one use of biometrics as one Biometrics, that's only biometric authentication right.

771
00:53:16,471 --> 00:53:22,760
Speaker 0: biometrics as a whole is simply measuring human biology with computers.

772
00:53:24,360 --> 00:53:24,822
Speaker 1: Biometric.

773
00:53:25,324 --> 00:53:28,116
Speaker 0: yeah, your your heart rate sensor that you use their Fitbit.

774
00:53:28,196 --> 00:53:29,060
Speaker 0: That's biometrics.

775
00:53:29,441 --> 00:53:36,922
Speaker 1: Right, in fact the Wikipedia right here for the application of statistics to biology see bio statistics Mm-hmm.

776
00:53:37,043 --> 00:53:48,065
Speaker 0: Yeah, if you got some like device a breathalyzer For the fraudulently marketed by contour treatment see Peter Foster It's some scam problem.

777
00:53:48,085 --> 00:53:50,735
Speaker 1: I guess there's a scam that was called biometrics or something.

778
00:53:50,815 --> 00:54:00,558
Speaker 0: Anyway, probably You know, you could consider Like a baseballs, you know a speed gun used to track a baseball sort of biometric.

779
00:54:00,739 --> 00:54:03,046
Speaker 1: It's great One step removed like it's an order.

780
00:54:03,086 --> 00:54:06,859
Speaker 1: Yes, but it's capturing a holistic metric of a biological action.

781
00:54:08,945 --> 00:54:17,633
Speaker 0: But if you aim it at Usain Bolt while he's running and doesn't have when he gets hopefully better from Kofi Then that would be a biometric.

782
00:54:17,694 --> 00:54:37,860
Speaker 1: Yeah, so biometrics like I guess they are a very powerful tool like way more powerful than you might realize even if you're already afraid of like facial tracking like The power here is immense the danger here is immense But also the capabilities to better mankind are immense.

783
00:54:38,021 --> 00:54:43,780
Speaker 1: This is a field that needs a lot of care and judgment and thought and guidance and ethics.

784
00:54:44,585 --> 00:54:50,009
Speaker 0: Yep, it's like okay we can measure Hopefully most things about the human body.

785
00:54:50,029 --> 00:54:52,658
Speaker 0: you can be completely measured and quantized in.

786
00:54:53,019 --> 00:54:55,540
Speaker 0: you know Many many if not all aspects, right?

787
00:54:55,560 --> 00:55:03,700
Speaker 0: Well, that's great for your health if you have a doctor who acts in good faith Because now we can figure out exactly what's wrong with you and fix it to the best of our ability?

788
00:55:03,780 --> 00:55:08,600
Speaker 1: What if your doctor acts in bad faith to try to scam you or harm you in some way?

789
00:55:09,080 --> 00:55:10,920
Speaker 1: What if your doctor is acting in good faith?

790
00:55:11,280 --> 00:55:20,800
Speaker 1: But let's say the technology that underpins American health care is shitty and all that biometric data gets stolen By someone who isn't your doctor, even though your doctor is using it to help you.

791
00:55:22,002 --> 00:55:25,720
Speaker 1: That data could be used by a third party to harm you immensely.

792
00:55:26,693 --> 00:55:33,280
Speaker 0: Yep It's like, you know, let's say, you know, we talk about biometric authentication is being the one that gets the most attention, right?

793
00:55:33,680 --> 00:55:40,739
Speaker 0: But it's like yeah It's like sometimes you want to prove exactly who you are and sometimes you don't want anyone to know who you are.

794
00:55:41,141 --> 00:55:46,260
Speaker 0: But your biology is the one thing that you cannot yet escape, right?

795
00:55:46,641 --> 00:55:54,836
Speaker 0: Yeah, so if there is biometric authentication Someone who has access to it can always prove who you are.

796
00:55:55,056 --> 00:56:08,381
Speaker 0: even in cases We don't want anyone to prove who you are And if the data is somehow messed up or the system is faulty It may become difficult or impossible to prove who you are when you want to prove who you are Here are.

797
00:56:08,542 --> 00:56:09,507
Speaker 1: I have two examples.

798
00:56:09,547 --> 00:56:11,636
Speaker 1: So one I worked as you know a long time ago.

799
00:56:11,656 --> 00:56:13,224
Speaker 1: it look God That was a long time ago.

800
00:56:13,686 --> 00:56:20,779
Speaker 1: I did project management and IT for hospitals So I had to wash my hands and then turn the page a lot.

801
00:56:21,642 --> 00:56:27,360
Speaker 1: I washed my fingerprints off over time because of the chemicals I was using something that happens to nurses often.

802
00:56:28,042 --> 00:56:28,924
Speaker 1: So I didn't have fingerprints.

803
00:56:29,726 --> 00:56:50,980
Speaker 1: So the biometric systems that I used as part of the security infrastructure I interacted with either would not work because I did not have something that would recognize as a fingerprint in their system or Recognized a fingerprint that was so generic that fucking any finger would open it if I was using my own system.

804
00:56:51,643 --> 00:56:53,310
Speaker 0: Well, yeah, it's like, you know, they register.

805
00:56:53,391 --> 00:56:55,440
Speaker 0: some doctor who's rubbed his fingerprints off.

806
00:56:55,480 --> 00:56:57,550
Speaker 0: He registers with a blank fingerprint.

807
00:56:57,590 --> 00:56:59,480
Speaker 0: Now all the blank fingerprint people can get it.

808
00:57:00,162 --> 00:57:04,694
Speaker 1: That's why while in the movies you often see single-factor biometric authentication.

809
00:57:05,035 --> 00:57:06,740
Speaker 1: Here's the two real dangers of that one.

810
00:57:07,921 --> 00:57:14,340
Speaker 1: What if someone steals that by like pulling your eye out like a spy and holding it in front of a cat?

811
00:57:14,962 --> 00:57:17,532
Speaker 0: That's already happens in every cyberpunk story.

812
00:57:17,552 --> 00:57:19,540
Speaker 0: Yeah, but that's a real fear.

813
00:57:19,881 --> 00:57:26,724
Speaker 1: I have seen proofs of concept of sham eyes for retina scanners sham fingerprints sham Everything.

814
00:57:26,744 --> 00:57:28,212
Speaker 1: if you don't even need to see.

815
00:57:28,233 --> 00:57:30,182
Speaker 1: you don't need to cut someone's finger off Necessarily.

816
00:57:30,543 --> 00:57:46,460
Speaker 1: just get their fingerprint and make a mold make it out of capacitive material that will feel like a finger put a little warmer In it like once someone has the data that comprises your biometric They have your biometric and can prove with that factor that they are you

817
00:57:47,284 --> 00:57:49,518
Speaker 0: Alright, so let's you want to get really fun, right?

818
00:57:49,598 --> 00:57:52,880
Speaker 0: Okay Hypothetical distant future, right?

819
00:57:53,140 --> 00:57:58,795
Speaker 0: We have something that's the equivalent of a camera with a super zoom lens and anyone you aim it at.

820
00:57:59,056 --> 00:58:04,380
Speaker 0: you can get their full DNA sequence right every single pair on the whole thing.

821
00:58:04,520 --> 00:58:07,412
Speaker 0: It's like, you know, right like the full fucking thing you could.

822
00:58:07,513 --> 00:58:09,260
Speaker 0: and then you can make you print out a clone body.

823
00:58:09,340 --> 00:58:10,103
Speaker 0: It's so precise.

824
00:58:10,123 --> 00:58:12,752
Speaker 1: I print out DNA evidence to obscure the crime.

825
00:58:12,812 --> 00:58:14,619
Speaker 1: I just committed and pin it on someone else.

826
00:58:15,811 --> 00:58:19,872
Speaker 0: Great You know all kinds of crazy shit going down there, right?

827
00:58:20,053 --> 00:58:26,379
Speaker 1: So in authentication biometrics Must always be one of several factors though.

828
00:58:26,399 --> 00:58:43,427
Speaker 1: I There I gotta point out right now as long as humans remain biological Technically in a pedantic and meaningless sense passwords are biometrics because you they're physically stored in your brain and Theoretically could be retrieved.

829
00:58:43,688 --> 00:58:46,699
Speaker 1: There's an engram in your brain somewhere that has your password in it.

830
00:58:47,202 --> 00:58:56,220
Speaker 1: There's a famous old Superman TV like episode I remember where someone is there's hostages and they're tied up and there's a donkey that can read minds.

831
00:58:56,320 --> 00:58:58,535
Speaker 1: Let's not worry about why there's a donkey that can read minds.

832
00:58:58,796 --> 00:59:04,094
Speaker 1: It's Superman And basically the one of the three people knows the past.

833
00:59:04,175 --> 00:59:06,805
Speaker 1: but like the combination to a safe But you can't open.

834
00:59:06,845 --> 00:59:10,721
Speaker 1: let them open the safe because there's like kryptonite in it and they're gonna use it to kill Superman like this All plot.

835
00:59:10,781 --> 00:59:11,925
Speaker 0: Oh, no, so good.

836
00:59:12,326 --> 00:59:23,567
Speaker 1: Basically the criminal brings in the donkey and they're like, I'll never say the password I'll never say the name of the combination and he's just like, all right Don't think about the combination to the safe.

837
00:59:23,587 --> 00:59:33,108
Speaker 1: know whatever way you do don't think that number and then the donkey is just like 13 and they got the combination.

838
00:59:33,951 --> 00:59:35,538
Speaker 0: Well, fuck you donkey.

839
00:59:35,719 --> 00:59:41,200
Speaker 1: Yep But in terms of like free authentication like the other I did a recent one.

840
00:59:41,220 --> 00:59:42,788
Speaker 1: This is something that happens to me today.

841
00:59:42,808 --> 00:59:49,060
Speaker 1: And this is one of this is not the like far future Security problem or even the near future security problem.

842
00:59:49,141 --> 00:59:49,764
Speaker 1: It's more the.

843
00:59:50,388 --> 00:59:52,180
Speaker 1: it makes security more annoying for me.

844
00:59:52,340 --> 00:59:56,300
Speaker 1: So I work for a fancy company where I have to use three-factor authentication to get into anything.

845
00:59:56,785 --> 01:00:01,710
Speaker 1: So I've got a physical device That I need to have on me to be able to get in.

846
01:00:02,052 --> 01:00:04,360
Speaker 1: that device has a fingerprint scanner on it.

847
01:00:04,721 --> 01:00:09,439
Speaker 1: It also has a sensor so it can basically detect a light with a little camera on it.

848
01:00:10,449 --> 01:00:25,725
Speaker 1: It does a lot of stuff But one of the things I do with it is I have to scan my fingerprint to turn it on and once it's on To get into certain systems I have to hold it up to my screen and that system after I enter my username and my password Flashes timecode data.

849
01:00:26,107 --> 01:00:31,120
Speaker 1: that thus this device will then use with random seeds to generate a TOTP code.

850
01:00:31,604 --> 01:00:33,760
Speaker 1: And I need to use all those things to log into a system.

851
01:00:35,285 --> 01:00:43,805
Speaker 1: if I take a shower and I don't wait about an hour before I try to log in my fingers a little swollen up like from the water I can't finger purge.

852
01:00:43,825 --> 01:00:44,508
Speaker 1: It doesn't fucking work.

853
01:00:44,568 --> 01:00:45,291
Speaker 1: Can't log into anything.

854
01:00:45,974 --> 01:00:46,215
Speaker 0: Mm-hmm.

855
01:00:46,677 --> 01:00:57,082
Speaker 1: So I just when I wake up in the morning, I Log into the systems lock everything then I go take a shower then I get to work Mm-hmm.

856
01:00:57,845 --> 01:01:00,191
Speaker 0: I just wrote a fictional story, right?

857
01:01:00,211 --> 01:01:00,673
Speaker 0: So you go.

858
01:01:01,074 --> 01:01:05,473
Speaker 0: so there's Indiana Jones, right and he's Obviously Indiana Jones knows something right?

859
01:01:05,493 --> 01:01:06,600
Speaker 0: He doesn't want the Nazis to know.

860
01:01:06,740 --> 01:01:09,500
Speaker 0: Yeah, so he's what he's but he's got to get past the Nazis.

861
01:01:09,660 --> 01:01:21,793
Speaker 0: So what he did is he recruited a bunch of people to dress up like Indiana Jones and that way the Nazis are gonna catch a bunch of fake Indiana Jones's and the real Indiana Jones is gonna make it past all the Nazis and deliver Right good play.

862
01:01:21,813 --> 01:01:26,369
Speaker 0: Okay, so It's in a perfect sort of future, right?

863
01:01:26,630 --> 01:01:27,432
Speaker 0: So the cost?

864
01:01:27,473 --> 01:01:29,680
Speaker 0: the Indiana Jones clone people, right?

865
01:01:29,780 --> 01:01:31,306
Speaker 0: They'll have the same face as Indiana Jones.

866
01:01:31,326 --> 01:01:33,052
Speaker 0: So they get past the facial recognition system.

867
01:01:33,092 --> 01:01:34,156
Speaker 0: They fool that right?

868
01:01:34,839 --> 01:01:37,334
Speaker 0: It's You know the let's see.

869
01:01:37,374 --> 01:01:43,725
Speaker 1: Well, there's Think they're Indiana Jones and they all try to steal the thing.

870
01:01:43,745 --> 01:01:47,610
Speaker 0: Oh possibly but the point of the story right is like, you know.

871
01:01:48,732 --> 01:01:50,861
Speaker 0: So they they capture some Indiana Jones's.

872
01:01:50,901 --> 01:01:52,850
Speaker 0: they want to figure out which one's the real one, right?

873
01:01:53,370 --> 01:01:57,225
Speaker 0: It's like something as simple as something that even exists today.

874
01:01:57,305 --> 01:01:58,650
Speaker 0: forget for our future, right?

875
01:01:59,090 --> 01:02:04,570
Speaker 0: Let's say the Nazis have the the Fitbit database and they know everyone's like heart rate zones.

876
01:02:04,752 --> 01:02:05,398
Speaker 0: Yeah, they.

877
01:02:05,600 --> 01:02:12,670
Speaker 0: they take some guns They point them at the end of Jones's they make them run on treadmills and they say who can who runs like Indiana Jones?

878
01:02:13,694 --> 01:02:24,827
Speaker 1: It's like or you know I've seen systems where it would ask you and your friends to type a bunch of stuff and then if Any of you type anything it's pretty accurate at telling who typed it just based on your typing style.

879
01:02:25,832 --> 01:02:26,953
Speaker 0: Yeah Or your walk it.

880
01:02:26,973 --> 01:02:33,135
Speaker 0: you rim could put on the best Lupin the third costume in the world or Lupin could put on the best Lupin the third costume in the world.

881
01:02:33,155 --> 01:02:35,926
Speaker 0: Yeah, and you could just see by the way he walks.

882
01:02:35,966 --> 01:02:36,468
Speaker 0: Oh, that's her.

883
01:02:36,709 --> 01:02:38,738
Speaker 1: Yep It's you know, it's no question.

884
01:02:39,000 --> 01:02:39,502
Speaker 1: I have nothing.

885
01:02:39,542 --> 01:02:42,213
Speaker 0: you that you could not fake it either There's nothing you could do.

886
01:02:42,534 --> 01:02:54,630
Speaker 1: the way I move my hands and the way my head like Bob's as I walk has caused Numerous people to recognize me in VR before I introduced myself like oh, there's rim.

887
01:02:55,496 --> 01:02:56,807
Speaker 1: This is literally happened to me.

888
01:02:57,872 --> 01:03:00,018
Speaker 1: Yeah, but let's forget about credentials here.

889
01:03:00,038 --> 01:03:00,960
Speaker 1: the other way this goes.

890
01:03:01,041 --> 01:03:03,788
Speaker 1: biometrics also data about you facial recognition.

891
01:03:04,129 --> 01:03:05,737
Speaker 1: now Listen old gig nights.

892
01:03:05,898 --> 01:03:12,090
Speaker 1: We talked a lot about like powerful cool things You could do with facial recognition like but the killer app for Google glass.

893
01:03:12,170 --> 01:03:13,775
Speaker 1: And of course, they're obvious.

894
01:03:13,995 --> 01:03:16,282
Speaker 1: as we're about to talk about dangers of this.

895
01:03:16,603 --> 01:03:18,950
Speaker 1: But if we forget the dangers first, here's the cool app.

896
01:03:19,612 --> 01:03:20,876
Speaker 1: I always have a camera on.

897
01:03:21,056 --> 01:03:21,879
Speaker 1: I got software.

898
01:03:22,420 --> 01:03:32,270
Speaker 1: if I meet a piece of shit person like I made a Nazi I made a Republican I meet like some incel like dangerous person someone who's annoying and harassing people.

899
01:03:32,633 --> 01:03:43,089
Speaker 1: I want to be able to flag them like that person's annoying So that my close personal friends if they ever encountered that person their camera will pop up a warning and say hey Rim said this person's a piece of shit.

900
01:03:44,611 --> 01:03:45,555
Speaker 1: Cool cool feature.

901
01:03:45,575 --> 01:03:47,222
Speaker 0: you could also have the opposite thing right.

902
01:03:47,282 --> 01:03:51,710
Speaker 0: some shady dudes coming up to you on the street Normally run don't talk do not engage.

903
01:03:52,071 --> 01:03:54,458
Speaker 0: But maybe it says rim verified.

904
01:03:54,498 --> 01:03:56,826
Speaker 0: this person is cool person and I'm like, huh?

905
01:03:57,107 --> 01:04:04,314
Speaker 0: Maybe all right I'll be like, oh, I know it was a listener and they just happen to recognize me and I was gonna run away Thanks to.

906
01:04:04,455 --> 01:04:12,490
Speaker 0: thanks to this system that is not being used in an evil way You know, I was able to get a slightly more interesting morning by meeting a listener.

907
01:04:12,699 --> 01:04:14,615
Speaker 1: Yep Now cool like that.

908
01:04:14,635 --> 01:04:24,275
Speaker 1: that would be an awesome thing being able to share daint the information about dangerous people with my close friend network So that they could avoid situations like harassment at conventions.

909
01:04:24,796 --> 01:04:25,577
Speaker 1: That's a killer app.

910
01:04:25,937 --> 01:04:29,291
Speaker 1: However, that exact same technology is Like.

911
01:04:29,994 --> 01:04:31,380
Speaker 1: you want to have super stalkers?

912
01:04:31,903 --> 01:04:33,550
Speaker 1: That is how you have super stalkers.

913
01:04:33,670 --> 01:04:38,070
Speaker 1: That is like you could track someone to the ends of the earth with that technology.

914
01:04:38,872 --> 01:04:39,073
Speaker 0: Yep,

915
01:04:39,494 --> 01:04:39,975
Speaker 1: because

916
01:04:40,376 --> 01:04:51,657
Speaker 0: people some not some guy some piece-of-shit guy also buys it is walking down the street Right looking at people and he sees someone and it's like, you know His piece-of-shit friend labeled someone as

917
01:04:51,777 --> 01:04:52,480
Speaker 1: an easy mark

918
01:04:52,901 --> 01:05:00,610
Speaker 0: that as jw from Twitter that the crap Right and goes over and he starts something with someone else with someone he would have otherwise ignored.

919
01:05:00,891 --> 01:05:03,620
Speaker 1: You know, all these fascist groups would enable everyone with.

920
01:05:03,901 --> 01:05:06,068
Speaker 1: here are the biometrics of people we are targeting.

921
01:05:06,148 --> 01:05:08,197
Speaker 1: if you see them You'll know those are the people to target like.

922
01:05:08,639 --> 01:05:11,029
Speaker 1: that's kind of already happening and this would accelerate that.

923
01:05:11,774 --> 01:05:15,228
Speaker 1: Yep, I don't know what to do about facial recognition And we haven't even.

924
01:05:15,268 --> 01:05:22,333
Speaker 0: yeah We haven't even begun to discuss the fact that you know any of these systems that depend upon machine learning have been trained With.

925
01:05:22,373 --> 01:05:37,850
Speaker 1: you know, basically racist data sets or you know Or to predict behavior or do other things are trained by data that will just Institutionalize encode the same institutional racism sexism and other problems that already exist in the systems.

926
01:05:37,910 --> 01:05:38,512
Speaker 1: They're modeling

927
01:05:39,035 --> 01:06:15,169
Speaker 0: and it's like even if you were to train the data sets on you know A good proportion of data from across the board right so that it would be equally good at detecting black faces and white faces and Chinese faces and you know, Iranian faces and whatever kind of faces Right, and it is equally good at detecting male and female faces and child faces and senior faces And all right, and if you removed somehow got a data set so large that it removed all Discrimination and it was equally good at you know doing things Suddenly that data set is so big that it's dangerous.

928
01:06:15,431 --> 01:06:29,359
Speaker 1: yep, because that is to be used to find trends and those trends could be used to target individuals or groups of people who would Vulnerable to certain kinds of manipulation or attack and like what happened in the 2016 election but on the tiniest scale compared to what's coming.

929
01:06:29,881 --> 01:06:35,714
Speaker 1: and the problem is facial recognition technology is Incredibly advanced already.

930
01:06:36,015 --> 01:06:47,110
Speaker 1: the killer apps we talked about only aren't made in public because for the most part people have Recognized that they would be abused and misused to such a degree that the public can't be trusted with it.

931
01:06:47,311 --> 01:06:57,770
Speaker 0: I could not think of any like public people who would with facial any facial recognition app Right that other than the one that people use which is sort your photo collection on your computer?

932
01:06:57,910 --> 01:07:06,961
Speaker 1: Yeah, right, but like my old gx1 camera like it can't even output video on its own HDMI port Yet it has a library in it.

933
01:07:07,563 --> 01:07:09,150
Speaker 1: Uh, I haven't updated a long time.

934
01:07:09,250 --> 01:07:17,039
Speaker 1: I. I took pictures of all our friends like years and years ago with this dumb camera and I put names like to all of It flags every picture with oh, that's Scott.

935
01:07:17,079 --> 01:07:17,561
Speaker 1: That's Emily.

936
01:07:17,581 --> 01:07:19,367
Speaker 1: That's all these people I could take.

937
01:07:19,548 --> 01:07:19,989
Speaker 0: but it's not.

938
01:07:20,049 --> 01:07:20,270
Speaker 0: it's not.

939
01:07:20,310 --> 01:07:21,678
Speaker 0: You're not accessing a date there.

940
01:07:21,698 --> 01:07:23,045
Speaker 0: the database would be it's not the.

941
01:07:23,267 --> 01:07:29,123
Speaker 0: I made my own Right, you made your own database, which is fine because it's gonna be small only for you.

942
01:07:29,605 --> 01:07:31,310
Speaker 0: Not very harmful, right?

943
01:07:31,990 --> 01:07:34,823
Speaker 0: Not being merged with the databases of all faces everywhere, right?

944
01:07:34,843 --> 01:07:36,330
Speaker 0: It's just for your personal use, right?

945
01:07:36,450 --> 01:07:37,474
Speaker 0: It's like what.

946
01:07:37,534 --> 01:07:38,197
Speaker 0: what harm is there?

947
01:07:38,217 --> 01:07:41,550
Speaker 0: and rim sorting his photos or having a camera that autofocus, but that's my data.

948
01:07:41,692 --> 01:07:42,289
Speaker 1: I could share it.

949
01:07:42,370 --> 01:07:48,672
Speaker 1: What if I drag a photo of someone I take into a reverse image search find other photos of that person and then use that To stock?

950
01:07:49,355 --> 01:07:50,198
Speaker 1: well, it already happens.

951
01:07:50,319 --> 01:07:52,589
Speaker 0: You could just do that with a camera that doesn't even have.

952
01:07:52,609 --> 01:07:54,395
Speaker 1: yeah I'm saying that already happens.

953
01:07:54,436 --> 01:07:59,996
Speaker 1: The technology is already out there, but we're not controlling it and we're not Like handling it.

954
01:08:00,458 --> 01:08:02,990
Speaker 1: and the technology is getting so advanced that is asymmetric.

955
01:08:03,730 --> 01:08:14,149
Speaker 1: governments and preg mega corporations have access to advanced facial recognition technology that I do not have To use to counter the effects they might have with it.

956
01:08:14,711 --> 01:08:16,234
Speaker 0: Yeah, but obviously it's like I was saying though.

957
01:08:16,255 --> 01:08:16,595
Speaker 0: It's the.

958
01:08:16,716 --> 01:08:20,166
Speaker 0: it's not actually the detection technology of saying.

959
01:08:20,225 --> 01:08:21,710
Speaker 0: Oh, that's a human face, right?

960
01:08:21,850 --> 01:08:23,336
Speaker 0: That's the most dangerous.

961
01:08:23,416 --> 01:08:26,689
Speaker 0: It's simply the large databases the most dangerous, right?

962
01:08:26,970 --> 01:08:30,442
Speaker 0: If you don't have the large databases, then all the other things are real.

963
01:08:30,502 --> 01:08:32,810
Speaker 0: It's like oh, I have a machine that can read fingerprints.

964
01:08:32,911 --> 01:08:33,895
Speaker 0: Yes, so does everybody.

965
01:08:33,916 --> 01:08:34,520
Speaker 0: they're really cheap.

966
01:08:34,560 --> 01:08:36,290
Speaker 0: You can just buy one but even without the large.

967
01:08:36,310 --> 01:08:38,545
Speaker 0: But it's like I have a database of all fingerprints.

968
01:08:38,666 --> 01:08:45,109
Speaker 1: Uh-oh Like you use a zoom lens to get good photos of one person you're making a database of one.

969
01:08:45,390 --> 01:08:47,537
Speaker 1: What are the by facial biometrics of one person?

970
01:08:47,979 --> 01:08:51,529
Speaker 1: but then you see that now with a database of biometric data?

971
01:08:52,050 --> 01:08:55,573
Speaker 1: you compare that against a database of Cameras all over the world.

972
01:08:55,673 --> 01:09:01,390
Speaker 1: dumb cameras video footage troll all of YouTube looking for where does that face appear?

973
01:09:02,572 --> 01:09:05,990
Speaker 1: The biometric data itself is not even the primary danger.

974
01:09:06,451 --> 01:09:18,448
Speaker 1: It's the database of data that you could overlay that biometric information on to ask that data questions That could not be asked of it previously at a scale that no human had ever imagined when the technology was developed.

975
01:09:19,555 --> 01:09:30,920
Speaker 0: You could also learn things like, you know Say like you're an employer and you're collecting whatever biometric data you can on your employees and then you find out Oh this employee has a cancer.

976
01:09:31,020 --> 01:09:32,988
Speaker 0: Yeah, maybe they don't even know it.

977
01:09:33,933 --> 01:09:35,621
Speaker 1: Use a ring fit adventure or Fitbit.

978
01:09:35,661 --> 01:09:37,569
Speaker 1: that's collecting a ton of biometrics.

979
01:09:38,233 --> 01:09:46,042
Speaker 0: I don't think it's sending it to Nintendo now, but it get can collect data Sure, and sometimes it's on the SD card and your switch.

980
01:09:46,162 --> 01:09:47,165
Speaker 0: Nintendo could collect it.

981
01:09:47,366 --> 01:09:55,070
Speaker 1: I guess the most difficult thing is that It's not always obvious what data could be used for something in the future.

982
01:09:55,150 --> 01:09:56,736
Speaker 1: Like it's not always a layperson.

983
01:09:57,298 --> 01:10:00,770
Speaker 1: all kind of data is useful or not useful dangerous or not dangerous.

984
01:10:01,651 --> 01:10:15,030
Speaker 1: All of it, yep, but like look at the difference a photo of your face extremely useful extremely dangerous trivial to obtain cannot be controlled Mm-hmm, but heart rate data could be controlled.

985
01:10:15,411 --> 01:10:18,282
Speaker 1: But many people give that data away to a bunch of different sites.

986
01:10:18,322 --> 01:10:21,113
Speaker 1: Like I give my heart rate data away to Strava I just get.

987
01:10:21,154 --> 01:10:23,228
Speaker 1: I just use it like Strava has all my heart rate data.

988
01:10:24,714 --> 01:10:25,845
Speaker 1: Yeah, I'm taking a risk there.

989
01:10:25,885 --> 01:10:31,484
Speaker 1: theoretically I don't plan to use heart rate biometrics anytime soon But someone else might use it against me.

990
01:10:33,554 --> 01:10:35,840
Speaker 1: But the real problem is these biometrics can't be.

991
01:10:35,900 --> 01:10:38,648
Speaker 0: she also might use it for you right to help fitness.

992
01:10:38,808 --> 01:10:42,022
Speaker 1: Yeah What if here's a detect heart disease?

993
01:10:42,303 --> 01:10:43,770
Speaker 1: Yeah, what if somehow?

994
01:10:46,092 --> 01:10:56,804
Speaker 1: They passed a law they passed all this data and they privately reached out to the 4 million Americans who have a rare heart condition That was detected by ring fit 5 in the year 2040.

995
01:10:56,804 --> 01:10:58,710
Speaker 1: That would be an objective boon to society.

996
01:10:59,372 --> 01:11:01,780
Speaker 0: But at the same time Apple says they're trying to do right?

997
01:11:01,840 --> 01:11:05,150
Speaker 1: Yeah, but can we trust mega corporations or our current governments?

998
01:11:05,390 --> 01:11:06,354
Speaker 0: No, that's the same.

999
01:11:06,475 --> 01:11:07,781
Speaker 0: That's the same evil Apple.

1000
01:11:07,801 --> 01:11:12,695
Speaker 0: We talked about in the first hour of the show The same evil.

1001
01:11:12,776 --> 01:11:15,090
Speaker 0: Apple that did that thing is also trying to solve heart disease.

1002
01:11:15,532 --> 01:11:18,569
Speaker 1: So I guess because now I am hungry we've gone on over an hour.

1003
01:11:19,352 --> 01:11:20,255
Speaker 0: Okay, good, right.

1004
01:11:20,296 --> 01:11:24,150
Speaker 1: if you don't if you don't know a lot about biometrics what I'd actually recommend?

1005
01:11:24,814 --> 01:11:26,324
Speaker 1: Read the Wikipedia page we're linking to.

1006
01:11:26,385 --> 01:11:27,049
Speaker 1: it's not long.

1007
01:11:27,831 --> 01:11:29,157
Speaker 1: It's at the right level.

1008
01:11:29,197 --> 01:11:32,130
Speaker 1: Like I've been skimming it like this is at a level that you would understand.

1009
01:11:32,872 --> 01:11:36,323
Speaker 0: Are you saying that this whole episode of geek nights was you reading Wikipedia?

1010
01:11:36,343 --> 01:11:38,530
Speaker 0: saying the geek nights is two guys reading Wikipedia?

1011
01:11:39,231 --> 01:11:39,854
Speaker 0: I know anything.

1012
01:11:40,135 --> 01:11:41,139
Speaker 1: I mean I do the live stream.

1013
01:11:41,180 --> 01:11:43,510
Speaker 1: people can usually see what I'm looking at while I'm talking.

1014
01:11:44,132 --> 01:11:48,657
Speaker 1: Sometimes the listener will see me Geek nights to read Wikipedia.

1015
01:11:49,360 --> 01:11:51,890
Speaker 0: Yeah, we pick a random Wikipedia page and read it out loud to you.

1016
01:11:52,050 --> 01:11:57,129
Speaker 1: Actually the Wikipedia goes way deeper than we went we were mostly talking about might be useful for people who can't see.

1017
01:11:57,832 --> 01:11:59,541
Speaker 1: Yeah, did you see here?

1018
01:11:59,601 --> 01:12:07,310
Speaker 1: Here's something to end on total aside Did you see that dude who has been filling the Scots Wikipedia with made-up articles forever?

1019
01:12:08,691 --> 01:12:09,601
Speaker 0: I read something about.

1020
01:12:09,661 --> 01:12:10,287
Speaker 0: I read that like.

1021
01:12:11,911 --> 01:12:12,894
Speaker 1: That's it.

1022
01:12:13,014 --> 01:12:14,298
Speaker 0: I read a headline.

1023
01:12:14,859 --> 01:12:18,630
Speaker 0: I read a headline that said the Scots Wikipedia has mostly been written by a white guy.

1024
01:12:18,670 --> 01:12:24,188
Speaker 1: So it's supposed to be articles written in the Scots dialect partly to preserve that dialect and to make it more excessive.

1025
01:12:24,228 --> 01:12:25,725
Speaker 1: like there's a lot Of reasons why that's a good thing.

1026
01:12:26,612 --> 01:12:36,086
Speaker 1: But most of the articles are written by this like American dude who apparently was just writing articles with a fakie Bullshitty Scots accent like Uncle Scrooge McDuck.

1027
01:12:36,167 --> 01:12:39,560
Speaker 0: Yeah Glad II need the biometrics.

1028
01:12:39,761 --> 01:12:40,223
Speaker 0: watch out.

1029
01:12:40,444 --> 01:12:40,625
Speaker 1: Yep.

1030
01:12:40,806 --> 01:12:44,987
Speaker 1: It's basically like make a fake accent and just write articles in it.

1031
01:12:45,208 --> 01:12:46,893
Speaker 0: and Well, they could.

1032
01:12:46,994 --> 01:12:50,869
Speaker 0: at least they're all written by the same guy with the same account, yeah pretty easy to suss that one out.

1033
01:12:51,531 --> 01:12:58,800
Speaker 1: Yeah, this has been geek nights with rim and Scott special.

1034
01:12:58,860 --> 01:13:03,620
Speaker 1: Thanks to DJ pretzel for the opening music cat leave for web design and Brando K for the logos.

1035
01:13:03,921 --> 01:13:08,940
Speaker 0: Be sure to visit our website at front row crew comm for show notes discussion news and more.

1036
01:13:09,200 --> 01:13:16,620
Speaker 1: Remember geek nights is not one but four different shows sci-tech Mondays gaming Tuesdays anime comic Wednesdays and indiscriminate Thursdays.

1037
01:13:16,981 --> 01:13:20,136
Speaker 0: Geek nights is distributed under a Creative Commons attribution 3.0 license.

1038
01:13:21,401 --> 01:13:24,491
Speaker 0: Geek nights is recorded live with no studio and no audience.

1039
01:13:24,691 --> 01:13:26,155
Speaker 0: But unlike those other late shows.

1040
01:13:26,296 --> 01:13:33,920
Speaker 1: It's actually recorded at night And the patreon patrons for this episode of geek nights are Alan Joyce hiding McNichol Marty green.

1041
01:13:33,980 --> 01:13:36,415
Speaker 1: You just like a do gags or television Graham Finch.

1042
01:13:36,435 --> 01:13:37,360
Speaker 1: You hold the key to my heart.

1043
01:13:37,400 --> 01:13:39,067
Speaker 1: She gave me a kiss and she gave me my ticket.

1044
01:13:39,107 --> 01:13:41,517
Speaker 1: Clinton Walton J Bantz rain from New Zealand Ryan parent.

1045
01:13:41,578 --> 01:13:51,300
Speaker 1: It was Brando Chris midkiff the thirst for hydrated Gannon dread Lily Tenebrae Chris Reimer Finn Sean Klein sure about all and a bunch of people who don't want me to say their names.

1046
01:13:52,042 --> 01:13:53,512
Speaker 1: yeah, we uh, we got a new.

1047
01:13:53,532 --> 01:13:59,479
Speaker 1: we're gonna do a Shorter version of a panel that we've done before so it's gonna be like a best of highlights.

1048
01:13:59,520 --> 01:14:00,062
Speaker 1: real We're gonna see.

1049
01:14:00,082 --> 01:14:04,220
Speaker 1: we're working on this new panel for Meg West, but it's definitely something no one's ever seen before.

1050
01:14:04,280 --> 01:14:07,495
Speaker 1: We've never had to do this talk in like 20 to 25 minutes.

1051
01:14:08,581 --> 01:14:09,932
Speaker 1: So we're gonna come up with a new version of.

1052
01:14:09,992 --> 01:14:10,799
Speaker 1: it should be a fun time.

1053
01:14:11,242 --> 01:14:12,331
Speaker 1: Stay tuned for other conventions.

1054
01:14:12,371 --> 01:14:13,560
Speaker 1: We might be appearing at online.

1055
01:14:14,062 --> 01:14:17,333
Speaker 1: If you think you want us to appear at some convention that's happening online.

1056
01:14:17,353 --> 01:14:18,477
Speaker 1: Just let us know.

1057
01:14:18,497 --> 01:14:21,205
Speaker 1: worst case scenario We say no, we can't do it, but you never know.

1058
01:14:21,286 --> 01:14:21,988
Speaker 1: We might do it.

1059
01:14:22,489 --> 01:14:23,753
Speaker 1: But anyway for tonight.

1060
01:14:23,773 --> 01:14:25,880
Speaker 1: I'll leave you with.

