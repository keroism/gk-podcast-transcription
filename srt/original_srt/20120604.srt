1
00:00:08,300 --> 00:00:11,809
Speaker 0: It's Monday, June 4th, 2012.

2
00:00:11,809 --> 00:00:12,271
Speaker 0: I'm Rem.

3
00:00:12,551 --> 00:00:13,053
Speaker 1: I'm Scott.

4
00:00:13,153 --> 00:00:16,241
Speaker 0: And this is Geek Nights Tonight, Government Hackers.

5
00:00:20,184 --> 00:00:21,265
Speaker 1: Let's do this.

6
00:00:24,087 --> 00:00:31,583
Speaker 0: So, this is the second episode of Geek Nights that we did but isn't online yet because our new website is not complete.

7
00:00:31,904 --> 00:00:34,997
Speaker 1: It's actually complete except for the part that uploads the episodes.

8
00:00:35,017 --> 00:00:35,560
Speaker 0: That works.

9
00:00:35,660 --> 00:00:36,746
Speaker 0: Except for the podcast part.

10
00:00:36,766 --> 00:00:37,349
Speaker 1: It actually works.

11
00:00:37,870 --> 00:00:39,819
Speaker 0: Except for that part of, you know, Geek Nights.

12
00:00:40,281 --> 00:00:41,848
Speaker 1: Except, no, it actually works.

13
00:00:41,908 --> 00:00:43,493
Speaker 1: It's just running at a hard drive space.

14
00:00:43,955 --> 00:00:50,375
Speaker 1: So, the website works but the hard drive space saving mechanism does not work.

15
00:00:50,777 --> 00:00:51,984
Speaker 0: So, what's taking up all the space?

16
00:00:52,004 --> 00:00:53,110
Speaker 0: Because the episodes aren't there.

17
00:00:53,210 --> 00:00:53,993
Speaker 1: The episodes.

18
00:00:54,094 --> 00:00:56,203
Speaker 0: But I thought we put all the episodes on Ellipse.

19
00:00:56,223 --> 00:00:59,617
Speaker 1: No, the episodes are also on the machine.

20
00:00:59,657 --> 00:01:03,494
Speaker 1: That's because they had to be on the computer when they are ID3 tagged and such and such.

21
00:01:03,534 --> 00:01:06,932
Speaker 0: But why don't we have a cron job that deletes them after, I don't know.

22
00:01:07,012 --> 00:01:13,041
Speaker 1: Because then the database will become very confused when there is a file name in the database and the file is not present in the file system.

23
00:01:13,443 --> 00:01:16,535
Speaker 0: So, it archives both the local file and the...

24
00:01:16,916 --> 00:01:19,787
Speaker 1: That is the default behavior of a Django file field.

25
00:01:19,948 --> 00:01:24,727
Speaker 1: So, I must override this behavior and keep the files in S3 or whatever.

26
00:01:24,747 --> 00:01:25,148
Speaker 0: So, I take it.

27
00:01:25,168 --> 00:01:30,023
Speaker 0: the database doesn't have the old like 2005 episodes because they're not local.

28
00:01:30,545 --> 00:01:31,267
Speaker 1: No, it does not.

29
00:01:31,287 --> 00:01:32,170
Speaker 0: Uh huh.

30
00:01:33,831 --> 00:01:35,758
Speaker 0: I still need a dump of that database but I digress.

31
00:01:37,404 --> 00:01:44,676
Speaker 0: So, I can do my auto backup to my local NAS and make the torrent I want to make of like every episode of Geek Nights from 2005 to like now.

32
00:01:44,696 --> 00:01:48,330
Speaker 0: Because I can host it here if one person downloads it, whatever.

33
00:01:48,430 --> 00:01:49,174
Speaker 0: I have plenty of bandwidth.

34
00:01:49,415 --> 00:01:52,592
Speaker 0: And if a hundred people download it, BitTorrent takes care of that.

35
00:01:52,774 --> 00:01:54,505
Speaker 1: Yeah, I don't think that many people are going to download it.

36
00:01:54,686 --> 00:01:55,068
Speaker 0: Exactly.

37
00:01:55,109 --> 00:02:00,284
Speaker 0: But as long as basically it'll never hurt my bandwidth more than... We'll see.

38
00:02:00,966 --> 00:02:02,652
Speaker 0: We'll see what actually happens.

39
00:02:02,793 --> 00:02:04,581
Speaker 0: I was trying to calculate.

40
00:02:04,601 --> 00:02:09,505
Speaker 0: I realized it's more complex to calculate because I'm still seeding for the people and depending on the algorithm, but anyway.

41
00:02:09,806 --> 00:02:10,430
Speaker 1: It's a lot.

42
00:02:10,830 --> 00:02:18,584
Speaker 0: But yeah, got to miss our burning wheel game tomorrow and almost didn't do a show today because I just got back from Istanbul and now I got to go to Toronto.

43
00:02:18,604 --> 00:02:19,769
Speaker 0: Oh, shit.

44
00:02:19,909 --> 00:02:21,093
Speaker 0: I don't want to go to Toronto.

45
00:02:21,234 --> 00:02:22,077
Speaker 1: No, so don't.

46
00:02:23,984 --> 00:02:26,212
Speaker 0: Mostly because the children have cigarette faces for ads.

47
00:02:26,393 --> 00:02:26,714
Speaker 1: Yeah.

48
00:02:27,257 --> 00:02:28,824
Speaker 0: Mostly I'm flying like porter air.

49
00:02:28,844 --> 00:02:30,170
Speaker 0: Apparently I didn't know this, right?

50
00:02:30,410 --> 00:02:32,477
Speaker 0: Because we live near Toronto, we just like drive there.

51
00:02:33,079 --> 00:02:38,357
Speaker 0: But there's an airport in the tiny little airport.

52
00:02:39,060 --> 00:02:43,297
Speaker 0: So I'm going to fly to this tiny little airport, which means I got to leave from Newark over here.

53
00:02:43,317 --> 00:02:46,069
Speaker 1: You could just fly to Rochester, which is a major airport.

54
00:02:46,450 --> 00:02:46,731
Speaker 0: And then what?

55
00:02:46,752 --> 00:02:47,636
Speaker 0: Take the slow ferry?

56
00:02:47,656 --> 00:02:49,244
Speaker 0: Is that thing even still there?

57
00:02:49,265 --> 00:02:50,713
Speaker 1: I don't know what happened to that.

58
00:02:50,733 --> 00:02:56,066
Speaker 0: I'm going to see if that thing's still there because that was... If the word boondoggle ever described a thing, it is that thing.

59
00:02:56,126 --> 00:02:57,813
Speaker 1: There are things that are much more boondoggle.

60
00:02:59,096 --> 00:03:02,625
Speaker 1: How about that empty hotel in North Korea?

61
00:03:03,447 --> 00:03:08,224
Speaker 1: Or all the multiple empty unfinished buildings in various communist nations?

62
00:03:08,605 --> 00:03:09,810
Speaker 0: Ah, but that is not boondoggle.

63
00:03:09,850 --> 00:03:10,953
Speaker 0: That is simply communism.

64
00:03:12,538 --> 00:03:14,926
Speaker 1: Maybe communism is the biggest boondoggle then.

65
00:03:15,547 --> 00:03:16,069
Speaker 0: Possibly.

66
00:03:16,129 --> 00:03:17,894
Speaker 0: But then which brand of communism?

67
00:03:18,034 --> 00:03:19,097
Speaker 1: Red communism.

68
00:03:20,320 --> 00:03:22,184
Speaker 0: Not, you know, pilgrims.

69
00:03:22,324 --> 00:03:23,327
Speaker 0: Right.

70
00:03:23,467 --> 00:03:24,469
Speaker 1: With a little commune.

71
00:03:25,191 --> 00:03:26,234
Speaker 1: We're talking big time.

72
00:03:26,254 --> 00:03:27,057
Speaker 0: The ism part.

73
00:03:27,358 --> 00:03:27,719
Speaker 1: Right.

74
00:03:28,521 --> 00:03:28,862
Speaker 1: Anyway.

75
00:03:29,504 --> 00:03:30,568
Speaker 0: So what do you got for me?

76
00:03:30,769 --> 00:03:31,230
Speaker 0: It's Monday.

77
00:03:31,391 --> 00:03:33,016
Speaker 1: Why do we even have it for you?

78
00:03:33,036 --> 00:03:33,999
Speaker 1: I don't have anything for you.

79
00:03:34,019 --> 00:03:36,506
Speaker 1: Nothing for you.

80
00:03:36,527 --> 00:03:40,538
Speaker 1: I have a news to read for the listeners of the show.

81
00:03:40,558 --> 00:03:42,543
Speaker 1: For you I have nothing.

82
00:03:42,684 --> 00:03:58,012
Speaker 1: So, you know, NASA, it's been a hot topic lately ever since the space shuttle cancelling and the SpaceX increase in the first commercial space vessel made it to the, unmanned though, made it to the space station.

83
00:03:58,133 --> 00:03:59,176
Speaker 0: I was really excited about that.

84
00:03:59,196 --> 00:03:59,697
Speaker 1: It was pretty cool.

85
00:04:01,503 --> 00:04:08,431
Speaker 1: But, you know, for quite a long time NASA has, you know, the hot topic has been the NASA budget, how small it is.

86
00:04:08,832 --> 00:04:15,977
Speaker 1: How it used to be like a few percents of government spending and now it's half a percent of the budget is.

87
00:04:16,177 --> 00:04:23,685
Speaker 1: So every dollar you, you know, give to the government in taxes, one half of one penny is for NASA and the rest is for other shit.

88
00:04:24,107 --> 00:04:24,790
Speaker 1: That is not NASA.

89
00:04:25,431 --> 00:04:29,966
Speaker 1: So, you know, everyone's like raise the NASA budget to just one percent.

90
00:04:30,026 --> 00:04:35,203
Speaker 1: Come on, you know, but so that way one whole penny will go to them.

91
00:04:35,484 --> 00:04:38,015
Speaker 1: That doesn't look like it's happening, but nerds are yelling for it.

92
00:04:38,859 --> 00:04:45,270
Speaker 1: So it turns out that one of the things NASA has been working on for a long time is replacing the Hubble telescope, which is a pretty awesome thing.

93
00:04:45,370 --> 00:04:50,516
Speaker 1: And we went up to repair it a whole bunch of times, but it's expensive to maintain and a whole bunch of times.

94
00:04:50,556 --> 00:04:52,789
Speaker 0: How many times did we go up there and do anything to it?

95
00:04:52,889 --> 00:04:55,059
Speaker 1: Pretty sure we went up there and fixed it two or three times.

96
00:04:55,180 --> 00:05:00,363
Speaker 1: OK, anyway, I'm just based on memory of news and stuff, but then I don't have numbers.

97
00:05:00,564 --> 00:05:03,595
Speaker 1: We could go read Wikipedia and Hubble Space Telescope and find out.

98
00:05:04,780 --> 00:05:06,747
Speaker 1: But anyway, it's not doing too well.

99
00:05:07,028 --> 00:05:08,252
Speaker 1: It's kind of old and crummy.

100
00:05:08,373 --> 00:05:10,081
Speaker 1: We could do a lot better pretty easily.

101
00:05:10,101 --> 00:05:17,009
Speaker 1: And there's a project to do that that NASA is, you know, sort of, you know, spending too much money and time on called.

102
00:05:17,069 --> 00:05:17,651
Speaker 1: what's it called?

103
00:05:17,672 --> 00:05:20,284
Speaker 1: It is called the James Webb Space Telescope.

104
00:05:20,445 --> 00:05:20,606
Speaker 1: Right.

105
00:05:20,626 --> 00:05:22,212
Speaker 1: It's been eating up the science budget.

106
00:05:23,235 --> 00:05:32,222
Speaker 1: So apparently The Washington Post just reported the Department of Defense just gave two better than Hubble telescopes to NASA.

107
00:05:32,263 --> 00:05:32,664
Speaker 1: Like, here you go.

108
00:05:34,208 --> 00:05:35,474
Speaker 0: So we just had these lying around.

109
00:05:35,514 --> 00:05:36,963
Speaker 1: We just had these lying around unused.

110
00:05:37,506 --> 00:05:38,471
Speaker 0: Wait a minute, wait a minute, wait a minute.

111
00:05:38,491 --> 00:05:45,993
Speaker 0: So clearly what these are are spy telescopes that are so obsolete, spy satellites.

112
00:05:46,033 --> 00:05:49,048
Speaker 1: And the reason they had extra ones is because they were the spares.

113
00:05:49,189 --> 00:05:49,350
Speaker 1: Right.

114
00:05:49,551 --> 00:05:50,916
Speaker 1: And the real one must have been.

115
00:05:50,937 --> 00:05:51,559
Speaker 1: Right.

116
00:05:51,599 --> 00:05:55,457
Speaker 1: So these are spare because the Department of Defense always make spares of everything.

117
00:05:55,598 --> 00:05:55,819
Speaker 1: Yeah.

118
00:05:56,261 --> 00:05:57,910
Speaker 0: So what was the quote from contact?

119
00:05:58,230 --> 00:06:00,559
Speaker 0: Why build one when you can have two at twice the price?

120
00:06:00,920 --> 00:06:01,161
Speaker 1: Right.

121
00:06:01,623 --> 00:06:05,536
Speaker 1: So, you know, these are spares that are on the ground.

122
00:06:05,938 --> 00:06:06,319
Speaker 1: Right.

123
00:06:06,439 --> 00:06:12,799
Speaker 1: That means that, you know, they had one in space and they had at least another spare in space.

124
00:06:13,783 --> 00:06:15,489
Speaker 1: So there's multiples of these things.

125
00:06:15,509 --> 00:06:17,317
Speaker 1: They're just turned around the wrong way.

126
00:06:17,598 --> 00:06:38,902
Speaker 1: And if they're giving the ground, the never used spares to NASA, that means that they are that the ones in space are like they're done with the hose and they put up new ones already or maybe drove, you know, this speculation like, oh, maybe the since they have drones that are better, they don't need the space telescopes to spy anymore or all kinds of stuff.

127
00:06:39,404 --> 00:06:41,693
Speaker 1: But the point is, there's at least one in space.

128
00:06:42,155 --> 00:06:45,527
Speaker 1: If you're not using any more, just turn it the fuck around.

129
00:06:45,988 --> 00:06:48,040
Speaker 0: Well, you have to swap out the sensors, at least.

130
00:06:48,060 --> 00:06:49,389
Speaker 0: I mean, you're looking for different stuff.

131
00:06:49,449 --> 00:06:54,407
Speaker 1: Well, you know, if we had a space shuttle, we could have gone up there and fixed it.

132
00:06:54,427 --> 00:06:56,213
Speaker 1: The thing is, and we could I.

133
00:06:57,938 --> 00:07:10,346
Speaker 0: this is just a really fascinating story because it highlights so many of the like sort of high level arguments that nerds have around the military and space and everything that the military is so much money that they got just extras.

134
00:07:10,386 --> 00:07:13,078
Speaker 0: The thing that NASA just can't find enough money to build.

135
00:07:13,219 --> 00:07:13,420
Speaker 0: Right.

136
00:07:13,681 --> 00:07:15,952
Speaker 0: But the thing is, it's actually a lot more complex than that.

137
00:07:15,972 --> 00:07:16,153
Speaker 1: Yeah.

138
00:07:16,193 --> 00:07:23,003
Speaker 1: But one of the major defenses of defense spending is that, look, it brings about all these great things like Internet's and such like that.

139
00:07:23,103 --> 00:07:23,445
Speaker 1: Yeah.

140
00:07:23,666 --> 00:07:28,652
Speaker 1: You know, the great research that we do, you know, that's where actually most of the defense budget is, things like that.

141
00:07:28,753 --> 00:07:38,513
Speaker 1: And also building things after we've invented them, like a whole bunch of jets or the Ford class aircraft, a whole bunch of tanks or a whole bunch of boats or guns or whatever it is.

142
00:07:38,594 --> 00:07:38,734
Speaker 1: Right.

143
00:07:40,540 --> 00:07:54,655
Speaker 1: You know, but the problem is, is that those things all too often, you know, they keep citing all these examples of those things eventually becoming consumer grade goods or, you know, used by other people outside the military, things that were invented in the military, like the Internet's.

144
00:07:55,317 --> 00:08:03,902
Speaker 1: But apparently, you know, the primary goal, you know, you know, those things may happen.

145
00:08:03,922 --> 00:08:06,916
Speaker 1: Their primary goal is defense and also offense.

146
00:08:07,037 --> 00:08:10,132
Speaker 1: Even though they call themselves defense, there's offense going on a whole lot of offense.

147
00:08:11,056 --> 00:08:17,362
Speaker 1: And in, you know, games of defense and offense, when you invent something new and awesome, you got to keep it secret.

148
00:08:17,442 --> 00:08:19,633
Speaker 1: Otherwise, the other guy has it now and you're in big trouble.

149
00:08:19,773 --> 00:08:20,698
Speaker 0: Well, it depends there.

150
00:08:21,020 --> 00:08:26,850
Speaker 0: For example, there in software design, like, for example, say you have an interface that's really cool for some software is really cool.

151
00:08:27,131 --> 00:08:30,467
Speaker 0: You can show it to people like they see it and maybe they'll try to copy it.

152
00:08:30,889 --> 00:08:38,099
Speaker 0: Now, if your idea was not actually like there wasn't that novel, then they could just copy it from the interface and they've got the same thing as you.

153
00:08:38,179 --> 00:08:39,024
Speaker 0: Your thing was worthless.

154
00:08:39,688 --> 00:08:44,150
Speaker 0: But if the back end architecture is, you know, the real important part, then they can see it all they want.

155
00:08:44,171 --> 00:08:45,176
Speaker 0: They still can't copy it.

156
00:08:45,477 --> 00:08:45,698
Speaker 1: Yeah.

157
00:08:46,241 --> 00:08:51,039
Speaker 1: But the fact that they know you have it, for example, something like a spy satellite telescope.

158
00:08:51,259 --> 00:08:51,540
Speaker 1: Right.

159
00:08:51,901 --> 00:08:53,647
Speaker 1: Just even knowing it exists.

160
00:08:53,727 --> 00:09:03,583
Speaker 1: But they could look into space, figure out where it is, move out of the way when you say game theory that that information itself becomes part of the equation.

161
00:09:03,884 --> 00:09:13,388
Speaker 0: So you set up you make them know that you have this uber weapon, even if you don't, for example, or you let them know, yeah, we can see everything you're doing above ground with these satellites.

162
00:09:13,408 --> 00:09:13,509
Speaker 0: But

163
00:09:13,529 --> 00:09:27,030
Speaker 1: the point is, you're not going to start giving the technology for this space satellite to people outside of the military who are just like at NASA or whatever who might leak it or who knows what, you know, or to just people on the streets that they can make their own.

164
00:09:27,270 --> 00:09:33,136
Speaker 0: Because what that implies is that there is not that much special about these compared to what the military is using now.

165
00:09:33,257 --> 00:09:33,839
Speaker 0: Exactly.

166
00:09:34,120 --> 00:09:35,646
Speaker 1: And this is why we should take.

167
00:09:35,886 --> 00:09:44,683
Speaker 1: you know, it's like even though putting money into defense can result in research and new inventions that eventually, you know, might be used by us and better our lives.

168
00:09:44,703 --> 00:09:51,790
Speaker 1: You should instead take that money and just give it to research directly that is open in public research.

169
00:09:51,810 --> 00:10:03,211
Speaker 0: I'm going to make the the argument of I wouldn't necessarily say instead, because that begs the question that the value of the defense spending for the purposes of defense is not there.

170
00:10:03,231 --> 00:10:05,962
Speaker 1: No, because here's the thing that makes it work.

171
00:10:06,344 --> 00:10:06,605
Speaker 1: Right.

172
00:10:06,625 --> 00:10:17,424
Speaker 1: It's like, oh, let's say we had given the money to invent the even better space satellite that we probably have to NASA and NASA had invented the even better space satellite that we could have.

173
00:10:17,504 --> 00:10:18,969
Speaker 1: Right now.

174
00:10:19,050 --> 00:10:30,738
Speaker 1: Well, first of all, you know, that knowledge of how to make that awesome thing and, you know, it being used for space research would have resulted in way more benefits than just looking at terrorists and walking around somewhere.

175
00:10:30,759 --> 00:10:31,280
Speaker 1: Right.

176
00:10:32,103 --> 00:10:35,718
Speaker 1: And two, it's not like the Defense Department wouldn't have it also.

177
00:10:36,039 --> 00:10:36,240
Speaker 1: Right.

178
00:10:36,280 --> 00:10:36,823
Speaker 1: They would still.

179
00:10:36,924 --> 00:10:40,441
Speaker 1: they just get it from the NASA and still have spit the spy satellites necessary.

180
00:10:40,461 --> 00:10:44,463
Speaker 0: I think it comes down more to the logistics Scott of and even how the money is allocated.

181
00:10:44,483 --> 00:10:48,121
Speaker 0: I mean, how much of that money do you think is allocated to pure research in the military versus.

182
00:10:48,201 --> 00:10:48,422
Speaker 0: Yeah.

183
00:10:48,523 --> 00:10:50,150
Speaker 0: Here's a specific task and intent.

184
00:10:50,450 --> 00:10:56,415
Speaker 1: And even if right that, you know, so NASA invented the space thing instead of the Defense Department inventing it.

185
00:10:56,717 --> 00:10:58,909
Speaker 1: Therefore, everyone in the whole world knows how to make one.

186
00:10:59,411 --> 00:10:59,612
Speaker 1: Right.

187
00:11:00,013 --> 00:11:00,856
Speaker 1: But sure.

188
00:11:01,137 --> 00:11:01,418
Speaker 1: Great.

189
00:11:01,499 --> 00:11:02,522
Speaker 1: Everyone knows how to make one.

190
00:11:02,542 --> 00:11:03,345
Speaker 1: And we've got them.

191
00:11:04,309 --> 00:11:07,587
Speaker 1: You still don't know how many we've got, where they are, what we're doing with them.

192
00:11:07,627 --> 00:11:08,531
Speaker 1: So it's still secret.

193
00:11:08,833 --> 00:11:10,659
Speaker 0: And the argument against this.

194
00:11:10,679 --> 00:11:14,373
Speaker 1: And I'm still not convinced anyone else who wants to make one.

195
00:11:14,393 --> 00:11:17,690
Speaker 1: It's not like they can afford to make one anyway, even if they knew how.

196
00:11:17,870 --> 00:11:22,543
Speaker 0: So you rephrased what I said before and you added a little bit more nothing to it.

197
00:11:23,004 --> 00:11:31,455
Speaker 0: I don't think you've just made a compelling argument because these satellites, one, they weren't a technology problem.

198
00:11:31,475 --> 00:11:32,700
Speaker 0: They're an engineering problem.

199
00:11:33,764 --> 00:11:35,992
Speaker 0: And they were made for a specific purpose.

200
00:11:36,374 --> 00:11:43,566
Speaker 0: I think NASA's biggest problem is that there wasn't a very public, very direct goal that they were working toward with the majority of their effort.

201
00:11:43,848 --> 00:11:44,350
Speaker 1: Yeah, they were.

202
00:11:44,530 --> 00:11:45,415
Speaker 1: They were just suck it.

203
00:11:45,435 --> 00:11:46,320
Speaker 0: And what was their goal?

204
00:11:46,581 --> 00:11:49,316
Speaker 1: The James Webb Space Telescope, which is supposed to replace the Hubble.

205
00:11:49,457 --> 00:11:52,391
Speaker 1: But but it's been way over budget and not doing too well.

206
00:11:52,551 --> 00:11:52,752
Speaker 1: Yeah.

207
00:11:53,033 --> 00:11:59,481
Speaker 0: So you realize, Scott, these satellites that the military is giving them still have to be completely retooled to do this.

208
00:11:59,642 --> 00:12:03,579
Speaker 0: The science thing that NASA wants to do, because the military has no reason to do that part.

209
00:12:03,759 --> 00:12:06,992
Speaker 1: It is still much easier than making a whole new thing.

210
00:12:07,033 --> 00:12:07,274
Speaker 1: Yeah.

211
00:12:07,294 --> 00:12:09,966
Speaker 0: Scott, you realize the military made these satellites for one purpose.

212
00:12:10,730 --> 00:12:19,530
Speaker 0: The only really useful part of it, as far as I can gather from the articles I read on this for NASA, is that the satellite itself is already made, but it's not a special satellite.

213
00:12:19,990 --> 00:12:25,735
Speaker 0: The special part is the part NASA is going to add and make to it, which is the actual like sensors.

214
00:12:25,755 --> 00:12:25,976
Speaker 0: And

215
00:12:25,996 --> 00:12:38,494
Speaker 1: what I'm saying is if that money that was given to the Defense Department to make these things in the first place have been given to NASA in the first place, right, it would have gone the other way and we would have had them in both departments for a much longer period of time.

216
00:12:38,514 --> 00:12:44,010
Speaker 0: Maybe or maybe not, because we don't know what other fruit came out of the research in the military privately.

217
00:12:44,550 --> 00:12:44,651
Speaker 1: Right.

218
00:12:44,711 --> 00:12:48,190
Speaker 1: So it would have been even more fruit going both ways, because anything NASA invents.

219
00:12:48,370 --> 00:12:48,834
Speaker 1: Wait, wait, wait.

220
00:12:48,894 --> 00:12:50,649
Speaker 0: So your argument is we don't know.

221
00:12:51,031 --> 00:12:53,189
Speaker 0: So therefore, clearly it must have been more.

222
00:12:53,754 --> 00:12:54,180
Speaker 1: Oh, yeah.

223
00:12:54,200 --> 00:12:54,909
Speaker 1: You think it would be less?

224
00:12:55,331 --> 00:12:55,837
Speaker 0: It might be.

225
00:12:56,019 --> 00:12:56,930
Speaker 0: I thought it'd be less.

226
00:12:57,130 --> 00:13:02,849
Speaker 0: I'm saying that we don't know enough about what the money is actually spent on to make to have a discussion about that.

227
00:13:04,391 --> 00:13:09,275
Speaker 1: I'm the point is, if the if the Defense Department invents something right, it may eventually.

228
00:13:09,817 --> 00:13:12,570
Speaker 0: Yes, but did they invent something or is this just engineering?

229
00:13:12,770 --> 00:13:13,829
Speaker 0: They made some satellites.

230
00:13:14,431 --> 00:13:14,692
Speaker 1: Sure.

231
00:13:14,752 --> 00:13:16,439
Speaker 1: They had money to make a satellite.

232
00:13:17,262 --> 00:13:19,430
Speaker 1: if they had money to make that right.

233
00:13:19,470 --> 00:13:20,749
Speaker 1: If that money was given to NASA.

234
00:13:21,371 --> 00:13:21,612
Speaker 1: Right.

235
00:13:21,653 --> 00:13:25,934
Speaker 1: We could have had both defense satellites and NASA satellites, but instead we only have defense ones.

236
00:13:26,597 --> 00:13:29,130
Speaker 0: Well, apparently, no, we have both because they gave them to NASA.

237
00:13:29,311 --> 00:13:29,635
Speaker 0: Yeah.

238
00:13:30,059 --> 00:13:30,827
Speaker 1: Like extra one.

239
00:13:33,291 --> 00:13:34,057
Speaker 0: Maybe they had some.

240
00:13:34,239 --> 00:13:35,709
Speaker 1: We could have had them a long time ago.

241
00:13:35,990 --> 00:13:36,154
Speaker 1: Right.

242
00:13:36,174 --> 00:13:36,849
Speaker 1: Maybe or maybe not.

243
00:13:36,970 --> 00:13:37,593
Speaker 0: We don't really know.

244
00:13:37,613 --> 00:13:41,555
Speaker 1: I mean, the military probably has not given it to NASA if it's not old.

245
00:13:41,575 --> 00:13:42,609
Speaker 1: Yeah.

246
00:13:42,790 --> 00:13:47,813
Speaker 0: The thing is, no, nothing I've read says that these are particularly novel technology for satellites.

247
00:13:48,415 --> 00:13:51,830
Speaker 0: It's just that they already made them anyway.

248
00:13:52,590 --> 00:13:55,629
Speaker 0: Anyway, so we don't really need to dwell on it, but I'm sure you've read the news.

249
00:13:56,153 --> 00:13:58,346
Speaker 0: Google won APIs already.

250
00:13:59,330 --> 00:14:02,330
Speaker 0: No, we didn't, because the ruling had not been made the last time we did a show.

251
00:14:02,731 --> 00:14:03,353
Speaker 1: Big difference.

252
00:14:03,855 --> 00:14:09,750
Speaker 0: Yeah, because the case before the court, you know, the jury had ruled on some of the points about fair use and whatever.

253
00:14:09,830 --> 00:14:13,090
Speaker 0: But what had not been ruled on was the thing that the judge had to decide.

254
00:14:13,210 --> 00:14:14,728
Speaker 0: Basically, the court went, the case went like this.

255
00:14:15,710 --> 00:14:18,970
Speaker 0: Jury, tell us if Google infringed and if fair use is a defense.

256
00:14:20,090 --> 00:14:27,109
Speaker 0: Independently, if that answer, the judge got to say whether or not it even mattered, whether or not APIs are even copyrightable.

257
00:14:27,930 --> 00:14:33,370
Speaker 0: And I bring it up again, partly because this is a case of a judge who said, look, this is a technology thing.

258
00:14:33,573 --> 00:14:34,830
Speaker 0: I'm going to learn the technology.

259
00:14:35,570 --> 00:14:38,922
Speaker 0: And he basically told the Oracle lawyer.

260
00:14:39,223 --> 00:14:52,409
Speaker 0: when the Oracle lawyer tried to argue that this API and the shared code was so hard to make and so many millions of dollars in damages, the judge basically said, look, I learned how to do this and wrote the code that you say is so hard to make in a couple hours.

261
00:14:52,812 --> 00:14:56,870
Speaker 0: Are you really going to sit here and tell me that this is millions of dollars of damages?

262
00:14:57,110 --> 00:15:01,209
Speaker 0: The thing that I and old judge guy figured out kind of on my own in my spare time.

263
00:15:01,851 --> 00:15:06,130
Speaker 0: And the Oracle guy's response was basically, well, I'm not an expert on computers.

264
00:15:06,750 --> 00:15:09,030
Speaker 1: Then why are you lawyering computers?

265
00:15:09,390 --> 00:15:09,933
Speaker 0: But no, this is.

266
00:15:10,315 --> 00:15:18,450
Speaker 0: this is important because this is one of the times where the courts actually like there is no complaint from a nerd on how this all shook down.

267
00:15:18,711 --> 00:15:19,596
Speaker 1: Of course not.

268
00:15:19,998 --> 00:15:24,490
Speaker 1: And except for the fact that it shouldn't even happen in the first place, because these patents shouldn't exist in the first place.

269
00:15:24,851 --> 00:15:27,390
Speaker 1: How much time and money do we waste in this case?

270
00:15:27,670 --> 00:15:30,050
Speaker 0: It was about copyright and the then copyright.

271
00:15:30,233 --> 00:15:31,230
Speaker 0: Now we have a ruling.

272
00:15:31,673 --> 00:15:33,228
Speaker 0: You cannot copyright an API.

273
00:15:34,313 --> 00:15:35,350
Speaker 0: That's really important.

274
00:15:35,710 --> 00:15:37,809
Speaker 0: And that gone the other way would have been trouble.

275
00:15:38,271 --> 00:15:38,613
Speaker 1: Big trouble.

276
00:15:38,774 --> 00:15:49,189
Speaker 0: But no, the real thing I want to talk about is, you know, we've complained from the from the beginning when this was first a thing that this expansion of the top level domains in DNS is a bad idea.

277
00:15:50,270 --> 00:15:53,970
Speaker 0: There's so many reasons it's a bad idea, but it's happening anyway.

278
00:15:54,610 --> 00:15:55,829
Speaker 0: There's not much we can do about it.

279
00:15:56,190 --> 00:15:56,411
Speaker 0: Nope.

280
00:15:56,431 --> 00:16:05,048
Speaker 0: So I wonder what the actual end result is going to be, because Google at least sees this for what it is.

281
00:16:05,291 --> 00:16:05,838
Speaker 0: And they're getting.

282
00:16:05,858 --> 00:16:06,830
Speaker 0: you know, they got like Google.

283
00:16:07,011 --> 00:16:10,590
Speaker 0: They're doing what every big company is forced to do now, getting the company name.

284
00:16:10,891 --> 00:16:11,072
Speaker 0: Yep.

285
00:16:11,636 --> 00:16:13,990
Speaker 0: But Google also went for that law.

286
00:16:15,611 --> 00:16:21,127
Speaker 0: And I have a feeling if anyone is going to do the right thing with that law, it is going to be Google.

287
00:16:21,533 --> 00:16:22,829
Speaker 1: They're going to make Google that law.

288
00:16:23,170 --> 00:16:23,673
Speaker 1: Google.

289
00:16:26,005 --> 00:16:26,890
Speaker 0: I wonder what they're going to do with.

290
00:16:26,970 --> 00:16:31,172
Speaker 0: I think they're going to make that they're another one of their domain name shorteners for one.

291
00:16:31,192 --> 00:16:38,050
Speaker 0: I don't know what else they'll do with it, but I don't know how many of you paid attention to how these domains are actually being allocated.

292
00:16:38,050 --> 00:16:40,870
Speaker 1: Well, you have to run your own root servers if you get one of these, right?

293
00:16:41,573 --> 00:16:42,379
Speaker 0: I didn't read that part.

294
00:16:42,420 --> 00:16:43,449
Speaker 0: I assume so.

295
00:16:44,031 --> 00:16:44,253
Speaker 1: Yeah.

296
00:16:44,293 --> 00:16:46,550
Speaker 1: Which means you have to prove that you can actually run them properly.

297
00:16:46,830 --> 00:16:50,550
Speaker 0: It's got not root root, not, you know, the 13 at the core.

298
00:16:50,691 --> 00:16:51,173
Speaker 1: No, no, no.

299
00:16:51,193 --> 00:16:54,690
Speaker 0: But because those delegate, you know, where com net, whatever are.

300
00:16:54,850 --> 00:16:55,355
Speaker 1: So they have to run.

301
00:16:55,375 --> 00:16:56,829
Speaker 1: But there's someone who runs com.

302
00:16:57,210 --> 00:16:57,271
Speaker 1: Yes.

303
00:16:57,291 --> 00:16:58,910
Speaker 1: Doesn't VeriSign run com or something?

304
00:16:59,090 --> 00:16:59,395
Speaker 1: Google.

305
00:16:59,456 --> 00:17:00,330
Speaker 1: That's a lot of servers.

306
00:17:00,330 --> 00:17:02,690
Speaker 0: Google will probably have to run dot lol and dot Google.

307
00:17:03,010 --> 00:17:04,130
Speaker 1: Well, Google I'm sure can do it.

308
00:17:04,230 --> 00:17:06,130
Speaker 0: It's interesting that Google is going for docs.

309
00:17:06,251 --> 00:17:07,017
Speaker 0: I mean, Google docs.

310
00:17:07,058 --> 00:17:08,510
Speaker 0: Yeah, but that's a pretty generic term.

311
00:17:08,569 --> 00:17:09,868
Speaker 1: I'm sure they know how to run the servers.

312
00:17:10,150 --> 00:17:10,715
Speaker 0: Oh, I trust them.

313
00:17:11,060 --> 00:17:11,949
Speaker 1: They'll probably write their own.

314
00:17:12,430 --> 00:17:26,609
Speaker 0: But I would I would suggest that many of you look at how the lots are being allocated in terms of what domains are up for bidding and available when, because they're not going to release them all at once because this is a cash grab.

315
00:17:26,690 --> 00:17:32,495
Speaker 0: So every stupid bullshit domain that some spammer gets has to get its time in the limelight as check it out.

316
00:17:32,535 --> 00:17:35,330
Speaker 0: Here's the list of new domains this month or this week or this whatever.

317
00:17:36,290 --> 00:17:52,430
Speaker 0: So they're doing something that's kind of called digital archery, where they give you a link or something like that and you have to click it or shoot it, basically as close to a particular time as possible.

318
00:17:52,832 --> 00:17:55,409
Speaker 0: And whoever is closest wins.

319
00:17:56,432 --> 00:17:56,753
Speaker 1: What?

320
00:17:57,116 --> 00:17:59,590
Speaker 0: Yeah, you didn't pay attention to this stuff at all, did you?

321
00:17:59,690 --> 00:18:00,338
Speaker 1: This is stupid.

322
00:18:00,358 --> 00:18:01,370
Speaker 1: Are you sure this is real?

323
00:18:01,490 --> 00:18:01,831
Speaker 0: Yes.

324
00:18:02,914 --> 00:18:14,389
Speaker 0: So I have already found, for example, that there are a ridiculous number of people trying to offer a service of winning this archery for you.

325
00:18:14,890 --> 00:18:15,788
Speaker 1: Wasn't Google just going to win?

326
00:18:16,611 --> 00:18:16,872
Speaker 0: Yeah.

327
00:18:17,334 --> 00:18:21,489
Speaker 1: They have an atomic clock with a computer right next to the computer.

328
00:18:21,509 --> 00:18:22,071
Speaker 1: you have to hit.

329
00:18:22,312 --> 00:18:28,929
Speaker 0: I am going to suggest that every Google domain, every time Google is involved in digital archery, they're going to win.

330
00:18:29,273 --> 00:18:30,650
Speaker 0: And I defy anyone else to win.

331
00:18:30,850 --> 00:18:32,390
Speaker 1: Who came up with this retarded system?

332
00:18:32,810 --> 00:18:33,357
Speaker 0: Don't even get me.

333
00:18:33,579 --> 00:18:34,410
Speaker 1: I got a better system.

334
00:18:34,530 --> 00:18:35,339
Speaker 1: You ready for the system?

335
00:18:35,561 --> 00:18:36,310
Speaker 0: First come, first serve.

336
00:18:36,972 --> 00:18:37,698
Speaker 1: It's a good system.

337
00:18:37,739 --> 00:18:38,929
Speaker 1: I got another good round robin.

338
00:18:39,190 --> 00:18:40,050
Speaker 1: I got another good system.

339
00:18:40,391 --> 00:18:43,169
Speaker 1: As soon as they're approved, whoever pays the most money wins.

340
00:18:43,630 --> 00:18:43,951
Speaker 0: All right.

341
00:18:43,992 --> 00:18:49,054
Speaker 0: So you have to pay both to be ahead of everyone else for your domain and to get your domain.

342
00:18:49,074 --> 00:18:51,889
Speaker 0: All right, we could do that.

343
00:18:52,410 --> 00:18:55,049
Speaker 0: Google will still get them all because they have untold millions of dollars.

344
00:18:55,250 --> 00:18:57,057
Speaker 0: I'm saying I just.

345
00:18:57,961 --> 00:19:04,991
Speaker 0: what's interesting is that already a lot of professional associations are trying to get like dot bank and then like work among themselves to make that a secure place.

346
00:19:06,736 --> 00:19:14,690
Speaker 0: I still posit that the vast majority of the new top level domains will be untrusted and or ignored by the vast majority of people on the Internet.

347
00:19:14,931 --> 00:19:16,850
Speaker 1: I'm definitely not going to be trusting many of them.

348
00:19:17,612 --> 00:19:25,239
Speaker 0: I will probably use that Google because I've realized that my personal workflows, like my life stuff, pretty much like my life.

349
00:19:25,680 --> 00:19:29,531
Speaker 0: workflow online is really inside of Google the whole time.

350
00:19:29,572 --> 00:19:34,605
Speaker 0: Kind of like how when I do audio and video stuff, my workflow is pretty much inside of Adobe the whole time.

351
00:19:36,132 --> 00:19:39,333
Speaker 0: So I think I'll be on Google a lot, but I don't know how much I'll trust them as other stuff.

352
00:19:39,516 --> 00:19:40,670
Speaker 1: No, definitely not.

353
00:19:40,770 --> 00:19:42,730
Speaker 0: We're going to make sure Pirate Bay gets Bay.

354
00:19:43,333 --> 00:19:43,637
Speaker 1: .Bay.

355
00:19:43,719 --> 00:19:44,410
Speaker 1: Pirate.Bay.

356
00:19:47,990 --> 00:19:48,093
Speaker 0: .Yarrr.

357
00:19:48,113 --> 00:19:48,236
Speaker 0: .RRRRRR.

358
00:19:49,394 --> 00:19:50,870
Speaker 1: How are they going to host the servers?

359
00:19:51,395 --> 00:19:52,750
Speaker 1: Everyone will just block them easily.

360
00:19:53,811 --> 00:19:54,213
Speaker 0: We'll see.

361
00:19:54,233 --> 00:19:57,186
Speaker 0: I just wanted I wanted to point this out in the thing is right.

362
00:19:57,427 --> 00:19:58,111
Speaker 0: the last show we did.

363
00:19:58,151 --> 00:20:03,255
Speaker 0: I mentioned this archery thing and I don't think many people really knew what that was.

364
00:20:03,276 --> 00:20:04,550
Speaker 1: Here's what's going to happen, though, right.

365
00:20:04,812 --> 00:20:05,929
Speaker 1: Let's say I make .Yarrr.

366
00:20:07,533 --> 00:20:09,369
Speaker 1: And that's all pirate sites in there.

367
00:20:09,710 --> 00:20:09,810
Speaker 0: Right.

368
00:20:09,911 --> 00:20:10,172
Speaker 0: Yeah.

369
00:20:10,373 --> 00:20:19,930
Speaker 1: Then most people are just using like the Time Warner DNS server or the Verizon DNS server, those DNS servers, if you ask them like, hey, what's the IP address of?

370
00:20:21,311 --> 00:20:25,069
Speaker 1: They'll just be like, "Eh, I don't see anything called scott.yar, I never heard of it.

371
00:20:26,313 --> 00:20:26,577
Speaker 1: No such

372
00:20:26,618 --> 00:20:26,801
Speaker 1: thing.".

373
00:20:28,070 --> 00:20:31,537
Speaker 0: The thing is, DNS blocking, we know, doesn't really work to actually stop people from buying it.

374
00:20:31,670 --> 00:20:33,210
Speaker 1: No, but it stops normal people from going in.

375
00:20:33,290 --> 00:20:39,090
Speaker 1: So if I put up billboards everywhere, "Everyone go to scott.yar, check out my awesome website," and no one will be able to get to it unless they're smart.

376
00:20:40,092 --> 00:20:40,790
Speaker 0: We'll see what happens.

377
00:20:41,211 --> 00:20:48,350
Speaker 0: I really just wanted people to see this archery thing, and the sheer number of people who appear to be trying to turn that into a business.

378
00:20:50,411 --> 00:20:53,090
Speaker 0: I'm so disappointed in the internet that this is happening.

379
00:20:53,310 --> 00:20:54,030
Speaker 1: This is pretty dumb.

380
00:20:54,150 --> 00:20:55,388
Speaker 1: ICANN not doing so well.

381
00:20:56,070 --> 00:20:59,890
Speaker 1: Of course, our choices are like ICANN or governments, and it's like, "Fuck!

382
00:21:01,312 --> 00:21:04,609
Speaker 1: Why don't we just friggin' have the open source people take care of

383
00:21:04,630 --> 00:21:04,670
Speaker 1: it?".

384
00:21:04,730 --> 00:21:15,550
Speaker 0: That's kind of a secondary thing, that as much as I complain about the US government and ICANN and all these things, I really don't want the UN to have any power over the internet as a technological thing.

385
00:21:15,570 --> 00:21:20,630
Speaker 0: I'd rather have the US and/or ICANN than, I don't know, the rest of the world combined.

386
00:21:21,070 --> 00:21:25,069
Speaker 1: There should be some sort of open source academic guys who run the thing, you know?

387
00:21:25,490 --> 00:21:27,170
Speaker 0: Yeah, who picks who the academics are?

388
00:21:28,031 --> 00:21:29,630
Speaker 1: We vote the way Debian votes.

389
00:21:30,992 --> 00:21:32,630
Speaker 0: Okay, so we do a democracy.

390
00:21:33,451 --> 00:21:34,610
Speaker 1: Yeah, but it's all Linux guys.

391
00:21:34,970 --> 00:21:35,829
Speaker 0: So only Linux guys?

392
00:21:35,930 --> 00:21:38,166
Speaker 1: All the nutologists get the friggin'-.

393
00:21:38,186 --> 00:21:38,750
Speaker 0: So here's how it is.

394
00:21:38,930 --> 00:21:40,370
Speaker 1: If you want to vote- The whitebeards.

395
00:21:40,470 --> 00:22:00,530
Speaker 0: If you want to vote, you have to tellnet to a particular IP address and port, IPv6 only, and there you have to use get and set commands directly, natively, it won't allow anything else, to follow an arcane, dungeon-crawling game served up entirely via-.

396
00:22:00,670 --> 00:22:06,150
Speaker 1: You get to vote if you're big, fat, you have a big-ass white beard.

397
00:22:06,651 --> 00:22:07,710
Speaker 0: And rainbow suspenders.

398
00:22:07,710 --> 00:22:13,970
Speaker 1: You use vim, you have rainbow suspenders, and you've only ever seen a UNIX command line.

399
00:22:13,970 --> 00:22:15,526
Speaker 1: and when you see another computer, you're like, "What the hell's

400
00:22:15,546 --> 00:22:15,708
Speaker 1: that?".

401
00:22:19,180 --> 00:22:19,450
Speaker 1: Anyway.

402
00:22:19,610 --> 00:22:20,787
Speaker 1: Everyone knows who the guys are.

403
00:22:27,160 --> 00:22:29,620
Speaker 0: But anyway, things of the day.

404
00:22:31,161 --> 00:22:38,979
Speaker 0: This made the rounds on the internet with a ferocity and rapidity that will rarely be repeated in the world.

405
00:22:39,620 --> 00:22:47,100
Speaker 0: It's a thing so epic, I can't say awesome, because it's both awesome and not awesome.

406
00:22:47,840 --> 00:22:50,100
Speaker 0: Can't say crazy, because I've seen crazier stuff.

407
00:22:50,880 --> 00:22:52,640
Speaker 0: This really just counts as epic.

408
00:22:53,641 --> 00:22:54,760
Speaker 0: So a dude, his cat died.

409
00:22:55,580 --> 00:22:56,479
Speaker 0: I don't know the whole story.

410
00:22:57,220 --> 00:22:57,737
Speaker 1: Well, cat's dead.

411
00:22:58,620 --> 00:22:59,177
Speaker 0: You know, that happens.

412
00:23:00,143 --> 00:23:02,640
Speaker 0: No one- Immortal dog only works on dogs.

413
00:23:04,121 --> 00:23:14,438
Speaker 0: And he taxidermied the cat and turned the cat into the best remote-controlled helicopter the world has ever seen and proceeded to fly around and scare the ever-living shit out of cows with it.

414
00:23:15,260 --> 00:23:15,899
Speaker 1: This is crazy.

415
00:23:16,320 --> 00:23:21,680
Speaker 0: This video combines everything that is both right and wrong with the internet together.

416
00:23:21,860 --> 00:23:24,580
Speaker 0: The only thing it's lacking is rule 34, and I'm sure that's coming.

417
00:23:26,742 --> 00:23:30,839
Speaker 0: I just want to point out the number one comment on this video is in Cyrillic.

418
00:23:31,482 --> 00:23:35,634
Speaker 0: The number two comment says, and I quote, "Am I the only person here that wants to know what that music

419
00:23:35,757 --> 00:23:35,818
Speaker 0: is?".

420
00:23:36,001 --> 00:23:38,260
Speaker 1: He uses weird, cute Japanese cat music.

421
00:23:38,720 --> 00:23:44,698
Speaker 0: It's like the kind of music you'd hear in the opening video to a dating game or something like that.

422
00:23:44,921 --> 00:23:45,233
Speaker 0: I don't know.

423
00:23:45,545 --> 00:23:45,858
Speaker 0: I don't know.

424
00:23:46,040 --> 00:23:51,239
Speaker 0: It's odd, but this is the kind of thing you'd see a picture of it and think, "Wow, that is not real.

425
00:23:51,360 --> 00:23:52,411
Speaker 0: That is obviously a

426
00:23:52,431 --> 00:23:52,937
Speaker 0: photoshop.".

427
00:23:54,042 --> 00:24:01,375
Speaker 0: Now, not only is this real and epic, but the way he made the cat into a helicopter just makes it better.

428
00:24:03,202 --> 00:24:07,240
Speaker 0: The cat is splayed out like it's flying with holding four propellers.

429
00:24:08,860 --> 00:24:13,567
Speaker 1: Yeah, I thought he would just have the propeller coming out the cat's top like a whale hole, but- No.

430
00:24:14,602 --> 00:24:18,400
Speaker 0: I imagine the cat was named Orville because the video ... It's called the Orville copter by most people.

431
00:24:18,500 --> 00:24:18,689
Speaker 1: All right.

432
00:24:19,722 --> 00:24:20,398
Speaker 0: This is pretty great.

433
00:24:21,781 --> 00:24:22,919
Speaker 1: So, check this video out.

434
00:24:23,462 --> 00:24:23,840
Speaker 0: I'm checking.

435
00:24:24,221 --> 00:24:31,040
Speaker 1: So, this video is this guy explaining how the accelerometer in the cell phone works.

436
00:24:31,741 --> 00:24:34,760
Speaker 1: Most people ... You might know how a regular accelerometer works.

437
00:24:34,920 --> 00:24:39,028
Speaker 0: Yeah, there's a couple different kinds, but- But very few people know how ...

438
00:24:39,028 --> 00:24:41,498
Speaker 1: It's like, "How do you make that ridiculously

439
00:24:41,598 --> 00:24:41,939
Speaker 1: small?".

440
00:24:42,980 --> 00:24:53,600
Speaker 1: It's sort of the same way as we did the differential gear one, where it's like you see the basic concept with the tinker toys, and you're like, "Oh, the tinker toys," right?

441
00:24:53,880 --> 00:24:59,460
Speaker 1: But then you see how they miniaturize it and get it to be so much more precise, even though it's the same mechanism.

442
00:24:59,880 --> 00:25:00,740
Speaker 1: This is the same thing.

443
00:25:00,840 --> 00:25:02,120
Speaker 1: It's like, "What's an accelerometer?

444
00:25:02,261 --> 00:25:03,654
Speaker 1: It's a ball on a spring in a

445
00:25:03,735 --> 00:25:04,058
Speaker 1: jar.".

446
00:25:04,614 --> 00:25:04,780
Speaker 1: Right?

447
00:25:04,800 --> 00:25:09,656
Speaker 1: Well, how do we make a ball on a spring in a jar in a few nanometers of silicon?

448
00:25:11,303 --> 00:25:12,379
Speaker 1: And that's what this video is about.

449
00:25:13,401 --> 00:25:18,620
Speaker 0: The thing is, historically, accelerometers are notoriously inaccurate in many situations.

450
00:25:19,100 --> 00:25:19,253
Speaker 1: Oh, yeah.

451
00:25:19,960 --> 00:25:35,180
Speaker 0: And much of what I've read is that the main reason accelerometers seem so good recently partly is due to better software to interpret the data coming from the somewhat flawed accelerometer and constrain it reasonably to kind of infer what you're actually doing.

452
00:25:36,142 --> 00:25:39,457
Speaker 0: That's a whole neat thing that I don't know enough about to say anything more than what I just said.

453
00:25:40,701 --> 00:25:41,560
Speaker 1: But yeah, this video's good.

454
00:25:41,581 --> 00:25:42,158
Speaker 1: You should watch it.

455
00:25:42,440 --> 00:25:44,710
Speaker 0: So in the meta moment, the book club book is QTEEN84 or 1Q84.

456
00:25:47,800 --> 00:25:49,578
Speaker 0: I'm pretty much... I'm almost done with it.

457
00:25:49,882 --> 00:25:50,499
Speaker 0: And since I'm...

458
00:25:50,581 --> 00:25:50,968
Speaker 1: Or E.T.Q.

459
00:25:52,261 --> 00:25:52,640
Speaker 1: Achion.

460
00:25:53,040 --> 00:25:59,099
Speaker 0: I'm flying to Toronto tomorrow, and while I don't want to go to Toronto, I'll probably finish the book on the flight home.

461
00:25:59,320 --> 00:25:59,760
Speaker 1: Yeah, probably.

462
00:26:00,160 --> 00:26:00,251
Speaker 0: Yeah.

463
00:26:00,941 --> 00:26:02,679
Speaker 0: So we'll do a book club show on it real soon.

464
00:26:04,023 --> 00:26:05,640
Speaker 0: I don't know when this episode will actually air.

465
00:26:05,800 --> 00:26:07,126
Speaker 0: We have a previous episode.

466
00:26:07,146 --> 00:26:11,478
Speaker 0: we did that also may or may not be online yet, though I guess by the time you hear this...

467
00:26:11,660 --> 00:26:14,800
Speaker 1: I'm probably going to fix this when I get home, so it'll work.

468
00:26:15,540 --> 00:26:18,940
Speaker 0: But Kineticon is coming up in the Hartford Convention Center in July.

469
00:26:19,462 --> 00:26:21,420
Speaker 0: We run the panels and workshops department.

470
00:26:21,901 --> 00:26:25,760
Speaker 0: The vast majority of the schedule is done, complete, up on the website.

471
00:26:26,781 --> 00:26:33,639
Speaker 0: And you should go, because it's an everything con, and we have panels on almost any crazy topic you can think of.

472
00:26:34,204 --> 00:26:35,399
Speaker 0: It's going to be an exciting time.

473
00:26:37,825 --> 00:26:38,920
Speaker 0: You won't get to hang out with us, though.

474
00:26:38,920 --> 00:26:39,518
Speaker 0: We're kind of busy.

475
00:26:40,860 --> 00:26:43,480
Speaker 1: Also, we upgraded our website, which is why it might take a while.

476
00:26:43,680 --> 00:26:46,200
Speaker 0: We're getting that little geek night sperm out all over the internet.

477
00:26:47,982 --> 00:26:53,258
Speaker 1: So come to our website if you really want, or just keep following us wherever you follow things.

478
00:26:53,820 --> 00:26:57,440
Speaker 0: For example, many of you might be watching the live stream of this or trying out the Google thing.

479
00:26:57,520 --> 00:27:07,800
Speaker 0: If it works out, we'll start doing it regularly, kind of see what we do before and after the show, which usually is sit here, kind of quiet, occasionally saying, "That's bullshit.

480
00:27:07,921 --> 00:27:08,568
Speaker 0: Don't use that as your

481
00:27:08,609 --> 00:27:08,832
Speaker 0: news.".

482
00:27:09,962 --> 00:27:13,018
Speaker 1: Let me add this to my to-do list to possibly integrate the...

483
00:27:13,582 --> 00:27:14,360
Speaker 0: We should integrate this.

484
00:27:14,740 --> 00:27:17,512
Speaker 0: If this video, like the video of the current show, was always just up there, that'd be cool.

485
00:27:19,480 --> 00:27:19,576
Speaker 0: Yeah?

486
00:27:19,980 --> 00:27:29,160
Speaker 0: Thing is, I'll tell you right now, we're probably going to try to integrate this to a different YouTube account for regularness, rather than it going up on, I guess, my personal.

487
00:27:29,240 --> 00:27:31,238
Speaker 0: I'm not actually sure what YouTube account this is going to go to.

488
00:27:31,586 --> 00:27:31,857
Speaker 0: I don't know.

489
00:27:32,182 --> 00:27:44,820
Speaker 0: Probably my personal one, which... Every time I upload a video that is not My Little Pony, you would not believe the amount of feedback I get from people that's like, "Yeah, where's the more pony stuff?

490
00:27:45,060 --> 00:27:46,834
Speaker 0: Why are you putting up non-pony

491
00:27:46,875 --> 00:27:47,096
Speaker 0: stuff?".

492
00:27:47,782 --> 00:27:50,220
Speaker 0: I feel like I need to segregate the pony stuff from the other stuff.

493
00:27:50,320 --> 00:27:51,940
Speaker 1: I think you can make channels to separate...

494
00:27:51,961 --> 00:27:52,197
Speaker 0: You can.

495
00:27:52,525 --> 00:27:52,938
Speaker 0: I did.

496
00:27:53,541 --> 00:27:57,320
Speaker 0: I don't think anyone who uses YouTube knows how to subscribe to just a channel.

497
00:27:57,420 --> 00:27:58,079
Speaker 1: That's tough shit.

498
00:27:58,821 --> 00:27:59,398
Speaker 1: Just ignore them.

499
00:27:59,398 --> 00:28:05,300
Speaker 0: 99% of the people subscribed to me are just on the account as a whole.

500
00:28:05,580 --> 00:28:06,057
Speaker 1: Just ignore them.

501
00:28:08,160 --> 00:28:08,460
Speaker 1: Who cares?

502
00:28:09,380 --> 00:28:11,158
Speaker 0: PAX Prime, PAX Dev, coming up.

503
00:28:11,600 --> 00:28:17,051
Speaker 0: We will very likely be at PAX Prime doing one or more panels and events, maybe or maybe not the...

504
00:28:17,520 --> 00:28:19,319
Speaker 1: What was that awesome panel idea we came up with?

505
00:28:20,644 --> 00:28:22,440
Speaker 0: I was going to ask you that, because I kind of forgot.

506
00:28:23,921 --> 00:28:24,260
Speaker 0: Oh, shit.

507
00:28:24,260 --> 00:28:27,657
Speaker 0: It was about... The concept was something about getting people...

508
00:28:27,980 --> 00:28:28,620
Speaker 1: Pokemon and airhogging?

509
00:28:28,662 --> 00:28:28,786
Speaker 1: Yeah.

510
00:28:29,340 --> 00:28:31,380
Speaker 0: That was the... We're calling it Pokemon and airhockey.

511
00:28:31,580 --> 00:28:40,198
Speaker 0: But really, it's about getting... You go to a gaming con, or an anime con, and there's the guys who only care about one kind of anime.

512
00:28:40,600 --> 00:28:42,659
Speaker 0: So they go to the thing about that thing.

513
00:28:43,000 --> 00:28:46,540
Speaker 0: So things about that thing cater to the hardcore people who already know about it.

514
00:28:47,261 --> 00:28:54,940
Speaker 0: At a geek convention, like for computers, say we did a panel on public key cryptography.

515
00:28:55,641 --> 00:29:02,459
Speaker 0: People who already know what that is are going to expect it to be way inside baseball, because otherwise they already know how it works.

516
00:29:04,520 --> 00:29:07,739
Speaker 0: And anyone who doesn't know what it is is not going to show up to the panel about that.

517
00:29:08,500 --> 00:29:23,699
Speaker 0: So you get to the situation where it's impossible to get people who are unaware of a particular nerdery or geekery into that thing at a nerd or geek conference, because you're either superficial, but people who are into that thing won't go to it or will hate it, and people who aren't into it won't think to go.

518
00:29:24,121 --> 00:29:27,495
Speaker 0: Or you're hardcore, and the people who are into it go to it, and you never get anyone else.

519
00:29:27,781 --> 00:29:29,598
Speaker 1: That's too much of an explanation for metamoment.

520
00:29:30,940 --> 00:29:31,940
Speaker 1: The sun's shining in my eyes.

521
00:29:32,184 --> 00:29:35,500
Speaker 0: We will... Oh yeah, I gotta put the thing back up in the studio.

522
00:29:35,680 --> 00:29:36,359
Speaker 1: The sun, it moved.

523
00:29:36,662 --> 00:29:37,098
Speaker 1: It's summer.

524
00:29:38,163 --> 00:29:38,332
Speaker 1: Summer.

525
00:29:39,106 --> 00:29:39,400
Speaker 0: Oh god.

526
00:29:39,540 --> 00:29:48,020
Speaker 0: Also, we will very likely be doing the board game tabletop workshop thing again, because at PAX East, that went really, really well.

527
00:29:48,160 --> 00:29:48,577
Speaker 0: It was pretty good.

528
00:29:49,146 --> 00:29:49,700
Speaker 0: I was amazed.

529
00:29:49,760 --> 00:29:57,520
Speaker 0: Scott taught a bunch of people how to play a really long winded German board game, and they sat silently the entire time, and then they all played the board game.

530
00:29:58,202 --> 00:29:58,839
Speaker 0: I was kind of amazed.

531
00:30:00,181 --> 00:30:04,920
Speaker 0: Other conventions, not going to Otacon, because they hate us and we're blacklisted.

532
00:30:05,467 --> 00:30:05,720
Speaker 1: Whatever.

533
00:30:05,980 --> 00:30:06,720
Speaker 0: Yeah, whatever.

534
00:30:07,763 --> 00:30:09,417
Speaker 0: And we'll be going to anime Boston next year.

535
00:30:10,200 --> 00:30:11,740
Speaker 0: Magfest is coming.

536
00:30:12,060 --> 00:30:13,120
Speaker 1: That's enough conventions.

537
00:30:13,240 --> 00:30:13,960
Speaker 0: Enough conventions.

538
00:30:14,681 --> 00:30:16,720
Speaker 1: Any other meta bits?

539
00:30:16,800 --> 00:30:17,940
Speaker 0: That's pretty much it.

540
00:30:18,020 --> 00:30:18,417
Speaker 1: That's good enough.

541
00:30:18,801 --> 00:30:22,560
Speaker 0: Shows will be a little sporadic until I get off of this travel schedule.

542
00:30:23,421 --> 00:30:39,380
Speaker 0: So, turns out, we learned recently that Stuxnet, Flame, there's been some high profile viruses, which happens from time to time, but by all appearances, these were written by the government for political purposes.

543
00:30:40,121 --> 00:30:46,670
Speaker 1: Usually you would think most of the viruses and things out there are part of botnets that are set up by Russian, Chinese.

544
00:30:47,840 --> 00:30:52,380
Speaker 0: I feel like we could do a whole panel or a whole show on the history of malware.

545
00:30:53,680 --> 00:30:54,160
Speaker 0: Because think about it.

546
00:30:54,260 --> 00:30:55,279
Speaker 1: It requires a lot of research.

547
00:30:55,581 --> 00:30:57,879
Speaker 1: Yeah, but it went from- Because a lot of that history is hidden history.

548
00:30:58,100 --> 00:31:08,340
Speaker 0: But it went from harmless pranks, like the foreign virus, to actively malicious, like the ogre, to just trying to make money, like the botnets and the spam bots.

549
00:31:08,820 --> 00:31:16,000
Speaker 0: And now we've got government cyber warfare, which cyber warfare has been mostly a joke up to this point.

550
00:31:16,460 --> 00:31:23,480
Speaker 1: It's kind of funny because we don't really know how much of it has happened or is happening because it's super secret.

551
00:31:24,262 --> 00:31:27,900
Speaker 1: And all we know is what we discover on computers around the world.

552
00:31:29,000 --> 00:31:30,425
Speaker 1: And the U.S.

553
00:31:30,465 --> 00:31:35,259
Speaker 1: government has been very proactive, openly proactive, like there's going to be cyber war.

554
00:31:35,540 --> 00:31:36,360
Speaker 1: Let's prepare for it.

555
00:31:36,380 --> 00:31:41,640
Speaker 1: And for years, since the 90s or even earlier, they've been like, yeah, there's going to be computer warfare.

556
00:31:41,901 --> 00:31:48,780
Speaker 1: People will attack other countries, computer systems to deal, you know, economic or even physical harm.

557
00:31:49,323 --> 00:31:51,079
Speaker 1: And we had to prepare to defend against that.

558
00:31:51,687 --> 00:31:51,820
Speaker 1: Right.

559
00:31:52,683 --> 00:31:54,440
Speaker 1: But meanwhile, they said it was going to happen.

560
00:31:54,680 --> 00:31:55,540
Speaker 1: You know why it's going to happen?

561
00:31:55,621 --> 00:31:56,578
Speaker 1: Because you made it happen.

562
00:31:57,204 --> 00:31:58,216
Speaker 1: You pretty much started it.

563
00:31:59,020 --> 00:31:59,140
Speaker 1: Right.

564
00:31:59,400 --> 00:32:12,638
Speaker 1: I mean, from all from, you know, from every the evidence that we have, you know, not only were they, you know, very loud about, you know, suggesting that, you know, someone else was going to start it and that they had to have defenses against it.

565
00:32:13,542 --> 00:32:17,379
Speaker 1: But yeah, they pretty much also built the offenses and started it.

566
00:32:17,700 --> 00:32:18,307
Speaker 0: I think it's got.

567
00:32:18,347 --> 00:32:19,520
Speaker 0: this is not a new thing.

568
00:32:19,761 --> 00:32:25,861
Speaker 0: And I point you to are you familiar with the Siberian pipeline sabotage incident of 1982?

569
00:32:25,861 --> 00:32:29,840
Speaker 1: I do remember that though they're sad that the pipeline was sabotaged.

570
00:32:29,960 --> 00:32:31,164
Speaker 1: I do not remember details of.

571
00:32:31,225 --> 00:32:32,931
Speaker 1: basically the details

572
00:32:32,991 --> 00:32:52,460
Speaker 0: of this are that now there's different classified and declassified or whatever, but basically it is alleged pretty solidly that the CIA inserted a sort of like a trigger or some bad logic in these chips that they knew were going to be used to control the valves on this pipeline.

573
00:32:53,261 --> 00:32:59,341
Speaker 0: And then we're able to later cause it to explode in 1982.

574
00:32:59,341 --> 00:33:03,817
Speaker 1: So I read recently that like someone definitely it could have been a B.S.

575
00:33:04,118 --> 00:33:05,380
Speaker 1: story because I only read the headlines.

576
00:33:05,560 --> 00:33:10,380
Speaker 1: I don't know if it's true, but there's always been this sort of worry that you buy chips made from some other country.

577
00:33:10,742 --> 00:33:12,019
Speaker 1: They're going to have a backdoor in them.

578
00:33:12,060 --> 00:33:15,858
Speaker 1: And it's like, first of all, if you're worried about that, that probably means you're doing it on your chips.

579
00:33:16,227 --> 00:33:16,460
Speaker 1: Right.

580
00:33:16,540 --> 00:33:17,620
Speaker 1: Because, you know, it's possible.

581
00:33:17,980 --> 00:33:21,074
Speaker 0: Well, you know, Scott, you think that I want to point out.

582
00:33:21,114 --> 00:33:22,540
Speaker 0: I worked at IBM a long time ago.

583
00:33:22,560 --> 00:33:28,219
Speaker 0: You know, I actually like did stuff in the factory where the PS3 chips happen, like people use my terminals to do that crap.

584
00:33:30,700 --> 00:33:41,578
Speaker 0: So many of the chips that are in technology that the military would like to use or the government would like to use, no one in the United States makes the chips, nor any analog of those chips.

585
00:33:42,280 --> 00:33:45,857
Speaker 0: But there are rules where certain kinds of things have to be made on U.S.

586
00:33:45,897 --> 00:33:47,197
Speaker 0: soil to prevent that sort of thing.

587
00:33:47,901 --> 00:33:48,986
Speaker 0: And many times the U.S.

588
00:33:49,006 --> 00:33:55,440
Speaker 0: military government is in a situation where they need X. No company in the United States makes X anymore.

589
00:33:56,081 --> 00:33:57,940
Speaker 0: And they have to get it from China.

590
00:33:58,822 --> 00:34:01,440
Speaker 0: So we kind of shot our own selves in the ass with that one.

591
00:34:01,620 --> 00:34:10,060
Speaker 1: What I'm saying is that recently I saw a headline, which could be just some guy on the Internet that said they confirmed finding a backdoor in some Chinese chip somewhere.

592
00:34:10,239 --> 00:34:10,333
Speaker 0: Yep.

593
00:34:10,460 --> 00:34:13,699
Speaker 0: I saw some articles downplaying it, but stuff like that does happen.

594
00:34:13,822 --> 00:34:14,138
Speaker 0: You know?

595
00:34:14,465 --> 00:34:14,551
Speaker 0: Yeah.

596
00:34:14,940 --> 00:34:16,219
Speaker 0: It's not that hard to do.

597
00:34:16,480 --> 00:34:19,500
Speaker 1: But when something's in the chip, it's like, what can what the fuck can you do?

598
00:34:19,560 --> 00:34:21,020
Speaker 1: You can't just patch it with the download.

599
00:34:21,400 --> 00:34:23,320
Speaker 0: But think about the complexity of that kind of hack.

600
00:34:23,400 --> 00:34:27,839
Speaker 0: So like say you hack up like you make a special Intel chip, like a CPU.

601
00:34:28,801 --> 00:34:35,539
Speaker 0: It's got to be such that it can hijack something the OS is doing and give you a backdoor into the OS.

602
00:34:35,940 --> 00:34:41,978
Speaker 1: Well, I mean, if you know the vast majority of the time, the OS is going to be like Linux kernel or Windows.

603
00:34:42,190 --> 00:34:42,339
Speaker 1: Right.

604
00:34:42,440 --> 00:34:44,139
Speaker 1: There are a lot of common elements there.

605
00:34:44,460 --> 00:34:50,199
Speaker 1: You can target something that's on a lot of machines or you just need to know what machine you're hitting or you can write something so generic.

606
00:34:50,850 --> 00:34:51,060
Speaker 1: Right.

607
00:34:51,139 --> 00:35:00,540
Speaker 1: Like, you know, you could put something you could get like just an assembly program in there that runs in the background, you know, and just sort of takes like every other CPU cycle or something if you're that low.

608
00:35:01,061 --> 00:35:06,519
Speaker 1: And so it's like, OK, the computer is going slowly or maybe, you know, the computer so fast you don't even notice it.

609
00:35:06,921 --> 00:35:18,760
Speaker 1: But really what it's doing is, you know, in a space you can't even see because it's, you know, just assembly code running in the CPU is reading bits out of your hard drive and then sending them over the network wire.

610
00:35:19,362 --> 00:35:27,100
Speaker 1: And the only way you could see that is like if you're looking at like, you know, the network traffic directly, you know, even like ethereal wouldn't see it.

611
00:35:27,140 --> 00:35:28,120
Speaker 1: It was on the same computer.

612
00:35:28,240 --> 00:35:29,479
Speaker 1: We need to look from another computer.

613
00:35:29,661 --> 00:35:29,821
Speaker 0: Yeah.

614
00:35:29,841 --> 00:35:33,500
Speaker 0: But at the same time, the complexity of it's theoretically, theoretically possible.

615
00:35:33,580 --> 00:35:38,500
Speaker 0: But like the complexity of controlling all of those bits to where there's no sort of audit log someone would notice.

616
00:35:38,560 --> 00:35:43,000
Speaker 0: But then in the real world, security doesn't work for crap and no one actually does.

617
00:35:43,260 --> 00:35:47,339
Speaker 0: Very few people do the level of due diligence that all the experts say one should do.

618
00:35:47,803 --> 00:35:48,559
Speaker 1: So no one does that.

619
00:35:49,266 --> 00:35:50,439
Speaker 1: But so the NSA maybe.

620
00:35:51,004 --> 00:35:52,140
Speaker 0: So what do we do about that?

621
00:35:52,300 --> 00:35:52,682
Speaker 0: Like what's?

622
00:35:53,527 --> 00:35:55,539
Speaker 0: I mean, it appears that the U.S.

623
00:35:55,800 --> 00:36:01,060
Speaker 0: government may have made or made with other people flame and possibly Stuxnet.

624
00:36:01,300 --> 00:36:02,287
Speaker 1: Well, we know that we're pretty.

625
00:36:02,468 --> 00:36:04,200
Speaker 1: everyone knows they made probably both of these.

626
00:36:04,280 --> 00:36:04,482
Speaker 0: Yeah.

627
00:36:04,523 --> 00:36:06,080
Speaker 1: The evidence is very high.

628
00:36:06,240 --> 00:36:07,900
Speaker 1: The book is they're so complicated.

629
00:36:08,621 --> 00:36:14,360
Speaker 1: And if you look at the you know, the view, it's going to take a long time to really look through all the decompiled code.

630
00:36:14,680 --> 00:36:16,540
Speaker 0: Well, did you see them today?

631
00:36:16,720 --> 00:36:18,620
Speaker 0: There was an article was I saw this.

632
00:36:18,660 --> 00:36:21,800
Speaker 0: About how they happen to be signed by Microsoft certificates.

633
00:36:22,360 --> 00:36:23,404
Speaker 0: Right.

634
00:36:23,465 --> 00:36:27,400
Speaker 1: So if you don't know, right, when you install some software on a computer, right.

635
00:36:27,640 --> 00:36:34,934
Speaker 1: You know, it always Windows is like, hey, you know, is that this driver is not signed, you know, by us, which means we didn't verify.

636
00:36:34,974 --> 00:36:35,860
Speaker 1: this is a good driver.

637
00:36:35,900 --> 00:36:37,337
Speaker 1: It's just something you download from the Internet.

638
00:36:38,044 --> 00:36:39,219
Speaker 1: Are you sure you want to trust this?

639
00:36:39,601 --> 00:36:39,801
Speaker 1: Yes.

640
00:36:39,822 --> 00:36:39,862
Speaker 1: No.

641
00:36:40,163 --> 00:36:49,564
Speaker 1: Now, in order to apply that signature to avoid the yes no question so that it's trusted by the operating system, you need a private key, which we've talked about on the show before.

642
00:36:49,584 --> 00:36:52,201
Speaker 1: You can go listen to episodes about it or watch a good YouTube video about it.

643
00:36:53,205 --> 00:37:00,240
Speaker 1: And that private key is only in the possession of Microsoft, the company, because when you're buying Windows, well, you're trusting Microsoft with your operating system.

644
00:37:00,300 --> 00:37:03,360
Speaker 1: You trust them with, you know, telling you of a driver's good or bad.

645
00:37:03,421 --> 00:37:04,460
Speaker 1: You're already trusting them anyway.

646
00:37:04,642 --> 00:37:04,844
Speaker 1: Right.

647
00:37:04,985 --> 00:37:06,539
Speaker 1: Because they wrote all the code in the OS.

648
00:37:06,940 --> 00:37:07,833
Speaker 1: So, I mean, come on.

649
00:37:09,661 --> 00:37:13,740
Speaker 1: So if this virus is signed by Microsoft, that means one of a few things.

650
00:37:13,841 --> 00:37:16,340
Speaker 1: It means number one, Microsoft made.

651
00:37:16,600 --> 00:37:23,339
Speaker 0: Well, Microsoft says it is a spoof certificate and they've already issued a patch to prevent it from working again.

652
00:37:23,601 --> 00:37:24,655
Speaker 1: No, no, no, no, no.

653
00:37:24,695 --> 00:37:25,060
Speaker 1: Let me finish.

654
00:37:25,100 --> 00:37:25,945
Speaker 1: You're not letting me finish.

655
00:37:26,005 --> 00:37:30,459
Speaker 1: I was listing the things that could possibly be and I didn't finish one of the things that could possibly be.

656
00:37:30,620 --> 00:37:32,440
Speaker 0: Yeah, because I think the thing's pretty obvious.

657
00:37:32,960 --> 00:37:35,960
Speaker 1: I guess not to people who listen to this show and aren't experts.

658
00:37:36,642 --> 00:37:37,770
Speaker 1: So a thing you could possibly be.

659
00:37:37,830 --> 00:37:39,219
Speaker 1: number one is Microsoft did it.

660
00:37:39,620 --> 00:37:40,418
Speaker 1: I highly doubt that.

661
00:37:41,744 --> 00:37:42,230
Speaker 1: I'm not.

662
00:37:42,575 --> 00:37:42,899
Speaker 0: Well, not.

663
00:37:43,280 --> 00:37:44,268
Speaker 1: Yeah, that's what I'm saying.

664
00:37:44,309 --> 00:37:45,599
Speaker 1: Did it as if they made flame.

665
00:37:45,881 --> 00:37:46,021
Speaker 1: Yeah.

666
00:37:46,081 --> 00:37:53,279
Speaker 1: Number two, somebody else made flame and then paid or got Microsoft to apply the digital signature to it.

667
00:37:53,741 --> 00:37:59,600
Speaker 1: The government could have coerced Microsoft into doing that, or maybe Microsoft did it willingly for money or free or who knows possible.

668
00:38:00,461 --> 00:38:12,479
Speaker 1: Number three, somebody was able to get the key from Microsoft or crack it with some incredible computer or guess it or who knows unlikely and then applied it themselves without Microsoft being involved.

669
00:38:13,307 --> 00:38:14,120
Speaker 0: I call unlikely.

670
00:38:14,260 --> 00:38:20,942
Speaker 0: My guess, my gut feeling is that the government may or may not have advised Microsoft to let this go.

671
00:38:21,324 --> 00:38:29,940
Speaker 0: Microsoft just gave the keys to the government or Microsoft signed it or something, because now that it's public, Microsoft immediately had a patch available.

672
00:38:30,160 --> 00:38:31,345
Speaker 0: Now, I didn't.

673
00:38:31,566 --> 00:38:36,977
Speaker 0: I mean, for all I know, it's probably pretty easy to issue a patch that just says this particular certificate is no longer good.

674
00:38:37,600 --> 00:38:37,962
Speaker 1: That's pretty much.

675
00:38:37,983 --> 00:38:41,980
Speaker 1: what the patch says is, hey, anything that was signed with this certificate is no good anymore.

676
00:38:42,601 --> 00:38:46,620
Speaker 1: And anything that you see, you see this, you know, certificate coming through, deny.

677
00:38:46,960 --> 00:38:52,108
Speaker 0: The thing is, if the certificate is that easily spoofed, well, Microsoft's in trouble anyway.

678
00:38:52,291 --> 00:38:52,820
Speaker 1: That is true.

679
00:38:52,980 --> 00:38:58,800
Speaker 0: So if the government got Microsoft to do it, I am not saying this is what happened.

680
00:38:58,900 --> 00:39:03,841
Speaker 0: I'm going to pull a Fahrenheit 9/11, but it is interesting that Microsoft had a patch so quickly.

681
00:39:04,243 --> 00:39:10,700
Speaker 0: Well, it's not hard to make it to remove a certificate, but were I the kind of person who was trying to convince people of a certain narrative?

682
00:39:11,361 --> 00:39:12,906
Speaker 0: It is interesting how quickly.

683
00:39:12,926 --> 00:39:21,260
Speaker 0: I really wouldn't be surprised if Microsoft was at least someone at Microsoft or Microsoft as a company was in on this with the governments.

684
00:39:21,901 --> 00:39:23,439
Speaker 1: It's it's a likely scenario.

685
00:39:23,881 --> 00:39:28,445
Speaker 0: I think more likely, even though it sounds like a conspiracy theory, mathematically speak.

686
00:39:28,485 --> 00:39:28,627
Speaker 1: Right.

687
00:39:28,647 --> 00:39:29,599
Speaker 1: This is a matter of math.

688
00:39:30,161 --> 00:39:34,940
Speaker 1: What's more likely this somewhat believable conspiracy theory?

689
00:39:34,940 --> 00:39:43,720
Speaker 1: OK, I don't like to believe conspiracy theories or incredibly powerful computers defying the odds of powerful cryptography.

690
00:39:45,082 --> 00:39:49,699
Speaker 1: There are also the possibility I read somewhere that it was like a third party, like handoff kind of cert.

691
00:39:50,182 --> 00:39:51,397
Speaker 1: So there could have been some other.

692
00:39:51,900 --> 00:39:53,099
Speaker 0: But it was third party handoff cert.

693
00:39:53,701 --> 00:39:54,820
Speaker 0: Definitely the government.

694
00:39:55,280 --> 00:39:55,685
Speaker 1: Yes.

695
00:39:55,807 --> 00:39:56,780
Speaker 1: I mean, really.

696
00:39:57,206 --> 00:39:58,099
Speaker 1: Everyone knows you did it.

697
00:39:58,500 --> 00:39:59,340
Speaker 0: Well, there was another article.

698
00:39:59,460 --> 00:40:02,220
Speaker 1: It's one of those things where it's like you robbed the convenience store.

699
00:40:02,360 --> 00:40:05,900
Speaker 1: Everyone knows you're out the convenience store, but they don't have any firm evidence.

700
00:40:06,042 --> 00:40:06,467
Speaker 1: It was you.

701
00:40:06,508 --> 00:40:07,379
Speaker 1: But everyone knows it.

702
00:40:07,740 --> 00:40:10,240
Speaker 0: There was another article on Slashdot that was so much better.

703
00:40:10,340 --> 00:40:11,338
Speaker 0: The headline says it all.

704
00:40:12,020 --> 00:40:15,340
Speaker 0: Antivirus firms out of their league with sucks net and flame.

705
00:40:15,580 --> 00:40:20,540
Speaker 0: Seriously, antivirus as software like, you know, McGaffey, all these like antivirus.

706
00:40:21,000 --> 00:40:24,140
Speaker 0: Yeah, we've discussed this a lot of times as a technology professional.

707
00:40:24,280 --> 00:40:25,280
Speaker 0: That software is bullshit.

708
00:40:25,544 --> 00:40:26,294
Speaker 0: It's useless.

709
00:40:26,415 --> 00:40:26,739
Speaker 0: Crap.

710
00:40:27,080 --> 00:40:27,402
Speaker 1: Nothing.

711
00:40:27,803 --> 00:40:31,220
Speaker 0: I feel like in my professional opinion, you should never use software like that.

712
00:40:31,500 --> 00:40:33,440
Speaker 0: If you're running Windows, just use Windows.

713
00:40:33,641 --> 00:40:34,859
Speaker 0: You know, defender works fine.

714
00:40:35,163 --> 00:40:36,760
Speaker 1: And Windows security, the central.

715
00:40:37,020 --> 00:40:37,281
Speaker 0: Yeah.

716
00:40:37,764 --> 00:40:40,700
Speaker 1: But I mean, that's not, you know, just don't even really pay attention to it.

717
00:40:40,940 --> 00:40:45,139
Speaker 0: But really, real security takes place at all these other layers in the stack.

718
00:40:46,061 --> 00:40:52,200
Speaker 0: The local PC with its antivirus, that'll keep out baby's first, you know, Trojan.

719
00:40:52,400 --> 00:40:52,481
Speaker 1: Yeah.

720
00:40:52,541 --> 00:40:56,078
Speaker 1: But anyway, let's talk about this flame specifically, because there's some interesting things about it.

721
00:40:56,118 --> 00:40:56,220
Speaker 1: Right.

722
00:40:56,460 --> 00:41:01,979
Speaker 1: Most, you know, you know, like you were saying throughout history, we've seen viruses that just make skulls float around the screen.

723
00:41:02,301 --> 00:41:02,683
Speaker 1: We've seen.

724
00:41:02,723 --> 00:41:09,740
Speaker 0: Well, because it was it was cool hackers being like like I wrote a crappy virus based on something once and infected a bunch of my friend's PCs.

725
00:41:10,340 --> 00:41:13,580
Speaker 1: And I've seen ones that control people's computers and make them send spam.

726
00:41:14,061 --> 00:41:16,320
Speaker 1: We've seen ones that destroy people's computers.

727
00:41:16,481 --> 00:41:17,516
Speaker 1: You've seen all kinds.

728
00:41:17,617 --> 00:41:17,780
Speaker 1: Right.

729
00:41:17,840 --> 00:41:19,359
Speaker 1: We've seen ones to show people ads.

730
00:41:19,801 --> 00:41:25,118
Speaker 0: There's a lot of those still going on and probably have been ones that have been the sort of cyber warfare thing that we didn't see.

731
00:41:25,821 --> 00:41:32,139
Speaker 1: But this one in particular, the way the flame works is if you get it, you probably won't realize you have it, first of all.

732
00:41:32,561 --> 00:41:41,920
Speaker 1: And second of all, what happens is your computer is basically just spying on you all the time and sending all the things it's spying on to somebody.

733
00:41:42,041 --> 00:41:48,160
Speaker 1: We can't really tell who because it's very well, you know, concealed and proxied and knows what you know, that that not to interrupt.

734
00:41:48,220 --> 00:41:51,921
Speaker 1: So like it'll turn your webcam on and look at you and turn your microphone on and listen to you.

735
00:41:51,962 --> 00:41:58,680
Speaker 1: But you won't know your webcam's on because the light won't be on and it'll get your key presses and all your web history and all this.

736
00:41:58,860 --> 00:42:03,700
Speaker 1: It'll basically just spies on you like crazy and then sends that information somewhere.

737
00:42:04,221 --> 00:42:14,779
Speaker 0: Now, the reason what I was interrupting for is that I feel like we could do a whole show on the fact that the Internet's like on one hand, the RIA and the MPAA are always like suing people with IP addresses.

738
00:42:15,021 --> 00:42:24,019
Speaker 0: And yet you can send information out in the Internet to whoever you want with no one be even like big governments not able to figure out who you're sending it to.

739
00:42:24,520 --> 00:42:24,721
Speaker 0: Yeah.

740
00:42:24,802 --> 00:42:27,119
Speaker 0: And the technology as to how that works is actually pretty neat.

741
00:42:28,940 --> 00:42:32,779
Speaker 0: I think the best example, you know, read up on numbers stations.

742
00:42:34,341 --> 00:42:35,004
Speaker 0: Our hangout died.

743
00:42:35,024 --> 00:42:37,333
Speaker 0: Oh, well, I'll see I can.

744
00:42:37,554 --> 00:42:39,160
Speaker 0: I'll try to reconnect anyway.

745
00:42:39,680 --> 00:42:40,999
Speaker 0: There's not going to stop the show for that.

746
00:42:41,120 --> 00:42:43,399
Speaker 0: We were doing a live stream hangout and it stopped.

747
00:42:43,740 --> 00:42:45,799
Speaker 1: OK, wait, I'd ruin the show for that.

748
00:42:46,061 --> 00:42:46,284
Speaker 0: Yeah.

749
00:42:46,406 --> 00:42:47,114
Speaker 1: Oh, mentioning it.

750
00:42:48,061 --> 00:42:59,123
Speaker 0: I had to say as anyway, read up on numbers stations, because that is basically how you send data to people in an encrypted fashion, even if you don't know who they are or where they are.

751
00:42:59,685 --> 00:43:02,739
Speaker 0: And then there's literally no way to figure out who's consuming that data.

752
00:43:03,163 --> 00:43:03,304
Speaker 0: Yeah.

753
00:43:03,973 --> 00:43:04,418
Speaker 0: Pace bin.

754
00:43:05,621 --> 00:43:06,369
Speaker 0: Yeah, pace bin.

755
00:43:07,076 --> 00:43:07,500
Speaker 1: Exactly.

756
00:43:08,801 --> 00:43:11,115
Speaker 0: But anyway, so go on, go on.

757
00:43:12,180 --> 00:43:14,680
Speaker 1: What you were talking about, how I was just saying how flames spotted.

758
00:43:14,940 --> 00:43:15,848
Speaker 0: That's what it does.

759
00:43:15,869 --> 00:43:17,140
Speaker 0: OK, so that's why it's clearly.

760
00:43:17,481 --> 00:43:18,023
Speaker 1: It's obvious.

761
00:43:18,084 --> 00:43:26,779
Speaker 1: Based on that functionality, it's so obvious why a government would say want to infect people that it thought were, you know, you know, why the U.S.

762
00:43:27,160 --> 00:43:29,460
Speaker 1: would want to infect people who it thought were anti U.S.

763
00:43:29,560 --> 00:43:30,023
Speaker 1: with that.

764
00:43:30,184 --> 00:43:32,960
Speaker 1: But at the same time, gather as much intelligence about them as possible.

765
00:43:33,100 --> 00:43:36,680
Speaker 0: What also makes it very interesting is how elegantly done it is.

766
00:43:36,880 --> 00:43:48,519
Speaker 0: And a lot of the reasons why no antivirus software caught it was that it was designed to hide in a way that viruses are not designed like viruses tend to look in a common way, especially crappy viruses.

767
00:43:49,101 --> 00:43:55,420
Speaker 0: But this one used a whole bunch of like like SQLite and Lua and the kinds of stuff.

768
00:43:55,520 --> 00:43:56,063
Speaker 1: It's right.

769
00:43:56,124 --> 00:43:59,320
Speaker 1: It's written using using modern software development techniques.

770
00:43:59,400 --> 00:44:05,859
Speaker 0: And as a result, it looks like the kind of enterprise bullshit software that every big organization in the world installs and all their PCs.

771
00:44:06,261 --> 00:44:07,438
Speaker 1: But it's also rather large.

772
00:44:07,640 --> 00:44:11,537
Speaker 1: It's like a 30 meg program that's running hides just like a normal.

773
00:44:11,557 --> 00:44:13,679
Speaker 0: like it looks like something you're actually trying to run.

774
00:44:13,840 --> 00:44:14,081
Speaker 0: Yeah.

775
00:44:14,523 --> 00:44:19,280
Speaker 0: I mean, in the old days, I'd be like, all right, what's forum dot exe?

776
00:44:19,460 --> 00:44:20,497
Speaker 0: The fuck did that come from?

777
00:44:20,840 --> 00:44:29,060
Speaker 1: The other thing that's interesting about it is that how, you know, it's set up in such a way to where not everyone who's infected is sort of running it all the time.

778
00:44:29,460 --> 00:44:38,180
Speaker 1: It's sort of like it's they get it out as many computers as possible, but then they only activate it on, you know, certain people's computers, you know, at a time.

779
00:44:38,320 --> 00:44:49,275
Speaker 1: So even though you might have like a million computers infected, if you're in control of the back end of this, you might say, OK, let's spy on those 20 guys or catch your audio from those guys.

780
00:44:49,356 --> 00:44:49,478
Speaker 1: Right.

781
00:44:50,260 --> 00:44:57,760
Speaker 1: So it seems like the kind of thing that government would want to do would be infect as many people who are bad as possible at this thing or even some good people.

782
00:44:57,860 --> 00:44:58,408
Speaker 1: We don't care.

783
00:44:58,429 --> 00:44:58,896
Speaker 1: Right.

784
00:44:59,441 --> 00:45:09,504
Speaker 1: And then if there's a bad person and we want to spy on them, we'll see if their computer's infected or try to get it infected and then put them on the on list and then they'll start sending data to us.

785
00:45:10,047 --> 00:45:16,680
Speaker 1: And, you know, maybe someone who already will get to get lucky, someone who is we discover that's a bad person happens to be infected.

786
00:45:16,760 --> 00:45:20,303
Speaker 1: We just turn them on and we start getting data from them because they got infected a long time ago.

787
00:45:20,323 --> 00:45:26,359
Speaker 1: You know, that's you know, and you wouldn't want to just have data coming in from everyone all the time because it's a pain in the ass.

788
00:45:26,900 --> 00:45:29,088
Speaker 0: So I what I

789
00:45:29,108 --> 00:45:32,400
Speaker 1: would like to see sounds like an NSA because on the NSA would like remember

790
00:45:32,480 --> 00:45:42,478
Speaker 0: we always say about no one really makes the destructive viruses because everyone is making viruses now are people who are making them for either a government or a military or a financial end.

791
00:45:44,040 --> 00:45:57,020
Speaker 0: I feel like one way to make this sort to kind of inoculate the world against this level of of virus software, basically, would be to make ultra destructive viruses.

792
00:45:57,360 --> 00:46:02,081
Speaker 0: I agree, because that would basically destroy all the infrastructure that can't deal with it.

793
00:46:02,724 --> 00:46:08,780
Speaker 1: in an obvious, hopefully it would not destroy any essential infrastructure like power plants and future trains.

794
00:46:08,960 --> 00:46:20,680
Speaker 0: The thing is, stuff like that usually would, you know, if I was going to make something like that, I'd model it on the old ogre, encrypt the hard drive and then delete it, delete the key or just start deleting files randomly till the PC crashes.

795
00:46:23,061 --> 00:46:36,500
Speaker 0: I mean, if that's what you got to do, if you want to really like really makes personal security happen, I'm not saying we should do that because as an intelligent and rational adult, you say that that's the Batman solution.

796
00:46:36,580 --> 00:46:44,628
Speaker 1: Let's say that everybody, even though your computer is absolutely you think your computer is secure because it's so up to date and you update all the programs, you don't use shady programs.

797
00:46:44,750 --> 00:46:45,400
Speaker 0: I'm a professional.

798
00:46:45,520 --> 00:46:46,287
Speaker 0: I'm pretty careful.

799
00:46:46,368 --> 00:46:47,600
Speaker 1: And that keeps you really safe.

800
00:46:47,700 --> 00:46:48,927
Speaker 1: And, you know, you got firewalls.

801
00:46:49,028 --> 00:46:51,160
Speaker 1: even, you know, not that worms really work anymore.

802
00:46:51,261 --> 00:46:51,422
Speaker 1: Right.

803
00:46:51,442 --> 00:46:53,720
Speaker 1: But, you know, so you think you're pretty safe.

804
00:46:53,820 --> 00:46:59,100
Speaker 1: But even then, right, there's a market for zero day vulnerabilities out there.

805
00:46:59,481 --> 00:47:07,160
Speaker 1: And it's actually becoming sort of a problem in that, you know, back in the day it used to be, you know, people would find a vulnerability and immediately publish it.

806
00:47:07,320 --> 00:47:11,660
Speaker 1: And it was like, whoa, guys, you know, I guess that's cool, but it's not that cool.

807
00:47:11,860 --> 00:47:13,260
Speaker 0: Now you think, all right, whatever.

808
00:47:13,521 --> 00:47:15,900
Speaker 0: I have my NAS backups and my S3 backups.

809
00:47:16,000 --> 00:47:16,305
Speaker 0: You know what?

810
00:47:16,325 --> 00:47:17,180
Speaker 0: I mean, tell you guys something.

811
00:47:17,781 --> 00:47:33,043
Speaker 0: The people who advocate this sort of thing don't think about what Scott's bringing up, that if I'm going to write a sophisticated virus like flame, like a real deal virus, I can probably, if I get access to your computer, log into your S3 and fucking delete everything there.

812
00:47:33,104 --> 00:47:40,420
Speaker 1: Well, no, but what I'm saying is there used to be, you know, talk about, you know, publication, the ethics of publication of vulnerabilities.

813
00:47:40,641 --> 00:47:40,842
Speaker 1: Right.

814
00:47:40,862 --> 00:47:43,980
Speaker 1: It used to be you'd release her out of the way for fame and whatnot.

815
00:47:44,321 --> 00:47:55,000
Speaker 1: So he finally sort of pushed, you know, the community sort of pushed and said, look, guys, what you do is you give the people who who run the software a head start to get a patch out and then you publish it and then we're all cool.

816
00:47:55,180 --> 00:47:56,900
Speaker 1: And that what it does is you give a deadline.

817
00:47:57,301 --> 00:48:05,743
Speaker 1: So the company is still pressured to fix the security hole and you still publish it because that's useful knowledge and, you know, helpful for everyone to make everything more secure.

818
00:48:06,366 --> 00:48:12,560
Speaker 1: And but you still give a head start because if you just publish it immediately, that gives all the bad guys a chance to use it before the patch is out.

819
00:48:12,620 --> 00:48:13,206
Speaker 1: And that's no good.

820
00:48:13,589 --> 00:48:14,720
Speaker 1: So that's where we sort of got to.

821
00:48:14,820 --> 00:48:20,659
Speaker 1: But now what's happening is there's actually a huge market for zero day vulnerabilities because patches come out so fast.

822
00:48:21,262 --> 00:48:31,720
Speaker 1: If you find a vulnerability, there's actually a huge incentive to not go through the warning the company and doing the best practice, but instead just sell it to some evil dude for a zillion dollars.

823
00:48:32,121 --> 00:48:40,092
Speaker 1: And now even people who are super patched and protected and they're using like Chrome on, you know, OS X, there's.

824
00:48:40,494 --> 00:48:41,940
Speaker 1: I've seen these vulnerabilities lately.

825
00:48:42,000 --> 00:48:49,680
Speaker 1: People have found that, like, go through loop de loop ease and use like six vulnerabilities combined to run unauthorized code on machines.

826
00:48:50,181 --> 00:48:55,979
Speaker 1: And like you just visit the wrong website, even with a fully updated Chrome on a fully updated computer, who knows what.

827
00:48:56,342 --> 00:49:00,559
Speaker 1: And they could get you with one of these zero day things because the patch doesn't come out for two more days.

828
00:49:00,882 --> 00:49:01,124
Speaker 0: Yeah.

829
00:49:01,305 --> 00:49:03,119
Speaker 1: And some guy paid a lot of money to get that.

830
00:49:03,280 --> 00:49:12,820
Speaker 1: So even when you're crazy secure, right, even if, you know, rim if people made those crazy destructive viruses, you might get hit by one on the zero day.

831
00:49:13,220 --> 00:49:23,860
Speaker 1: Well, hence, notice I said I'm not really know because maybe someone finds a zero day that works against the slash servers and then puts a thing on there that contains another zero day against your computer.

832
00:49:24,162 --> 00:49:27,080
Speaker 1: You visit slash that and you're dead and your hard drives are raised.

833
00:49:27,361 --> 00:49:28,125
Speaker 0: Yep.

834
00:49:28,165 --> 00:49:30,760
Speaker 0: Granted, I got plenty of backups and rotations and everything.

835
00:49:31,040 --> 00:49:31,181
Speaker 1: Oh, yeah.

836
00:49:31,201 --> 00:49:33,419
Speaker 1: I mean, a backup that's offline and a hard drive in a box.

837
00:49:33,560 --> 00:49:34,952
Speaker 1: You're pretty safe right there.

838
00:49:35,013 --> 00:49:35,759
Speaker 0: now for.

839
00:49:35,820 --> 00:49:41,726
Speaker 1: Yeah, he's going to make the virus that makes a ghost come out of your CD Rob and fly over to your external.

840
00:49:41,867 --> 00:49:44,402
Speaker 1: Look through your house, find your external hard drives and smash.

841
00:49:44,442 --> 00:49:47,520
Speaker 0: So it's the virus that it infects all your PCs over time.

842
00:49:47,520 --> 00:49:54,660
Speaker 0: And then one day it deletes everything on your main computers, but it only maybe it detects when it's on laptops.

843
00:49:55,281 --> 00:50:01,020
Speaker 0: So if you plug an external hard drive into a laptop after the virus has been triggered, it just deletes it immediately.

844
00:50:02,882 --> 00:50:05,740
Speaker 0: You could do clever stuff like that, but I think that's a silly discussion.

845
00:50:05,920 --> 00:50:09,597
Speaker 0: Anyway, so I don't think we've talked about a long time ago the whole.

846
00:50:09,657 --> 00:50:10,481
Speaker 0: the, you know, the U.S.

847
00:50:10,501 --> 00:50:11,144
Speaker 0: military and U.S.

848
00:50:11,185 --> 00:50:21,040
Speaker 0: government basically said that cyber warfare is considered effectively to be one part of the spectrum of real warfare and that it would be feasible to respond to a cyber threat with munitions.

849
00:50:21,340 --> 00:50:21,421
Speaker 1: Yeah.

850
00:50:21,441 --> 00:50:22,879
Speaker 1: Someone said that once, I think.

851
00:50:23,521 --> 00:50:32,840
Speaker 0: So how does that jive with the fact that it appears that our government has been engaging in active cyber warfare for some time against foreign nations?

852
00:50:33,141 --> 00:50:36,540
Speaker 1: Well, I mean, come on, if you're not a hypocrite, that means people can shoot us, right?

853
00:50:36,820 --> 00:50:39,720
Speaker 0: Well, in the sense that they can shoot us in a war.

854
00:50:40,120 --> 00:50:40,220
Speaker 1: Right.

855
00:50:40,240 --> 00:50:49,100
Speaker 1: If you flamed us and you can't flame back, it's apparently, you know, according to us, that means you're justified in missiling us with real missiles.

856
00:50:49,720 --> 00:50:50,395
Speaker 1: Right.

857
00:50:50,415 --> 00:50:50,620
Speaker 1: Right.

858
00:50:51,321 --> 00:50:51,843
Speaker 0: Yeah.

859
00:50:51,863 --> 00:50:55,420
Speaker 0: Granted, we some of these people we've bombed before anyway.

860
00:50:55,880 --> 00:50:56,446
Speaker 1: That's true.

861
00:50:56,467 --> 00:50:57,700
Speaker 0: It's not like they can bomb us back.

862
00:50:58,180 --> 00:51:02,443
Speaker 1: That is, you know, the thing about, you know, modern warfare is, you know, pretty crappy game.

863
00:51:02,463 --> 00:51:02,685
Speaker 0: Yeah.

864
00:51:02,766 --> 00:51:04,440
Speaker 1: In the olden days, right.

865
00:51:04,800 --> 00:51:07,380
Speaker 1: When, you know, you bombed Hitler, Hitler would bomb London.

866
00:51:07,620 --> 00:51:08,800
Speaker 1: You bombed back and forth.

867
00:51:09,162 --> 00:51:11,600
Speaker 1: And, you know, I mean, Hitler deserved the bombing more.

868
00:51:12,001 --> 00:51:13,620
Speaker 1: In fact, he was the only one who deserved the bombing.

869
00:51:13,962 --> 00:51:17,240
Speaker 1: But, you know, the good German people didn't deserve the bombing.

870
00:51:18,661 --> 00:51:19,223
Speaker 1: But Hitler did.

871
00:51:20,287 --> 00:51:31,540
Speaker 1: And, you know, but in a way, right, despite the, you know, typical horribleness of all, you know, physical warfare, you know, it was sort of from a game perspective, it's like, yeah, you're bombing back and forth.

872
00:51:31,641 --> 00:51:32,650
Speaker 0: It's like, what about America?

873
00:51:32,670 --> 00:51:33,598
Speaker 0: No one was bombing us.

874
00:51:34,101 --> 00:51:35,179
Speaker 1: Well, we're far away.

875
00:51:35,900 --> 00:51:46,360
Speaker 1: These days, it's one way bombing, which is like, well, you know, no matter who you think good guys and bad guys are, whatever, you know, one way bombing, I'm bombing you.

876
00:51:46,640 --> 00:51:51,100
Speaker 1: No one's bombing back, you know, in another way.

877
00:51:51,181 --> 00:51:52,119
Speaker 1: That's just not right.

878
00:51:52,501 --> 00:51:59,200
Speaker 0: One could argue that that at least makes conflict shorter or people who don't have the ability to bomb back as willing to engage in such behavior.

879
00:51:59,300 --> 00:52:00,649
Speaker 1: Yeah, it's like punching.

880
00:52:00,689 --> 00:52:02,540
Speaker 1: a handicapped guy can't punch back.

881
00:52:02,760 --> 00:52:07,164
Speaker 0: Well, the handicapped guy's got a gun to a cat and the cat can't fly away because he hasn't been a helicopter.

882
00:52:07,546 --> 00:52:11,218
Speaker 1: I see the missile, the handicapped guy, and all he can do is shoot back with his gun.

883
00:52:11,602 --> 00:52:13,840
Speaker 0: Yeah, but you got to missile him so he doesn't kill the cat.

884
00:52:14,041 --> 00:52:16,219
Speaker 1: I'm just saying it's this is how the world you do.

885
00:52:16,684 --> 00:52:17,009
Speaker 1: Do you?

886
00:52:17,091 --> 00:52:17,600
Speaker 1: It's a crazy.

887
00:52:18,021 --> 00:52:20,220
Speaker 0: Do you kill the spiders to save the butterflies?

888
00:52:20,500 --> 00:52:20,682
Speaker 1: I'm just.

889
00:52:20,702 --> 00:52:21,125
Speaker 1: I'm only.

890
00:52:21,206 --> 00:52:22,920
Speaker 1: I know it's a crazy fucked up world.

891
00:52:23,261 --> 00:52:23,462
Speaker 1: Right.

892
00:52:23,522 --> 00:52:26,980
Speaker 1: But I'm talking about this one aspect of, you know, everything's going one way.

893
00:52:27,040 --> 00:52:28,880
Speaker 1: Frankly, we're going to cyber warfare you.

894
00:52:28,981 --> 00:52:29,770
Speaker 1: We're going to hack you.

895
00:52:29,791 --> 00:52:30,519
Speaker 1: We're going to bomb you.

896
00:52:30,620 --> 00:52:31,688
Speaker 1: And you're not going to do anything.

897
00:52:31,709 --> 00:52:34,718
Speaker 0: Well, frankly, one, I think a lot of our infrastructure is just as vulnerable to it.

898
00:52:35,360 --> 00:52:35,722
Speaker 1: Yeah, it is.

899
00:52:35,803 --> 00:52:38,739
Speaker 0: I am amazed that our government was able to pull it off.

900
00:52:40,382 --> 00:52:44,662
Speaker 1: You know, we're assuming it was us, which is a safe assumption, but it's possible in Israel.

901
00:52:45,104 --> 00:52:45,808
Speaker 0: It's possible.

902
00:52:45,848 --> 00:52:47,859
Speaker 0: it was someone else, probably us and Israel.

903
00:52:48,324 --> 00:52:49,460
Speaker 1: Just there are other people.

904
00:52:49,581 --> 00:52:52,638
Speaker 1: It could be it's just most likely that it is us or Israel.

905
00:52:53,040 --> 00:52:53,281
Speaker 1: Yeah.

906
00:52:53,462 --> 00:52:53,682
Speaker 1: Yeah.

907
00:52:54,285 --> 00:52:59,367
Speaker 0: So where can I get the source code to flame to infect my friends with it and spy on them?

908
00:52:59,468 --> 00:53:01,040
Speaker 1: Well, you can't because they all got the patch today.

909
00:53:01,400 --> 00:53:01,602
Speaker 1: Right.

910
00:53:02,852 --> 00:53:03,014
Speaker 1: Right.

911
00:53:05,344 --> 00:53:06,578
Speaker 1: Or they're running Linux, right?

912
00:53:08,622 --> 00:53:08,964
Speaker 0: I wonder.

913
00:53:08,985 --> 00:53:11,259
Speaker 0: No, I'm not going to.

914
00:53:11,600 --> 00:53:18,240
Speaker 1: You know, it's weird, like, you know, I don't want to go too off on a tangent, but, you know, Linux on the desktop comes up all the time.

915
00:53:18,861 --> 00:53:29,080
Speaker 1: And, you know, more recently, like Linux on the desktop has been getting worse with the Unity desktop and the Linux on the desktop has two really big advantages, despite the mountain of disadvantages.

916
00:53:29,400 --> 00:53:31,519
Speaker 0: One, you can make it secure.

917
00:53:32,041 --> 00:53:32,405
Speaker 1: Yeah.

918
00:53:32,506 --> 00:53:33,740
Speaker 0: Like really secure.

919
00:53:33,881 --> 00:53:34,143
Speaker 0: Oh, yeah.

920
00:53:34,366 --> 00:53:35,720
Speaker 0: In fact, you can make it so secure.

921
00:53:35,880 --> 00:53:42,900
Speaker 0: This is a pain in the ass to use until you can code on it much more easily.

922
00:53:43,040 --> 00:53:47,000
Speaker 1: But I'm saying I'm actually starting to starting to feel, you know, look at Valve.

923
00:53:47,080 --> 00:53:50,279
Speaker 1: They just hired tons of Linux guys and they're making that steam Linux.

924
00:53:51,422 --> 00:53:55,000
Speaker 1: I'm not saying this is the year of Linux on the desktop because that'll never be true.

925
00:53:55,542 --> 00:54:00,418
Speaker 1: But I can see, like, this is the year of you look five to 10 years.

926
00:54:02,022 --> 00:54:05,075
Speaker 1: I can see Linux be in the desktop market, more and more.

927
00:54:05,155 --> 00:54:09,640
Speaker 1: looking at, you know, when these sorts of other things develop, Linux is the alternate desktop.

928
00:54:09,840 --> 00:54:16,658
Speaker 0: Linux is what the people who actually care about and need to care about security for their local data use.

929
00:54:17,401 --> 00:54:21,940
Speaker 0: Linux will be what the DOD guy with the secret laptop walking around is running.

930
00:54:22,984 --> 00:54:25,279
Speaker 1: I think there's going to be a lot more Linux going around.

931
00:54:26,283 --> 00:54:27,900
Speaker 0: But I think it'll be a weird switch.

932
00:54:28,380 --> 00:54:35,980
Speaker 0: I think if you want to talk predictions, I think in the next 10 or 15 years, Microsoft is backing away from the corporate world and trying to go after the regular people.

933
00:54:36,301 --> 00:54:39,560
Speaker 0: And I think Linux on the desktop is going to really target the corporate side.

934
00:54:39,740 --> 00:54:40,305
Speaker 1: It's possible.

935
00:54:40,567 --> 00:54:42,180
Speaker 0: I think that's the flip that's going to happen.

936
00:54:42,461 --> 00:54:42,762
Speaker 0: Could be.

937
00:54:43,044 --> 00:54:47,339
Speaker 0: I mean, I'm not I'm actually not too happy about where Metro is going lately, but that's that's digression.

938
00:54:48,380 --> 00:54:48,564
Speaker 1: Whatever.

939
00:54:48,584 --> 00:54:49,279
Speaker 0: For another show.

940
00:54:49,661 --> 00:54:56,400
Speaker 1: If you look the best graph, I love this graph is the graph that shows the Microsoft stock price or profits or whatever it is.

941
00:54:56,561 --> 00:54:56,783
Speaker 1: Right.

942
00:54:57,146 --> 00:54:58,739
Speaker 1: And you see it goes up and up and up and up.

943
00:54:58,841 --> 00:55:00,180
Speaker 1: And then there's the top of the mountain.

944
00:55:00,341 --> 00:55:06,679
Speaker 1: And that top of the mountain is when Bill Gates leaves and Ballmer comes in and then the man goes, I wonder if Apple will have a similar price.

945
00:55:07,220 --> 00:55:08,299
Speaker 1: Ballmer still has his job.

946
00:55:08,461 --> 00:55:09,819
Speaker 1: It's amazing that he's still in charge.

947
00:55:10,040 --> 00:55:11,638
Speaker 0: He's kind of like a Biden in a way.

948
00:55:12,620 --> 00:55:13,795
Speaker 1: I don't know how he's still there.

949
00:55:15,381 --> 00:55:15,924
Speaker 1: How can this?

950
00:55:16,125 --> 00:55:18,760
Speaker 1: how can the board hasn't booted him because he gets results?

951
00:55:18,780 --> 00:55:19,905
Speaker 1: He doesn't get any results.

952
00:55:19,925 --> 00:55:26,399
Speaker 1: A man who gets results, loses all the money's developers to pay for the developers to OK.

953
00:55:27,220 --> 00:55:28,211
Speaker 0: I think we're done here.

954
00:55:28,312 --> 00:55:29,100
Speaker 1: We've been done for a while.

955
00:55:29,120 --> 00:55:30,560
Speaker 0: Oh, by the way, get that Windows update.

956
00:55:30,660 --> 00:55:31,550
Speaker 0: We're not kidding, guys.

957
00:55:31,752 --> 00:55:32,420
Speaker 0: Yeah, really.

958
00:55:39,202 --> 00:55:41,340
Speaker 0: This has been Geek Nights with Rim and Scott.

959
00:55:41,520 --> 00:55:42,478
Speaker 0: Special thanks to D.J.

960
00:55:42,680 --> 00:55:46,520
Speaker 0: Pretzel for the opening music, Kat Lee for Web design and Brando K for the logos.

961
00:55:46,860 --> 00:55:51,905
Speaker 1: Be sure to visit our Web site at front row crew dot com for show notes, discussion news and more.

962
00:55:52,148 --> 00:55:53,500
Speaker 0: Remember, Geek Nights is not one.

963
00:55:53,580 --> 00:55:59,539
Speaker 0: But four different shows, SciTech Mondays, Gaming Tuesdays, Anime Comic Wednesdays and Indiscriminate Thursdays.

964
00:55:59,980 --> 00:56:03,076
Speaker 1: Geek Nights is distributed under a Creative Commons Attribution 3.0 license.

965
00:56:04,400 --> 00:56:07,380
Speaker 1: Geek Nights is recorded live with no studio and no audience.

966
00:56:07,660 --> 00:56:10,500
Speaker 1: But unlike those other late shows, it's actually recorded at night.

