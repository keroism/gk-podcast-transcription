1
00:00:09,100 --> 00:00:11,207
Speaker 1: It's Thursday November 15th.

2
00:00:11,588 --> 00:00:12,210
Speaker 1: I'm Scott.

3
00:00:12,370 --> 00:00:13,293
Speaker 0: I'm really tired.

4
00:00:13,333 --> 00:00:14,818
Speaker 1: Me too, and this is Geek Nights.

5
00:00:15,199 --> 00:00:23,733
Speaker 1: Tonight, Telogical Fallacies Teh?

6
00:00:24,370 --> 00:00:25,388
Speaker 1: Let's do this.

7
00:00:29,412 --> 00:00:30,939
Speaker 0: Well this weekend ought to be interesting.

8
00:00:30,979 --> 00:00:37,490
Speaker 0: We're uh for the first time in a long time We're going to some other geek house instead of having people at our geek house.

9
00:00:37,530 --> 00:00:44,497
Speaker 1: I try to avoid doing that as much as possible because it usually means I'm gonna have to sleep on the floor and The days of sleeping on the floor are done for me.

10
00:00:45,119 --> 00:00:45,941
Speaker 1: It's bad or nothing.

11
00:00:46,322 --> 00:00:54,050
Speaker 0: See, but the thing is in return for sleeping on The floor what we get is a weekend full of geekery with all our friends and all the Visigoths.

12
00:00:55,072 --> 00:00:55,939
Speaker 0: No mess to clean up.

13
00:00:55,999 --> 00:00:57,026
Speaker 0: No responsibilities.

14
00:00:57,087 --> 00:00:57,510
Speaker 0: No nothing.

15
00:00:58,491 --> 00:01:00,077
Speaker 1: But I have to drive for hours.

16
00:01:00,097 --> 00:01:00,679
Speaker 0: No you don't.

17
00:01:00,699 --> 00:01:05,253
Speaker 0: You have to sit in a car playing worms with me while Alex drives Maybe.

18
00:01:05,453 --> 00:01:07,782
Speaker 0: Or you can drive and me and Alex can play worms.

19
00:01:08,124 --> 00:01:15,416
Speaker 1: Yeah, either way It's I got to sit in a car and then like all my all the stuff I want to do in this house.

20
00:01:15,476 --> 00:01:15,999
Speaker 1: I can't do.

21
00:01:16,040 --> 00:01:16,824
Speaker 0: I can't even sit in my chair.

22
00:01:16,844 --> 00:01:17,307
Speaker 0: See, that's the point.

23
00:01:17,327 --> 00:01:17,850
Speaker 0: We get away.

24
00:01:18,152 --> 00:01:19,441
Speaker 0: So bring the chair with you.

25
00:01:19,461 --> 00:01:20,790
Speaker 1: That's not gonna happen.

26
00:01:21,671 --> 00:01:22,635
Speaker 1: Let someone vomit on it.

27
00:01:22,876 --> 00:01:23,880
Speaker 0: That's kind of the point though.

28
00:01:23,901 --> 00:01:30,498
Speaker 0: by getting out of the house like that like when I'm here I always think well, I could work on all that geek night stuff I've been shit talking about for the last two years.

29
00:01:30,578 --> 00:01:32,446
Speaker 0: or I could do this or I could do that.

30
00:01:32,506 --> 00:01:33,691
Speaker 0: if I had someone else's House.

31
00:01:33,912 --> 00:01:44,737
Speaker 0: I wake up and not only do I have zero responsibility to anyone in the world Not only can I do make whatever mess I want do whatever I want There's no chance.

32
00:01:44,778 --> 00:01:46,190
Speaker 0: I'll get worked on so I don't even think about it.

33
00:01:46,230 --> 00:01:47,841
Speaker 1: See my problem is I take it a step further.

34
00:01:47,861 --> 00:01:49,351
Speaker 1: when I wake up in someone else's house I go.

35
00:01:49,371 --> 00:01:50,378
Speaker 1: why the fuck did I come here?

36
00:01:50,418 --> 00:01:51,908
Speaker 1: I could have stayed home and worked on my stuff.

37
00:01:54,091 --> 00:02:04,117
Speaker 0: But this will be fun also because uh Let's just say the place where you're going and the event that is happening is one of those Kind of not what you'd expect us to go to.

38
00:02:04,218 --> 00:02:07,849
Speaker 0: it's a. I think Bach and Elle might be the word I would use.

39
00:02:08,572 --> 00:02:10,238
Speaker 1: I don't know how much of a bucket L will be.

40
00:02:10,258 --> 00:02:15,723
Speaker 0: well if tails from the previous event That was much like this are not exactly.

41
00:02:15,864 --> 00:02:17,793
Speaker 0: Yeah, cuz neither Scott I have also.

42
00:02:17,913 --> 00:02:22,230
Speaker 1: I have heard tale though that the the worst offenders are not are not gonna be there.

43
00:02:22,692 --> 00:02:25,745
Speaker 0: Yeah, it'll be tough to say it's a tough call.

44
00:02:25,786 --> 00:02:26,770
Speaker 1: You'll hear more next week.

45
00:02:26,991 --> 00:02:31,670
Speaker 0: Yes, but I can guarantee that if anyone's gonna be dry heaving it's not gonna be us.

46
00:02:32,131 --> 00:02:34,581
Speaker 1: No, I will definitely not be the any heaving.

47
00:02:35,123 --> 00:02:38,616
Speaker 1: So speaking of dry heaves This is nothing to do with dry heaves.

48
00:02:38,636 --> 00:02:39,178
Speaker 0: Yes, it does.

49
00:02:39,198 --> 00:02:40,362
Speaker 1: Oh, yeah.

50
00:02:40,463 --> 00:02:40,764
Speaker 0: Okay.

51
00:02:40,804 --> 00:02:42,350
Speaker 0: All right, you think I'd all right.

52
00:02:43,011 --> 00:02:44,522
Speaker 1: So you work dry heaves into whatever.

53
00:02:44,562 --> 00:02:45,710
Speaker 1: your news is absinthe.

54
00:02:46,732 --> 00:02:52,402
Speaker 0: Okay, it's kind of worries that I'm not gonna get into all the details here because you probably don't care.

55
00:02:52,562 --> 00:02:56,201
Speaker 0: absinthe is a very alcoholic liquor that Tastes pretty good.

56
00:02:56,221 --> 00:02:58,985
Speaker 0: If you like anis Anis you mean anus?

57
00:03:00,114 --> 00:03:02,114
Speaker 0: No, I mean anis You know licorice.

58
00:03:02,134 --> 00:03:07,505
Speaker 0: I'm gonna taste like ass I'm sure you would know.

59
00:03:10,111 --> 00:03:17,710
Speaker 0: Yeah, if you can't tell guys we're tired tonight and we had a lot of stuff to do I was falling asleep on the train and while reading manga so that tells you something.

60
00:03:18,011 --> 00:03:18,574
Speaker 0: That's the worst.

61
00:03:18,594 --> 00:03:28,832
Speaker 1: when you're reading a book or something and then you suddenly realize because I was reading frickin massive Mooney Shiro's crazy nutjob footnotes in the bottom of ghost in the shell one and a half in the tiny text and I Was falling.

62
00:03:28,873 --> 00:03:29,595
Speaker 1: I just got trapped.

63
00:03:29,615 --> 00:03:33,670
Speaker 1: I'm like, I'm gonna read this one footnote and then go and then doze off.

64
00:03:34,112 --> 00:03:36,487
Speaker 1: I couldn't finish the footnote like my eyes would not stay.

65
00:03:36,567 --> 00:03:37,030
Speaker 0: it was worse.

66
00:03:37,110 --> 00:03:42,050
Speaker 0: I had that thing where you read and read and read and then you realize like I don't remember what I just read.

67
00:03:42,155 --> 00:03:47,370
Speaker 0: Yeah Start backtracking back and realize that I flipped like 15 pages and didn't remember our goddamn thing.

68
00:03:47,410 --> 00:03:51,290
Speaker 1: I hate that when you're reading read and read but your brain like sort of doesn't actually process the words.

69
00:03:51,370 --> 00:03:53,360
Speaker 1: You just sort of process them only with the eyeballs.

70
00:03:53,380 --> 00:03:54,043
Speaker 0: I think it tricks you.

71
00:03:54,083 --> 00:03:55,370
Speaker 0: I think the brain is like, you know what?

72
00:03:55,650 --> 00:03:56,510
Speaker 0: He's too tired to notice.

73
00:03:56,530 --> 00:03:58,115
Speaker 1: It's like you know I'm totally gonna just have.

74
00:03:58,135 --> 00:04:00,526
Speaker 1: it's like you need two parts of your brain to read.

75
00:04:00,546 --> 00:04:06,295
Speaker 1: you need the part that Processes the words and you need the part that actually turns the words like imagination and imagery.

76
00:04:06,616 --> 00:04:07,639
Speaker 1: and it's like you can use.

77
00:04:07,739 --> 00:04:12,978
Speaker 1: you can do one without the other and when you do that you end up Flipping a lot of pages in the book without actually getting.

78
00:04:13,018 --> 00:04:14,363
Speaker 0: I think it's simpler to go back.

79
00:04:14,383 --> 00:04:17,516
Speaker 0: brain says he won't know He's not paying attention.

80
00:04:17,555 --> 00:04:20,269
Speaker 1: I ain't doing work and then it figures itself out.

81
00:04:22,631 --> 00:04:23,916
Speaker 1: Well, I caught you brain.

82
00:04:24,518 --> 00:04:26,466
Speaker 0: Oh brain I got you.

83
00:04:26,486 --> 00:04:27,510
Speaker 1: the brain catches itself.

84
00:04:27,711 --> 00:04:42,230
Speaker 0: But yeah, it looks like absinthe is now less illegal in the United States Which is good news for one really important reason All the reasons that the government has given over the years to make absinthe illegal are completely made up bullshit.

85
00:04:42,631 --> 00:04:46,120
Speaker 0: Absinthe is just a really alcoholic beverage that tastes pretty good.

86
00:04:46,160 --> 00:04:47,684
Speaker 0: If you like that licorice.

87
00:04:48,666 --> 00:04:50,250
Speaker 0: I mean, I like Sambuca a lot.

88
00:04:51,612 --> 00:05:02,596
Speaker 0: of course a lot of people make the mistake of drinking absinthe as it is without diluting it in water, but people drink laudanum also, I Hear laudanum tastes terrible.

89
00:05:02,877 --> 00:05:03,840
Speaker 1: Yeah, well people drink it.

90
00:05:03,860 --> 00:05:05,425
Speaker 0: Also who drinks laudanum.

91
00:05:05,966 --> 00:05:06,127
Speaker 1: Yeah.

92
00:05:06,147 --> 00:05:06,969
Speaker 1: I know a lot of people.

93
00:05:06,989 --> 00:05:12,046
Speaker 0: Oh You know one person who's not even real aka captain laudanum.

94
00:05:12,388 --> 00:05:12,809
Speaker 1: That's right.

95
00:05:13,031 --> 00:05:15,930
Speaker 1: But now captain laudanum it drinks enough laudanum for ten men.

96
00:05:16,292 --> 00:05:25,914
Speaker 0: This is a step in the right direction because the government always said yeah Absinthe we're banning it because it makes people crazy and it's hallucinogen and it's a drug and it's got through Joan in it Causes through Joan.

97
00:05:26,115 --> 00:05:28,000
Speaker 0: Yeah, that was totally made up.

98
00:05:28,160 --> 00:05:31,990
Speaker 0: absinthe has no effects other than just being alcoholic.

99
00:05:32,772 --> 00:05:34,386
Speaker 1: Really is worth alcoholic.

100
00:05:34,406 --> 00:05:37,197
Speaker 0: Yeah Yeah, it's not even close to Everclear.

101
00:05:37,337 --> 00:05:38,360
Speaker 1: Is it more than Vodak?

102
00:05:38,901 --> 00:05:39,202
Speaker 0: Yes.

103
00:05:39,343 --> 00:05:39,704
Speaker 1: Okay.

104
00:05:39,764 --> 00:05:40,726
Speaker 1: It's like double Vodak.

105
00:05:41,107 --> 00:05:45,398
Speaker 0: It's usually about 120 proof so it's double Vodak.

106
00:05:45,719 --> 00:05:46,040
Speaker 0: Yeah.

107
00:05:46,060 --> 00:05:48,590
Speaker 1: Alright, so if you just well not quite double.

108
00:05:48,670 --> 00:05:53,010
Speaker 1: So if you just use half as much absinthe as you normally use Vodak, you'll be alright.

109
00:05:53,672 --> 00:05:57,284
Speaker 0: Well, you're supposed to drink absinthe diluted in water possibly with sugar.

110
00:05:57,304 --> 00:05:58,147
Speaker 0: Okay.

111
00:05:58,589 --> 00:06:00,741
Speaker 0: Yeah But I like this.

112
00:06:00,781 --> 00:06:01,830
Speaker 0: it's a step in the right direction.

113
00:06:01,870 --> 00:06:10,677
Speaker 0: It means that someone has convinced the government a little bit to go back on an absolutely stupid and meaningless decision They made to arbitrarily ban something.

114
00:06:10,717 --> 00:06:14,594
Speaker 1: There's no reason to ban it or maybe there was a time limit on the old thing And it ran out.

115
00:06:14,755 --> 00:06:27,861
Speaker 0: I know it had more to do with the fact that Manufacturers and foreign countries that wanted to really start selling it out here and people who realize they can make money selling absinthe on the mystique that it gained when Moulin Rouge came out and a bunch of kids went.

116
00:06:28,223 --> 00:06:29,470
Speaker 0: oh, I want to get me some of that.

117
00:06:30,450 --> 00:06:31,694
Speaker 0: Great cuz absinthe.

118
00:06:31,714 --> 00:06:37,846
Speaker 0: there's all this mystique around it and it's just a really alcoholic licorice drink my prediction vomiting.

119
00:06:39,451 --> 00:06:39,913
Speaker 0: I imagine.

120
00:06:39,973 --> 00:06:50,290
Speaker 0: all the people who are actually gonna drink it are gonna drink it because they want to like they want to be one of those people who drinks absinthe and I think they'll be disavowed of that obsession rather quickly when they taste it.

121
00:06:50,691 --> 00:06:53,981
Speaker 1: It is shall we say it takes a special kind of person to drink.

122
00:06:54,363 --> 00:06:56,690
Speaker 0: it is an acquired taste acquired.

123
00:06:57,891 --> 00:06:59,456
Speaker 0: Yes, that is how I would put it.

124
00:06:59,497 --> 00:07:02,146
Speaker 0: It is it is not for one with a delicate palate.

125
00:07:02,166 --> 00:07:07,602
Speaker 1: All right, so There's a if you know the website in gadget and gadget comm.

126
00:07:07,802 --> 00:07:10,010
Speaker 1: it's the pretty much the tech blog period.

127
00:07:11,272 --> 00:07:26,619
Speaker 1: They have every story about tech that you care about and well There's run by two people mostly with this guy named Ryan block But also this other guy named Peter Rojas, right and these guys they're both pretty Outspoken against DRM and stuff.

128
00:07:26,639 --> 00:07:29,550
Speaker 1: They're pretty much on the side of the consumers in all things.

129
00:07:29,771 --> 00:07:34,838
Speaker 1: They're sort of like think of them as the gave in taiko of the technology world You know gave in taiko or the video games.

130
00:07:35,240 --> 00:07:37,569
Speaker 1: Ryan block and Peter Rojas are the gadgets, right?

131
00:07:38,570 --> 00:07:40,316
Speaker 1: The Peter Rojas guy he.

132
00:07:40,436 --> 00:07:44,490
Speaker 1: today they announced that he is starting a record label.

133
00:07:45,071 --> 00:07:53,080
Speaker 1: the record label will be called record blue RCRD space LBL all caps and That's pretty good.

134
00:07:53,100 --> 00:08:13,190
Speaker 1: Yeah, and this record label will distribute all digital all free Streaming or download no DRM music Aha, and they already have artists such as most F block party and the stills.

135
00:08:13,531 --> 00:08:15,563
Speaker 0: I'll admit that I've never heard of any of them.

136
00:08:15,583 --> 00:08:19,528
Speaker 1: I Think I've heard of most F but I don't think I've ever heard any of most devs.

137
00:08:19,569 --> 00:08:19,770
Speaker 1: music.

138
00:08:19,851 --> 00:08:21,706
Speaker 1: I've never heard of block party or the stills.

139
00:08:22,772 --> 00:08:23,353
Speaker 0: It's a start.

140
00:08:23,554 --> 00:08:29,070
Speaker 1: They've also partnered with some other labels like warp and dimmock, which is a pretty dumb name for record.

141
00:08:30,891 --> 00:08:34,703
Speaker 1: So I guess whatever music whatever artists they have they're gonna partner up with.

142
00:08:34,783 --> 00:08:43,315
Speaker 1: and I like I don't know how well this is Gonna go cuz I don't know how he's gonna make money But I I hope it works out.

143
00:08:43,355 --> 00:08:47,470
Speaker 1: Well, and I think if they play the cards, right this could be like the record label.

144
00:08:47,753 --> 00:08:52,757
Speaker 1: you know as the name implies and If they get some, you know good music on there.

145
00:08:52,857 --> 00:08:55,906
Speaker 1: Well, I will be listening because I couldn't hurt.

146
00:08:56,467 --> 00:08:58,518
Speaker 1: right free music That's how it's supposed to be.

147
00:08:58,781 --> 00:09:06,554
Speaker 0: Yeah, uh Maybe this I mean I'd say oh this might be the start of the revolution and everything is gonna change when it comes to audio distribution.

148
00:09:06,594 --> 00:09:07,178
Speaker 0: for real.

149
00:09:07,258 --> 00:09:16,927
Speaker 0: but people have tried Similar things not not quite to this extent but there have been a lot of little labels that were like Yeah, we're gonna buck the trend and go with what the people want.

150
00:09:16,967 --> 00:09:19,416
Speaker 1: Yeah to me This is this is sort of like the first.

151
00:09:19,677 --> 00:09:28,690
Speaker 1: well, it's not the first but it's it's the first real Try like someone's actually gonna give it a full-on go and we're gonna see what happens.

152
00:09:28,810 --> 00:09:34,448
Speaker 1: So whether it succeeds or fails is not as important as whether we learn what we learn from this.

153
00:09:34,949 --> 00:09:36,716
Speaker 1: plus You know, it's someone awesome doing it.

154
00:09:36,776 --> 00:09:48,758
Speaker 1: So so best of luck to them I say and free music for me Even if it's cracking, huh?

155
00:09:48,998 --> 00:09:50,720
Speaker 0: At any rate if you can't tell we're kind of tired.

156
00:09:50,800 --> 00:09:53,490
Speaker 0: So I think I'll just jump right into things of the day.

157
00:09:54,011 --> 00:09:54,794
Speaker 1: I'm already sleeping.

158
00:09:54,814 --> 00:09:56,340
Speaker 1: My thing of the day should be sleep.

159
00:09:56,721 --> 00:09:59,898
Speaker 1: It is fun and nice and everybody should take extra sleep.

160
00:10:01,261 --> 00:10:03,769
Speaker 0: So you remember the 90s?

161
00:10:04,391 --> 00:10:05,474
Speaker 0: remember back in the 90s?

162
00:10:05,575 --> 00:10:07,260
Speaker 0: Yeah, there were no cell phones.

163
00:10:07,862 --> 00:10:10,552
Speaker 1: They were just expensive and large.

164
00:10:10,592 --> 00:10:12,880
Speaker 1: well, yeah, usually they were car phones and not cell phone.

165
00:10:12,880 --> 00:10:14,728
Speaker 0: Well, there weren't cell phones like we have now.

166
00:10:14,748 --> 00:10:15,973
Speaker 0: No, not even close.

167
00:10:16,133 --> 00:10:16,997
Speaker 0: I mean I had one.

168
00:10:17,037 --> 00:10:17,720
Speaker 0: it was a big break.

169
00:10:17,800 --> 00:10:18,645
Speaker 0: It was totally useless.

170
00:10:18,665 --> 00:10:23,837
Speaker 0: You could talk for 45 minutes before the battery died I know or you could put it in standby for four hours.

171
00:10:24,380 --> 00:10:27,794
Speaker 1: I know some people had car phones that were as big as regular phone.

172
00:10:27,834 --> 00:10:28,938
Speaker 0: car phones were the late 80s.

173
00:10:29,400 --> 00:10:31,754
Speaker 0: Yeah, they were by 1993 or four.

174
00:10:31,774 --> 00:10:34,024
Speaker 0: there were some cell phones But not the Verizon.

175
00:10:34,124 --> 00:10:38,075
Speaker 0: I remember Scott and I didn't have cell phones until we were already in college.

176
00:10:38,396 --> 00:10:41,531
Speaker 1: I had a cell phone In the year 2000.

177
00:10:41,531 --> 00:10:43,000
Speaker 0: Yeah, that was when we went to college.

178
00:10:43,921 --> 00:10:45,266
Speaker 0: Yeah, I think I remember it.

179
00:10:45,286 --> 00:10:45,467
Speaker 0: didn't?

180
00:10:45,487 --> 00:10:47,154
Speaker 0: you got it while we were in college.

181
00:10:47,395 --> 00:10:47,817
Speaker 1: Did I?

182
00:10:47,877 --> 00:10:49,744
Speaker 0: Yeah Cuz I remember.

183
00:10:49,804 --> 00:10:55,168
Speaker 0: we went to get one and then you found out that you had to put a big deposit down Because your credit history wasn't long.

184
00:10:55,228 --> 00:10:57,860
Speaker 0: Yeah, all right, you were like well screw this and he had your mom do it.

185
00:10:57,880 --> 00:10:58,381
Speaker 1: That's right Cuz.

186
00:10:58,422 --> 00:11:06,143
Speaker 1: my dad got rid of his Motorola StarTech Which is still one of the best cell phones ever and then I had to go try to get it activated at the Verizon At the mall.

187
00:11:06,183 --> 00:11:10,993
Speaker 0: In fact, we went to some of our first anime cons Without cell phones.

188
00:11:11,154 --> 00:11:11,680
Speaker 1: Yeah, we did.

189
00:11:11,760 --> 00:11:21,009
Speaker 1: We had to get those walkie-talkies from Best Buy which suck but which became awesome because only in one instance because you see Somewhere like Otacon whenever.

190
00:11:21,371 --> 00:11:23,498
Speaker 0: well back then which whenever amount?

191
00:11:23,518 --> 00:11:24,020
Speaker 0: is it twice?

192
00:11:24,280 --> 00:11:25,607
Speaker 1: I think we should get around to the thing of the day.

193
00:11:25,708 --> 00:11:25,929
Speaker 0: Why?

194
00:11:25,949 --> 00:11:26,814
Speaker 1: I don't know.

195
00:11:26,834 --> 00:11:28,864
Speaker 0: I Guess I'll save the.

196
00:11:28,944 --> 00:11:31,275
Speaker 0: it's a me a Mario story for another day before.

197
00:11:31,456 --> 00:11:32,220
Speaker 0: a long time ago.

198
00:11:32,240 --> 00:11:33,686
Speaker 0: I'll bet half our listeners never heard it.

199
00:11:33,786 --> 00:11:35,132
Speaker 1: Well, they can hear it again later.

200
00:11:35,152 --> 00:11:40,453
Speaker 1: We'll keep them enticed by something at least It's a me a Mario Right.

201
00:11:40,473 --> 00:11:44,367
Speaker 0: So anyway Whatever my thing of the day is a video College Humor.

202
00:11:44,768 --> 00:11:50,781
Speaker 0: What if that show 24 which I think is kind of stupid was set in 1994?

203
00:11:50,781 --> 00:11:55,279
Speaker 1: I I don't know much about the show 24 other than it's pretty popular and I've never seen it.

204
00:11:55,500 --> 00:11:57,853
Speaker 1: I guess it's a lot like this video.

205
00:11:58,054 --> 00:11:58,315
Speaker 1: Yes.

206
00:11:58,335 --> 00:11:58,878
Speaker 1: That's a guess.

207
00:11:58,918 --> 00:11:59,159
Speaker 0: it is.

208
00:11:59,481 --> 00:12:02,432
Speaker 1: I've seen two episodes one of them assumption to make.

209
00:12:02,472 --> 00:12:11,110
Speaker 0: I think one of them was just really Stupid and the other one really kind of glorified Overreaching anti-terrorism measures.

210
00:12:11,432 --> 00:12:13,159
Speaker 0: and what was it?

211
00:12:13,740 --> 00:12:24,914
Speaker 1: well Anyway, the the video we just watch is really funny because it's like you see these people back with like, you know The early AOL dial-up modem technology like running into all these problems because of it.

212
00:12:24,975 --> 00:12:29,657
Speaker 1: and it's sort of like wow That was just like not even 10 years ago.

213
00:12:31,364 --> 00:12:32,468
Speaker 0: Think about this nowadays.

214
00:12:32,568 --> 00:12:34,314
Speaker 0: say I'm gonna meet you and Emily in the city.

215
00:12:34,354 --> 00:12:35,036
Speaker 0: We're gonna get dinner.

216
00:12:35,638 --> 00:12:38,749
Speaker 0: All right Say I don't show up at the restaurant.

217
00:12:39,171 --> 00:12:40,217
Speaker 0: You call my cell phone rim.

218
00:12:40,237 --> 00:12:40,719
Speaker 0: Where are you?

219
00:12:41,281 --> 00:12:42,310
Speaker 0: Hey, the six train didn't come.

220
00:12:42,370 --> 00:12:46,332
Speaker 0: I'm walking or yeah I'm in book off because I forgot to go to the restaurant.

221
00:12:46,994 --> 00:12:50,304
Speaker 0: now back then it was Shit, where's rim?

222
00:12:50,324 --> 00:12:51,748
Speaker 0: I don't know.

223
00:12:52,089 --> 00:12:52,751
Speaker 0: What do we do?

224
00:12:52,771 --> 00:12:54,376
Speaker 1: I don't know.

225
00:12:54,798 --> 00:12:55,580
Speaker 0: How do we find him?

226
00:12:55,660 --> 00:12:56,657
Speaker 0: There's no way to.

227
00:12:57,441 --> 00:12:58,769
Speaker 0: Yeah, there was no way.

228
00:12:58,789 --> 00:13:00,700
Speaker 0: I guess I could find a payphone.

229
00:13:01,101 --> 00:13:02,346
Speaker 0: Call the restaurant.

230
00:13:02,467 --> 00:13:05,780
Speaker 0: if I knew the number which of course I don't I could try to look it up in the phone book.

231
00:13:06,042 --> 00:13:07,539
Speaker 0: But where am I gonna find a phone book?

232
00:13:07,940 --> 00:13:13,320
Speaker 0: Even back then when people needed them any phone book tied to a phone booth was broken and full of penises

233
00:13:14,060 --> 00:13:18,254
Speaker 1: Missing pages because punk high school kids tore them out for their scavenger hunts like I did

234
00:13:18,676 --> 00:13:21,113
Speaker 0: or they tore them out when they needed a number to remember or

235
00:13:21,133 --> 00:13:23,605
Speaker 1: toilet paper For the gas station.

236
00:13:24,128 --> 00:13:33,279
Speaker 0: gas station has always had toilet paper as far as I was But yet self Station and on the roll of toilet paper would be the phone book.

237
00:13:33,782 --> 00:13:37,863
Speaker 0: I'm sure some old fogies are gonna think us punk kids don't know how hard it was But you know what?

238
00:13:38,165 --> 00:13:39,553
Speaker 0: I'm glad I don't know how hard it was.

239
00:13:39,835 --> 00:13:42,680
Speaker 0: without my cell phone My life would be largely miserable and difficult.

240
00:13:42,780 --> 00:13:47,744
Speaker 1: Yeah, and if you're old fogies complaining about how punk kids got it easy and you had it hard in your day Well, you know what?

241
00:13:48,047 --> 00:13:52,165
Speaker 1: You have only yourself to blame Easy what?

242
00:13:52,246 --> 00:13:54,680
Speaker 0: wait, but you know, you could take that another way.

243
00:13:54,720 --> 00:13:59,153
Speaker 0: You have yourself to blame for not inventing cell phones and then making them widely distributed.

244
00:13:59,575 --> 00:14:01,139
Speaker 0: Yeah, take that grandpa.

245
00:14:01,480 --> 00:14:10,600
Speaker 1: Well, it's like they have themselves to blame for not inventing the good stuff sooner And they also have themselves to blame for inventing the stuff and then letting us have it without having to invent it.

246
00:14:10,800 --> 00:14:15,497
Speaker 0: But what about the old the people who didn't invent it and didn't want it and now it's just here tough.

247
00:14:16,019 --> 00:14:17,683
Speaker 0: Okay Right.

248
00:14:17,704 --> 00:14:19,718
Speaker 1: So what are you there fall for not preventing the invention of it?

249
00:14:20,360 --> 00:14:22,068
Speaker 1: Alright, so, you know those people.

250
00:14:22,108 --> 00:14:28,097
Speaker 1: they play the miniatures games with the rulers, you know Like I like those games that people talk that someone asked us about I guess.

251
00:14:29,142 --> 00:14:40,820
Speaker 1: But anyway, like Warhammer and stuff like that, you know people always make terrains for those games like they make hills and there's a whole hobby of just making like maps and like trees and Stuff like that and buildings.

252
00:14:40,840 --> 00:14:43,992
Speaker 0: It's very much related to that same thing about railroads.

253
00:14:44,072 --> 00:14:46,240
Speaker 0: make a little model railroad with the terrain all around.

254
00:14:46,280 --> 00:14:47,797
Speaker 0: They use a lot of the same techniques, right?

255
00:14:48,320 --> 00:14:56,955
Speaker 1: Well, here are some pictures of some guys who made a sort of post apocalyptic city thing for their miniatures game.

256
00:14:57,016 --> 00:14:59,767
Speaker 1: and well I'm not gonna say anything else.

257
00:14:59,787 --> 00:15:05,651
Speaker 1: You're probably like whatever from my description, but if you look at this I think you will change your mind and go what the fuck?

258
00:15:05,732 --> 00:15:06,897
Speaker 1: Oh my god, those guys.

259
00:15:06,977 --> 00:15:07,600
Speaker 1: They're the crazy.

260
00:15:08,507 --> 00:15:09,058
Speaker 1: You should look at this.

261
00:15:09,861 --> 00:15:11,098
Speaker 1: That's what else can I say?

262
00:15:11,700 --> 00:15:13,659
Speaker 1: Especially if you have an interest in those kind of games you this.

263
00:15:13,679 --> 00:15:17,700
Speaker 1: well This is like probably the best terrain maybe in the whole world that I've ever seen.

264
00:15:18,182 --> 00:15:27,391
Speaker 1: Someone else are probably like now here's the best terrain and post some images, but this is the best I've seen right, so Since as you can tell we're dragging we're just getting right into it.

265
00:15:28,094 --> 00:15:29,380
Speaker 0: We've brought them up a lot.

266
00:15:29,721 --> 00:15:37,140
Speaker 0: We've talked about them on the show obliquely many times, but we've never really gone through the logical fallacies.

267
00:15:37,283 --> 00:15:41,754
Speaker 0: I mean we did our Somewhat epic show on the burden of proof and that sort of thing.

268
00:15:41,794 --> 00:15:43,280
Speaker 0: We talked about how to speak in public.

269
00:15:43,624 --> 00:15:54,608
Speaker 0: We've talked briefly about how to argue but we're still gonna do a whole show on How to argue for truth and then a separate show on how to argue to win because they are very different Techniques very different.

270
00:15:54,668 --> 00:16:00,552
Speaker 1: mostly I am concerned with the arguing for truth and Graham is concerned with the arguing for winning.

271
00:16:00,633 --> 00:16:08,120
Speaker 1: see Scott here thinks he's a comedian but a Good example of the arguing to win versus my arguing for truth.

272
00:16:08,381 --> 00:16:17,274
Speaker 0: It all comes down to the eternal battle between Calicles and Sophocles where Sophocles said There is truth and we must find it and Calicles said truth is whatever.

273
00:16:17,334 --> 00:16:22,328
Speaker 0: I convinced all the stupid people around me And it's like Calicles is the bad guy and that D1.

274
00:16:22,850 --> 00:16:25,256
Speaker 1: yeah bad guys win the car old.

275
00:16:25,497 --> 00:16:26,720
Speaker 1: shitty world bad guys win.

276
00:16:26,760 --> 00:16:30,275
Speaker 1: You know what shitty world bad guys win me is the truth.

277
00:16:30,637 --> 00:16:30,978
Speaker 1: That's how.

278
00:16:31,018 --> 00:16:31,460
Speaker 1: that's the truth.

279
00:16:32,421 --> 00:16:34,246
Speaker 0: That might be the mean world fallacy.

280
00:16:34,929 --> 00:16:36,414
Speaker 1: It could be mean world fallacy.

281
00:16:36,474 --> 00:16:40,573
Speaker 1: Anyway, right now first We got to talk about I think arguments in general.

282
00:16:40,593 --> 00:16:51,475
Speaker 0: Yeah, I'm gonna say one thing we're going to talk about a lot of this very generally because there's actually a whole field of study in terms of Argumentation and it involves a lot of Latin words.

283
00:16:51,496 --> 00:16:52,059
Speaker 1: We don't know.

284
00:16:52,321 --> 00:17:00,000
Speaker 0: Well more than that it involves a lot of very precise Terminology and it would take a whole show just to explain the bounds before we can even get into the good stuff.

285
00:17:00,160 --> 00:17:04,294
Speaker 1: Yeah, and most of that terminology we don't know even though we know the the thinking behind it.

286
00:17:04,796 --> 00:17:10,354
Speaker 0: but in the end all Argumentation which is the fancy way of saying yelling at each other.

287
00:17:10,374 --> 00:17:11,520
Speaker 0: Yep comes down.

288
00:17:11,929 --> 00:17:16,980
Speaker 1: Oh, by the way This is a show you should pay attention to because it will help you on the Internet's where argumentation is common.

289
00:17:17,526 --> 00:17:25,000
Speaker 0: And also once again You should go back and listen to our episode on the burden of proof because that is also critical very critical.

290
00:17:25,502 --> 00:17:32,827
Speaker 0: But all argumentation comes down to either arguing to convince or Arguing for collective truth.

291
00:17:33,529 --> 00:17:34,452
Speaker 0: and aside from that.

292
00:17:34,993 --> 00:17:36,899
Speaker 0: Are you inductively argue me?

293
00:17:37,460 --> 00:17:43,584
Speaker 0: argumenting arguing or are you deductively argumenting argumenting Dating.

294
00:17:43,804 --> 00:17:44,085
Speaker 1: Yes.

295
00:17:44,246 --> 00:17:46,232
Speaker 1: Are you deducting or inducting?

296
00:17:46,352 --> 00:17:48,720
Speaker 1: deducting is like Sherlock Holmes?

297
00:17:49,580 --> 00:17:54,206
Speaker 0: Well, it's more like very simply All snakes are green.

298
00:17:54,627 --> 00:17:56,131
Speaker 0: Let's say that that is my premise.

299
00:17:56,312 --> 00:17:58,117
Speaker 0: I am assuming that all snakes are green.

300
00:17:59,280 --> 00:17:59,897
Speaker 0: I see a snake.

301
00:18:00,762 --> 00:18:04,935
Speaker 0: The snake therefore is green or there's a. I know that all snakes are green.

302
00:18:05,256 --> 00:18:06,359
Speaker 0: There's a snake in that box.

303
00:18:07,384 --> 00:18:09,212
Speaker 0: I know that that snake is green.

304
00:18:09,553 --> 00:18:17,660
Speaker 0: now in deductive arguments If you accept the premise and the logic follows true, then you must accept the conclusion.

305
00:18:18,462 --> 00:18:19,805
Speaker 0: Case closed end of that it is.

306
00:18:20,106 --> 00:18:22,813
Speaker 0: it is a very precise and exact logic.

307
00:18:23,074 --> 00:18:27,588
Speaker 0: this therefore this it's if this and This then that that sort of thing.

308
00:18:27,629 --> 00:18:27,810
Speaker 0: Yep.

309
00:18:27,970 --> 00:18:29,599
Speaker 1: All A's are blue.

310
00:18:30,783 --> 00:18:32,280
Speaker 1: Here's an A that A is blue.

311
00:18:32,561 --> 00:18:37,900
Speaker 1: Because if you believe that all A's are blue the first thing then you have to accept the second thing.

312
00:18:38,101 --> 00:18:39,044
Speaker 1: You can't get around it.

313
00:18:39,205 --> 00:18:40,730
Speaker 1: Otherwise, the first thing was wrong.

314
00:18:40,770 --> 00:18:41,533
Speaker 1: Go back to square one.

315
00:18:41,573 --> 00:18:50,380
Speaker 0: Now this kind of argumentation is Difficult in one way because you have to be extremely precise in what you say and very careful about what you accept.

316
00:18:50,962 --> 00:18:57,725
Speaker 0: But at the same time it's very easy because the conclusions are obvious absolutely obvious and undeniable.

317
00:18:58,147 --> 00:19:03,602
Speaker 0: and furthermore a logical fallacy in regards to a deductive argument is Perfect.

318
00:19:03,883 --> 00:19:10,749
Speaker 0: a logical fallacy in that case means that your argument is patently wrong Logically untrue.

319
00:19:10,769 --> 00:19:11,855
Speaker 0: it is stupid.

320
00:19:11,876 --> 00:19:12,640
Speaker 0: You're an idiot.

321
00:19:13,001 --> 00:19:20,904
Speaker 1: Yeah, if you're making a deductive argument and you may you know submit a statement that is logically fallacious It is wrong.

322
00:19:20,924 --> 00:19:26,580
Speaker 1: automatically just period up your girl up wrong and sorry go back to start wrong answer.

323
00:19:26,740 --> 00:19:28,824
Speaker 1: It doesn't matter what you said it was wrong.

324
00:19:28,884 --> 00:19:29,866
Speaker 1: It was logical fallacy.

325
00:19:30,086 --> 00:19:30,527
Speaker 1: game over.

326
00:19:31,088 --> 00:19:41,200
Speaker 0: For example if I said all males are Human which is obviously not true, but let's say we accept that all male beings that could ever exist are human.

327
00:19:41,421 --> 00:19:42,830
Speaker 1: Oh, here's a male dolphin.

328
00:19:44,038 --> 00:19:46,916
Speaker 0: Ah All right, forget that you get the idea.

329
00:19:46,936 --> 00:19:56,060
Speaker 0: yeah All right But that's not what we're gonna talk about so much because that is no one ever argues deductively in the real world.

330
00:19:56,180 --> 00:20:03,240
Speaker 0: They do in debate class debate class in high school debate club and that they kind of yeah like quiz ball is not debate.

331
00:20:03,541 --> 00:20:04,223
Speaker 0: It's literally.

332
00:20:04,585 --> 00:20:09,040
Speaker 0: how fast can you talk and how fast can you flip through index cards and read things?

333
00:20:09,300 --> 00:20:10,245
Speaker 0: Someone else already wrote on.

334
00:20:10,285 --> 00:20:12,014
Speaker 1: and how much did you research in advance?

335
00:20:12,275 --> 00:20:13,160
Speaker 0: You don't do any research.

336
00:20:13,221 --> 00:20:14,200
Speaker 0: It's already done for you.

337
00:20:14,220 --> 00:20:20,200
Speaker 0: If you're in the not I don't want to say professional but in like the people who go in like the national tournaments It's all already done.

338
00:20:20,240 --> 00:20:25,233
Speaker 0: You literally just flip through note cards Like they'll make an argument and you boil it down to.

339
00:20:25,273 --> 00:20:26,960
Speaker 0: did they say Clinton good or Clinton bad?

340
00:20:27,301 --> 00:20:33,911
Speaker 0: And if they said Clinton good you flip through to your Clinton folder until you find the Clinton good argument And you don't care what it is.

341
00:20:33,951 --> 00:20:35,319
Speaker 0: You just read what's on that note card.

342
00:20:35,621 --> 00:20:37,266
Speaker 0: No ignore what you're actually saying.

343
00:20:37,567 --> 00:20:41,220
Speaker 0: you just read the note card and assume that that refuted whatever they said.

344
00:20:41,541 --> 00:20:44,509
Speaker 0: Yeah, it's so stupid, but I digress.

345
00:20:44,810 --> 00:20:47,357
Speaker 1: Yeah, I'm sure some debate club fans out there.

346
00:20:47,417 --> 00:20:47,558
Speaker 1: good.

347
00:20:47,578 --> 00:20:48,842
Speaker 0: Yeah, bring it You know what?

348
00:20:48,942 --> 00:20:49,625
Speaker 0: I was debate.

349
00:20:49,665 --> 00:20:51,612
Speaker 0: I was varsity debate for like three years.

350
00:20:51,633 --> 00:20:53,781
Speaker 0: All right, it is exactly like that All right.

351
00:20:53,801 --> 00:20:56,455
Speaker 1: Well rim you'll be defending that then I'm sure I can.

352
00:20:56,515 --> 00:20:57,380
Speaker 0: I think I can handle that.

353
00:20:57,440 --> 00:20:58,687
Speaker 1: You'll be arguing about arguing.

354
00:20:59,230 --> 00:21:00,396
Speaker 0: I always argued the affirmative.

355
00:21:00,677 --> 00:21:00,899
Speaker 1: All right.

356
00:21:01,701 --> 00:21:04,368
Speaker 1: So do you want to talk about the inductive arguments?

357
00:21:04,869 --> 00:21:09,160
Speaker 0: inductive reasoning is pretty much what you do in your daily life.

358
00:21:09,401 --> 00:21:10,725
Speaker 0: It's not so much.

359
00:21:10,765 --> 00:21:14,337
Speaker 0: There's a lot more kind of language involved or more reference.

360
00:21:14,357 --> 00:21:15,400
Speaker 0: I'm trying to be very generic here.

361
00:21:15,420 --> 00:21:20,531
Speaker 0: I don't want to bog you down with terms that you probably won't understand or they just won't be Interesting or that will be wrong about.

362
00:21:20,551 --> 00:21:21,336
Speaker 1: I get yelled at.

363
00:21:21,779 --> 00:21:29,059
Speaker 0: Yeah I mean if you really want to know the details Just go find an article that describes the differences between deductive and inductive scientific method.

364
00:21:30,041 --> 00:21:31,890
Speaker 0: That'll probably explain it pretty succinctly.

365
00:21:32,460 --> 00:21:37,380
Speaker 0: Yep, but even in an inductive argument, you can still make a logical fallacy.

366
00:21:37,822 --> 00:21:44,525
Speaker 0: The only difference is that a logical fallacy in those cases does not necessarily Always not follow.

367
00:21:44,545 --> 00:21:49,360
Speaker 0: you might make a logical fallacy, but the truth at the end of the fallacy might be true.

368
00:21:49,440 --> 00:21:56,980
Speaker 0: Anyway, the difference is if your argument consists of nothing but logical fallacies, then you don't actually have an argument.

369
00:21:57,141 --> 00:22:07,640
Speaker 1: Yeah, the best you could try to hope for is some sort of preponderance of evidence argument Mm-hmm in practical use of everydayness, which is what you care about the most, you know on the internet or with friends.

370
00:22:08,360 --> 00:22:13,054
Speaker 1: Logical fallacies are basically a way to help you win arguments against people.

371
00:22:13,114 --> 00:22:17,359
Speaker 1: if you know the logical fallacies You know, which there there are a set number of them.

372
00:22:17,601 --> 00:22:22,880
Speaker 0: Well, I mean there are a lot that people mention but there's a lot of classical ones that are clearly fallacy.

373
00:22:23,047 --> 00:22:33,743
Speaker 1: Yes If you know them and you study them and you know what they are Then when you argue with someone you can just be like that was the logical fallacy of blah and you can just erase Everything they said.

374
00:22:33,823 --> 00:22:48,220
Speaker 1: so in practical everyday use knowing logical fallacies helps you smack people down Because you because most people when they argue just you know Normally without you know thinking really hard about or studying make logical fallacies left and riding up and down.

375
00:22:48,623 --> 00:22:55,900
Speaker 1: So if you know how to point them out You can just own people in arguments without even having to give one point of evidence in favor of your position.

376
00:22:56,000 --> 00:23:07,197
Speaker 0: In fact, there's an entire branch of rhetorical debate that effectively is dedicated to using logical fallacies like that to basically Confound idiots and then convince them that you're right.

377
00:23:07,519 --> 00:23:15,339
Speaker 1: Yep But on the other hand if you're so smart that you recognize this you have the ultimate defense where no logically fallacious Argument can stand in your way.

378
00:23:15,641 --> 00:23:22,220
Speaker 1: But at the same time many correct arguments will fall before you because the people presenting them are so inept at arguing.

379
00:23:22,904 --> 00:23:28,752
Speaker 0: now you can also take it one step further and You could if you're really clever and evil.

380
00:23:29,093 --> 00:23:34,592
Speaker 0: you could use false Logical fallacies to confound your opponents and then win an argument.

381
00:23:34,612 --> 00:23:37,200
Speaker 0: All right, especially if you just make up Latin words.

382
00:23:37,625 --> 00:23:44,582
Speaker 0: Making up Latin words is great You know, I I think this is the direction we should go in because we're definitely not awake enough to talk about the you know Nitty-gritty.

383
00:23:44,602 --> 00:23:46,328
Speaker 0: Well this therefore there's blah blah blah blah blah.

384
00:23:46,348 --> 00:23:47,091
Speaker 0: This is called this kind of.

385
00:23:47,572 --> 00:23:50,543
Speaker 0: let's just go straight into the logical fallacies That matter the most.

386
00:23:50,723 --> 00:23:59,340
Speaker 1: All right, the one that matters the most as far as I am concerned is my favorite one Which is postdoc ergo proctor hoc.

387
00:23:59,621 --> 00:24:03,496
Speaker 0: I think that actually means that that does not follow or that that does follow or I don't know.

388
00:24:03,576 --> 00:24:11,866
Speaker 1: I think it means Just because it comes after Doesn't mean it's basically Correlation does not equal causality, right?

389
00:24:11,906 --> 00:24:23,749
Speaker 1: For example, let's say I have a statistic and the statistic says that People walking out of I'm trying to think of an example.

390
00:24:23,789 --> 00:24:24,232
Speaker 1: It's funny.

391
00:24:24,473 --> 00:24:25,177
Speaker 1: Can you think of anything?

392
00:24:25,198 --> 00:24:25,540
Speaker 1: It's funny.

393
00:24:26,122 --> 00:24:28,634
Speaker 0: I think we just go with a straight-up exam go at the straight-up exam.

394
00:24:28,654 --> 00:24:32,034
Speaker 0: All right, so let's say I Can't come up with anything either guy.

395
00:24:32,074 --> 00:24:38,559
Speaker 0: No, hold on You know, I guess we're just so good at arguing that we have trouble actually making a logical value.

396
00:24:40,891 --> 00:24:49,728
Speaker 0: So let's say I have a statistic that says that in the past ten years The globe the average temperature of the earth has increased steadily and we can chart it clearly.

397
00:24:49,768 --> 00:24:58,010
Speaker 0: It's increased Yep, and in that same span of ten years the number of pirates in international waters has decreased.

398
00:24:58,734 --> 00:25:07,564
Speaker 0: now I could make the conclusion from this data that Pirates decreasing causes an increase in global temperature and this is obviously not true.

399
00:25:07,725 --> 00:25:08,467
Speaker 1: No, it's not.

400
00:25:08,507 --> 00:25:09,850
Speaker 1: there are many things in the world.

401
00:25:09,870 --> 00:25:12,056
Speaker 1: They're coincidences all the time.

402
00:25:12,097 --> 00:25:13,120
Speaker 1: They're you know, they're.

403
00:25:13,340 --> 00:25:23,738
Speaker 1: you know, Google is making more and more money every day and I'm getting a little bit more money every day and Google's getting a lot Here's that mean that Google.

404
00:25:23,758 --> 00:25:26,790
Speaker 1: getting more money causes me getting more money or vice versa.

405
00:25:27,383 --> 00:25:35,050
Speaker 1: No They just be two things in the world Happen to both be going up or two things happen to both be going down or one happens to go up when another goes down.

406
00:25:35,070 --> 00:25:36,750
Speaker 0: I mean, here's a real-world example.

407
00:25:37,313 --> 00:25:51,269
Speaker 0: There's there is a perceived correlation between immunizations and autism which as Smart people know is caused mostly by the fact that children get their immunizations right about the time when autism symptoms kick in.

408
00:25:51,289 --> 00:25:56,930
Speaker 0: and There's all this other evidence too that basically that correlation is completely fallacious.

409
00:25:57,393 --> 00:26:04,630
Speaker 0: But yet people still make the argument which is a logical fallacy That they cause autism when in fact they do not and there's evidence that they do not.

410
00:26:05,012 --> 00:26:07,590
Speaker 1: There are many things that they seem to go together.

411
00:26:07,730 --> 00:26:16,388
Speaker 1: You know one thing happens and another thing happens at the same time or one thing seems to happen a lot after Something else happens and it looks like it causes it.

412
00:26:17,051 --> 00:26:34,360
Speaker 1: But unless you can actually show evidence that yes this caused it For example, you could show in like, you know a test tube, you know some DNA and then some vaccine and then the vaccine Modifying the DNA before and after to actually change it in a way That is to make that would make a person autistic.

413
00:26:34,601 --> 00:26:36,670
Speaker 1: that would be a demonstration of causation.

414
00:26:37,373 --> 00:26:48,230
Speaker 1: Other than that just because two things happen to coincide or you know Anything like that does not mean one thing caused the other and to say so without enough evidence is logically fallacious.

415
00:26:48,852 --> 00:26:55,890
Speaker 0: So I think right along those lines perhaps my favorite because I'll admit that I use this as a rhetorical technique often ad hominins.

416
00:26:56,373 --> 00:26:57,138
Speaker 1: No, no, no.

417
00:26:57,621 --> 00:26:58,890
Speaker 0: the false dilemma.

418
00:26:59,952 --> 00:27:01,839
Speaker 0: Now the false dilemma is very simple.

419
00:27:02,642 --> 00:27:03,244
Speaker 0: all I do.

420
00:27:03,324 --> 00:27:12,182
Speaker 0: you do use the false dilemma quite a bit And you know what it works because as a rhetorical strategy, it is brilliance brilliant I say even though I shoot it down all the time.

421
00:27:12,684 --> 00:27:25,068
Speaker 0: All you do is present what two or more options in an argument and Make the kind of beg to question assertion that those are in fact the only two options.

422
00:27:25,108 --> 00:27:29,090
Speaker 1: for example You know rim will make a statement and I'll say oh that statement, huh?

423
00:27:29,410 --> 00:27:32,037
Speaker 1: So either a or B, which is it?

424
00:27:32,278 --> 00:27:32,799
Speaker 1: which is it?

425
00:27:33,120 --> 00:27:51,409
Speaker 1: and I'm totally ignoring the fact that there could be CDE and F. I'm acting as if a and B are the only possibilities in the whole world if you assume that what rim just said is true and it sort of traps rim because a is bad and B is bad also, but he can't get his mind out in out of that box and start thinking about CDE and F

426
00:27:52,092 --> 00:27:52,413
Speaker 0: Certain.

427
00:27:52,734 --> 00:27:57,210
Speaker 0: well one government in particular in the world in recent years has used this fallacy extensively.

428
00:27:57,913 --> 00:28:02,049
Speaker 0: I believe you may know it as you're either with us or you're against us.

429
00:28:03,712 --> 00:28:05,804
Speaker 0: That is very much the false dichotomy.

430
00:28:06,065 --> 00:28:08,718
Speaker 1: Yep False dichotomies are great.

431
00:28:08,919 --> 00:28:11,330
Speaker 0: So you want to since you mentioned it you want to bring up the ad hominem?

432
00:28:11,710 --> 00:28:17,210
Speaker 1: All right ad hominem is is perhaps the the worst of all logical fallacies and the most used on the internet.

433
00:28:17,270 --> 00:28:20,110
Speaker 1: For example, let's say rim set rims make up make a true statement.

434
00:28:21,144 --> 00:28:24,139
Speaker 0: I am Incredibly intelligent and good-looking.

435
00:28:24,360 --> 00:28:26,230
Speaker 1: No, that's not a true statement.

436
00:28:26,230 --> 00:28:32,550
Speaker 1: You have to come up with something bad, but anyway, let's pretend the rim said that Scott was incredibly intelligent and good-looking.

437
00:28:32,991 --> 00:28:34,777
Speaker 1: So that's a true statement.

438
00:28:34,897 --> 00:28:38,990
Speaker 1: But now let's say I go and I say well rim you're wrong because you're ugly.

439
00:28:40,031 --> 00:28:41,415
Speaker 1: That's basically what ad hominem is.

440
00:28:41,455 --> 00:28:46,630
Speaker 1: you attack the person making the argument and you basically say well you're stupid.

441
00:28:46,912 --> 00:28:48,427
Speaker 1: Therefore the thing you said is wrong.

442
00:28:48,467 --> 00:28:52,986
Speaker 1: Listen You know, there are people in this world who are more educated than others.

443
00:28:53,006 --> 00:28:53,890
Speaker 1: that that's just the truth.

444
00:28:54,030 --> 00:28:57,005
Speaker 1: You know, there are some people in the world who are smarter than others.

445
00:28:57,045 --> 00:29:02,810
Speaker 1: That's the way it is, but Just because someone is dumb doesn't mean everything they say is automatically wrong.

446
00:29:02,930 --> 00:29:10,433
Speaker 1: I mean you could find the dumbest person in the world and they might say 1 plus 1 is 2. you can't say Well, you're dumb.

447
00:29:10,453 --> 00:29:14,510
Speaker 1: that so 1 plus 1 isn't - no 1 plus 1 is - it's how it is.

448
00:29:15,012 --> 00:29:19,347
Speaker 1: The person making the argument has nothing to do with the validity of the argument itself.

449
00:29:19,407 --> 00:29:36,910
Speaker 1: like a lot of people You know, someone will be making a bunch of arguments and then someone will say well You're an ex-convict who killed a bunch of people and you know, that's a lot of the news channels will do that a lot, you know with some crazy person is making an argument, you know of some kind and you know Crazy people are usually wrong because they're crazy.

450
00:29:37,354 --> 00:29:38,950
Speaker 1: It's they say a lot of crazy things.

451
00:29:39,030 --> 00:29:53,710
Speaker 1: But sometimes a crazy person says something right and people use ad hoc the logical fallacy of the ad hominem attack To sort of make it so that anyone if they're crazy or if they're evil or if they can they can make the person seem like a bad person.

452
00:29:54,231 --> 00:29:59,065
Speaker 1: then it may give the impression that everything they say is wrong because they're a bad person.

453
00:29:59,085 --> 00:30:00,268
Speaker 1: and that's just not true.

454
00:30:00,468 --> 00:30:12,290
Speaker 0: right along those lines is the argument from fallacy which is the false conclusion that just because an Argument was itself technically a logical fallacy that therefore the conclusion is false.

455
00:30:13,532 --> 00:30:17,386
Speaker 0: The example I'm just poking around Wikipedia to remind myself of which ones I want to talk about.

456
00:30:17,426 --> 00:30:20,149
Speaker 0: but there's a good example here All cats are animals.

457
00:30:20,651 --> 00:30:21,694
Speaker 0: Ginger is an animal.

458
00:30:21,995 --> 00:30:23,679
Speaker 0: therefore ginger is a cat.

459
00:30:24,161 --> 00:30:26,367
Speaker 0: now that does affirm the consequent.

460
00:30:26,427 --> 00:30:27,530
Speaker 0: It is a logical fallacy.

461
00:30:28,193 --> 00:30:31,590
Speaker 0: But so the argument technically is an illogical argument.

462
00:30:31,650 --> 00:30:35,230
Speaker 0: But at the same time that does not prove that ginger is not a cat, right?

463
00:30:35,451 --> 00:30:38,490
Speaker 0: It just proves that the person arguing doesn't know what they're talking about exactly.

464
00:30:38,731 --> 00:30:40,139
Speaker 1: So the person makes that argument.

465
00:30:40,220 --> 00:30:42,010
Speaker 1: you don't have to believe that ginger is a cat.

466
00:30:42,110 --> 00:30:43,596
Speaker 0: Yeah, here's a good example.

467
00:30:43,817 --> 00:30:46,326
Speaker 0: The sky is blue because I am God and I made it that way.

468
00:30:46,346 --> 00:30:50,153
Speaker 1: Yeah, exactly It's like the sky might still be blue Just be.

469
00:30:50,193 --> 00:30:54,410
Speaker 1: but the argument that they use to support the fact that the sky was blue was a bad argument.

470
00:30:54,753 --> 00:30:56,669
Speaker 1: That doesn't mean the sky is suddenly not blue.

471
00:30:56,971 --> 00:31:03,491
Speaker 1: I mean there are people around the world who argue for all sorts of different things and they use different evidence to support all those Arguments.

472
00:31:03,551 --> 00:31:12,190
Speaker 1: but just because someone who's really bad at arguing is arguing for the right thing with bad evidence or falsehoods Doesn't mean that their conclusion is wrong.

473
00:31:12,231 --> 00:31:12,659
Speaker 1: They might have.

474
00:31:13,006 --> 00:31:23,949
Speaker 1: you know I might be trying to argue that one plus one is two and I might say well one is a half and one is a half and yeah, then you know, I might say something completely batshit and My argument might be bad.

475
00:31:24,050 --> 00:31:29,850
Speaker 1: But one plus one is still two either even though I just I'm not able to argue in favor of it because I suck.

476
00:31:30,791 --> 00:31:35,730
Speaker 0: So, I know you've been waiting to bring it up so I figure I'll let you broke the no true Scotsman.

477
00:31:36,072 --> 00:31:47,725
Speaker 1: Oh, no, no true Scotsman the game of goof Yes, the no true Scotsman argument is something you will find quite often and it's actually something related to.

478
00:31:47,786 --> 00:31:54,003
Speaker 1: another pet peeve of mine is basically, someone will say some it really has to do a lot with semantics.

479
00:31:54,063 --> 00:32:19,350
Speaker 1: the no true Scotsman argument is where someone will say Well, like I'll use Emily's mom was like, oh, well, they're not athletes and it's like well It's like people have these personal definitions of words or they assign their own value systems to the definition of a word in some way and it's like they don't want to apply a Certain label to something for whatever reason but it has nothing to do with with reality or truth.

480
00:32:19,511 --> 00:32:23,967
Speaker 1: It's like oh, that's not a bagel because it's not at every if it's not an everything bagel.

481
00:32:24,007 --> 00:32:24,670
Speaker 1: It's not a bagel.

482
00:32:24,810 --> 00:32:29,750
Speaker 1: Well, no a bagel by definition is a circular bread baked in a certain way with a certain dough.

483
00:32:29,911 --> 00:32:42,170
Speaker 0: but at the same time if you're arguing the no true Scotsman is a Very easy way to get yourself out of a tricky situation If you can introduce it in such a way to where it's not clear right away that you're making the no true Scotsman.

484
00:32:42,170 --> 00:32:55,464
Speaker 0: Yes because if it's someone proves like if someone proves that I'm an Englishman and I don't want to be Portrayed as an Englishman for whatever reason then I could say ah But I do blah and no true Englishman would do blah therefore.

485
00:32:55,605 --> 00:32:56,950
Speaker 0: I am NOT really an Englishman.

486
00:32:57,150 --> 00:33:02,130
Speaker 0: Yes, despite the fact that you have just proven me to be an Englishman, but that is the unstated part.

487
00:33:02,431 --> 00:33:04,322
Speaker 0: That's the part you say quietly to yourself.

488
00:33:04,523 --> 00:33:04,704
Speaker 0: Yep.

489
00:33:04,764 --> 00:33:05,005
Speaker 1: It's like.

490
00:33:05,066 --> 00:33:16,763
Speaker 1: on another podcast I listen to some guy was like science fiction means Spaceships and planets and that stuff and he I'm like, well, what about like, I don't know the Twilight Zone He's like in my personal definition.

491
00:33:17,024 --> 00:33:18,030
Speaker 1: That's not science fiction.

492
00:33:18,672 --> 00:33:22,988
Speaker 1: First if you think you have a personal definition of a word I gotta say this it's bullshit.

493
00:33:23,209 --> 00:33:24,561
Speaker 0: Well, no No, it isn't what you do.

494
00:33:24,581 --> 00:33:34,404
Speaker 0: in that case it's just that that it's that fallacy often comes about unwittingly on both sides because The fallacy can arise if people are using different lexicons to argue.

495
00:33:34,524 --> 00:33:36,230
Speaker 0: That's true, which happens often.

496
00:33:36,270 --> 00:33:49,525
Speaker 0: That's why probably the most important thing you can do when you're actually debating with someone and we'll talk about this whenever we do the argument show is to together Agree on the terms any time a word comes up and there's any disagreement.

497
00:33:49,545 --> 00:33:59,630
Speaker 0: that would result in a no true Scotsman you kind of have a Subdebate where you both agree that the word means X and then you finish the debate as though that word means what you agreed upon.

498
00:33:59,715 --> 00:34:04,350
Speaker 0: Yep Otherwise, you can't actually have a true argument because you're coming from two different positions.

499
00:34:04,751 --> 00:34:18,440
Speaker 0: if I think that all Scotsman or Willie and I argue as though any person who is Scottish is exactly like Willie from the Simpsons and Scott Argues from the perspective that Scottish people are Scottish we have a problem woman.

500
00:34:18,841 --> 00:34:19,884
Speaker 1: Have you got any grease?

501
00:34:20,346 --> 00:34:20,626
Speaker 0: Yes.

502
00:34:20,967 --> 00:34:21,469
Speaker 0: Yes, I do.

503
00:34:21,810 --> 00:34:23,134
Speaker 1: Then grease me up woman.

504
00:34:23,435 --> 00:34:24,097
Speaker 0: Okie dokie.

505
00:34:24,178 --> 00:34:24,940
Speaker 0: All right.

506
00:34:25,482 --> 00:34:25,803
Speaker 0: All right.

507
00:34:26,625 --> 00:34:27,025
Speaker 0: I got it.

508
00:34:27,306 --> 00:34:28,130
Speaker 0: I got to do this one.

509
00:34:28,330 --> 00:34:32,083
Speaker 0: All right, partly because people use this phrase wrong.

510
00:34:32,164 --> 00:34:33,328
Speaker 1: Are you gonna beg your question?

511
00:34:33,348 --> 00:34:34,010
Speaker 0: I might.

512
00:34:34,090 --> 00:34:35,437
Speaker 1: I know you love begging the question.

513
00:34:36,139 --> 00:34:49,969
Speaker 0: if you ever want to infuriate me There is nothing you can do more perfectly more elegantly more Immediately than to use the phrase to beg the question to mean to raise the question.

514
00:34:50,955 --> 00:34:53,830
Speaker 0: That is not what that means and you're doing it wrong.

515
00:34:54,231 --> 00:35:10,208
Speaker 0: Begging the question is a brilliant and subtle fallacy where you basically make an argument That assumes something But you just go right past proving the thing you're assuming and act as though it's already a postulate mmm-hmm.

516
00:35:11,030 --> 00:35:19,750
Speaker 0: and Basically what you've done is you've begged the question For example, I say the world is flat because God made it that way.

517
00:35:20,572 --> 00:35:23,180
Speaker 0: Well now I've begged a whole bunch of questions.

518
00:35:23,562 --> 00:35:24,344
Speaker 0: So there's a God.

519
00:35:24,444 --> 00:35:26,190
Speaker 0: so we made the world so we made it flat.

520
00:35:26,378 --> 00:35:32,718
Speaker 1: Yeah It's you make a statement and you act like the statement has already been proven like and you didn't you know back it up at all.

521
00:35:32,738 --> 00:35:40,970
Speaker 1: and Now the people are gonna ask a whole bunch of questions like well How wait a minute go back a minute that thing you you just said something to support another argument.

522
00:35:41,251 --> 00:35:43,920
Speaker 1: But that's something you said isn't quite right.

523
00:35:43,960 --> 00:35:46,690
Speaker 1: I got a bunch of questions to ask about it's kind of it's circular logic.

524
00:35:46,790 --> 00:35:48,355
Speaker 0: It's like you use your can.

525
00:35:48,376 --> 00:35:51,546
Speaker 0: your conclusion implicitly proves the precedent.

526
00:35:51,747 --> 00:35:51,967
Speaker 1: Yep.

527
00:35:52,349 --> 00:35:54,034
Speaker 1: Yep Alright, you want me to do one?

528
00:35:54,335 --> 00:35:55,118
Speaker 0: I think you should do one.

529
00:35:55,499 --> 00:36:01,117
Speaker 1: Alright, this is the fallacy of many questions Of the loaded question.

530
00:36:01,197 --> 00:36:03,666
Speaker 1: in Latin the Plurium interrogate.

531
00:36:03,706 --> 00:36:04,770
Speaker 0: you're looking at Wikipedia.

532
00:36:04,770 --> 00:36:05,573
Speaker 1: Yes, I am.

533
00:36:05,593 --> 00:36:11,673
Speaker 1: Okay, but you know, you know kids will often pick on each other and they'll say something like hey Have you?

534
00:36:11,874 --> 00:36:13,822
Speaker 1: uh, have you told your parents that you're stupid?

535
00:36:14,465 --> 00:36:15,690
Speaker 0: When did you stop beating your wife?

536
00:36:15,990 --> 00:36:17,942
Speaker 1: Yeah, when'd you stop beating your wife did?

537
00:36:17,983 --> 00:36:19,150
Speaker 0: how long have you been a communist?

538
00:36:19,730 --> 00:36:20,212
Speaker 1: Exactly.

539
00:36:20,795 --> 00:36:22,383
Speaker 1: It's how long have you been a communist?

540
00:36:22,423 --> 00:36:23,770
Speaker 1: you you in your statement?

541
00:36:24,151 --> 00:36:31,495
Speaker 1: You you basically ask a question where no answer to the question directly Will be true.

542
00:36:31,535 --> 00:36:36,410
Speaker 1: because like if you ask someone how long have you been a communist you're making the assumption that they're a communist.

543
00:36:36,552 --> 00:36:41,530
Speaker 1: And if they're not a communist How do you can't say wait your question is wrong.

544
00:36:41,911 --> 00:36:51,830
Speaker 1: this is basically asking a question in which the question carries a false assumption and It's a really good trick because people are like what the fuck and it's you know, what do you say to that?

545
00:36:51,850 --> 00:36:58,030
Speaker 1: I mean, you know, it's like even if someone comes up to you and says hey Have you have you told your parents that you know?

546
00:36:58,170 --> 00:37:02,490
Speaker 1: You stole a million dollars from the bank and it'd be like I didn't steal a million dollars in the bank.

547
00:37:02,650 --> 00:37:04,555
Speaker 1: That's sort of a weak comeback to that.

548
00:37:04,756 --> 00:37:06,741
Speaker 1: Are you know convincingly to other people?

549
00:37:06,801 --> 00:37:08,847
Speaker 1: So it's it.

550
00:37:09,187 --> 00:37:10,050
Speaker 1: it's very false.

551
00:37:10,572 --> 00:37:20,496
Speaker 1: But if you're arguing with people and you use this technique It's very difficult for them to say something that makes them look powerful, you know It really puts you on top of the game.

552
00:37:21,159 --> 00:37:24,270
Speaker 0: now one particular branch of five fallacies.

553
00:37:24,390 --> 00:37:32,209
Speaker 0: I'll just call them the appeals in general and This is an argument that you don't make really to the person you're arguing with ever.

554
00:37:32,932 --> 00:37:38,930
Speaker 0: Wow, it seems like every time I bring up a fallacy I end up describing it as here's how to use this fallacy in an argument.

555
00:37:39,211 --> 00:37:44,550
Speaker 0: Yeah, but this is a the kind of thing where you're not even you don't even care who you're arguing with.

556
00:37:44,832 --> 00:37:53,750
Speaker 0: this is a fallacy where you appeal to the audience and Furthermore you appeal to something that has nothing to do with the argument with the audience like an appeal to fear.

557
00:37:54,291 --> 00:38:02,416
Speaker 0: You appeal to the fear of the audience like if we listen to him then Nazis are gonna come and kill you all That.

558
00:38:02,778 --> 00:38:06,517
Speaker 0: if not, unless you're in World War two era Germany is a logical fallacy.

559
00:38:06,537 --> 00:38:08,385
Speaker 0: you were appealing to the fear of the audience.

560
00:38:08,606 --> 00:38:12,722
Speaker 0: their fear of Nazis Have nothing to do with the argument at hand.

561
00:38:12,862 --> 00:38:27,310
Speaker 1: You're basically scaring people into Agreeing with what you say no matter what your bait you're saying at all, you know, like I could say All right I say X and rim says why and if you believe why you're all gonna die tomorrow.

562
00:38:27,551 --> 00:38:30,909
Speaker 1: if you believe X will all live in paradise, which one do you believe?

563
00:38:30,929 --> 00:38:37,210
Speaker 1: and The the ifs the if statements that I just presented were both had absolutely no evidence to support them whatsoever.

564
00:38:37,693 --> 00:38:45,630
Speaker 1: But by making them I was able to basically Convince weak-minded people into believing my thing no matter what a is and no matter what X is.

565
00:38:46,434 --> 00:38:47,609
Speaker 1: That that's what he's talking about.

566
00:38:48,003 --> 00:38:59,570
Speaker 0: Yeah and I also got to bring this one up because it's also a very useful one and it's one that we've actually brought up a lot because I I've been known to use it occasionally in a rhetorical debate, but the straw man

567
00:39:00,072 --> 00:39:01,700
Speaker 1: Oh the strong of the famous straw man.

568
00:39:01,740 --> 00:39:05,457
Speaker 1: many people they talk about the straw man But they don't really know what the straw man is.

569
00:39:05,498 --> 00:39:07,909
Speaker 0: They think Wizard of Oz nothing burns like an effigy.

570
00:39:08,674 --> 00:39:13,507
Speaker 0: Nothing quite burns like the effigy basically, so Scott's arguing some point.

571
00:39:13,909 --> 00:39:15,838
Speaker 0: now What I'm doing.

572
00:39:15,858 --> 00:39:16,963
Speaker 1: Zelda 1 is the greatest.

573
00:39:17,144 --> 00:39:21,068
Speaker 0: the analogy that I'll do that I'll make here is that Scott is standing there arguing.

574
00:39:21,088 --> 00:39:30,983
Speaker 0: I distract the audience by making a straw man a scarecrow that looks like Scott and Then I set it on fire and the audience says wow.

575
00:39:31,023 --> 00:39:32,350
Speaker 0: He just burned that scarecrow.

576
00:39:32,632 --> 00:39:34,123
Speaker 0: Meanwhile, the real Scott is standing there.

577
00:39:34,143 --> 00:39:34,929
Speaker 0: No one's listening to him.

578
00:39:35,793 --> 00:39:59,090
Speaker 0: The straw man is when you take the other person's argument and Reframe it or rephrase it in such a way that it sounds so much worse than it was or even better if you change it entirely and you make it disappear as though your enemy is arguing something that they're not really arguing and Furthermore you make that thing that you have made it sound like they're arguing be patently false and easily disproven.

579
00:39:59,231 --> 00:40:02,810
Speaker 1: For example rim might say so pick rim pick a video game.

580
00:40:03,111 --> 00:40:06,210
Speaker 0: Alright Silver Surfer is the best video game ever right?

581
00:40:06,570 --> 00:40:07,674
Speaker 1: So I say so.

582
00:40:07,714 --> 00:40:11,445
Speaker 1: you're saying that Zelda 1 is a terrible god-awful game.

583
00:40:11,666 --> 00:40:12,930
Speaker 1: Well, you must be a terrible person.

584
00:40:13,854 --> 00:40:21,150
Speaker 1: But I said right he didn't say anything about Zelda But I basically put words in his mouth to make it, you know.

585
00:40:21,230 --> 00:40:29,459
Speaker 1: And I basically, you know made this scarecrow that looks like rim and I put my hand in the back of it Like a little puppeteer, you know or a wedding marionette.

586
00:40:29,700 --> 00:40:34,857
Speaker 1: and I made that scarecrow say Zelda is terrible And then I set it on fire like it.

587
00:40:34,918 --> 00:40:37,447
Speaker 1: Look rim said Zelda's terrible and everyone agrees with me.

588
00:40:37,688 --> 00:40:39,878
Speaker 1: Yeah Get him Zelda's great.

589
00:40:39,918 --> 00:40:47,630
Speaker 1: Yeah, even though rim didn't say Zelda was terrible I just make it look like rim said something really bad that everyone will disagree with when he didn't say anything of the sort.

590
00:40:48,113 --> 00:40:57,448
Speaker 0: It's basically a way to make your opponent look bad And as a result, you can then use the leverage you've gained from making them look bad to make everything else They say look just as bad.

591
00:40:57,771 --> 00:41:08,050
Speaker 0: Yep, and also if they make a real solid argument by reframing the argument carefully You can introduce a way of defeating the argument that wasn't there in what they originally said.

592
00:41:08,391 --> 00:41:09,998
Speaker 1: Now there's a problem with the straw man.

593
00:41:10,018 --> 00:41:12,650
Speaker 1: that I run into quite often is if you're making an argument.

594
00:41:13,071 --> 00:41:18,110
Speaker 1: Sometimes you can straw man yourself by accident because you'll have an idea in your mind.

595
00:41:18,491 --> 00:41:29,646
Speaker 1: It usually happens more the less eloquent you are and you have an idea in your mind of what you arguing But you're unable to express that idea or maybe you're just unable to communicate that idea to ever.

596
00:41:29,686 --> 00:41:36,984
Speaker 1: you trying to communicate it to you And the idea they get in their head from your words is Different from the idea that you're actually trying to get across.

597
00:41:37,105 --> 00:41:38,190
Speaker 1: and thus the argue.

598
00:41:38,250 --> 00:41:44,910
Speaker 1: You'll basically build a straw man by accident and then they'll the person you're trying to convince starts beating up the straw man.

599
00:41:44,970 --> 00:41:46,777
Speaker 1: You're like I'm over here guys.

600
00:41:46,837 --> 00:41:48,042
Speaker 1: It's not what I was trying to say.

601
00:41:48,143 --> 00:41:49,990
Speaker 1: Maybe I should call that man by accident.

602
00:41:50,050 --> 00:41:51,867
Speaker 0: Maybe we should call that the funeral pyre.

603
00:41:53,756 --> 00:41:57,329
Speaker 0: I build a funeral pyre around myself and then I just wait for my opponent to light it.

604
00:41:57,530 --> 00:41:59,480
Speaker 0: Yes, I'm like that, you know, I know even better.

605
00:41:59,501 --> 00:42:01,230
Speaker 0: We'll call it the gas can on the head fallacy.

606
00:42:02,833 --> 00:42:06,830
Speaker 0: All right, let's argue but I'm gonna stand here with this gas can and I know you've got a match.

607
00:42:09,472 --> 00:42:14,790
Speaker 1: I got one that people use quite often and is really pissing me off every day and people don't seem to stop using it.

608
00:42:14,870 --> 00:42:15,152
Speaker 1: All right.

609
00:42:15,172 --> 00:42:17,510
Speaker 1: So hey rim a is true.

610
00:42:17,911 --> 00:42:19,095
Speaker 1: You know why is true?

611
00:42:19,436 --> 00:42:23,990
Speaker 1: because all my friends say so and because everyone else says so you know what?

612
00:42:24,730 --> 00:42:34,582
Speaker 1: if everyone in the whole world Except for me says that one plus one is three and I say that one plus one is two I'm right and everyone else in the world is wrong.

613
00:42:34,622 --> 00:42:34,823
Speaker 1: Now.

614
00:42:35,244 --> 00:42:42,468
Speaker 1: This is a tricky one because Conspiracy theory type people will often be like yeah, the whole world is wrong.

615
00:42:42,528 --> 00:42:43,090
Speaker 1: It's a huge concern.

616
00:42:43,371 --> 00:42:46,450
Speaker 1: It's not common for the whole world to be wrong.

617
00:42:46,891 --> 00:42:52,210
Speaker 0: When anytime, you know, you see some crazy guy I was gonna remember, you know, how do you know that?

618
00:42:52,310 --> 00:42:53,012
Speaker 0: You're not that guy.

619
00:42:53,113 --> 00:42:58,310
Speaker 0: anytime you think that everyone else is crazy, but you the odds are against you.

620
00:42:58,450 --> 00:43:07,030
Speaker 1: Yeah, I mean crazy people generally seem to think that you know They're right and everyone else in the whole world has got it wrong about achievements whatever.

621
00:43:07,712 --> 00:43:12,707
Speaker 1: But it's not just because many crazy people are like that and they are crazy.

622
00:43:12,747 --> 00:43:15,970
Speaker 1: Don't get yourself wrong Doesn't mean it's necessarily true.

623
00:43:16,010 --> 00:43:22,190
Speaker 1: I mean like Albert Einstein came up with the theory of relativity It was like him and a few people in the whole rest of the world had it wrong.

624
00:43:22,431 --> 00:43:26,847
Speaker 1: And now the whole rest of the world realized and now we have it right err than we did before.

625
00:43:27,048 --> 00:43:27,489
Speaker 1: you know, right?

626
00:43:28,210 --> 00:43:29,756
Speaker 1: Right err more correct.

627
00:43:30,318 --> 00:43:42,210
Speaker 1: So just because a large number of P It's the argument ad populum populace many people, you know a population of people It just because a lot of people agree on something doesn't make it true.

628
00:43:42,532 --> 00:43:47,315
Speaker 1: a lot of people agree on a lot of things and They're very wrong.

629
00:43:47,335 --> 00:43:50,910
Speaker 1: a lot of people, you know, a lot of people in this world believe all sorts of crazy stuff.

630
00:43:51,351 --> 00:43:57,970
Speaker 1: I mean people are believing in like fake medicine and all sorts of bad shit, you know psychic powers and it's all false.

631
00:43:58,351 --> 00:44:02,463
Speaker 1: just because a lot just because more people agree on something doesn't make it more true.

632
00:44:02,884 --> 00:44:11,334
Speaker 1: if everyone in the whole world said that you know Nintendo is spelled QX JBF It's still fell.

633
00:44:11,414 --> 00:44:13,502
Speaker 1: it's still spelled nint endo.

634
00:44:14,004 --> 00:44:21,330
Speaker 0: the real point here is pretty simple Just any time someone is trying to argue with you don't you don't need to memorize the stupid names of fallacies.

635
00:44:21,431 --> 00:44:27,221
Speaker 0: You don't need to know like well, that's the fallacy of this and that's an informal fallacy And that's a formal fallacy and that it out of that.

636
00:44:27,904 --> 00:44:38,775
Speaker 0: All you need to do is In your head whenever someone's speaking boil down what they're saying to what logical argument They're actually making if they're making a logical argument at all.

637
00:44:39,236 --> 00:44:46,010
Speaker 0: And at that point if you can do that Very often if they're making a bad argument, it will become readily apparent.

638
00:44:46,372 --> 00:44:49,726
Speaker 0: And if you can point that out, you've pretty much won the day.

639
00:44:49,746 --> 00:44:53,035
Speaker 1: Mm-hmm Oh and you know That's pretty much what it comes down to.

640
00:44:53,075 --> 00:44:57,070
Speaker 1: you're arguing with people and the way people argue on the internet these days is just logical.

641
00:44:57,211 --> 00:44:58,316
Speaker 1: Fallacies left and right.

642
00:44:58,698 --> 00:45:02,658
Speaker 1: so if you just learn to notice them You could just win any are you?

643
00:45:02,698 --> 00:45:05,250
Speaker 1: just shut people down left and right shut down shut down shut down.

644
00:45:05,551 --> 00:45:09,470
Speaker 1: The thing is it takes quite a bit of thinking and quite a bit of learning and quite a bit of practice.

645
00:45:09,732 --> 00:45:12,530
Speaker 0: That's where the so-called name fallacies kind of come anyone.

646
00:45:12,711 --> 00:45:16,249
Speaker 1: Yeah, if anyone comes along and is like hey Scott, you don't argue that way.

647
00:45:16,471 --> 00:45:18,330
Speaker 1: Yeah, cuz I you know not trying to do it all the time.

648
00:45:18,350 --> 00:45:18,972
Speaker 1: What do you want from me?

649
00:45:19,895 --> 00:45:23,726
Speaker 0: and I often use the opposite and I use logical fallacies to my own ends.

650
00:45:23,826 --> 00:45:24,147
Speaker 1: Yes.

651
00:45:24,247 --> 00:45:26,092
Speaker 1: Yes you do All right.

652
00:45:26,112 --> 00:45:27,478
Speaker 1: We have anything else to say about this now.

653
00:45:27,498 --> 00:45:28,080
Speaker 0: I'm going to bed.

654
00:45:28,281 --> 00:45:28,803
Speaker 0: Good God.

655
00:45:29,125 --> 00:45:40,946
Speaker 0: Yeah, good God This has been geek nights with rim and Scott.

656
00:45:41,026 --> 00:45:43,490
Speaker 0: special thanks to DJ pretzel for the opening music.

657
00:45:44,196 --> 00:45:55,390
Speaker 1: Be sure to visit our website at www.frontroadcrew.com Where you'll find show notes links our awesome forum a link to our frapper map and links to all the RSS feeds.

658
00:45:55,951 --> 00:46:01,610
Speaker 0: We say feeds plural because geek nights airs four nights a week covering four different brands of geekery.

659
00:46:02,152 --> 00:46:04,321
Speaker 0: Mondays are science and technology Tuesdays.

660
00:46:04,361 --> 00:46:06,370
Speaker 0: We have video games board games and RPGs.

661
00:46:06,831 --> 00:46:12,230
Speaker 0: Wednesdays are anime manga comic nights and Thursdays are the catch-alls for various rants and tomfoolery.

662
00:46:12,711 --> 00:46:20,854
Speaker 1: You can send us feedback by email to geek nights at front row crew comm or you can send audio feedback Via audio.

663
00:46:21,135 --> 00:46:24,350
Speaker 1: just click the link that says send me an audio on the right side of our website.

664
00:46:24,713 --> 00:46:25,621
Speaker 0: If you like what you hear.

665
00:46:25,702 --> 00:46:29,860
Speaker 0: you can catch the last 100 episodes in iTunes or in your favorite podcatcher.

666
00:46:30,080 --> 00:46:33,190
Speaker 0: for the complete archives visit the website which has everything.

667
00:46:33,752 --> 00:46:39,775
Speaker 1: Geek nights is distributed under a Creative Commons attribution non-commercial share alike 2.5 license.

668
00:46:40,277 --> 00:46:43,630
Speaker 1: this means you can do whatever you want with it as long as you give us credit.

669
00:46:44,093 --> 00:46:46,329
Speaker 1: Don't make money and share it in time.

670
00:46:47,132 --> 00:46:52,546
Speaker 1: Geek nights is recorded live with no studio and no audience, but unlike those other late shows.

671
00:46:52,847 --> 00:46:54,170
Speaker 1: It's actually recorded at night.

