1
00:00:08,540 --> 00:00:10,227
Speaker 0: It's Thursday, October 26th, 2023.

2
00:00:10,227 --> 00:00:10,408
Speaker 0: I'm Rem.

3
00:00:13,705 --> 00:00:14,259
Speaker 1: I'm Scott.

4
00:00:14,460 --> 00:00:15,949
Speaker 0: And this is Geek Nights Tonight.

5
00:00:15,989 --> 00:00:17,920
Speaker 0: We are talking about scams.

6
00:00:19,440 --> 00:00:20,377
Speaker 1: Let's do this.

7
00:00:21,460 --> 00:00:23,319
Speaker 0: So, uh, long day.

8
00:00:24,762 --> 00:00:34,659
Speaker 0: I didn't notice, like, I was working from home and I was home all day working on stuff and I thought, oh, maybe I should go run and I step out on the balcony and it's like 70-something degrees.

9
00:00:36,664 --> 00:00:39,297
Speaker 0: And it looks like it's going to be 80, uh, what, Saturday?

10
00:00:40,220 --> 00:00:44,538
Speaker 0: It's going to be hot for a few days relative to what late October should be.

11
00:00:45,420 --> 00:00:45,510
Speaker 1: Good.

12
00:00:46,981 --> 00:00:52,660
Speaker 1: At least, you know, if you're going to destroy me and the world, at least I can enjoy it, right?

13
00:00:53,441 --> 00:00:57,240
Speaker 0: Because we have very little control over that situation right now.

14
00:00:57,580 --> 00:00:57,937
Speaker 0: What was that?

15
00:00:58,300 --> 00:01:00,920
Speaker 0: When I see another Discord, I already vote.

16
00:01:01,721 --> 00:01:06,940
Speaker 1: Well, I guess you don't have too many opening bits when, uh, you know, we're just sitting inside working all day.

17
00:01:07,147 --> 00:01:07,320
Speaker 1: Right.

18
00:01:07,500 --> 00:01:11,860
Speaker 1: On weekdays, uh, and we do show, doing shows more often so there's no stockpiles.

19
00:01:12,300 --> 00:01:12,920
Speaker 0: Yup, back to normal.

20
00:01:13,100 --> 00:01:17,900
Speaker 0: I didn't bike to work, uh, yesterday so I didn't, uh, encounter any funny Manhattan situations.

21
00:01:18,180 --> 00:01:21,140
Speaker 1: I haven't biked to work in, like, years because there's no work to bike to work.

22
00:01:22,401 --> 00:01:26,160
Speaker 1: I wouldn't mind a bike to work, just, you know, the work part I would, I mind.

23
00:01:27,580 --> 00:01:27,664
Speaker 1: Yeah.

24
00:01:27,960 --> 00:01:28,163
Speaker 1: Um, yeah.

25
00:01:29,300 --> 00:01:41,960
Speaker 1: So, uh, here's a really big news, uh, that I think basically the news is not reporting on because there are other, I guess, sexier news is to report on even though I think this one is, uh, a, a positive news.

26
00:01:42,020 --> 00:01:44,080
Speaker 1: I guess positive news is don't get clicks, right?

27
00:01:44,164 --> 00:01:44,289
Speaker 1: Yup.

28
00:01:44,540 --> 00:01:51,200
Speaker 1: And, uh, and also not going to impress or, you know, people won't understand how big a deal it is.

29
00:01:51,340 --> 00:02:09,520
Speaker 1: But we all know that I have often and still do criticize the many rich people, Bill Gates foremost among them, right, who had billions of dollars and have chosen to make their primary charitable, I guess, endeavor, uh, trying to fight malaria.

30
00:02:09,740 --> 00:02:11,800
Speaker 1: Now, obviously, malaria is bad.

31
00:02:11,961 --> 00:02:13,639
Speaker 1: I'm not saying, like, don't fight it, right?

32
00:02:14,141 --> 00:02:21,200
Speaker 1: But my personal opinion is that a, uh, cars kill more people than malaria, right?

33
00:02:21,400 --> 00:02:26,840
Speaker 1: Cars, in terms of people just getting hit by cars, it's like one to two million people per year.

34
00:02:26,920 --> 00:02:30,200
Speaker 1: And that doesn't include all the other ways cars kill people, right?

35
00:02:30,320 --> 00:02:37,560
Speaker 0: Oh, it's actually, so for once, not only, this isn't even hyperbole, uh, because a couple of news organizations have covered this over the last few years.

36
00:02:38,280 --> 00:02:44,740
Speaker 0: Cars, car crashes alone kill more people than malaria, HIV, and tuberculosis combined.

37
00:02:45,400 --> 00:02:52,500
Speaker 1: Right, but there's no way Bill Gates is going to fight cars with his money because that dude has a giant garage full of porches, right?

38
00:02:52,820 --> 00:02:53,866
Speaker 1: It's not going to happen, right?

39
00:02:53,886 --> 00:02:56,420
Speaker 1: He's not even thinking of that on his hit list, right?

40
00:02:56,761 --> 00:03:13,759
Speaker 1: And two, my other opinion, and this is just an opinion you may agree or not, right, is that in my view, if you're mad wealthy and you want to make positive change in the world, your best bet is to do what the evil Republican rich people do, and that's bribe the U.S.

41
00:03:13,779 --> 00:03:14,080
Speaker 1: government.

42
00:03:14,200 --> 00:03:17,170
Speaker 1: Because even if you're a billionaire, the U.S.

43
00:03:17,210 --> 00:03:20,360
Speaker 1: government is a multi-trillionaire, right?

44
00:03:20,400 --> 00:03:21,343
Speaker 0: Well, also, the U.S.

45
00:03:21,363 --> 00:03:25,959
Speaker 0: government has two things that even the rich, all the richest people in the world combined do not have.

46
00:03:27,020 --> 00:03:29,265
Speaker 0: Well, but the military, I guess I wanted to highlight a point.

47
00:03:29,345 --> 00:03:37,420
Speaker 0: It's not just the military, because yes, as evil and dangerous as Megacorps are in the year 2023, Amazon does not have an aircraft carrier.

48
00:03:38,100 --> 00:03:38,354
Speaker 1: Not yet.

49
00:03:38,801 --> 00:03:46,836
Speaker 0: But I guess, yeah, sadly, but I guess the real power of something like the U.S.

50
00:03:46,877 --> 00:03:48,640
Speaker 0: military is not that it can kill people.

51
00:03:48,940 --> 00:03:58,740
Speaker 0: Like, that's like, what you need to really understand is that the United States military is the most advanced logistical system the world has ever seen.

52
00:03:59,301 --> 00:04:13,100
Speaker 0: Like, if there is a disaster and you needed to get food aid or evacuate people or do the kinds of things you often need to do in the world, there is literally no organization on earth better equipped to do literally anything anywhere than the United States military.

53
00:04:13,501 --> 00:04:21,640
Speaker 1: Right, but the point is, is that if you can influence the United States government to do positive things, that becomes a force multiplier, right?

54
00:04:21,740 --> 00:04:24,989
Speaker 1: A trillion is a thousand billions, right?

55
00:04:25,470 --> 00:04:26,373
Speaker 1: And the U.S.

56
00:04:26,393 --> 00:04:29,040
Speaker 1: government is multi-trillion dollar, right?

57
00:04:29,180 --> 00:04:35,440
Speaker 1: So, if you can use mere billions, mere billions, billions, right, with a B, mere, right?

58
00:04:35,520 --> 00:04:38,889
Speaker 1: If you can use that to influence and get the U.S.

59
00:04:38,909 --> 00:04:52,480
Speaker 1: government to change its policies in a positive way, you have basically can cause thousand times more your investment, right, in terms of what you want to happen in the world, right?

60
00:04:52,560 --> 00:05:02,940
Speaker 1: So, that's my criticism, but those two uses aside of billions of dollars, right, fighting malaria is still way up on the list.

61
00:05:02,980 --> 00:05:05,980
Speaker 1: We're talking top ten things to spend money on, right?

62
00:05:06,701 --> 00:05:12,800
Speaker 1: The number of people killed by malaria each year in the world is like between half a million and a million, right?

63
00:05:13,220 --> 00:05:25,820
Speaker 1: It kills a shit ton of people, and not only that, as the climate change is happening, the mosquitoes expand their territory, and the malaria is going to kill more people, right?

64
00:05:26,360 --> 00:05:29,426
Speaker 1: So, fighting malaria, it's up there.

65
00:05:29,627 --> 00:05:35,799
Speaker 1: It's not, he could do better, and that's why my criticism is there, in case anyone has heard me criticize on a previous podcast.

66
00:05:36,651 --> 00:05:36,919
Speaker 0: More.

67
00:05:38,000 --> 00:05:46,276
Speaker 1: You could, yeah, sure, but regardless, fighting malaria, really good, right, in terms of the overall picture.

68
00:05:46,296 --> 00:05:48,540
Speaker 1: There's a lot worse things you could do, for sure.

69
00:05:48,901 --> 00:05:50,199
Speaker 0: Like buy Twitter and destroy it.

70
00:05:51,521 --> 00:05:55,640
Speaker 1: Yeah, right, that's completely useless compared to fighting malaria, right?

71
00:05:55,720 --> 00:06:04,820
Speaker 1: So, anyway, in the fight against malaria, there has been a revolutionary event, right?

72
00:06:05,442 --> 00:06:11,120
Speaker 1: They have a vaccine, and I guess there have been vaccines before, and there will be different ones in the future.

73
00:06:11,340 --> 00:06:16,320
Speaker 0: There's a lot of reasons why it's very hard to make a vaccine for malaria compared to a lot of other things.

74
00:06:16,560 --> 00:06:20,519
Speaker 1: 'Cause malaria is a motherfucker, right, compared to those other viruses, right, you know?

75
00:06:21,880 --> 00:06:33,316
Speaker 1: But they have a vaccine for malaria, and in the pilots and the tests that they have done, right, it has cut the deaths among children by 13% over four years.

76
00:06:36,401 --> 00:06:38,065
Speaker 1: And you think, well, that's a small percentage.

77
00:06:38,486 --> 00:06:40,269
Speaker 1: It's like 13% times, what, like 600,000, right?

78
00:06:40,269 --> 00:06:48,086
Speaker 1: 600,000 times .13, that's saving 78,000 people a year, right?

79
00:06:54,340 --> 00:07:00,599
Speaker 0: I mean, even if it was 10%, and there's 10 kids, it just saved a kid in a room of 10 kids.

80
00:07:01,621 --> 00:07:01,882
Speaker 1: Sure.

81
00:07:02,223 --> 00:07:14,147
Speaker 1: So, but the point is that that 13%, and that's deployed over a small group that they tested on, if you deployed this vaccine, even in its imperfect,

82
00:07:14,648 --> 00:07:16,532
Speaker 0: flawed,

83
00:07:16,912 --> 00:07:36,157
Speaker 1: not super effective, just somewhat good effective vaccine, widely, to the people of the world who are threatened by malaria, right, you will basically revolutionize those areas of the world, because so many less people will just die prematurely and unnecessarily, right?

84
00:07:37,520 --> 00:07:50,719
Speaker 1: The economies, the cultures, just everything going on in those parts of the world will be dramatically changed if you can deploy this vaccine, which I think they're probably going to do.

85
00:07:51,200 --> 00:08:06,740
Speaker 0: Yeah, and this vaccine has a 36% efficacy rate in the current clinical trials, so there's more ground we can cover as well, but this leads into something we talk about a lot on Geek Nights around how it's not the bleeding edge of technology that is actually saving lives.

86
00:08:06,800 --> 00:08:18,379
Speaker 0: It's taking technology we've got, however flawed, and deploying it at scale, and deploying logistics around it, using what we've already developed, and just giving it to people, or giving people access to it.

87
00:08:18,920 --> 00:08:24,600
Speaker 0: Like, clean water will save a lot of people on Earth, and we have the science to clean water.

88
00:08:24,700 --> 00:08:27,700
Speaker 0: We've had it for a very long time, we just don't use it everywhere.

89
00:08:30,483 --> 00:08:33,676
Speaker 1: So yeah, this is, I hope this works, right?

90
00:08:35,264 --> 00:08:35,352
Speaker 1: Yeah.

91
00:08:35,520 --> 00:08:41,119
Speaker 1: I want to be really interested to see, like, what happens in the malaria-ed parts of the world, right?

92
00:08:42,061 --> 00:08:44,259
Speaker 1: Over the course of the next decade or so.

93
00:08:45,000 --> 00:09:04,279
Speaker 0: Well, I remember, so there was a thing on PBS a long time ago, 2016, I dug it up because I remember reading this, and it was talking about the American South, and how there was, like, let's ignore the current political realities of the American South, and just focus on this aspect of it.

94
00:09:04,620 --> 00:09:18,136
Speaker 0: There was a long-standing cultural idea that people in the South were lazy, and lethargic, and would laze around a lot, the germ of laziness, like it was the thing that you'd see in a lot of writing.

95
00:09:19,240 --> 00:09:22,700
Speaker 1: You mean it's hot out, and they didn't have air conditioning.

96
00:09:23,380 --> 00:09:26,019
Speaker 0: Ah, so there was a bigger factor going on.

97
00:09:26,640 --> 00:09:33,500
Speaker 0: A huge percentage of people who lived in the American South for a very long time were infected with hookworms.

98
00:09:34,266 --> 00:09:35,840
Speaker 0: Which are also endemic in much of the world.

99
00:09:36,820 --> 00:09:50,420
Speaker 0: And what ended that particular, basically, like, endemic disease was aggressive treatment, education, shoes, and a couple of, like, there's a bunch of stuff happening that you can read this article to see all the details about.

100
00:09:50,500 --> 00:09:51,058
Speaker 0: I found it again.

101
00:09:51,560 --> 00:10:07,500
Speaker 0: And basically, this disease was not talked about, and yet it was very likely the primary cause of all of these cultural associations, and a significant contributor to some of the economic challenges that the area faced for a long time.

102
00:10:08,622 --> 00:10:18,780
Speaker 0: And people don't think about the extra externalities of endemic disease, especially people who have access to the internet and sit around in their houses working from home and making podcasts.

103
00:10:20,022 --> 00:10:30,180
Speaker 0: Because if you live in the United States, you very likely do not encounter, even if you are relatively poor, the kinds of endemic diseases that are in much of the rest of the world.

104
00:10:31,220 --> 00:10:40,900
Speaker 0: And the way we have made that happen could be deployed very widely, and it is not for political and economic reasons that are bullshit.

105
00:10:41,960 --> 00:10:42,040
Speaker 1: Yep.

106
00:10:42,301 --> 00:10:47,040
Speaker 1: It's like, you know, it's the same old story where we've heard about, you know, crime and lead poisoning.

107
00:10:47,520 --> 00:10:50,732
Speaker 1: It's like, you know, how true, right?

108
00:10:50,933 --> 00:10:52,298
Speaker 1: Seems to be somewhat true, right?

109
00:10:52,861 --> 00:10:54,880
Speaker 1: Go, I guess, read about it if you care.

110
00:10:55,120 --> 00:11:10,099
Speaker 1: But it's like, there are these other explanations for historical events and trends on a mass scale that are outside of anything that we could see or detect, especially in the past when we didn't have the technology that we do now.

111
00:11:11,100 --> 00:11:19,500
Speaker 1: And it's like, we seem to just, you know, tell the history of human society as, you know, just humans, you know, being how they are.

112
00:11:19,640 --> 00:11:24,700
Speaker 1: And it's like, actually, a lot of things could have been environmental things that caused it to happen.

113
00:11:24,820 --> 00:11:37,060
Speaker 1: They were just invisible environmental things, not like volcanoes and hurricanes or, you know, they were visible at the time, but it's like we had no way to know that they happened unless there's some really good geology or, you know, who knows?

114
00:11:37,562 --> 00:11:47,560
Speaker 0: Like the collapse of what the Mycenaean civilization where, yeah, all we know is around the same time, a bunch of these places all seem to have burned down and/or been abandoned, but we don't know what actually caused that.

115
00:11:48,581 --> 00:11:48,762
Speaker 1: Yeah.

116
00:11:49,083 --> 00:11:53,000
Speaker 1: But, you know, even more recent things, it's like, we know about the Black Plague.

117
00:11:53,300 --> 00:11:53,396
Speaker 1: Yeah.

118
00:11:53,680 --> 00:12:08,380
Speaker 1: It's like, but that was sort of a one that you could see even though it was a virus, but there are any, you know, diseases especially, right, that only have non-lethal, non-visible symptomatic, you know, non-visible symptoms, right?

119
00:12:08,580 --> 00:12:12,800
Speaker 1: There could be some virus that just, you know, like you said, the hookworm that makes people tired.

120
00:12:12,920 --> 00:12:15,973
Speaker 1: It's a parasite or, you know, lead poisoning.

121
00:12:16,014 --> 00:12:17,440
Speaker 1: It makes people angry and stupid.

122
00:12:17,541 --> 00:12:17,662
Speaker 1: Yeah.

123
00:12:17,702 --> 00:12:19,032
Speaker 1: So does vitamin B deficiency.

124
00:12:19,072 --> 00:12:19,959
Speaker 1: Things of that nature.

125
00:12:21,180 --> 00:12:21,601
Speaker 1: Right.

126
00:12:21,782 --> 00:12:29,240
Speaker 1: It's like, you know, there's no way, we had to do a lot of research in science to blame the correct thing.

127
00:12:29,443 --> 00:12:29,571
Speaker 1: Yeah.

128
00:12:30,060 --> 00:12:36,640
Speaker 1: Instead of, you know, people, certain people who always blame, you know, just individual responsibility on everything.

129
00:12:36,700 --> 00:12:43,700
Speaker 0: It was a great, I just watched a lecture at the Royal Institute that was talking about obesity and food and the difference between processed food.

130
00:12:43,740 --> 00:12:44,280
Speaker 1: That's another one, yeah.

131
00:12:44,982 --> 00:12:57,640
Speaker 0: But he had a really good line, I'm paraphrasing, but he basically said in the context of physical fitness and health, that personal responsibility or willpower is usually just a proxy for poverty.

132
00:12:58,461 --> 00:12:58,939
Speaker 0: That's correct.

133
00:12:59,863 --> 00:13:01,580
Speaker 0: And he went into this for a while.

134
00:13:01,980 --> 00:13:19,400
Speaker 0: And then he pulled up a really interesting statistic that showed that across, in America, across every demographic, every racial line, every cultural line, sex, gender, everything, obesity started rising at the same time for everyone, every age group, everything.

135
00:13:19,500 --> 00:13:27,159
Speaker 0: There was a year where it basically started to rise from that point, which implies that nothing anyone human did had anything to do with this.

136
00:13:28,540 --> 00:13:28,664
Speaker 1: Mm-hmm.

137
00:13:30,362 --> 00:13:34,560
Speaker 0: In some other news, there's also very good news, but in a different way.

138
00:13:35,081 --> 00:13:44,760
Speaker 0: You may remember that not that long ago, a bunch of open Nazis in something called "Unite the Right" had a torch-bearing Nazi rally.

139
00:13:45,360 --> 00:13:54,440
Speaker 0: And a lot of people tried to act like they were not in fact Nazis, but were just concerned right-wing people who were expressing their rights or whatever.

140
00:13:54,680 --> 00:14:00,760
Speaker 0: But the focal point of them and a movement around them has been around Confederate statues.

141
00:14:01,101 --> 00:14:06,600
Speaker 0: Now, we already know, if you listen to Geek Nights, you know that Confederate statues are bullshit and they're not even historical.

142
00:14:06,740 --> 00:14:10,000
Speaker 0: Most of them were built during the Civil Rights era, which tells you everything you need to know about them.

143
00:14:10,340 --> 00:14:14,280
Speaker 0: It's not like they were built right after World War II, right after the Civil War.

144
00:14:15,121 --> 00:14:16,820
Speaker 1: Even if they were, that would be weird.

145
00:14:17,560 --> 00:14:25,900
Speaker 1: Imagine, like, you know, Genghis Khan and Alexander the Great have a fight and Alexander the Great loses.

146
00:14:26,441 --> 00:14:33,860
Speaker 1: And then Genghis Khan has some Alexander the Great statues built, and they're not just like a memorial or some shit to my great opponent in an anime or something.

147
00:14:34,921 --> 00:14:38,015
Speaker 1: They're like in all these random towns all over Asia, right?

148
00:14:40,380 --> 00:14:45,980
Speaker 1: And they're built by, obviously, the people who were supporters of Alexander the Great after they got defeated.

149
00:14:46,260 --> 00:14:49,560
Speaker 1: That would be, and, you know, it's like, hmm, that's a little weird.

150
00:14:52,323 --> 00:15:06,720
Speaker 0: So there's a particularly important and famous statue of a traitor, Robert E. Lee, who, fun fact, a lot of people try to rehabilitate him by arguing that he fought for some noble reason or that he was a great general.

151
00:15:07,182 --> 00:15:08,519
Speaker 0: And neither of those things is true.

152
00:15:09,162 --> 00:15:10,240
Speaker 1: He was a stupid villain.

153
00:15:10,401 --> 00:15:10,623
Speaker 0: Yep.

154
00:15:10,904 --> 00:15:13,240
Speaker 0: He was also not even a particularly good general.

155
00:15:13,380 --> 00:15:20,840
Speaker 0: The North basically didn't want to engage with the full might of its military right away for a bunch of complicated reasons.

156
00:15:21,880 --> 00:15:27,780
Speaker 0: And his early quote victories were kind of just happenstance or the fact that the North wasn't really fighting that hard.

157
00:15:27,880 --> 00:15:39,620
Speaker 0: But anyway, so this statue became the focal point of the neo-Confederate Nazis in Charlottesville, and the government decided to take it down.

158
00:15:39,901 --> 00:15:41,309
Speaker 0: And there were a lot of threats of violence.

159
00:15:41,671 --> 00:15:43,420
Speaker 0: It was very difficult to take it down safely.

160
00:15:43,880 --> 00:15:46,640
Speaker 0: Nazis kept showing up anytime, like, people moved in to remove it.

161
00:15:47,140 --> 00:15:52,460
Speaker 0: It was moved to a secret location at one point, and over time, the news kind of forgot about it.

162
00:15:52,500 --> 00:15:53,860
Speaker 0: People stopped talking about this statue.

163
00:15:55,161 --> 00:15:58,660
Speaker 0: Just now, we now know the final fate of the statue.

164
00:15:59,220 --> 00:16:00,023
Speaker 0: Today at 3

165
00:16:00,023 --> 00:16:00,344
Speaker 0: p.m.,

166
00:16:00,805 --> 00:16:05,420
Speaker 0: the Washington Post has a bunch of video, and you can see exactly what they did to the statue.

167
00:16:05,540 --> 00:16:11,740
Speaker 0: They took it to a secret foundry that was not named because they're afraid that Nazis will attack the people who work there.

168
00:16:12,501 --> 00:16:15,571
Speaker 0: And they invited a small number of journalists and activists.

169
00:16:16,092 --> 00:16:18,440
Speaker 0: A lot of non-white people were there for reasons you can imagine.

170
00:16:19,141 --> 00:16:28,460
Speaker 0: And they videoed the extensive process of cutting this thing apart, melting it into slag, and then preparing to use it to make art in a museum for the future.

171
00:16:29,641 --> 00:16:32,620
Speaker 1: They didn't make a "Lissey says Grant statue" outfit?

172
00:16:33,121 --> 00:16:34,805
Speaker 0: That would be fantastic.

173
00:16:34,845 --> 00:16:48,320
Speaker 0: I'm not sure exactly what they're going to make out of it, but this article has extensive video of them cutting this thing apart, and a lot of very cool people making very good and correct statements about what is going on and why.

174
00:16:49,480 --> 00:16:56,357
Speaker 1: You know, that does remind me, I was thinking earlier this week, the same thing, is that in Manhattan, there is famous Grant's Tomb.

175
00:16:56,478 --> 00:16:57,340
Speaker 1: Grant's Tomb is right there.

176
00:16:58,226 --> 00:16:58,931
Speaker 1: Have I been there?

177
00:16:58,991 --> 00:17:00,280
Speaker 1: Yes, many times, actually.

178
00:17:00,923 --> 00:17:02,180
Speaker 0: Who's buried in Grant's Tomb?

179
00:17:03,041 --> 00:17:03,889
Speaker 1: There's nobody.

180
00:17:03,909 --> 00:17:04,636
Speaker 1: It's not a burial.

181
00:17:04,656 --> 00:17:05,079
Speaker 1: It's a tomb.

182
00:17:07,359 --> 00:17:13,118
Speaker 0: Oh my god, I typed "who's buried" because I was going to pull out the old reference to that, and Google recommended "in Grant's

183
00:17:13,179 --> 00:17:13,420
Speaker 0: Tomb.".

184
00:17:15,941 --> 00:17:17,646
Speaker 1: Noted New Yorker, Ulysses Grant.

185
00:17:17,685 --> 00:17:22,520
Speaker 1: Anyway, it's this little building, and it's like this park.

186
00:17:22,861 --> 00:17:27,800
Speaker 1: There's even a little playground in that area, generally speaking, but you know, it's grass and a building, right?

187
00:17:28,240 --> 00:17:29,845
Speaker 1: And I've been there many times.

188
00:17:29,906 --> 00:17:31,370
Speaker 1: I've been passed there many times.

189
00:17:31,470 --> 00:17:32,875
Speaker 1: I biked past it many times.

190
00:17:32,995 --> 00:17:34,540
Speaker 1: I could tell you exactly where the fuck it is.

191
00:17:34,660 --> 00:17:36,344
Speaker 1: I could walk there without a map, right?

192
00:17:36,565 --> 00:17:37,086
Speaker 1: And you know what?

193
00:17:37,447 --> 00:17:42,200
Speaker 1: I was thinking earlier this week, and also right now, I never went inside, not even one time.

194
00:17:42,520 --> 00:17:43,907
Speaker 0: I've never been inside.

195
00:17:44,611 --> 00:17:46,520
Speaker 0: I never thought about if you could go inside.

196
00:17:47,460 --> 00:17:50,060
Speaker 1: I think it's open if you go during the day, right?

197
00:17:50,140 --> 00:17:56,720
Speaker 0: I see a photo when I just went to a website, the National Park Service website, and it shows what looks like a bunch of people walking into it.

198
00:17:58,001 --> 00:17:59,025
Speaker 1: Yeah, it's a national park.

199
00:17:59,046 --> 00:17:59,728
Speaker 1: You can go in there.

200
00:17:59,789 --> 00:18:02,360
Speaker 1: I just have never gone in there, even though it's right there.

201
00:18:02,962 --> 00:18:03,800
Speaker 0: We should go to Grant's Tomb.

202
00:18:04,580 --> 00:18:04,982
Speaker 1: I don't know.

203
00:18:05,484 --> 00:18:08,820
Speaker 1: Can you see Grant, or is it just like, no, you just see his name or something?

204
00:18:08,880 --> 00:18:09,121
Speaker 0: I don't know.

205
00:18:09,142 --> 00:18:11,696
Speaker 0: There's no photo of the inside in this article that I just clicked on.

206
00:18:13,660 --> 00:18:13,980
Speaker 0: Alright.

207
00:18:14,461 --> 00:18:16,571
Speaker 1: I don't know, because I don't really want to see a skeleton.

208
00:18:16,933 --> 00:18:18,460
Speaker 1: It's not, you know, it's Halloween, but seriously.

209
00:18:19,181 --> 00:18:19,989
Speaker 0: Skeletons are neat.

210
00:18:20,070 --> 00:18:21,100
Speaker 0: I could see Grant's skeleton.

211
00:18:22,161 --> 00:18:23,180
Speaker 1: He was a big dude, right?

212
00:18:23,862 --> 00:18:26,399
Speaker 0: I don't actually know how tall Grant was.

213
00:18:26,720 --> 00:18:27,632
Speaker 1: I thought he was a big dude.

214
00:18:27,653 --> 00:18:27,896
Speaker 1: Let me check.

215
00:18:28,220 --> 00:18:29,480
Speaker 0: How tall was Grant?

216
00:18:31,021 --> 00:18:32,630
Speaker 0: No, he was not a big dude.

217
00:18:32,670 --> 00:18:32,911
Speaker 0: He was 5'8".

218
00:18:35,021 --> 00:18:43,460
Speaker 0: He was taller than the average adult male in the year 1860.

219
00:18:43,460 --> 00:18:44,419
Speaker 0: He was taller than me.

220
00:18:45,643 --> 00:18:47,077
Speaker 1: Yeah, he was shorter than me.

221
00:18:47,218 --> 00:18:47,440
Speaker 1: Alright.

222
00:18:50,744 --> 00:18:51,811
Speaker 1: I could have taken him.

223
00:18:52,756 --> 00:18:53,320
Speaker 1: Probably not.

224
00:18:53,921 --> 00:18:54,970
Speaker 1: I can't do one push-up.

225
00:18:55,010 --> 00:18:56,200
Speaker 1: I think Grant could do push-ups.

226
00:18:56,940 --> 00:18:57,738
Speaker 0: So, one last little news.

227
00:18:58,500 --> 00:19:02,000
Speaker 0: Now, I guess this news would be better fitting on a Tuesday, because it's about a game.

228
00:19:02,481 --> 00:19:03,379
Speaker 0: The game of ice hockey.

229
00:19:05,242 --> 00:19:29,420
Speaker 0: A thing that happened in hockey recently is, for bigoted reasons, and the fact that no major capitalist organization wants to engage with what it perceives to be culture wars, because they don't want to deal with the assumed hassle, the NHL basically made this kind of bullshitty policy that effectively said players shouldn't put rainbow pride tape on their sticks during warm-ups.

230
00:19:29,920 --> 00:19:30,021
Speaker 1: Right.

231
00:19:30,041 --> 00:19:35,780
Speaker 1: Well, I mean, the whole policy was basically, it's like they just quietly, right, just sort of sent out a memo.

232
00:19:36,403 --> 00:19:38,339
Speaker 1: And the thing is, it doesn't bother me.

233
00:19:38,621 --> 00:19:41,380
Speaker 1: I mean, it does bother me that they have this wrong, stupid policy.

234
00:19:42,141 --> 00:19:48,420
Speaker 1: But the thing that bothers me more is that you don't have the guts to explain yourself, right?

235
00:19:48,700 --> 00:19:51,020
Speaker 1: It's like defend what your policy is.

236
00:19:51,160 --> 00:19:57,056
Speaker 1: It's like if someone comes out and is like, "I want to kill all the poor people, and here's

237
00:19:57,137 --> 00:19:57,599
Speaker 1: why.".

238
00:19:57,840 --> 00:20:00,652
Speaker 1: And it's like, "Alright, you're a right-wing nutjob.

239
00:20:01,034 --> 00:20:01,637
Speaker 1: I don't like you.

240
00:20:01,857 --> 00:20:02,360
Speaker 1: You're bad.

241
00:20:02,840 --> 00:20:07,460
Speaker 1: But at least I can't, you know, it's like you are who you are, right?

242
00:20:07,480 --> 00:20:08,153
Speaker 1: You're being true to

243
00:20:08,194 --> 00:20:08,500
Speaker 1: yourself.".

244
00:20:09,060 --> 00:20:28,018
Speaker 1: If someone comes out and is like, "No players may do, wear, or display anything on the ice to support any cause, no individuality whatsoever, including specifically calling out the pride tape, which is the main

245
00:20:28,198 --> 00:20:28,299
Speaker 1: one."

246
00:20:28,860 --> 00:20:32,750
Speaker 1: And it's like, "Alright, do you have a reason?

247
00:20:32,910 --> 00:20:34,234
Speaker 1: Why?

248
00:20:34,956 --> 00:20:35,998
Speaker 1: We're not going to say.

249
00:20:36,058 --> 00:20:36,219
Speaker 1: No

250
00:20:36,279 --> 00:20:36,680
Speaker 1: comment."

251
00:20:36,782 --> 00:20:37,455
Speaker 1: It's like, "Well...".

252
00:20:39,183 --> 00:20:50,193
Speaker 0: We have a lot of additional information where it's pretty obvious what the reasons were in that it mostly seems like it came down to certain unnamed players on.

253
00:20:50,273 --> 00:20:58,040
Speaker 0: certain teams are bigoted assholes and did not want to do it, but also didn't want...

254
00:20:58,081 --> 00:20:59,539
Speaker 1: Well, that was the jerseys last year.

255
00:20:59,980 --> 00:21:05,380
Speaker 1: But the tape, the new rule this year, there was no whys or wherefores.

256
00:21:06,385 --> 00:21:09,480
Speaker 0: I'm pretty sure it has to do with these players who are assholes.

257
00:21:10,080 --> 00:21:11,250
Speaker 0: One, don't want to let that...

258
00:21:13,281 --> 00:21:14,330
Speaker 1: It came from the owners.

259
00:21:14,411 --> 00:21:15,420
Speaker 1: It didn't come from the players.

260
00:21:15,700 --> 00:21:19,360
Speaker 0: Well, I think the owners are probably worried about the sensibility of specific individual players.

261
00:21:19,380 --> 00:21:22,178
Speaker 1: Well, the owners are just 32 different billionaire assholes, right?

262
00:21:22,238 --> 00:21:22,520
Speaker 1: Anyway.

263
00:21:23,622 --> 00:21:28,760
Speaker 0: But I guess if a whole team does it and one person on the team doesn't, well, we know who the asshole is.

264
00:21:29,100 --> 00:21:30,000
Speaker 0: And I don't think... Yeah, good.

265
00:21:30,440 --> 00:21:32,038
Speaker 0: Yeah, but the assholes don't want that.

266
00:21:32,601 --> 00:21:37,880
Speaker 0: So a player on the Arizona Coyotes, Travis Dermott, just said fuck it.

267
00:21:38,720 --> 00:21:42,140
Speaker 1: So people who aren't hockey people, you got to know Travis Dermott, right?

268
00:21:42,560 --> 00:21:44,130
Speaker 1: This guy is an NHL player.

269
00:21:44,171 --> 00:21:45,660
Speaker 1: He's in the NHL, right?

270
00:21:46,040 --> 00:21:51,874
Speaker 1: But he is not like an always NHL player.

271
00:21:51,914 --> 00:21:54,320
Speaker 1: This is one of those guys who's like spending AHL time.

272
00:21:54,400 --> 00:21:56,020
Speaker 1: He's a borderline guy, right?

273
00:21:56,441 --> 00:22:01,720
Speaker 1: So he actually has, on the one hand, he's got more to lose, right?

274
00:22:01,800 --> 00:22:06,520
Speaker 1: Because if you're sent down to the AHL, the money you make significantly decreases, right?

275
00:22:06,960 --> 00:22:12,420
Speaker 1: A fine, if he's fined, he doesn't make a zillion dollars, right?

276
00:22:12,500 --> 00:22:13,730
Speaker 1: Like the top players.

277
00:22:13,770 --> 00:22:14,919
Speaker 1: He gets paid way less.

278
00:22:16,101 --> 00:22:21,460
Speaker 1: Let's go to Cap Friendly and see how much money Travis Dermott gets.

279
00:22:22,104 --> 00:22:29,900
Speaker 0: And even though it's going to sound like a lot because it's professional sports, you have to understand that you can't keep playing that sport past like 30.

280
00:22:29,900 --> 00:22:35,659
Speaker 1: Travis Dermott has basically the league minimum $800,000 contract and he's a UFA at the end of this season.

281
00:22:36,040 --> 00:22:44,358
Speaker 1: So basically, you know, it's like he's in the weakest position and basically an NHL player can be in, right?

282
00:22:45,161 --> 00:22:47,720
Speaker 1: And other players, to their credit, right?

283
00:22:47,780 --> 00:22:55,660
Speaker 1: Including like the top player, like, you know, Connor McDavid did say things about this policy, you know, saying it's stupid, whatever.

284
00:22:56,282 --> 00:22:58,519
Speaker 1: But only Travis Dermott, who had everything to lose.

285
00:22:59,020 --> 00:23:04,400
Speaker 1: And, you know, this cause of, you know, of LGBT issues was important to him, right?

286
00:23:04,783 --> 00:23:06,099
Speaker 1: And has been for some time.

287
00:23:06,761 --> 00:23:15,000
Speaker 1: He was the only one to actually have the guts to put a little piece of tape with some colors on it on his stick during a real hockey game.

288
00:23:15,201 --> 00:23:19,911
Speaker 0: He didn't do the trolly type thing you could have done of, it's just, it's a rainbow.

289
00:23:19,931 --> 00:23:21,000
Speaker 0: What are you going to find me over it?

290
00:23:21,160 --> 00:23:23,573
Speaker 0: No, he was very vocal about why he did it.

291
00:23:24,076 --> 00:23:24,779
Speaker 0: He just did it.

292
00:23:25,081 --> 00:23:26,332
Speaker 0: He basically said, bring it.

293
00:23:26,352 --> 00:23:26,998
Speaker 0: What are you going to do?

294
00:23:27,401 --> 00:23:30,260
Speaker 0: Because now this was brave and powerful.

295
00:23:30,460 --> 00:23:33,820
Speaker 0: This forced the NHL to, and all these billionaires.

296
00:23:34,120 --> 00:23:37,880
Speaker 1: Look at this, one little guy, like this no name guy, right?

297
00:23:38,080 --> 00:23:40,660
Speaker 1: Puts a little piece of tape on the stick, right?

298
00:23:40,902 --> 00:23:42,015
Speaker 1: And they asked the NHL, right?

299
00:23:42,640 --> 00:23:46,720
Speaker 1: The reporters who are basically all, every NHL reporter that I've heard, right?

300
00:23:46,780 --> 00:23:52,280
Speaker 1: It's like, there must not be any right wing NHL reporters, or at least not any open their mouth.

301
00:23:52,320 --> 00:23:56,640
Speaker 1: Because literally every single NHL writer from teams all over, right?

302
00:23:57,140 --> 00:24:01,580
Speaker 1: Even teams that are in like, you know, places you would think are not left wing.

303
00:24:01,861 --> 00:24:04,400
Speaker 1: Were like, they were against, they wanted the tape.

304
00:24:04,660 --> 00:24:07,840
Speaker 1: They were called, they were bashing the NHL big time, right?

305
00:24:09,220 --> 00:24:17,572
Speaker 1: But one dude puts a little piece of tape on his stick, who's a nobody in the league basically, and the NHL immediately folds.

306
00:24:17,773 --> 00:24:19,040
Speaker 1: They're like, all right, you can do it.

307
00:24:19,440 --> 00:24:21,979
Speaker 0: They folded so fast and you can see why.

308
00:24:22,160 --> 00:24:22,939
Speaker 1: They're like, all right, you can do it.

309
00:24:23,642 --> 00:24:32,800
Speaker 0: Because think about it, you put them in a position now, if instead of their cowardly nonstatement originally, like this cowardly policy that's obscuring all the reasons and everything.

310
00:24:32,960 --> 00:24:37,040
Speaker 1: But again, they folded, which is the right call, again with no explanation.

311
00:24:37,702 --> 00:24:42,940
Speaker 1: No guts to say why you're doing what you're doing or defend what you're doing.

312
00:24:43,040 --> 00:24:44,920
Speaker 1: You just say, this is what I'm doing.

313
00:24:45,281 --> 00:24:46,558
Speaker 1: This is what our policy is.

314
00:24:47,140 --> 00:24:54,040
Speaker 1: No, not even one shred of courage to be willing to say why you made those decisions that you did.

315
00:24:54,380 --> 00:24:55,200
Speaker 0: And think about how it worked.

316
00:24:55,460 --> 00:24:57,800
Speaker 0: The NHL now to respond to him, what could they have done?

317
00:24:57,860 --> 00:25:02,180
Speaker 0: They could have won, fucked over the little guy, and then they'd have to say why.

318
00:25:02,462 --> 00:25:04,219
Speaker 0: And if they didn't, it would still be obvious why.

319
00:25:04,661 --> 00:25:11,280
Speaker 0: And if the story is, player fined by NHL for expressing pro-LGBT.

320
00:25:11,882 --> 00:25:14,140
Speaker 1: Other people were going to pay his fine if he got fined.

321
00:25:15,061 --> 00:25:16,399
Speaker 1: That's besides the point.

322
00:25:16,480 --> 00:25:20,498
Speaker 0: But the media circus and the scrutiny the NHL would have been under if they got after him.

323
00:25:22,963 --> 00:25:25,620
Speaker 0: Any institution like this will always take the coward's path.

324
00:25:26,020 --> 00:25:32,039
Speaker 0: So the coward's path in this situation is to say almost nothing and just stop enforcing the thing you didn't say anything about the first time.

325
00:25:33,623 --> 00:25:45,579
Speaker 0: So if you're ever in a situation where you have an enemy who is a coward and you think the coward's path will get what you wanted anyway, try to force them into the coward's path.

326
00:25:46,200 --> 00:25:54,260
Speaker 0: And two, never lose sight of the fact that one person taking a stand often can have a huge impact in situations.

327
00:25:54,440 --> 00:25:57,920
Speaker 0: Partly because almost no one is ever willing to take that stand.

328
00:25:58,121 --> 00:26:04,257
Speaker 0: You need at least one person to take a stand openly and risk those consequences and actually just go for it.

329
00:26:05,000 --> 00:26:22,220
Speaker 1: And also, if you had any suspicions that all of the corporate entities who were, I guess we can call it rainbow washing, who are doing pride events or any other cause when any corporation acts like they're supporting some cause.

330
00:26:23,543 --> 00:26:26,540
Speaker 1: And you think it might not be genuine, but at least it helps.

331
00:26:27,223 --> 00:26:29,855
Speaker 1: It's like here's the confirmation you needed.

332
00:26:30,096 --> 00:26:30,920
Speaker 1: It's not genuine.

333
00:26:31,240 --> 00:26:32,399
Speaker 1: You know that it's not.

334
00:26:32,700 --> 00:26:42,880
Speaker 1: It's like if they're supporting, there's a capitalist motivation behind it unless proven otherwise with some actual meaningful gutsy actions.

335
00:26:43,480 --> 00:26:50,492
Speaker 1: When they say hockey is for everyone, what they're really saying is please don't hate hockey.

336
00:26:50,532 --> 00:26:56,880
Speaker 1: We need the biggest audience we can and we don't want to shun any, we don't want to make any possible customers feel unwelcome.

337
00:26:57,140 --> 00:27:00,720
Speaker 0: Yeah, translate that hockey is for everyone, mostly means to the NHL.

338
00:27:01,180 --> 00:27:03,340
Speaker 0: We want to make sure the right wing nut jobs keep watching.

339
00:27:04,100 --> 00:27:05,788
Speaker 1: Right, but do we actually support you?

340
00:27:06,070 --> 00:27:13,739
Speaker 1: Will we actually stand up for you and lay down, you know, make a sacrifice to support your cause or lay ourselves down on the line for you?

341
00:27:14,403 --> 00:27:15,700
Speaker 1: No, because we don't actually care.

342
00:27:15,780 --> 00:27:18,920
Speaker 1: We just want to make sure that we keep as the maximum number of customers as possible.

343
00:27:18,920 --> 00:27:23,500
Speaker 0: Well, this is too why I treat rainbow washing as something different.

344
00:27:24,040 --> 00:27:44,460
Speaker 0: What I use it as primarily, it's almost like a bellwether or a windsock about the actual sentiment of what's going on in regard to capital and LGBT rights in that if society is opening, then the companies will do whatever they think is on the side of the money.

345
00:27:44,922 --> 00:27:45,986
Speaker 0: So it's a good sign.

346
00:27:46,227 --> 00:27:58,790
Speaker 0: when more companies are willing to take that extreme, even if it's a purely selfish "stand" and they're just doing it for promotional purposes, it means that the bean counters and lawyers have decided.

347
00:27:58,810 --> 00:28:04,800
Speaker 0: the money in society is on this side of that issue, which means that we're slowly winning the fight in society.

348
00:28:05,342 --> 00:28:18,598
Speaker 0: And it's worrying that a number of major companies, including Disney just recently, have started to back off because they're afraid of backlash from the right wing because that backlash has been growing rapidly just over the last year.

349
00:28:20,641 --> 00:28:20,862
Speaker 1: Yeah.

350
00:28:21,504 --> 00:28:45,728
Speaker 1: I think the other problem is that while on the one hand you can see the capitalist companies, in the United States at least, go against or for the way the government goes because it's like the money, despite capitalism being bullshit, is still somewhat democratic in terms of the number of people.

351
00:28:45,929 --> 00:29:00,673
Speaker 1: If the majority of the people in the United States support a thing and the dollar votes go to that thing, it's like, yeah, so companies will go in that direction, but yet the federal government especially is undemocratic.

352
00:29:00,934 --> 00:29:05,227
Speaker 1: It doesn't reflect the popular vote and therefore you can see the mismatch.

353
00:29:05,508 --> 00:29:29,500
Speaker 1: But if you see the companies more fearful of actions the government will take, then how people will vote with their dollars, you could see the companies go away from what's popular among the people because the government harm might hurt their bottom line with policies more than the loss of customers.

354
00:29:34,688 --> 00:29:37,974
Speaker 0: So anyway, things of the day.

355
00:29:38,334 --> 00:29:45,451
Speaker 0: So this is actually an extremely well done video and it's called Nothing's Working Out, Waluigi.

356
00:29:45,992 --> 00:30:05,594
Speaker 0: It's a full length song and a very well animated, extremely stylish, professional looking music video and the song seems to be about someone whose life just isn't working out and it's all about Waluigi and his life just not working out.

357
00:30:05,714 --> 00:30:07,680
Speaker 0: It's super well done.

358
00:30:08,360 --> 00:30:13,460
Speaker 0: So I dug a little deeper to see what the deal was and it seems like it's just original fan animation straight up.

359
00:30:13,940 --> 00:30:15,205
Speaker 0: It's not even one of those.

360
00:30:15,487 --> 00:30:18,460
Speaker 0: take an anime opener or something else and just sort of reanimate it.

361
00:30:18,860 --> 00:30:20,324
Speaker 0: It seems like it's completely original.

362
00:30:20,845 --> 00:30:35,980
Speaker 0: The song that is used is from a band in Japan, Meiyo, and they have an animated music video, but the music video they have is not the same as the Waluigi one.

363
00:30:36,380 --> 00:30:42,240
Speaker 0: The Waluigi one is basically completely original animation that has only a few aesthetic references to the original video.

364
00:30:42,600 --> 00:30:47,459
Speaker 0: The original video is also great and the song is great, but this Waluigi video just stands out to me.

365
00:30:48,700 --> 00:30:49,836
Speaker 1: Oh, getting complicated.

366
00:30:49,857 --> 00:30:50,080
Speaker 1: Alright.

367
00:30:50,621 --> 00:30:52,426
Speaker 0: Oh, there's a further rabbit hole.

368
00:30:52,727 --> 00:30:58,020
Speaker 0: There's a women's version of the song as well from the same band that has its own animated music video.

369
00:30:59,120 --> 00:30:59,209
Speaker 1: Okay.

370
00:31:01,061 --> 00:31:02,773
Speaker 0: But yeah, you want to see sexy Waluigi?

371
00:31:02,914 --> 00:31:03,357
Speaker 0: Here we go.

372
00:31:06,260 --> 00:31:13,480
Speaker 1: So, lately I've been rearranging my internet reading situation, especially with the death of all social things basically.

373
00:31:14,720 --> 00:31:19,840
Speaker 1: And I was thinking about old newspapers and there's been this conglomeration of things that have happened.

374
00:31:20,280 --> 00:31:35,519
Speaker 1: One thing that happened is the New Yorker wrote a review and I was reminded that the Bill Watterson book that we talked about a hundred years ago, the little story book called The Mysteries that he did with John Cash, it finally came out like sixteen days ago.

375
00:31:42,920 --> 00:31:43,169
Speaker 1: Oh.

376
00:31:43,480 --> 00:31:44,763
Speaker 1: I've been reading so many web comics.

377
00:31:45,184 --> 00:31:51,140
Speaker 1: It's like the newspaper, I'm trying to basically reorganize all my reading biz.

378
00:31:51,580 --> 00:31:56,590
Speaker 1: It's like newspapers always used to have funny bits and it's like now.

379
00:31:56,690 --> 00:32:01,600
Speaker 1: people are reading news and there's no funny bits mixed in unless it's the New Yorker.

380
00:32:02,001 --> 00:32:04,084
Speaker 1: So it has comics on everything, right?

381
00:32:04,525 --> 00:32:11,216
Speaker 1: And it's like, hey, I should try to basically incorporate into my internet reading.

382
00:32:11,256 --> 00:32:13,660
Speaker 1: I should try to bring back the comics going on.

383
00:32:15,402 --> 00:32:19,760
Speaker 1: And another thing the newspapers had, right along with the comics, is the puzzle action.

384
00:32:20,861 --> 00:32:27,718
Speaker 1: So I've actually been using the New York Puzzly app, which basically the crossword, I'm not huge on crossword.

385
00:32:27,758 --> 00:32:28,500
Speaker 1: I'm really bad at them.

386
00:32:28,580 --> 00:32:30,484
Speaker 1: I can't even do them past like Wednesday.

387
00:32:30,504 --> 00:32:32,046
Speaker 1: Sometimes not even Wednesday.

388
00:32:33,529 --> 00:32:46,514
Speaker 1: But regardless, it's like they have added all these other puzzles to the New York Times puzzle app, including, you know, the wordle obviously, but they got this connections one that's really hot and the spelling bee one.

389
00:32:46,534 --> 00:32:48,058
Speaker 1: I like the spelling bee one a lot.

390
00:32:48,098 --> 00:32:49,100
Speaker 1: That's like my top one.

391
00:32:51,521 --> 00:32:53,605
Speaker 1: So what's happened is Zach Gage.

392
00:32:53,705 --> 00:33:01,200
Speaker 1: You may know Zach Gage because I think he worked at like for some other people making other games.

393
00:33:01,280 --> 00:33:05,268
Speaker 1: You might know, like I think he had a hand in the ridiculous fishing, even though that wasn't his main.

394
00:33:05,549 --> 00:33:06,691
Speaker 1: He wasn't the main guy on it.

395
00:33:07,172 --> 00:33:10,980
Speaker 1: But Spell Tower, you may have heard of the really bad chess.

396
00:33:11,060 --> 00:33:11,782
Speaker 1: You may have heard of.

397
00:33:11,902 --> 00:33:12,223
Speaker 1: Right.

398
00:33:12,845 --> 00:33:14,048
Speaker 1: So Zach Gage is.

399
00:33:14,188 --> 00:33:18,840
Speaker 1: latest thing is this thing called Puzmo and it's you can go to Puzmo dot com.

400
00:33:19,601 --> 00:33:28,660
Speaker 1: And what they're trying to do is they're trying to basically recreate, you know, basically it's going to be a competitor for that New York Times puzzle game app.

401
00:33:28,980 --> 00:33:29,241
Speaker 1: Right.

402
00:33:29,261 --> 00:33:32,366
Speaker 1: It's like daily puzzle action going on.

403
00:33:32,626 --> 00:33:32,867
Speaker 1: Right.

404
00:33:33,347 --> 00:33:41,320
Speaker 1: And so what they've done is every day they're going to mail out five hundred keys to people to get into Puzmo.

405
00:33:41,500 --> 00:33:42,883
Speaker 1: It's not open to the world yet.

406
00:33:43,684 --> 00:33:45,888
Speaker 1: So how do you get one of the five hundred keys?

407
00:33:45,988 --> 00:33:52,320
Speaker 1: Well, if you sign up to the mailing list, they email you the moment the daily puzzle goes live.

408
00:33:52,380 --> 00:33:54,844
Speaker 1: They got one puzzle that you don't have to log in to play.

409
00:33:55,645 --> 00:34:05,340
Speaker 1: And if you're one of the first five hundred people to solve that puzzle, then you can mail you a key in the snail mail to get into Puzmo.

410
00:34:06,100 --> 00:34:06,681
Speaker 1: Right.

411
00:34:07,383 --> 00:34:12,815
Speaker 1: So the first day that I noticed this Puzmo, there was a chess puzzle and five hundred people already solved it.

412
00:34:13,097 --> 00:34:14,560
Speaker 1: And I suck at chess puzzles anyway.

413
00:34:14,719 --> 00:34:17,628
Speaker 0: I just did today's puzzle while you were talking because it was not I did yesterday.

414
00:34:18,150 --> 00:34:18,411
Speaker 1: Yeah.

415
00:34:18,471 --> 00:34:19,534
Speaker 1: But that was an easy one.

416
00:34:19,574 --> 00:34:19,714
Speaker 1: Right.

417
00:34:19,754 --> 00:34:21,620
Speaker 1: But I did yesterday's puzzle.

418
00:34:22,681 --> 00:34:25,405
Speaker 1: And I was one of the first five hundred to do it.

419
00:34:25,425 --> 00:34:29,610
Speaker 1: So I'm going to get in the mail a key to get into Puzmo.

420
00:34:30,132 --> 00:34:31,654
Speaker 1: And I guess, Rim, you can.

421
00:34:31,975 --> 00:34:35,820
Speaker 1: if you put your email address in and you're fast tomorrow, you might be able to get a key.

422
00:34:36,000 --> 00:34:37,322
Speaker 0: I should try to be fast tomorrow.

423
00:34:38,304 --> 00:34:39,186
Speaker 1: Yeah.

424
00:34:39,505 --> 00:34:47,460
Speaker 1: But yeah, Puzmo I think is going to be hopefully a good addition to the daily, you know, daily biz.

425
00:34:48,420 --> 00:34:48,983
Speaker 1: So check out.

426
00:34:49,163 --> 00:34:52,714
Speaker 1: And if you if you if you're not fast, at least you're still getting one puzzle every day.

427
00:34:52,734 --> 00:34:53,176
Speaker 1: So, you know.

428
00:34:55,260 --> 00:34:58,166
Speaker 0: In the meta moment, the Geek Nights Book Club book, The Murderbot Diaries.

429
00:34:58,426 --> 00:35:05,120
Speaker 0: I am like 80 percent through the last of the currently published Murderbot diaries that I have access to.

430
00:35:06,561 --> 00:35:08,929
Speaker 0: And when the new one comes out, as we've said, we're going to do the show.

431
00:35:08,969 --> 00:35:12,280
Speaker 0: We'll give you a couple of few weeks to read more Murderbot.

432
00:35:12,541 --> 00:35:15,770
Speaker 0: But we're going to talk about the whole Murderbot series when we do.

433
00:35:15,810 --> 00:35:17,916
Speaker 1: the next Murderbot book is one of the small ones.

434
00:35:17,936 --> 00:35:19,320
Speaker 1: I'm going to read it in like a sitting.

435
00:35:19,680 --> 00:35:22,547
Speaker 0: Yeah, the Murderbot books are real fast reads.

436
00:35:22,828 --> 00:35:28,180
Speaker 0: And I guess the only thing I'll say now, because it couldn't be further from from Taylor Genji, the Murderbot.

437
00:35:28,480 --> 00:35:29,061
Speaker 1: Right.

438
00:35:29,081 --> 00:35:41,640
Speaker 0: It's a they were refreshing science fiction to read in that they take a straight line toward the interesting aspects of the science fiction concepts they are dealing with.

439
00:35:42,483 --> 00:35:44,831
Speaker 0: And they just kind of shine on them directly.

440
00:35:44,872 --> 00:35:47,200
Speaker 0: But also the characters are kind of delightful.

441
00:35:47,921 --> 00:35:54,780
Speaker 0: And I have the exact opposite opinion of the listener who said that as soon as the books got long, they got tedious and there's just one long book.

442
00:35:55,140 --> 00:35:56,406
Speaker 1: Just one of them is long.

443
00:35:56,486 --> 00:35:58,656
Speaker 0: But I love the human characters.

444
00:35:58,696 --> 00:35:59,500
Speaker 0: They're all great.

445
00:36:00,141 --> 00:36:08,720
Speaker 0: I love how Murderbot has these weird opinions of all the different human characters and like secretly kind of idolizes one of them is annoyed by one of them.

446
00:36:08,860 --> 00:36:14,380
Speaker 0: And the whole thing with the kid and the fourth book, fifth book, fifth book, the teenager.

447
00:36:15,421 --> 00:36:16,723
Speaker 1: Our new Web site is up.

448
00:36:17,545 --> 00:36:18,226
Speaker 1: It is live.

449
00:36:18,286 --> 00:36:19,108
Speaker 1: It is functioning.

450
00:36:19,549 --> 00:36:25,500
Speaker 1: But it is still in the process of continuous and forever improvement for as long as Geek Nights exists.

451
00:36:26,180 --> 00:36:27,745
Speaker 1: So, you know, check it out.

452
00:36:28,106 --> 00:36:32,439
Speaker 1: Use it for what you need to use it for or don't use it because something else satisfies you.

453
00:36:32,700 --> 00:36:32,942
Speaker 0: Yep.

454
00:36:33,505 --> 00:36:34,330
Speaker 1: Give us your comments.

455
00:36:34,410 --> 00:36:35,275
Speaker 0: Tell us what you think.

456
00:36:35,537 --> 00:36:36,080
Speaker 0: Report bugs.

457
00:36:36,581 --> 00:36:38,127
Speaker 1: We need to know about features.

458
00:36:38,348 --> 00:36:41,520
Speaker 1: We need to know about bugs, changes, anything like that.

459
00:36:41,600 --> 00:36:46,700
Speaker 0: I mean, the listener pointed out it was hard to get the thing of the day links in various forms and Scott fixed that basically right away.

460
00:36:47,440 --> 00:36:50,108
Speaker 1: Well, that took me like that was actually somewhat annoying defense.

461
00:36:50,128 --> 00:36:53,900
Speaker 1: But yeah, that felt like an important one that the, you know, the posts were basically incomplete.

462
00:36:54,700 --> 00:36:58,011
Speaker 1: You know, I'm working on improving where I can.

463
00:36:58,031 --> 00:36:59,958
Speaker 1: We got to get the automatic forum post working.

464
00:36:59,978 --> 00:37:00,480
Speaker 1: That's the next.

465
00:37:00,741 --> 00:37:01,424
Speaker 0: Yeah, we'll get there.

466
00:37:01,624 --> 00:37:02,126
Speaker 0: Bit by bit.

467
00:37:02,187 --> 00:37:03,391
Speaker 0: I got to make some pipelines.

468
00:37:03,411 --> 00:37:05,500
Speaker 0: There's a few things I got to do still in my task list.

469
00:37:06,220 --> 00:37:09,529
Speaker 0: We will be live at PAX Unplugged on Friday.

470
00:37:09,850 --> 00:37:13,200
Speaker 0: Learn and play Wist, Hearts and Wizard.

471
00:37:14,241 --> 00:37:16,350
Speaker 0: We're not just going to tell you how to play these games.

472
00:37:16,591 --> 00:37:18,420
Speaker 0: We're going to teach you basically R trick taking.

473
00:37:18,980 --> 00:37:29,120
Speaker 0: And then we're going to teach you how to be not the best in the world, but pretty dangerous and good, especially at Hearts and Wizard because we are both pretty good at Hearts and Wizard.

474
00:37:29,281 --> 00:37:34,220
Speaker 0: I think if Scott and I played in a long form Hearts tournament, it'd be a pretty close fight.

475
00:37:35,060 --> 00:37:38,260
Speaker 1: Yeah, I played some Oh Hell, which is like 90 percent the same as Wizard yesterday.

476
00:37:39,600 --> 00:37:43,492
Speaker 1: And it's not as good as at least whatever rules they were using, especially there's.

477
00:37:43,532 --> 00:37:46,220
Speaker 1: it was not as good, especially with seven people.

478
00:37:47,744 --> 00:37:48,247
Speaker 1: It was not.

479
00:37:48,689 --> 00:37:49,635
Speaker 1: it was not good.

480
00:37:49,655 --> 00:37:50,600
Speaker 1: I'd much rather play Wizard.

481
00:37:52,282 --> 00:37:55,510
Speaker 0: And then on Saturday, mastering game mechanics, worker placement.

482
00:37:55,791 --> 00:37:59,520
Speaker 0: Fifty nine minutes of us talking about worker placement, the mechanic.

483
00:37:59,920 --> 00:38:02,447
Speaker 0: I got to start working on those slides a little more deeply.

484
00:38:02,487 --> 00:38:03,209
Speaker 0: We got about a month.

485
00:38:04,934 --> 00:38:07,060
Speaker 0: Luckily, I think we have more than an hour's worth of content.

486
00:38:07,200 --> 00:38:13,280
Speaker 0: So this is going to be mostly an editing and whittling down exercise rather than a writing an entire panel exercise.

487
00:38:14,181 --> 00:38:24,620
Speaker 1: I think the biggest problem is that, you know, while we've played many worker placement games and have many skills at those games, there's so many worker placement games we haven't played and things we don't know.

488
00:38:25,100 --> 00:38:28,754
Speaker 1: And, you know, there's always going to be that nerd who's like, oh, what about this one that does it differently?

489
00:38:28,774 --> 00:38:30,240
Speaker 1: And what about that one that doesn't differently?

490
00:38:30,320 --> 00:38:34,860
Speaker 1: And it's like, look, you know, I've played a thousand games, but I haven't played ten thousand games.

491
00:38:35,482 --> 00:38:40,800
Speaker 0: But I feel like we're going to we're going to teach enough rules from a few specific several specific examples.

492
00:38:41,420 --> 00:38:52,800
Speaker 0: I feel like example driven conversations in this will be more useful than purely abstract, because if we just want to define what a worker placement game is in a reasonably objective way, that would take more than an hour by itself.

493
00:38:53,341 --> 00:39:02,799
Speaker 0: So there's a story here and there's a lot to unpack about it and not necessarily what you, the listener, might think we would say we should unpack about it.

494
00:39:03,200 --> 00:39:17,600
Speaker 0: But the cause scam, like the concept of a scam, like in general, has been around as long as there have been humans who can communicate with each other and have needs and wants and desires and difficulty achieving those things.

495
00:39:17,740 --> 00:39:35,960
Speaker 1: Scams are I mean, I mean, the core of a scam is that one human basically deceives another human and convinces that human to act in the interest of the deceiver at great misfortune of the person being deceived.

496
00:39:37,201 --> 00:39:38,102
Speaker 0: If we have to define it.

497
00:39:38,522 --> 00:40:02,640
Speaker 0: So the story here is fascinating because basically two people got scammed by actually a very common form of scam now where basically someone will message someone who's not super technologically proficient online and make a long term fake friendship with them, mostly via text messages and Facebook posts and that kind of thing.

498
00:40:03,241 --> 00:40:12,920
Speaker 0: And then well into that relationship, make stuff up and then kick off the scam and start collecting money from them from there.

499
00:40:13,020 --> 00:40:25,480
Speaker 0: Like it's a very long form close up magic style of scam, but it's so common and it almost always involves certain kinds of financial transactions, usually to buy dubious cryptocurrency.

500
00:40:26,502 --> 00:40:36,600
Speaker 0: So all the banks and all the places you can interact with even cryptocurrency or transfer money or anything basically know about these things.

501
00:40:37,340 --> 00:40:52,580
Speaker 0: And the problem they're having is that there are a lot of situations like this one where someone is obviously being scammed, like anyone who knows this person and finds out about the transaction they're trying to accomplish would say, yo, you're being scammed.

502
00:40:52,961 --> 00:40:56,267
Speaker 0: But the people are being scammed will absolutely not listen to them.

503
00:40:56,727 --> 00:41:03,700
Speaker 0: But the banks know and the banks will tell people directly, look, the transaction you just tried to put in is definitely a scam.

504
00:41:04,641 --> 00:41:09,435
Speaker 0: If you proceed with this transaction, which we have currently blocked, you're almost definitely going to lose your money.

505
00:41:09,796 --> 00:41:11,120
Speaker 0: We cannot help you get it back.

506
00:41:11,621 --> 00:41:14,046
Speaker 0: Even if you call the police, there'll be nothing we can do.

507
00:41:14,066 --> 00:41:20,940
Speaker 0: And often what the people who are being scammed will do is threaten to sue their own bank if they don't make the transaction go through.

508
00:41:21,541 --> 00:41:40,220
Speaker 0: So the bank eventually, in this case, they made the person who was being scammed write a handwritten note explaining, quote, Revolut has warned me that this is likely a scam and that I am unlikely to recover my funds, et cetera, et cetera.

509
00:41:40,441 --> 00:41:47,800
Speaker 0: They made her write this out on a piece of paper, take a selfie of herself holding up the piece of paper with the date and send it to them.

510
00:41:48,400 --> 00:41:52,149
Speaker 0: And then when they couldn't convince her, they eventually let the transaction go through.

511
00:41:52,670 --> 00:41:56,980
Speaker 0: And the news article is about, oh, no, it was a scam and she gave up her life savings.

512
00:41:58,821 --> 00:42:00,403
Speaker 0: It's common, this kind of thing.

513
00:42:01,265 --> 00:42:04,611
Speaker 0: And it is easy to try to blame the victim.

514
00:42:05,312 --> 00:42:09,840
Speaker 0: And there are a lot of very credulous people out there who are easily scammed.

515
00:42:10,280 --> 00:42:26,280
Speaker 0: But there is also a bigger story around why and how people fall for scams in general, because it's kind of sad how often people fall for what appear to the kind of person who listens to Geek Nights as obviously a scam, like zero doubt instantly.

516
00:42:28,329 --> 00:42:29,180
Speaker 0: Have you ever been scammed?

517
00:42:30,683 --> 00:42:32,340
Speaker 1: Have I been scammed?

518
00:42:32,620 --> 00:42:40,035
Speaker 0: I have been scammed once when I was young in a late middle school by a carny out of like 20 bucks.

519
00:42:40,576 --> 00:42:42,780
Speaker 0: And I was scammed, but I knew it was a scam.

520
00:42:42,840 --> 00:42:44,803
Speaker 0: And I went along with it because it was funny and fun.

521
00:42:44,823 --> 00:42:54,200
Speaker 0: I was in India once and I bought some worthless art for basically five or six US dollars, which was clearly part of a scam to sell me something worthless.

522
00:42:56,380 --> 00:43:05,229
Speaker 1: I don't know if that's so much a scam, but there have been times where people awkwardly pressure you.

523
00:43:05,249 --> 00:43:09,093
Speaker 1: I think that's a good example in a market.

524
00:43:09,453 --> 00:43:12,796
Speaker 1: Especially the kind of market that doesn't exist in the US so much.

525
00:43:13,117 --> 00:43:16,580
Speaker 1: I guess it does flee markets, but street markets.

526
00:43:16,680 --> 00:43:24,420
Speaker 0: I've had people pull the aggressive to the point of I am uncomfortable hard sell on me and artist alleys at anime conventions before.

527
00:43:25,440 --> 00:43:25,887
Speaker 1: Oh, that's true.

528
00:43:25,927 --> 00:43:26,780
Speaker 1: That's another good example.

529
00:43:26,780 --> 00:43:35,140
Speaker 0: I can definitely feel someone who was less willful or more worried about social consequences of falling for it and buying a print they didn't want.

530
00:43:36,701 --> 00:43:43,049
Speaker 1: Actually, I can tell you a time where I was pressured and it didn't work because I was in Israel in the year 2000.

531
00:43:43,049 --> 00:43:50,860
Speaker 1: And this dude, we're going through a place that's a street market with various crafts and touristy tchotchkes and all that kind of stuff that you would expect.

532
00:43:51,700 --> 00:43:55,847
Speaker 1: And this dude comes up behind me because I'm some 18 year old white kid.

533
00:43:55,927 --> 00:43:57,550
Speaker 1: Clearly, I'm speaking English.

534
00:43:57,590 --> 00:44:00,895
Speaker 1: He can see that I'm not.

535
00:44:01,235 --> 00:44:02,778
Speaker 1: He puts his arm around me.

536
00:44:02,798 --> 00:44:04,160
Speaker 1: He's like, hello, my friend.

537
00:44:04,320 --> 00:44:04,461
Speaker 1: Right.

538
00:44:04,521 --> 00:44:04,902
Speaker 1: It was so.

539
00:44:04,942 --> 00:44:05,944
Speaker 1: it was like from a movie.

540
00:44:05,984 --> 00:44:08,631
Speaker 1: I think he was talking that way, like almost on purpose already.

541
00:44:08,912 --> 00:44:12,280
Speaker 0: My pickpocket flag is that full alert just from what you said.

542
00:44:13,021 --> 00:44:13,341
Speaker 1: Oh, yeah.

543
00:44:13,402 --> 00:44:15,086
Speaker 1: But it wasn't a pickpocket issue.

544
00:44:15,126 --> 00:44:15,386
Speaker 1: Right.

545
00:44:15,767 --> 00:44:20,900
Speaker 1: But he's that he's like, hey, come here, check out my friends, you know, merge, you know, original handmade.

546
00:44:22,041 --> 00:44:22,461
Speaker 1: So great.

547
00:44:22,521 --> 00:44:23,383
Speaker 1: Oh, this is the best.

548
00:44:23,443 --> 00:44:24,184
Speaker 1: Isn't it beautiful?

549
00:44:24,264 --> 00:44:24,484
Speaker 1: Right.

550
00:44:24,504 --> 00:44:26,788
Speaker 1: And it's like, you know, he's basically they create.

551
00:44:26,908 --> 00:44:29,532
Speaker 1: it's not a scam so much as where you're being deceived.

552
00:44:29,572 --> 00:44:31,174
Speaker 1: I mean, there might have been some deception.

553
00:44:31,255 --> 00:44:31,435
Speaker 1: Right.

554
00:44:31,455 --> 00:44:34,920
Speaker 1: It's like, was it all handmade Armenian high quality, rare shit?

555
00:44:35,220 --> 00:44:35,501
Speaker 1: No.

556
00:44:35,521 --> 00:44:36,021
Speaker 1: Right.

557
00:44:37,123 --> 00:44:40,928
Speaker 1: But it's like, you know, that was the price too high, probably.

558
00:44:41,069 --> 00:44:43,332
Speaker 1: I didn't buy any of it because even then I knew better.

559
00:44:43,652 --> 00:44:49,180
Speaker 1: But it's like people in those situations, the things that like in New York City, people do the CD selling.

560
00:44:49,560 --> 00:44:49,881
Speaker 1: Right.

561
00:44:49,981 --> 00:44:50,261
Speaker 0: Yeah.

562
00:44:50,642 --> 00:44:53,045
Speaker 1: It's like or the or the petty cab guys.

563
00:44:53,245 --> 00:44:54,386
Speaker 1: It's like they don't.

564
00:44:54,867 --> 00:45:01,976
Speaker 1: they're not lying to you so much as they are putting you in a situation where it's they're making it.

565
00:45:02,256 --> 00:45:04,479
Speaker 1: if you aren't don't have courage.

566
00:45:04,980 --> 00:45:05,220
Speaker 1: Right.

567
00:45:05,620 --> 00:45:12,425
Speaker 1: You're afraid for to say no and you end up just losing money that you didn't lose.

568
00:45:12,645 --> 00:45:15,547
Speaker 1: Some of those attacks on people who don't have courage.

569
00:45:15,627 --> 00:45:23,232
Speaker 0: And some of those get dicey because they edge into an unspoken threat and they effectively become a mugging in some cases.

570
00:45:23,272 --> 00:45:24,573
Speaker 0: Some of those CD sell cases.

571
00:45:24,593 --> 00:45:24,833
Speaker 1: Yeah.

572
00:45:24,933 --> 00:45:26,754
Speaker 1: If they're actually going to follow through.

573
00:45:26,774 --> 00:45:27,595
Speaker 1: Right.

574
00:45:27,895 --> 00:45:31,738
Speaker 1: You know, even if they were, it's not just a dangerous situation.

575
00:45:31,838 --> 00:45:33,799
Speaker 0: They will imply that they're angry.

576
00:45:33,839 --> 00:45:35,000
Speaker 0: They might not actually throw a punch.

577
00:45:35,441 --> 00:45:38,926
Speaker 0: But they will talk like they will without actually making an explicit threat.

578
00:45:39,267 --> 00:45:42,572
Speaker 0: I've watched them shake down tourists in Bryant Park before.

579
00:45:43,574 --> 00:45:47,200
Speaker 0: Like they edge into straight up mugging someone under threat of violence.

580
00:45:48,060 --> 00:45:48,240
Speaker 1: Right.

581
00:45:48,280 --> 00:45:49,281
Speaker 1: But the scams.

582
00:45:49,721 --> 00:45:50,002
Speaker 1: Right.

583
00:45:50,382 --> 00:45:52,263
Speaker 1: Differ from those in two ways.

584
00:45:52,363 --> 00:45:52,523
Speaker 1: Right.

585
00:45:52,844 --> 00:45:54,305
Speaker 1: Well, there's two kinds of scams.

586
00:45:54,445 --> 00:45:54,845
Speaker 1: And there's that.

587
00:45:55,005 --> 00:46:00,529
Speaker 1: one kind of scam is where you're sort of making it instead of threatening a person.

588
00:46:00,809 --> 00:46:00,970
Speaker 1: Right.

589
00:46:00,990 --> 00:46:04,392
Speaker 1: You're appealing to their sympathies like, you know, I'm so poor.

590
00:46:04,492 --> 00:46:05,653
Speaker 1: Please give me money.

591
00:46:05,793 --> 00:46:09,596
Speaker 1: Appealing to their their kind heart to get them to cave.

592
00:46:09,856 --> 00:46:11,577
Speaker 1: Whereas actually you're not poor at all.

593
00:46:11,597 --> 00:46:12,578
Speaker 1: You're you're right.

594
00:46:12,618 --> 00:46:15,260
Speaker 1: As soon as the day's over, you're going to get in your car and drive back.

595
00:46:15,400 --> 00:46:17,643
Speaker 0: Of course, even then, you know, we're talking about this.

596
00:46:17,683 --> 00:46:19,986
Speaker 0: I feel like that's not necessarily a scam either.

597
00:46:20,046 --> 00:46:23,050
Speaker 0: That's social pressure because there's no transaction.

598
00:46:23,090 --> 00:46:28,557
Speaker 0: It's not like like if you get tricked by someone like that who did not need that help.

599
00:46:28,978 --> 00:46:30,460
Speaker 0: Well, you still got whatever.

600
00:46:30,480 --> 00:46:30,940
Speaker 1: And I'm not.

601
00:46:31,020 --> 00:46:37,505
Speaker 1: I don't want people to get confused and think the people pretend to be poor to, you know, panhandle our extreme minority.

602
00:46:37,525 --> 00:46:37,765
Speaker 1: Yeah.

603
00:46:37,865 --> 00:46:40,767
Speaker 1: But there there are more than zero of those people that they do exist.

604
00:46:40,787 --> 00:46:48,092
Speaker 0: I guess I'm saying even a situation like that isn't necessarily really a scam because the person who gets a scam because they're lying.

605
00:46:48,232 --> 00:46:51,274
Speaker 1: Right.

606
00:46:51,294 --> 00:46:59,920
Speaker 0: But they're not lying about the transaction as it is conducted with the scammy in that the person who got scammed feels like they did a good thing.

607
00:46:59,960 --> 00:47:01,882
Speaker 0: So they got what they wanted out of the transaction.

608
00:47:02,463 --> 00:47:03,944
Speaker 0: They couldn't be different for them.

609
00:47:04,946 --> 00:47:06,447
Speaker 0: Doesn't matter what is for them.

610
00:47:07,408 --> 00:47:07,989
Speaker 1: I guess so.

611
00:47:08,770 --> 00:47:18,060
Speaker 1: But yeah, but I guess real scams like the one in your original story, that's a scam where the person was led to believe that they were investing and that their investment had big returns.

612
00:47:18,120 --> 00:47:18,440
Speaker 1: Yeah.

613
00:47:18,740 --> 00:47:22,043
Speaker 1: When actually they were giving and not getting any investment.

614
00:47:22,443 --> 00:47:24,384
Speaker 1: And these scans because someone made a fake website.

615
00:47:24,484 --> 00:47:27,606
Speaker 1: I can make a website that has the number of billion dollars written on it.

616
00:47:27,947 --> 00:47:31,249
Speaker 1: And if you believe that that's representing your investment.

617
00:47:32,129 --> 00:47:33,150
Speaker 0: Yeah.

618
00:47:33,170 --> 00:47:33,730
Speaker 0: I mean, that's kind of.

619
00:47:33,750 --> 00:47:36,893
Speaker 0: that's kind of what most Ponzi scams have been for all of time.

620
00:47:36,933 --> 00:47:38,454
Speaker 0: That's what most pyramid scams are.

621
00:47:38,734 --> 00:47:39,634
Speaker 0: They're all like that.

622
00:47:40,055 --> 00:47:41,676
Speaker 0: But I guess that's the line.

623
00:47:41,816 --> 00:47:48,060
Speaker 0: A scam unlike all these other forms of trickery and shenanigans and all this nonsense out there.

624
00:47:48,661 --> 00:47:58,373
Speaker 0: Scams, I feel like are related to first degree fraudulent transactions like a Fyre Festival was a scam.

625
00:47:58,473 --> 00:47:59,935
Speaker 0: There was no Fyre Festival.

626
00:47:59,955 --> 00:48:01,377
Speaker 0: There never was a Fyre Festival.

627
00:48:01,397 --> 00:48:03,800
Speaker 0: They were selling a fake thing from day one.

628
00:48:04,941 --> 00:48:05,121
Speaker 1: Yeah.

629
00:48:05,161 --> 00:48:06,522
Speaker 1: Or like, you know, what about.

630
00:48:07,042 --> 00:48:08,923
Speaker 1: Well, then what do you say about like a fake medicine?

631
00:48:08,983 --> 00:48:09,163
Speaker 1: Right.

632
00:48:09,183 --> 00:48:10,965
Speaker 1: Someone takes the fake medicine.

633
00:48:10,985 --> 00:48:12,586
Speaker 1: They're paying for basically nothing.

634
00:48:13,046 --> 00:48:15,708
Speaker 1: They take it and then maybe they think it worked on them.

635
00:48:15,928 --> 00:48:16,228
Speaker 1: Right.

636
00:48:18,110 --> 00:48:22,953
Speaker 0: I would argue selling someone a homeopathic remedy that makes a claim is a direct scam.

637
00:48:23,914 --> 00:48:24,134
Speaker 1: Right.

638
00:48:24,194 --> 00:48:33,140
Speaker 1: But but according to your argument about the you gave money to the fake poor person, you know, where you felt good while they take the homeopathy and they feel good.

639
00:48:34,241 --> 00:48:46,331
Speaker 0: I guess if you want to make a distinction there, a distinction could be that the advertisement of the effect is itself a scam because it cannot even be possible.

640
00:48:47,351 --> 00:48:48,652
Speaker 0: It is absolutely fake.

641
00:48:48,793 --> 00:48:50,854
Speaker 1: But the person experiences the effect.

642
00:48:51,014 --> 00:48:51,255
Speaker 1: Right.

643
00:48:51,295 --> 00:48:57,880
Speaker 1: Just like the person experienced the feeling of goodness of donating to a poor person, even though they donated to a not poor person.

644
00:48:58,460 --> 00:48:58,721
Speaker 0: True.

645
00:48:58,881 --> 00:49:06,747
Speaker 0: But the donating to the donation situation, at least that is a social effect as opposed to a medical effect that could be measured.

646
00:49:07,948 --> 00:49:13,252
Speaker 1: I still say like if somebody is deceived into doing something that is detrimental to them.

647
00:49:13,613 --> 00:49:13,793
Speaker 1: Right.

648
00:49:13,813 --> 00:49:14,994
Speaker 1: Whether they know it or not.

649
00:49:15,614 --> 00:49:15,874
Speaker 1: Right.

650
00:49:16,355 --> 00:49:18,216
Speaker 1: And beneficial to the deceiver.

651
00:49:18,436 --> 00:49:18,957
Speaker 1: That's enough.

652
00:49:19,037 --> 00:49:19,617
Speaker 1: Yeah.

653
00:49:20,098 --> 00:49:22,880
Speaker 0: But I guess like I differentiate scams more on the method.

654
00:49:23,821 --> 00:49:34,040
Speaker 1: If somehow my scam is so strong that you don't know you've been scammed even after you've been scammed and you never believe that you've been scammed for the rest of your life, even though you were, that's still a scam.

655
00:49:35,301 --> 00:49:35,942
Speaker 0: Was it really, though?

656
00:49:35,962 --> 00:49:40,433
Speaker 0: What if someone, Fyre Festival was exactly what they thought it was going to be and they had a grand old time.

657
00:49:41,576 --> 00:49:42,818
Speaker 1: Then they still got scammed.

658
00:49:43,159 --> 00:49:43,420
Speaker 1: Right.

659
00:49:44,921 --> 00:49:52,948
Speaker 0: I like to differentiate them more along the lines of what is the fundamental trigger or goad of the scam?

660
00:49:52,988 --> 00:49:57,453
Speaker 0: Because there's scams that play on sympathy, like you've mentioned.

661
00:49:57,733 --> 00:50:01,777
Speaker 0: Pretty sure one of our old forumites got scammed by someone who claimed to have a disease who didn't.

662
00:50:01,817 --> 00:50:03,658
Speaker 0: And there was a whole thing long ago.

663
00:50:03,999 --> 00:50:05,280
Speaker 0: One of those old divorced dad types.

664
00:50:06,781 --> 00:50:09,366
Speaker 0: But then there is the scam that plays on greed.

665
00:50:09,826 --> 00:50:13,153
Speaker 0: The scam of the too good to be true deal.

666
00:50:13,493 --> 00:50:16,880
Speaker 1: That is the other kind that I was going to talk about, which is the kind in your story.

667
00:50:17,180 --> 00:50:19,363
Speaker 0: Because those are the kind that I find the most interesting.

668
00:50:19,383 --> 00:50:32,560
Speaker 0: because when you, if you, if you find, especially the ones that imply that what's going on is shady, like in the one Hemingway book, I think it was in the Sun Also Rises where they go to the horse track.

669
00:50:33,641 --> 00:50:34,662
Speaker 0: Uh, might've been farewell to arms.

670
00:50:34,682 --> 00:50:35,503
Speaker 0: I think it was Sun Also Rises.

671
00:50:35,523 --> 00:50:36,305
Speaker 0: They go to the horse track.

672
00:50:36,365 --> 00:50:37,867
Speaker 1: I've read both of those, but I don't remember.

673
00:50:37,907 --> 00:50:43,716
Speaker 0: They go to a horse track and they see that one of the horses has been, has clearly been dyed black.

674
00:50:43,756 --> 00:50:45,078
Speaker 0: Like it's not actually black.

675
00:50:45,438 --> 00:50:46,620
Speaker 0: Like someone has died this horse.

676
00:50:47,201 --> 00:50:49,603
Speaker 0: So they assume shenanigans are afoot.

677
00:50:49,884 --> 00:50:52,126
Speaker 0: This must be a horse that's been like banned or something.

678
00:50:52,146 --> 00:50:53,608
Speaker 0: There's a mob thing going on.

679
00:50:54,009 --> 00:50:55,851
Speaker 0: So, and it's got really bad odds.

680
00:50:55,911 --> 00:51:03,420
Speaker 0: So we're going to bet on this horse, assuming that there is someone else conducting a mob style betting scam related to that horse.

681
00:51:03,961 --> 00:51:04,982
Speaker 0: And then the horse doesn't win.

682
00:51:05,343 --> 00:51:10,069
Speaker 0: And then they're mad that they got scammed when really, no, you tried to scam.

683
00:51:10,089 --> 00:51:11,491
Speaker 0: You tried to join the scam.

684
00:51:11,511 --> 00:51:13,334
Speaker 0: You thought it was a scam and you joined it.

685
00:51:13,654 --> 00:51:17,720
Speaker 0: Did you get, even if you got scammed, you're not a good person because you also tried to scam.

686
00:51:18,680 --> 00:51:24,228
Speaker 0: So the kind of scam that plays on like, Hey, you want to do some insider trading and trick someone to buy a penny stock.

687
00:51:24,749 --> 00:51:26,611
Speaker 0: that is a scam and it's immoral.

688
00:51:27,032 --> 00:51:33,040
Speaker 0: But I also don't have sympathy for the victim because in that case, the victim basically said, yes, I want to commit a crime for money.

689
00:51:34,001 --> 00:51:37,145
Speaker 1: It depends on the, the, you got to get into the details, right?

690
00:51:37,185 --> 00:51:40,990
Speaker 1: Because the greed based scams can fall into a few categories, right?

691
00:51:41,110 --> 00:51:45,076
Speaker 1: In your, in the story that started this whole episode, right?

692
00:51:45,557 --> 00:51:48,040
Speaker 1: That person, was their motivation greed?

693
00:51:49,461 --> 00:51:58,247
Speaker 0: Well, but it was great combined with concern for the family and also a phrase that gets misused where this is probably actually true here.

694
00:51:58,688 --> 00:52:10,956
Speaker 1: Economic anxiety because everybody's poor also, but also just, you know, a lack of education, you know, incompetence, ignorance, whatever you want to call it, but which is not that person's fault, right?

695
00:52:11,237 --> 00:52:16,100
Speaker 1: We're not going to blame a person themselves for not being smart enough, right?

696
00:52:16,440 --> 00:52:18,882
Speaker 1: That person might be super smart about something else.

697
00:52:18,942 --> 00:52:21,084
Speaker 1: That's not financial scams, right?

698
00:52:21,564 --> 00:52:23,906
Speaker 1: Um, they're just not smart about financial scams.

699
00:52:23,946 --> 00:52:31,432
Speaker 1: And therefore this, this, you know, it's like, I, I, you know, I, for all I know, I could have been scammed in some kind of scam.

700
00:52:31,892 --> 00:52:34,494
Speaker 1: that I'm just not, I don't know about that kind of right.

701
00:52:34,655 --> 00:52:36,336
Speaker 1: And it's like a whole world of scammery.

702
00:52:36,396 --> 00:52:39,979
Speaker 1: I that's, I've, I've been completely clueless to this whole time current definitions.

703
00:52:40,039 --> 00:52:41,480
Speaker 0: I think I've never been scams.

704
00:52:42,441 --> 00:52:43,662
Speaker 1: I don't think you don't think so.

705
00:52:43,962 --> 00:52:44,222
Speaker 1: Right.

706
00:52:44,683 --> 00:52:49,847
Speaker 1: But that brings you to the next kind of scam, which is when there is an actual con.

707
00:52:50,127 --> 00:52:50,528
Speaker 0: Yeah.

708
00:52:50,768 --> 00:53:04,440
Speaker 1: Whereas the scam is so complex and so elaborate that even the intelligent, smart, you know, can see a scam coming person is still fooled by it.

709
00:53:06,361 --> 00:53:16,350
Speaker 0: And the scammer gets access to your computer and then gaslights you and does things to set up the scam over the course of years for the big payout.

710
00:53:16,830 --> 00:53:25,318
Speaker 0: Like that level of attention from, imagine if an entire global crime network has picked you to scam personally, or like the CIA is trying to rip you off.

711
00:53:25,358 --> 00:53:27,440
Speaker 0: Like what are you going to be fucked no matter what in the end?

712
00:53:28,340 --> 00:53:31,423
Speaker 1: They're going to get you some, you know, something so elaborate, right?

713
00:53:31,443 --> 00:53:33,605
Speaker 1: It's like, usually you see this in movies, right?

714
00:53:33,725 --> 00:53:52,100
Speaker 1: But it's like, there have been some rare instances in real life of like, you know, someone, you know, a lot of times it's a sexually related or romantically related where somebody will, you know, get themselves involved with someone else, uh, in a, uh, insincere manner.

715
00:53:52,681 --> 00:53:52,941
Speaker 1: Right.

716
00:53:53,322 --> 00:53:55,525
Speaker 1: In order to get their monies, right.

717
00:53:55,805 --> 00:53:59,350
Speaker 1: Or getting their will or whatever, things of that nature.

718
00:53:59,370 --> 00:54:07,140
Speaker 1: Um, sometimes, you know, it's that it happens more than zero times and it's, it's, it's, it's a scam when it happens, right?

719
00:54:08,100 --> 00:54:08,320
Speaker 0: Yeah.

720
00:54:08,821 --> 00:54:13,445
Speaker 0: It's tough because the, a lot of scare, there's a lot of scams out there.

721
00:54:13,845 --> 00:54:24,834
Speaker 0: And I feel like one thing I read doing some research around this, like after reading this article this morning is there's some evidence that people who'd fall for one scam tend to fall for a lot of scams.

722
00:54:24,894 --> 00:54:31,820
Speaker 0: Like there's a big divide between people who tend to fall for scams broadly and people who rarely or never fall for scams.

723
00:54:31,940 --> 00:54:36,127
Speaker 1: The people who are vulnerable to scams gets like, you know, it's like, that's a hot, there's like a list.

724
00:54:36,167 --> 00:54:39,693
Speaker 1: It's like, once you've fallen for one, then it's like, you'll never hear the end of it.

725
00:54:39,713 --> 00:54:40,575
Speaker 1: It's the same thing.

726
00:54:40,635 --> 00:54:43,600
Speaker 1: It's not only scams, but like the debt collectors.

727
00:54:43,660 --> 00:54:43,840
Speaker 1: Right.

728
00:54:44,120 --> 00:54:49,608
Speaker 1: It's like, let's say you got some debts you can't pay and those, the original person you owed money to right.

729
00:54:49,868 --> 00:54:51,551
Speaker 1: Sells your debt to a debt collector.

730
00:54:51,611 --> 00:54:53,013
Speaker 1: They've rid themselves of that.

731
00:54:53,494 --> 00:54:53,694
Speaker 1: Right.

732
00:54:53,774 --> 00:54:57,840
Speaker 1: And now the debt collector is like, they have all these debts they've bought for pennies on the dollar.

733
00:54:58,381 --> 00:55:02,066
Speaker 1: And if they can actually get any money at all for, you know, they're, they're making bank.

734
00:55:02,507 --> 00:55:02,747
Speaker 1: Right.

735
00:55:03,068 --> 00:55:08,776
Speaker 1: So they're basically like, they're ready for not basically none of those debts to actually collect on.

736
00:55:08,976 --> 00:55:09,297
Speaker 1: Right.

737
00:55:09,337 --> 00:55:11,139
Speaker 1: Cause a lot of them are uncollectable.

738
00:55:11,280 --> 00:55:11,500
Speaker 1: Right.

739
00:55:11,820 --> 00:55:17,588
Speaker 1: But they think they can collect on enough of them to make, to get their money back from buying those heavily discounted debts.

740
00:55:18,289 --> 00:55:26,620
Speaker 1: So if they find you, like you actually in your, in the United States, at least your best interest is to not answer and not pay.

741
00:55:27,360 --> 00:55:33,949
Speaker 1: Because as soon as you pay one, they're like, ah, we got someone who actually pays off, tries to pay off their debts.

742
00:55:34,350 --> 00:55:34,570
Speaker 1: Right.

743
00:55:34,711 --> 00:55:41,260
Speaker 1: And then every debt collector will look for every debt that belongs to that person and start hounding them big time.

744
00:55:41,360 --> 00:55:46,629
Speaker 1: Because that's a person who will actually try to get money, can get money and we'll try to pay debts.

745
00:55:46,970 --> 00:55:49,174
Speaker 1: So let's get them to pay as many of the debts as we can.

746
00:55:49,254 --> 00:55:49,414
Speaker 1: Right.

747
00:55:49,695 --> 00:55:52,700
Speaker 1: Oh, that's a person who can be scammed every scammer in the universe.

748
00:55:52,960 --> 00:55:55,262
Speaker 1: They got a list of the people who are vulnerable to scams.

749
00:55:55,662 --> 00:55:55,902
Speaker 1: Right.

750
00:55:56,202 --> 00:55:58,044
Speaker 1: And they start hammering on those people.

751
00:55:58,504 --> 00:55:58,764
Speaker 1: Right.

752
00:55:58,904 --> 00:56:01,306
Speaker 0: The worst one I read was about those multi-level marketing.

753
00:56:01,326 --> 00:56:02,146
Speaker 1: Like in a gold rush.

754
00:56:02,186 --> 00:56:05,609
Speaker 1: And everyone goes to the one place that has a, where they heard there was gold.

755
00:56:05,649 --> 00:56:16,196
Speaker 0: Cause the multi-level marketing scams are extra insidious here because the kinds of people who fall for them, they will realize at the end of one that it was a scam and they were fucked and like admit to it.

756
00:56:16,236 --> 00:56:17,097
Speaker 1: And then do another one.

757
00:56:17,137 --> 00:56:17,237
Speaker 0: Yeah.

758
00:56:17,257 --> 00:56:18,878
Speaker 0: They'll go immediately to another one.

759
00:56:18,898 --> 00:56:21,940
Speaker 0: Like every few months they move on to another scam.

760
00:56:22,060 --> 00:56:36,233
Speaker 0: And it's, and the worst part is like reading the testimonials from like family and friends of these people, they are a hundred percent sure the next one's good and nothing anyone they know says will dissuade them from this course.

761
00:56:36,613 --> 00:56:43,700
Speaker 0: And the scams are not only obvious to the rest of the family, they're the exact same scam every time.

762
00:56:44,820 --> 00:56:45,040
Speaker 1: Yep.

763
00:56:45,681 --> 00:56:51,609
Speaker 1: I mean, you know, if I go to a video game and the boss has a weak spot and his eyeball, it's like the next time, do you see him?

764
00:56:51,629 --> 00:56:52,710
Speaker 1: Does he have eyeball armor?

765
00:56:52,770 --> 00:56:53,011
Speaker 1: No.

766
00:56:54,012 --> 00:56:54,392
Speaker 1: Doesn't.

767
00:56:57,276 --> 00:57:00,120
Speaker 1: So I guess eyeball is still the weak spot next time too.

768
00:57:00,640 --> 00:57:05,466
Speaker 0: And I don't know what to do about that because you've, we got to protect people from scams.

769
00:57:05,646 --> 00:57:10,852
Speaker 0: And I feel like the right way to go, education only seems to work up to a point.

770
00:57:11,713 --> 00:57:17,779
Speaker 0: Like it feels, cause it's a case of what the MLM people, no amount of education stops them from falling for those scams.

771
00:57:17,799 --> 00:57:18,580
Speaker 0: They'll keep falling for them.

772
00:57:18,580 --> 00:57:30,840
Speaker 1: There are some people though who like can be educated and like might've fallen for an MLM or they will stop after one or once they realize, but then there's another class that will like, you know, fall for it repeatedly.

773
00:57:31,100 --> 00:57:33,823
Speaker 0: And I feel like you have to be in all societal problems, like.

774
00:57:33,863 --> 00:57:36,166
Speaker 0: this is a microcosm of bigger picture things.

775
00:57:37,007 --> 00:57:38,669
Speaker 0: There's no panacea to any problem.

776
00:57:38,689 --> 00:57:39,970
Speaker 0: You have to treat those differently.

777
00:57:40,051 --> 00:57:47,940
Speaker 0: Like education campaigns are important because let's say you woke up from a coma today and you get back to your life.

778
00:57:48,661 --> 00:57:50,303
Speaker 0: And you've never heard of cryptocurrency.

779
00:57:50,804 --> 00:57:56,693
Speaker 0: And the first instance of Bitcoin you encounter is a Bitcoin person who's going to lie to you about it.

780
00:57:56,954 --> 00:58:01,920
Speaker 0: And if you try to do research, a lot of people lie about Bitcoin being worth more than $0.

781
00:58:01,920 --> 00:58:10,413
Speaker 0: So unless you were educated by society that Bitcoin is a scam, you could very easily fall for it, but the knowledge inoculates you.

782
00:58:11,095 --> 00:58:14,560
Speaker 0: That is a separate concern from the people who will just fall for scams forever.

783
00:58:14,920 --> 00:58:17,984
Speaker 0: And that's where we need to like criminalize multi-level marketing.

784
00:58:18,024 --> 00:58:20,227
Speaker 0: Like that should not be allowed to exist as a form of business.

785
00:58:20,508 --> 00:58:29,920
Speaker 0: We should not allow, well, you have to, even if we couldn't necessarily ban people practicing homeopathy like on themselves, we could definitely ban people selling it.

786
00:58:31,320 --> 00:58:31,541
Speaker 1: Yeah.

787
00:58:31,621 --> 00:58:44,616
Speaker 1: Let me, you know, it depends if you're going to talk about, you know, what the law is in any particular country, but I think it's just the core thing that allows scams to proliferate, proliferate, whatever, proliferate.

788
00:58:45,217 --> 00:58:48,160
Speaker 1: is this, you know, the philosophy of freedom, right?

789
00:58:48,240 --> 00:58:49,421
Speaker 1: People want freedom.

790
00:58:49,521 --> 00:58:50,862
Speaker 1: They don't want to be told what to do.

791
00:58:50,882 --> 00:58:52,724
Speaker 1: They don't want, you know, a nanny state.

792
00:58:52,804 --> 00:58:53,064
Speaker 1: Right.

793
00:58:53,124 --> 00:58:59,769
Speaker 1: And what, you know, you hear those sorts of ideas around and to a certain extent, it's like, you know, you agree with them.

794
00:58:59,829 --> 00:59:07,416
Speaker 1: It's like, hey, do you want them to force every single person who, you know, I don't know, go skiing?

795
00:59:07,736 --> 00:59:08,016
Speaker 1: Right.

796
00:59:08,376 --> 00:59:12,780
Speaker 1: You know, no more, no more dangerous hills skiing because people get hurt on them.

797
00:59:12,820 --> 00:59:20,786
Speaker 0: Or case in point, nobody, almost no resort requires helmets, but most people wear them most of the time because they're a good idea.

798
00:59:20,866 --> 00:59:26,411
Speaker 0: But sometimes I want to ski without a helmet because I'm doing something really easy or like biking to work on a city bike.

799
00:59:27,031 --> 00:59:30,774
Speaker 0: I don't wear a helmet when I do that, but biking 50 miles, I wear a helmet.

800
00:59:31,135 --> 00:59:31,895
Speaker 0: Is there risk there?

801
00:59:32,035 --> 00:59:32,656
Speaker 0: Absolutely.

802
00:59:32,856 --> 00:59:34,397
Speaker 0: But that's a risk.

803
00:59:34,497 --> 00:59:37,580
Speaker 0: That's a risk I think an adult human can choose to take on.

804
00:59:38,361 --> 00:59:46,031
Speaker 0: And I think where society needs to intervene and there's nanny state nonsense is usually just right wing people being mad about basic regulations that are good.

805
00:59:47,613 --> 00:59:53,440
Speaker 0: We need societal intervention when dangers are not obvious to the average person.

806
00:59:54,261 --> 00:59:58,724
Speaker 1: I think the difference is that the, not only are the danger is not obvious, right?

807
00:59:59,124 --> 01:00:02,227
Speaker 1: These dangers are created by people, right?

808
01:00:02,647 --> 01:00:08,492
Speaker 1: So I think what we need to do is you need to say, sure, you know, if you want to fall for a scam, that's legal.

809
01:00:08,632 --> 01:00:10,493
Speaker 1: It's legal to fall for a scam.

810
01:00:10,953 --> 01:00:12,475
Speaker 1: You're already victimizing yourself.

811
01:00:12,535 --> 01:00:15,417
Speaker 1: There's no point in having society victimize you further, right?

812
01:00:15,877 --> 01:00:19,380
Speaker 1: But if you are creating hazards, right?

813
01:00:19,840 --> 01:00:24,465
Speaker 1: If you are creating a danger that will harm people, right?

814
01:00:24,525 --> 01:00:40,240
Speaker 1: If I'm going to the ski mountain and I'm installing some extra hidden rocks and I'm putting some spikes on the trees and I'm putting a hidden, I don't know, pop up chainsaw under the snow.

815
01:00:41,000 --> 01:00:42,922
Speaker 0: Libertarians will tell you that should be fine.

816
01:00:42,962 --> 01:00:45,285
Speaker 0: And the market will decide because they're morons.

817
01:00:45,646 --> 01:00:47,548
Speaker 1: Ah, no one's coming to Scott's chainsaw.

818
01:00:49,130 --> 01:00:51,312
Speaker 1: Everybody goes, except super meat boy.

819
01:00:51,353 --> 01:00:52,995
Speaker 1: He's the only one who wants to ski there.

820
01:00:54,797 --> 01:00:56,278
Speaker 1: He skied down that mountain so many times.

821
01:00:56,319 --> 01:00:57,520
Speaker 1: Hasn't hit the bottom yet though.

822
01:00:58,841 --> 01:01:01,464
Speaker 1: Um, but yeah, it doesn't use the low either.

823
01:01:01,484 --> 01:01:02,565
Speaker 0: I actually have a good example.

824
01:01:02,605 --> 01:01:03,927
Speaker 0: So case in point, I don't know what they're called.

825
01:01:04,267 --> 01:01:14,280
Speaker 0: So there's a stupid thing that dangerous people are doing on ski mountains and they're all mad because ski mountains have figured this out and are banning them and they're making a big crusade.

826
01:01:14,660 --> 01:01:19,246
Speaker 0: There's all these, there's Reddit and nonsense about these things that people like, it's my right.

827
01:01:19,346 --> 01:01:22,450
Speaker 0: And the ski mountains should not be able to stop me from doing this, what they're doing.

828
01:01:22,951 --> 01:01:24,273
Speaker 0: So skis are long, right?

829
01:01:24,293 --> 01:01:25,014
Speaker 0: Like you've seen skis.

830
01:01:25,054 --> 01:01:27,898
Speaker 0: They're like, they're about as long as a person is tall in the modern era.

831
01:01:28,518 --> 01:01:29,720
Speaker 0: They need to be long for a reason.

832
01:01:30,460 --> 01:01:34,887
Speaker 0: Short skis are actually really dangerous to the people who use them.

833
01:01:35,127 --> 01:01:37,090
Speaker 0: They're not dangerous to other people, but they're dangerous to you.

834
01:01:37,110 --> 01:01:43,640
Speaker 0: Like you might think if you're bad at skiing, if you get those little short skis that are like a foot long, that you'll be able to turn easier.

835
01:01:43,680 --> 01:01:44,422
Speaker 0: It'll be more fun.

836
01:01:44,722 --> 01:01:47,168
Speaker 0: The reality is those things are just going to give you a spiral fracture.

837
01:01:47,228 --> 01:01:48,571
Speaker 0: Like skis are long for a reason.

838
01:01:48,631 --> 01:01:52,880
Speaker 0: Those things are dangerous and maybe they should be banned.

839
01:01:53,660 --> 01:01:56,205
Speaker 1: I mean, I see people in the Olympics and they don't use short skis.

840
01:01:56,665 --> 01:01:57,367
Speaker 0: Well, you can't go fast.

841
01:01:57,387 --> 01:01:59,430
Speaker 1: They think that the short ones are not the right ones.

842
01:01:59,470 --> 01:01:59,631
Speaker 0: Yeah.

843
01:01:59,651 --> 01:02:04,800
Speaker 0: Well, most people who try those short skis don't realize how dangerous they are because they don't actually know how to ski that well.

844
01:02:05,240 --> 01:02:15,052
Speaker 0: Or because they don't know how to ski that well, they feel like when skiing, they have trouble turning quickly and they feel like their long skis are awkward.

845
01:02:15,112 --> 01:02:21,820
Speaker 0: Kind of like how if you've never driven a car before, a car feels really big and awkward until you internalize like how big it really is when you drive it.

846
01:02:22,441 --> 01:02:27,688
Speaker 0: So they think they'll be easier to ski, but anyway, they're dangerous, but they're only dangerous to the person who uses them.

847
01:02:28,289 --> 01:02:35,460
Speaker 0: So ski resorts generally allow them, but they are responsible for most of the injuries at ski resorts.

848
01:02:36,340 --> 01:02:40,967
Speaker 0: But there's another kind of ski and these things are dangerous bullshit.

849
01:02:40,987 --> 01:02:44,431
Speaker 0: They're basically ski boots that themselves are just skis.

850
01:02:44,552 --> 01:02:48,517
Speaker 0: Like they just have a flat bottom and they're like as long as the boot.

851
01:02:49,118 --> 01:02:50,480
Speaker 0: Like they're just a boot basically.

852
01:02:51,241 --> 01:02:58,370
Speaker 0: And there's a very small but dedicated community of people who are obsessed with these things, but ski resorts have said that is too far.

853
01:02:59,111 --> 01:03:06,340
Speaker 0: Those are likely to cause uncontrolled falling situations, which are some of the most dangerous possible things in the ski resort.

854
01:03:06,780 --> 01:03:17,800
Speaker 0: And unlike the little short skis where you're really only a danger to yourself, these little ski boot things, you're a danger to everyone else on the mountain that you're going to hit when you slide down the entire mountain because those things don't work.

855
01:03:19,301 --> 01:03:23,731
Speaker 0: So the ski resorts have banned those because they're a danger to you and other people.

856
01:03:24,132 --> 01:03:27,600
Speaker 0: They haven't banned the short skis because they're really only a danger to you.

857
01:03:29,440 --> 01:03:49,700
Speaker 0: I thought that was an interesting line and I hate the people who are using these boot skis because there is nothing good about them and I found a whole bunch of YouTube shorts of people basically trying to do a gotcha on the cops who are kicking them off of ski resorts after they got trespassed when the ski resort said you can't ride our ski lift with those things, they're dangerous.

858
01:03:50,861 --> 01:04:02,340
Speaker 1: Yeah, I guess the analogy I would make for a scammer is imagine someone has a big long stick and they're holding it over their shoulders horizontally and they walk down the road.

859
01:04:02,800 --> 01:04:09,349
Speaker 1: It's like most people will see that stick and duck under the stick and not get hit as this person walks down the sidewalk.

860
01:04:09,409 --> 01:04:17,780
Speaker 1: But someone might not be paying attention, someone might not be able to see, somebody might just be a doofus, I don't know.

861
01:04:18,120 --> 01:04:22,727
Speaker 1: But some people are going to get hit in the head by this big wide stick.

862
01:04:22,767 --> 01:04:25,572
Speaker 1: Someone's walking down the road carrying it head level.

863
01:04:26,894 --> 01:04:30,980
Speaker 1: And it's like, hey, it's not the fault of any of the people who got hit in the head.

864
01:04:31,761 --> 01:04:37,777
Speaker 1: Even if someone gets hit the next time and the next time, every single time a stick person comes walking down the street, the same person keeps getting hit by it.

865
01:04:38,057 --> 01:04:39,020
Speaker 1: They haven't learned their lesson.

866
01:04:39,340 --> 01:04:40,062
Speaker 1: It doesn't matter.

867
01:04:40,082 --> 01:04:44,549
Speaker 1: The stick person who's carrying the stick that way shouldn't be doing that.

868
01:04:44,569 --> 01:04:46,151
Speaker 1: They're creating a dangerous situation.

869
01:04:46,292 --> 01:04:51,480
Speaker 1: Even if I duck under it every single time and it never hits me even once, that's besides the point.

870
01:04:53,043 --> 01:04:56,752
Speaker 1: When you're trying to scam people, you're creating a danger.

871
01:04:56,993 --> 01:04:59,820
Speaker 1: You're attempting to harm others, so go fuck yourself.

872
01:05:00,241 --> 01:05:00,441
Speaker 0: Yep.

873
01:05:01,402 --> 01:05:15,620
Speaker 0: So, I don't know how to prevent people who fall for scams from falling for scams, but the best I can do is give you, the listener, advice and maybe you won't fall for a scam, but it really comes down to, if something seems too good to be true, it definitely is.

874
01:05:16,341 --> 01:05:18,163
Speaker 0: That is how almost all scams are.

875
01:05:18,544 --> 01:05:30,680
Speaker 0: If it is hard to make money and it's hard to find a job that pays a lot and you see a job posting that seems like it pays a lot lot and doesn't require any particular skills, that's a scam.

876
01:05:30,680 --> 01:05:33,544
Speaker 0: 100% that's a scam.

877
01:05:33,905 --> 01:05:40,040
Speaker 0: If there were jobs that paid you $4,000 a week and they don't have any requirements, guess what I'd be doing?

878
01:05:41,701 --> 01:05:45,267
Speaker 1: I think that if someone's a Geek Nights listener, I'm going to trust you're smart.

879
01:05:45,307 --> 01:05:47,752
Speaker 1: You're probably not falling for scams on your own.

880
01:05:47,772 --> 01:05:52,060
Speaker 1: You're probably hip to the internet and you know how to avoid scams on your own.

881
01:05:52,260 --> 01:06:08,140
Speaker 1: But the things that I think are relevant to a Geek Nights listener are A, you're going to get old and there may reach a point in your life where no matter how smart you are now, you are no longer capable of avoiding scams in your old age.

882
01:06:09,302 --> 01:06:16,960
Speaker 1: Because the world would be even more different than it is now and your mental faculties may or may not fade depending on your circumstances.

883
01:06:17,800 --> 01:06:22,627
Speaker 1: And what do you do now to prevent yourself from getting scammed in the future?

884
01:06:23,128 --> 01:06:31,980
Speaker 1: is you just have to put in financial planning in place so that no one can loot you no matter how foolish you become.

885
01:06:32,821 --> 01:06:47,960
Speaker 1: And the second thing you have to do is that even if you are wise and avoid scams, there are people in your life that you care about who may not be so wise and you need to protect them from scams.

886
01:06:48,561 --> 01:07:07,120
Speaker 1: And if all your efforts cannot protect them from scams, what you need to do is you simply basically need to, as much as it may discomfort you, you need to basically make sure that somebody close to you falling for scams doesn't hurt you.

887
01:07:09,983 --> 01:07:14,940
Speaker 0: Put your own mask on first before you put someone else's mask on in a plane that is depressurized.

888
01:07:15,481 --> 01:07:15,702
Speaker 1: Right.

889
01:07:15,722 --> 01:07:23,400
Speaker 1: So like let's say your parent is aging and they reach the point where they're, you know, you see them going to fall for scams, right?

890
01:07:23,840 --> 01:07:28,686
Speaker 1: It's like, well, A, try to educate them obviously, right?

891
01:07:29,167 --> 01:07:39,040
Speaker 1: If they can't, right, you're going to need to resort to like, you know, measures like, hey, maybe they shouldn't be allowed to control their own monies anymore if they're so vulnerable to scam.

892
01:07:39,461 --> 01:07:48,657
Speaker 1: And if you somehow can't do that, right, you need to just, you've done all that you can do to protect them from themselves and getting scammed.

893
01:07:48,757 --> 01:07:50,240
Speaker 1: And there's no more that you can do.

894
01:07:50,600 --> 01:07:56,089
Speaker 0: Two of the listener in the stream talked about how they got scammed in various ways.

895
01:07:56,229 --> 01:08:01,578
Speaker 0: And a third listener's parents are currently in the process of being scammed and they don't know what to do.

896
01:08:01,658 --> 01:08:02,740
Speaker 0: It's a widespread problem.

897
01:08:03,341 --> 01:08:03,962
Speaker 1: That's a shame.

898
01:08:04,203 --> 01:08:05,044
Speaker 1: That's right.

899
01:08:05,144 --> 01:08:14,120
Speaker 1: I think if you can't educate them and they can't learn their lesson and you can't protect them from themselves using any available legal means.

900
01:08:14,400 --> 01:08:19,950
Speaker 0: I mean, I had a friend in high school who fell for the Amway scam and I hate to say it, I had to befriend them.

901
01:08:19,970 --> 01:08:22,875
Speaker 0: Like I could not interact with them anymore.

902
01:08:23,055 --> 01:08:25,800
Speaker 0: They were gone and there was nothing I could do about it.

903
01:08:26,321 --> 01:08:31,830
Speaker 1: It's like, it sucks big time, especially if it's like, you know, like the listener, right, where your parents are being scammed.

904
01:08:31,850 --> 01:08:33,131
Speaker 1: They're like, it sucks big time.

905
01:08:33,553 --> 01:08:37,720
Speaker 1: But once you've done all you can do, you just have to protect yourself, right?

906
01:08:37,840 --> 01:08:42,529
Speaker 1: If the person being scammed comes and asks you for money, it's like, no, absolutely.

907
01:08:42,549 --> 01:08:45,495
Speaker 1: You bought a bunch of MLM stuff and you're trying to sell it to me.

908
01:08:45,795 --> 01:08:46,796
Speaker 1: No, right.

909
01:08:47,018 --> 01:08:48,100
Speaker 1: I'm not going to be a part of it.

910
01:08:48,439 --> 01:08:53,687
Speaker 1: And if you keep coming after me for it, it's like, I have no choice but to stop being in contact with you.

911
01:08:53,886 --> 01:08:54,187
Speaker 1: Right.

912
01:08:54,287 --> 01:08:54,428
Speaker 1: Yeah.

913
01:08:54,448 --> 01:09:04,380
Speaker 1: It's like if it gets that bad and no amount of education, if all the other measures do not work, then that's like, you know, it's really sad.

914
01:09:04,819 --> 01:09:05,060
Speaker 1: Right.

915
01:09:05,220 --> 01:09:12,113
Speaker 1: That basically some strange scammer person could like effectively steal away like people that you cared about from your life.

916
01:09:12,774 --> 01:09:14,598
Speaker 1: But there's no there's no other option.

917
01:09:14,618 --> 01:09:15,479
Speaker 1: that I'm aware of.

918
01:09:15,880 --> 01:09:23,020
Speaker 0: Because there's still that there's still the bad guy, like they are the one, the scammer who is causing the moral hazard in this case.

919
01:09:26,462 --> 01:09:27,042
Speaker 1: Yeah, you know,

920
01:09:27,283 --> 01:09:28,163
Speaker 0: in terms of not getting

921
01:09:28,224 --> 01:09:40,819
Speaker 1: not a lot you can do once, you know, especially if you don't, it's like you could try to spend money to go and like, you know, what, find the scammer and, you know, hire what, investigators or who knows what to try and go fight the scammer or something.

922
01:09:40,881 --> 01:09:42,399
Speaker 1: But it's like, now you're losing money.

923
01:09:43,300 --> 01:09:44,582
Speaker 0: Oh, no.

924
01:09:44,923 --> 01:09:47,728
Speaker 0: One of the listeners even someone they know someone who fell for the Amway scam.

925
01:09:47,768 --> 01:09:51,955
Speaker 0: And it got to the point in high school where even the teachers were like, kid, it's a scam.

926
01:09:52,055 --> 01:09:53,017
Speaker 0: It's not a job.

927
01:09:53,057 --> 01:09:54,840
Speaker 0: You got to guess it didn't work.

928
01:09:57,040 --> 01:09:57,521
Speaker 0: That's the.

929
01:09:57,621 --> 01:10:08,997
Speaker 0: that's the thing that I have no idea how to help with is, is there anything you can do to protect someone else who is scam vulnerable just broadly, like the kind of person who moves from scam to scam to scam?

930
01:10:09,037 --> 01:10:10,619
Speaker 0: I feel like there's literally nothing you can do.

931
01:10:12,181 --> 01:10:12,381
Speaker 1: Yeah.

932
01:10:12,602 --> 01:10:20,380
Speaker 1: I mean, if we knew if we knew something you could do right, there would be a lot less scammers out there already because people would be doing that thing.

933
01:10:20,580 --> 01:10:20,840
Speaker 0: Yeah.

934
01:10:22,523 --> 01:10:22,663
Speaker 1: Right.

935
01:10:23,624 --> 01:10:26,828
Speaker 1: It's like if there was an answer, the problem would would be gone.

936
01:10:26,848 --> 01:10:27,269
Speaker 1: Right.

937
01:10:27,369 --> 01:10:36,240
Speaker 0: If there was a it's like if there were jobs that paid four thousand dollars a week to do nothing from home with a high school diploma, everyone would have that job.

938
01:10:37,360 --> 01:10:39,303
Speaker 1: I think that's actually a good way to think about.

939
01:10:39,323 --> 01:10:42,947
Speaker 1: it is like if you how do you know something is too good to be true?

940
01:10:43,388 --> 01:10:43,688
Speaker 1: Right.

941
01:10:43,808 --> 01:10:53,920
Speaker 1: It's like be like, you know, say, you know how the world is as long as you're I guess if you're your image of how the world is, is wrong, then you're already in a bad place.

942
01:10:53,960 --> 01:10:54,181
Speaker 1: Yeah.

943
01:10:54,241 --> 01:10:59,600
Speaker 0: But you're already you know, you're going to be in a weird church chugging homeopathy from your Amway stock if you're like that.

944
01:10:59,740 --> 01:11:10,800
Speaker 1: But as long as your impression of how the world is is close to correct and you look at something and you say, would the world be different than it is if that were true?

945
01:11:11,700 --> 01:11:15,688
Speaker 0: Why hasn't anyone else invested in this weird penny stock?

946
01:11:15,909 --> 01:11:21,560
Speaker 0: How come how come my new friend on the Internet has told me and no one else about this opportunity?

947
01:11:22,480 --> 01:11:22,761
Speaker 1: Right.

948
01:11:22,841 --> 01:11:26,106
Speaker 1: It's like that sort of thing is like, would the world make it?

949
01:11:26,286 --> 01:11:29,350
Speaker 1: Does this make sense within the greater context of reality?

950
01:11:29,451 --> 01:11:29,771
Speaker 0: Yeah.

951
01:11:29,931 --> 01:11:30,913
Speaker 0: Right.

952
01:11:31,133 --> 01:11:31,734
Speaker 1: And that's how.

953
01:11:31,874 --> 01:11:35,940
Speaker 0: how are there people if there are jobs that pay four thousand dollars a week for no skills?

954
01:11:37,021 --> 01:11:37,201
Speaker 1: Yep.

955
01:11:37,842 --> 01:11:38,343
Speaker 1: Exactly.

956
01:11:38,664 --> 01:11:38,844
Speaker 1: Right.

957
01:11:39,185 --> 01:11:39,445
Speaker 1: Why?

958
01:11:40,066 --> 01:11:44,454
Speaker 1: If this is just a matter of me being lucky, why is it me that's lucky?

959
01:11:44,474 --> 01:11:45,055
Speaker 1: Yeah.

960
01:11:45,376 --> 01:11:46,438
Speaker 1: It could have been anybody.

961
01:11:46,618 --> 01:11:47,300
Speaker 1: Why is it me?

962
01:11:49,381 --> 01:12:02,240
Speaker 0: And I guess if you treat the world that way and have a relatively accurate view of the world, then the odds of you missing out on a good opportunity are still basically zero because there aren't really opportunities like that.

963
01:12:03,080 --> 01:12:03,720
Speaker 0: It's in general.

964
01:12:08,620 --> 01:12:10,970
Speaker 0: This has been Geek Nights with Rim and Scott.

965
01:12:11,010 --> 01:12:13,520
Speaker 0: Special thanks to DJ Pretzel for the opening theme.

966
01:12:13,740 --> 01:12:19,740
Speaker 1: Be sure to visit our website at frontrowclue.com for show notes, discussion, links and more.

967
01:12:20,221 --> 01:12:22,905
Speaker 0: Remember, Geek Nights is not one, but four different shows.

968
01:12:23,206 --> 01:12:24,869
Speaker 0: Mondays are science and technology.

969
01:12:24,909 --> 01:12:26,672
Speaker 0: Tuesdays, gaming and games.

970
01:12:26,792 --> 01:12:28,595
Speaker 0: Wednesdays are animation and comics.

971
01:12:28,916 --> 01:12:31,400
Speaker 0: Thursdays are arbitrary and indiscriminate.

972
01:12:32,100 --> 01:12:36,960
Speaker 0: Geek Nights is distributed under a Creative Commons Attribution 4.0 international license.

973
01:12:37,520 --> 01:12:41,770
Speaker 1: Geek Nights is recorded live with no studio and no audience.

974
01:12:42,272 --> 01:12:45,720
Speaker 1: But unlike those other late shows, it's actually recorded at night.

975
01:12:46,720 --> 01:13:08,360
Speaker 0: And the Patreon patrons for this episode of Geek Nights are Alan Joyce, Link Eiji, Jarett, Lily Tenebrae, Case Care, Makes the Music, Chris, Dodd, Christopher Orr, Clinton Walton, M, Def, Mac, Finn, Joel Hayes, Penny Reimer, Rebecca Dunn, Sam Erickson, Shervin Von Harl, a ton of people who give like a dollar and a ton of people who give nothing at all just to get access to that sweet RSS feed.

976
01:13:08,921 --> 01:13:10,062
Speaker 0: Yeah?

977
01:13:10,122 --> 01:13:13,107
Speaker 0: Keep opening requests, comments, thoughts about the website.

978
01:13:14,008 --> 01:13:22,120
Speaker 0: We plan to continue to invest into it heavily now that we've gotten the baseline live and we're going to start working on additional syndication from there.

979
01:13:22,880 --> 01:13:36,040
Speaker 0: So otherwise, tonight there's late hockey and I leave you simply with... Tonight on Unsolved Mysteries.

980
01:13:38,821 --> 01:13:44,660
Speaker 0: Two families move into an idyllic suburb only to discover that their homes lie on top of an abandoned graveyard.

981
01:13:45,580 --> 01:13:51,660
Speaker 0: Soon they are tormented by strange phenomena and threatening apparitions and are driven into a state of complete terror.

982
01:13:52,700 --> 01:13:57,480
Speaker 0: Are the spirits of the dead seeking vengeance on the living for the desecration of their graves?

