1
00:00:00,700 --> 00:00:03,240
Speaker 0: Well, I know you've all been waiting for it, but it's finally here!

2
00:00:03,360 --> 00:00:04,559
Speaker 0: We're beginning it this week!

3
00:00:05,080 --> 00:00:07,100
Speaker 1: This week is questions week!

4
00:00:07,300 --> 00:00:07,717
Speaker 1: All week!

5
00:00:08,200 --> 00:00:10,059
Speaker 1: We're gonna answer your questions, and you know what?

6
00:00:10,620 --> 00:00:14,898
Speaker 1: We're not gonna do anything else but answer your questions, 'cause there's so goddamn many of them.

7
00:00:15,520 --> 00:00:18,320
Speaker 0: And that's even after the, uh, culling of the herd, if you will.

8
00:00:18,800 --> 00:00:18,868
Speaker 1: Yep.

9
00:00:19,220 --> 00:00:19,998
Speaker 1: Now, some other notes.

10
00:00:20,420 --> 00:00:24,960
Speaker 1: Since there's no news or things of the day this week, I know there's big news and big things of the day going on.

11
00:00:24,980 --> 00:00:28,200
Speaker 0: We're well aware there's some vidya games that, uh, may need to be talked about.

12
00:00:28,340 --> 00:00:28,433
Speaker 0: Yeah.

13
00:00:28,940 --> 00:00:31,680
Speaker 1: But, uh, all that is gonna get pushed back, 'cause you know what?

14
00:00:31,680 --> 00:00:39,719
Speaker 1: We're not a source of news, we're a source of news commentary, so if you don't know what the news is, maybe you should read some websites, 'cause that's where we get the news from.

15
00:00:40,280 --> 00:00:42,020
Speaker 1: It's not like we're reporters or anything.

16
00:00:43,040 --> 00:00:52,800
Speaker 1: And secondly, when we answer these questions, first of all, there's so many questions, we might actually make, like, two episodes' worth of question answerings.

17
00:00:53,000 --> 00:01:02,179
Speaker 1: So if that happens, we're just gonna answer all of them, and maybe another episode in a coming week will, uh, be generated today, and then we'll be ahead a week, and it'll be pretty awesome.

18
00:01:02,561 --> 00:01:07,660
Speaker 0: Yeah, we'll see, we really don't know how long this would take, we just kinda went through the questions shoddily and quickly.

19
00:01:08,020 --> 00:01:08,155
Speaker 0: Yep.

20
00:01:08,800 --> 00:01:12,920
Speaker 1: Also, we're not giving anyone credit for the questions they ask during the episode.

21
00:01:13,060 --> 00:01:18,898
Speaker 1: You know who you are if we ask your question, so you'll still feel good when we ask it, unless we make fun of you.

22
00:01:19,741 --> 00:01:23,200
Speaker 1: Uh, and if you don't know who asked the question, do you really care?

23
00:01:23,300 --> 00:01:27,360
Speaker 1: And you can find out on the forum for most of them, and there are only a few email questions.

24
00:01:27,461 --> 00:01:29,579
Speaker 1: So, whatever, we don't, and it takes up too much time.

25
00:01:30,880 --> 00:01:39,782
Speaker 1: So if we answer, plus, you know, we wanna avoid the psychology of us, if we see that, you know, three questions were all asked by the same person, it'll take time to make fun of them, and

26
00:01:40,284 --> 00:01:41,268
Speaker 0: we don't wanna

27
00:01:41,308 --> 00:01:45,119
Speaker 1: waste time on stuff like that, or introduce extra psychology into our answers.

28
00:01:45,540 --> 00:01:50,559
Speaker 0: And also, we cut out a lot of the questions that people ask, and we're not gonna bother with them.

29
00:01:50,700 --> 00:01:59,278
Speaker 0: Now, don't feel bad, because on one hand, a lot of the questions we cut, we cut because they were too good and we're gonna turn them into entire shows that are gonna come up in the coming weeks.

30
00:01:59,921 --> 00:02:04,819
Speaker 1: Yeah, I never would've thought, it seems so weird that we keep asking for episode ideas, no one can give 'em.

31
00:02:05,060 --> 00:02:08,500
Speaker 1: We ask for questions, we get more episode ideas than when we ask for episode ideas.

32
00:02:08,680 --> 00:02:12,612
Speaker 0: And also, some of you tried to be cute and clever, and nah, we're gonna have none of that.

33
00:02:13,082 --> 00:02:13,172
Speaker 1: Nope.

34
00:02:14,061 --> 00:02:15,160
Speaker 1: So you wanna just get on with this?

35
00:02:15,243 --> 00:02:15,558
Speaker 1: Let's move.

36
00:02:15,780 --> 00:02:18,600
Speaker 0: Yeah, I'll start with the first one, because it's one that really only I can answer.

37
00:02:18,640 --> 00:02:19,540
Speaker 1: Let's just do 'em in order.

38
00:02:19,885 --> 00:02:20,038
Speaker 0: Alright.

39
00:02:20,680 --> 00:02:25,402
Speaker 0: Could you provide a detailed description of your amazing quote, "Make Rim and Scott sound cleverer"?

40
00:02:25,646 --> 00:02:26,540
Speaker 0: filter, unquote.

41
00:02:27,343 --> 00:02:28,680
Speaker 0: Or how to achieve such an effect.

42
00:02:28,820 --> 00:02:29,533
Speaker 0: Be cleverer.

43
00:02:31,300 --> 00:02:45,174
Speaker 0: Well, I'm not gonna get into how we do the show or the fact that we really don't edit at all anymore, but this magic filter that, I didn't actually name it that, I think it was Jeff Tataric who, I said something about it and he said, "Wow, it made me sound a lot cleverer than I really

44
00:02:45,337 --> 00:02:45,397
Speaker 0: am.".

45
00:02:45,580 --> 00:02:51,680
Speaker 0: But all it does, real simply, is it goes through our audio, and I set up a bunch of parameters.

46
00:02:51,821 --> 00:02:55,860
Speaker 0: I'm not gonna go into the specific parameters, because very specifically, it doesn't matter.

47
00:02:56,201 --> 00:02:57,840
Speaker 0: Those parameters wouldn't mean anything to you.

48
00:02:58,100 --> 00:02:59,440
Speaker 1: Way to say specific a bunch of times.

49
00:02:59,640 --> 00:03:00,599
Speaker 0: Yeah, I'm proud of that.

50
00:03:01,100 --> 00:03:06,120
Speaker 0: But they don't mean anything to you, because you'd have to have everything calibrated the way we do and talk the way we do.

51
00:03:06,160 --> 00:03:22,361
Speaker 0: But basically, it looks through the audio, and whenever it finds a silence that lasts a certain amount of time based on a certain way of detecting silence and way of detecting volume, it'll shorten that period of silence from the center in both directions by 40%.

52
00:03:22,361 --> 00:03:25,320
Speaker 0: So it'll shorten the pause time between sentences.

53
00:03:25,481 --> 00:03:26,539
Speaker 0: Not enough to be noticeable.

54
00:03:27,140 --> 00:03:29,774
Speaker 0: It doesn't, it's not like if I'm dumb and I just go,

55
00:03:29,794 --> 00:03:30,800
Speaker 0: "Ahh.".

56
00:03:31,146 --> 00:03:31,800
Speaker 0: It gets rid of that.

57
00:03:31,880 --> 00:03:32,699
Speaker 0: It leaves all that in.

58
00:03:33,340 --> 00:03:39,400
Speaker 0: All it does is cut out the time when we're breathing sometimes, or when there's a slight pause, and it's a really subtle effect.

59
00:03:39,760 --> 00:03:47,880
Speaker 0: If you listen to one and then listen to the other, you really, you'd be hard-pressed to tell, but it cuts a good 15 or 20 seconds out of the show, all told.

60
00:03:48,320 --> 00:03:48,395
Speaker 0: Yep.

61
00:03:48,960 --> 00:03:49,980
Speaker 1: Alright, next question.

62
00:03:50,462 --> 00:03:54,258
Speaker 1: "Can you give your own opinions on Booray versus HD

63
00:03:54,298 --> 00:03:54,579
Speaker 1: DVD?".

64
00:03:54,760 --> 00:03:59,080
Speaker 1: Well, Booray is clearly superior to everything else.

65
00:03:59,360 --> 00:04:03,160
Speaker 0: When you have that quantum ghost mechanics, you can just put basically infinite data there.

66
00:04:03,500 --> 00:04:05,380
Speaker 1: Yeah, it can go right through walls.

67
00:04:05,640 --> 00:04:10,239
Speaker 1: It can be transported instantly because you can use the netherworld as a sort of a wormhole.

68
00:04:10,500 --> 00:04:14,000
Speaker 0: The only problem with Booray is that whenever I try to put a disk in, it always flips over.

69
00:04:15,122 --> 00:04:15,330
Speaker 1: Ahh!

70
00:04:16,064 --> 00:04:17,560
Speaker 1: It won't play unless you put it backwards.

71
00:04:18,221 --> 00:04:18,678
Speaker 1: Okay, no.

72
00:04:19,122 --> 00:04:22,980
Speaker 1: Okay, so, Booray, obviously, is what you're asking about versus HD DVD.

73
00:04:23,200 --> 00:04:28,380
Speaker 1: My opinion is, personally, because I really don't care about HD at all.

74
00:04:28,620 --> 00:04:43,020
Speaker 1: I mean, the only reason I would consider getting an HD TV is because I want the computer that we have in the living room to actually display at a decent resolution other than 640x480 or whatever on the television in the living room.

75
00:04:43,581 --> 00:04:52,400
Speaker 1: I don't want to watch Booray DVDs, I don't want to watch HD DVDs, DVD is good enough for me, I don't have a surround sound system, I have the speakers in the TV, I don't care.

76
00:04:52,800 --> 00:05:02,340
Speaker 0: I guess part of it is that Booray and HD DVD, I mean, when DVD came out, it was such an improvement over VHS in so many ways.

77
00:05:02,580 --> 00:05:04,760
Speaker 1: Sort of the same way as CD was an improvement over a cassette.

78
00:05:04,880 --> 00:05:08,560
Speaker 1: You could skip around really easily, you could pause without jaggy lines.

79
00:05:08,661 --> 00:05:10,920
Speaker 0: It didn't melt if I left it in my car on a hot day.

80
00:05:10,920 --> 00:05:14,920
Speaker 1: You didn't get your VCR all jammed up, you know, you just put the disk, you didn't have to rewind.

81
00:05:15,361 --> 00:05:16,600
Speaker 1: It was amazingly better.

82
00:05:16,881 --> 00:05:22,440
Speaker 0: And I feel like DVD wasn't even near the end of its life when Booray and HD DVD came out.

83
00:05:22,540 --> 00:05:24,769
Speaker 0: and they're still way too expensive.

84
00:05:24,909 --> 00:05:27,800
Speaker 0: and the DVD, well, the mediums, they cost more.

85
00:05:28,420 --> 00:05:31,800
Speaker 1: The only improvement is video quality and amount of storage space.

86
00:05:32,000 --> 00:05:39,140
Speaker 1: You know what, in terms of storing data for data purposes, a hard drive is a lot better than buying a Booray drive with a bunch of disks.

87
00:05:39,260 --> 00:05:42,793
Speaker 0: And even you think, what if I want to archive my stuff and have an offline backup, you know what?

88
00:05:42,940 --> 00:05:43,278
Speaker 1: Hard drives.

89
00:05:43,420 --> 00:05:44,819
Speaker 0: Fill up a hard drive and unplug it.

90
00:05:44,922 --> 00:05:45,299
Speaker 0: God damn.

91
00:05:45,380 --> 00:05:49,360
Speaker 1: Yeah, just have a pile of hard drives in a little box in your closet or something.

92
00:05:49,760 --> 00:05:51,820
Speaker 1: Not even a NAS, just hard drives.

93
00:05:51,960 --> 00:05:59,860
Speaker 0: The other thing is, it's just that Booray and HD DVD, already there are theoretical standards that just kick the living shit out of them in terms of storage.

94
00:06:00,841 --> 00:06:08,432
Speaker 0: And technology's moving so fast that any sort of set media like that is becoming less and less relevant just because everything gets better.

95
00:06:08,532 --> 00:06:12,640
Speaker 0: and by the time you perfect one standard, a new one that's better is already on the horizon.

96
00:06:12,740 --> 00:06:25,639
Speaker 1: I think these are the last or second to last physical entertainment transfer media before we switch to just all digital transfer, TCP/IP, whatever, and it's gonna be the end of it.

97
00:06:26,120 --> 00:06:33,620
Speaker 1: What we really need is some sort of new digital movie format that's better than MPEG-4 where we can get higher quality videos in less space.

98
00:06:34,221 --> 00:06:40,860
Speaker 1: And that's the, 'cause think about it, if we could develop that, we might be able to get HD quality video onto a DVD of space.

99
00:06:40,961 --> 00:06:42,880
Speaker 1: That's where the action is, better compression.

100
00:06:43,260 --> 00:06:52,640
Speaker 0: And we're on our way now because, I mean, part of the reason why MP3 came into existence was just that processors were getting fast enough to decode.

101
00:06:53,080 --> 00:06:57,720
Speaker 0: Generally, the faster processors are, the more you can compress data because you have more processing.

102
00:06:57,720 --> 00:07:01,800
Speaker 1: Yeah, but there are limits in terms of, right now we're at the limit of our mathematics and not the limit of our processors.

103
00:07:01,860 --> 00:07:05,880
Speaker 0: Well, I think we're also getting to the limit of making this a short answer to a question.

104
00:07:05,980 --> 00:07:07,779
Speaker 1: Yes we are, so that's what we gotta say about that.

105
00:07:08,101 --> 00:07:09,159
Speaker 0: Alright, so moving on.

106
00:07:09,381 --> 00:07:10,460
Speaker 1: We're gonna alternate with the questions.

107
00:07:10,560 --> 00:07:14,120
Speaker 0: How long do you think Japan will stay ahead of the world in technology?

108
00:07:14,400 --> 00:07:16,620
Speaker 0: Now, there's a little bit of a false premise there.

109
00:07:16,760 --> 00:07:29,100
Speaker 0: I mean, there is the common perception that Japan is like the end-all, be-all of technology and that they're just so far ahead of the rest of the world and I believe that is true in terms of consumer technology.

110
00:07:29,440 --> 00:07:34,400
Speaker 1: Well, they're not, you know, they're ahead in, you know, but they're not like number one across the board.

111
00:07:34,480 --> 00:07:39,419
Speaker 1: There are other countries that have as high or higher technology than Japan in different areas.

112
00:07:39,520 --> 00:07:45,540
Speaker 0: Apart, a lot of like Scandinavian countries actually, they're on the forefront of particle physics and all sorts of things and honestly.

113
00:07:46,040 --> 00:07:49,260
Speaker 1: South Korea has a lot of fancy technologies too, don't put that down.

114
00:07:49,381 --> 00:07:50,259
Speaker 0: Even the United States.

115
00:07:50,740 --> 00:07:50,980
Speaker 0: Hong Kong.

116
00:07:51,140 --> 00:07:58,360
Speaker 0: I mean, consumer technology may not be up to snuff in the US, but our medical research and things like that are unparalleled in many fields.

117
00:07:59,408 --> 00:08:00,660
Speaker 0: It's really not fair.

118
00:08:00,761 --> 00:08:03,240
Speaker 1: You can't touch the US in the pharmaceuticals department, that's for sure.

119
00:08:03,260 --> 00:08:06,000
Speaker 0: It's not fair to say that Japan is ahead of the world in technology.

120
00:08:06,040 --> 00:08:21,500
Speaker 0: What I think you mean is why Japan is ahead in terms of, you know, consumer technology, internet stuff, and I think a lot of that perception comes from the fact that Japan culturally is a lot more kind of willing to accept and be on the forefront of consumer technology.

121
00:08:21,620 --> 00:08:23,760
Speaker 0: They're willing to pay a lot more for a lot less.

122
00:08:23,920 --> 00:08:30,060
Speaker 1: I think another part of it is that, you know, generally in terms of consumer technology, there's this thing where like smaller is better.

123
00:08:30,180 --> 00:08:31,240
Speaker 1: I went to the Apple store today.

124
00:08:31,440 --> 00:08:32,480
Speaker 1: Everything was fucking small.

125
00:08:32,720 --> 00:08:35,039
Speaker 1: Japan is the land that we need stuff to be small.

126
00:08:35,080 --> 00:08:40,379
Speaker 1: Therefore, technology will always advance because they're constantly trying to make things smaller there.

127
00:08:40,940 --> 00:08:45,476
Speaker 1: So they're always going to have the smallest, coolest stuff and that's just because they need to.

128
00:08:45,700 --> 00:08:47,840
Speaker 1: In the US, we don't even bother because you have so much space.

129
00:08:47,980 --> 00:08:50,620
Speaker 1: We're just like, yeah, computer the size of a barn.

130
00:08:50,760 --> 00:08:51,757
Speaker 1: That's okay with me.

131
00:08:52,241 --> 00:08:55,864
Speaker 0: It's kind of like the difference between New York City and Sterling Heights where I grew up.

132
00:08:56,100 --> 00:08:58,600
Speaker 0: In New York City, there's no parking lot.

133
00:08:58,822 --> 00:08:59,399
Speaker 0: There's nothing.

134
00:08:59,682 --> 00:09:00,640
Speaker 0: There isn't even space.

135
00:09:00,840 --> 00:09:02,658
Speaker 0: Everything's crammed in as much as it can be.

136
00:09:03,301 --> 00:09:06,680
Speaker 1: Where I grew up, Tokyo's twice as bad, supposedly, even though I've never been there.

137
00:09:06,981 --> 00:09:12,659
Speaker 0: Every store I've ever went to had its own parking lot that was bigger than like most buildings in New York City.

138
00:09:13,000 --> 00:09:17,080
Speaker 0: In fact, I could park like eight cars at my house because no one cared.

139
00:09:17,160 --> 00:09:19,999
Speaker 0: They just wasted the space because space was practically free.

140
00:09:20,320 --> 00:09:20,416
Speaker 0: Yeah.

141
00:09:20,520 --> 00:09:20,775
Speaker 1: All right.

142
00:09:21,360 --> 00:09:24,400
Speaker 1: What would be your ideal electronic reading device?

143
00:09:24,701 --> 00:09:26,360
Speaker 1: Books, comics, video photos.

144
00:09:26,420 --> 00:09:37,497
Speaker 1: Well, I'll tell you, my ideal device would be some sort of imperceptible implant into my brain so it appeared as if holograms are floating around me and I can control them with my thoughts.

145
00:09:39,264 --> 00:09:41,320
Speaker 0: Now, it's arguable whether or not that is electronic.

146
00:09:42,402 --> 00:09:43,580
Speaker 1: It could be electronic.

147
00:09:43,880 --> 00:09:44,116
Speaker 1: It could be.

148
00:09:44,383 --> 00:09:48,240
Speaker 1: It's a tiny... It's like one nanobot that flies into my brain.

149
00:09:49,000 --> 00:09:50,060
Speaker 1: There, there's the electronic part.

150
00:09:50,281 --> 00:09:50,859
Speaker 1: One nanobot.

151
00:09:52,543 --> 00:09:54,960
Speaker 0: That's... I mean, you asked ideal and that's ideal.

152
00:09:55,200 --> 00:09:55,290
Speaker 0: Yeah.

153
00:09:55,720 --> 00:09:56,076
Speaker 0: Practically...

154
00:09:56,160 --> 00:09:58,300
Speaker 1: We're going to answer every question literally.

155
00:09:58,581 --> 00:10:02,560
Speaker 0: But I will say, practically in my lifetime, what I would like is just a book.

156
00:10:03,281 --> 00:10:06,238
Speaker 0: A little book and when I flip the pages, I just...

157
00:10:06,561 --> 00:10:07,460
Speaker 1: You want a primer?

158
00:10:08,201 --> 00:10:08,759
Speaker 0: Yeah, basically.

159
00:10:09,000 --> 00:10:09,560
Speaker 0: I want a primer.

160
00:10:09,880 --> 00:10:09,980
Speaker 1: Yeah.

161
00:10:10,123 --> 00:10:19,140
Speaker 1: I want... I would like, though, some sort of floating hologram system, even if I had to reach out and touch it or if it was like... Like I sit down at my desk, I push a button, a bunch of holograms pop up all over the place.

162
00:10:19,220 --> 00:10:20,160
Speaker 1: I can grab them with my hands.

163
00:10:20,200 --> 00:10:21,439
Speaker 0: When I was a little... A kid and I was...

164
00:10:21,460 --> 00:10:22,640
Speaker 1: Grab and put them on my lap right on them.

165
00:10:22,660 --> 00:10:31,938
Speaker 0: I was watching Tenshi Muyo and I remember that Washu, the super scientist, was working on her computer and basically she snapped and then a keyboard appeared in her eyes that was just in front of her.

166
00:10:32,280 --> 00:10:37,719
Speaker 0: And then she had windows all over in the space around her head and she just dragged them around with her hand and was looking at them and I'd like that.

167
00:10:38,760 --> 00:10:38,960
Speaker 1: All right.

168
00:10:39,260 --> 00:10:39,435
Speaker 1: You go.

169
00:10:40,000 --> 00:10:40,280
Speaker 0: All right.

170
00:10:40,883 --> 00:10:41,297
Speaker 0: Let's see.

171
00:10:41,760 --> 00:10:44,920
Speaker 0: Did you ever do the old school overclocking of CPU's and video cards?

172
00:10:45,320 --> 00:10:47,200
Speaker 0: Did you think... And a follow-up question.

173
00:10:47,300 --> 00:10:53,920
Speaker 0: Do you think Dell would ever eventually walk down the path... Well, did I think Dell would ever walk down the path of overclocking for their customers?

174
00:10:53,940 --> 00:10:54,494
Speaker 1: So did they?

175
00:10:55,785 --> 00:11:09,297
Speaker 0: There have been... I don't know about Dell specifically because I would never really buy a Dell, but a lot of people who sell components have been marketing them as overclocked to some degree and there are more and more motherboards that say, "Check out our overclocked little

176
00:11:09,317 --> 00:11:09,740
Speaker 0: motherboard.".

177
00:11:09,821 --> 00:11:11,698
Speaker 0: But for the first question, I did.

178
00:11:12,480 --> 00:11:22,498
Speaker 0: Back in the Athlon 800 700 megahertz days, I bought a K7 800 megahertz and I overclocked it to a little under a gigahertz.

179
00:11:23,170 --> 00:11:29,659
Speaker 0: And there was a significant and noticeable performance increase, especially because I greatly increased my front side bus speed.

180
00:11:30,300 --> 00:11:46,460
Speaker 1: Back in the day, my Pentium 3450, the first computer I ever built and the computer I learned most of what I know about PCs on, at least hardware-wise, I overclocked it because I was learning about that stuff and it was sort of a learning experiment kind of hobby exercise and then I un-overclocked it because it made it unstable.

181
00:11:46,840 --> 00:11:56,620
Speaker 0: See, it didn't make my computer unstable and once I found... I figured out after a lot of testing exactly how much I could overclock it without it going unstable and I left it that way until it died.

182
00:11:57,120 --> 00:12:04,260
Speaker 0: And while the motherboard kind of caught fire and exploded, I actually learned later it had nothing to do with my overclocking.

183
00:12:04,380 --> 00:12:09,140
Speaker 0: It was that 8-bit espionage fake fluid in the capacitors problem.

184
00:12:10,560 --> 00:12:13,680
Speaker 0: But I think nowadays, to be honest, overclocking is stupid.

185
00:12:14,041 --> 00:12:24,960
Speaker 0: The incremental cost of getting a faster computer and also whether or not your software will actually give you a perceptible performance increase, very rarely is that the case.

186
00:12:25,460 --> 00:12:39,300
Speaker 1: The only times overclocking actually does something these days are those people who go all out and they freaking make some crazy cooling rig and they overclock something like to insane levels in their labs and that's not really practical for a normal human being.

187
00:12:39,582 --> 00:12:40,114
Speaker 0: Forget that!

188
00:12:40,340 --> 00:12:46,240
Speaker 0: If you have to buy extra cooling, it'll probably end up costing more than it would if you just buy the faster chip in the first place.

189
00:12:47,201 --> 00:12:53,060
Speaker 1: I guess it's good as like a hobby activity because you kind of learn something and it's kind of fun, but for practical purposes, you're wasting your time.

190
00:12:53,380 --> 00:12:54,420
Speaker 1: Which goes to the next question.

191
00:12:54,820 --> 00:12:59,960
Speaker 1: How do I overclock my laptop duo core processor and is it safe for the laptop?

192
00:13:00,682 --> 00:13:05,343
Speaker 1: Well, first, what we just said about overclocking still stands and for a laptop especially, no!

193
00:13:06,560 --> 00:13:09,360
Speaker 1: Laptops are like on the brink of like overheating.

194
00:13:09,400 --> 00:13:15,119
Speaker 1: They have the cooling in those things like so figured out, if you overclock it or somehow manage to do so.

195
00:13:15,300 --> 00:13:20,560
Speaker 0: Dude, if you just use a laptop too much, especially like a standard ThinkPad or whatever, it's gonna overheat.

196
00:13:20,620 --> 00:13:21,939
Speaker 0: Yeah, you put your laptop on your lap.

197
00:13:22,121 --> 00:13:22,679
Speaker 1: It's warm!

198
00:13:22,920 --> 00:13:26,040
Speaker 1: It's so warm that it can actually make you sterile if you're a man.

199
00:13:26,881 --> 00:13:32,217
Speaker 1: So if you overclock it, you're gonna break your laptop from overheating even if the CPU can handle it.

200
00:13:32,780 --> 00:13:33,939
Speaker 0: So seriously, don't do it.

201
00:13:34,480 --> 00:13:38,560
Speaker 0: Alright, so do those penis pills I get email offers for really work?

202
00:13:38,808 --> 00:13:39,058
Speaker 0: No.

203
00:13:40,301 --> 00:13:45,800
Speaker 1: In general, please explain this frozen light phenomenon, this Lynx, but I'm using a piece of paper because of my laptop.

204
00:13:46,000 --> 00:13:48,360
Speaker 0: Yeah, I'm also using a piece of paper because it's just easier.

205
00:13:48,780 --> 00:14:15,760
Speaker 0: I didn't actually follow the Lynx, but I'm pretty sure you're referring to that quantum computer thing that's been in the news lately where basically all this is, really simply, is if you fire light, which is comprised of photons, into a Bose-Einstein condensate, which is basically, you know, there's the forms of matter, you know, solid liquid gas, there's a state above gas, higher energy called plasma, and there's a state below solid called Bose-Einstein condensate.

206
00:14:16,240 --> 00:14:18,579
Speaker 0: I'm not gonna get into how they're formed, but they're really, really cold.

207
00:14:19,440 --> 00:14:39,638
Speaker 0: And if in certain conditions you shine light photons into a Bose-Einstein condensate, effectively the Bose-Einstein condensate will store the quantum state of the photon you fired in, you know, the spin and whatever, and then if you warm up or somehow release or get the Bose-Einstein condensate to regenerate a photon, it'll come out with the same quantum state it went in with.

208
00:14:40,080 --> 00:14:45,300
Speaker 0: So effectively you can make a quantum transistor with photons and a Bose-Einstein condensate.

209
00:14:45,920 --> 00:14:49,337
Speaker 0: The problem is, it takes insane amounts of energy and is very difficult to do, and...

210
00:14:49,840 --> 00:14:51,260
Speaker 1: It's gotta be fucking cold, woman!

211
00:14:51,520 --> 00:14:51,634
Speaker 0: Woman!

212
00:14:52,100 --> 00:14:53,340
Speaker 0: Space is one cold!

213
00:14:53,987 --> 00:14:54,180
Speaker 0: Alright.

214
00:14:54,402 --> 00:14:54,553
Speaker 1: Alright.

215
00:14:55,546 --> 00:14:56,220
Speaker 1: What's the next one?

216
00:14:56,840 --> 00:15:01,580
Speaker 1: Oh, "Many products that are made with nanoparticles, such as khakis that are stain and wrinkle resistant.

217
00:15:01,841 --> 00:15:07,216
Speaker 1: What is your opinion of nanotech in general, and do you think we'll ever see nanotech like Michael Crichton describes in his novel

218
00:15:07,257 --> 00:15:07,479
Speaker 1: Prey?".

219
00:15:07,600 --> 00:15:10,180
Speaker 1: Well, I didn't read Prey, so I don't know what you're talking about.

220
00:15:11,380 --> 00:15:12,320
Speaker 1: And nanotech.

221
00:15:12,781 --> 00:15:13,699
Speaker 1: Nanotech is cool.

222
00:15:14,400 --> 00:15:24,400
Speaker 1: Uh, I guess that grey goo stuff people talk about could maybe happen, possibly, if someone makes like a nanobot that self-replicates and tears apart anything at ease.

223
00:15:24,801 --> 00:15:26,979
Speaker 0: Yeah, but even then, there are viruses that try to do that.

224
00:15:27,281 --> 00:15:37,199
Speaker 1: But then again, you know, how fast would it really happen mathematically, and, you know, how, you know, what kind, it would take so many resources to do something like that just to start it off.

225
00:15:37,644 --> 00:15:38,500
Speaker 1: It'd be so difficult.

226
00:15:38,620 --> 00:15:42,980
Speaker 0: Well, I think there's also a common misconception as to what nanotechnology the word means.

227
00:15:43,080 --> 00:15:48,713
Speaker 0: 'Cause when people hear nanotech, they immediately think, "Tiny robots that rebuild my arm after it gets cut off with a

228
00:15:48,734 --> 00:15:49,080
Speaker 0: lightsaber.".

229
00:15:49,140 --> 00:15:52,720
Speaker 1: Nanobots, which is what we generally think of, are a subset of nanotech.

230
00:15:52,900 --> 00:15:55,460
Speaker 1: It's like this nanotech, and one part of nanotech is nanobots.

231
00:15:55,661 --> 00:15:58,859
Speaker 1: Nanopots is the part I'm interested in, which I like, but there are other parts too.

232
00:16:00,061 --> 00:16:09,280
Speaker 0: But like, when you see these things, like, "Oh, this is made with nanotechnology," all that really means is that they made a substance or a surface or something on a molecular level.

233
00:16:09,440 --> 00:16:15,319
Speaker 0: Meaning they made a new substance, or a new kind of surface, just by laying out atoms in a certain way.

234
00:16:15,843 --> 00:16:17,600
Speaker 0: And that's how these stain-resistant things worked.

235
00:16:17,680 --> 00:16:26,740
Speaker 0: And they're marketed as nanotech, partly because of the public conception of nanotech, and they probably know that people will see that word and think, "Oh man, tiny robots!

236
00:16:27,042 --> 00:16:27,812
Speaker 0: Oh man, I'm buying these

237
00:16:27,852 --> 00:16:28,257
Speaker 0: khakis!".

238
00:16:28,600 --> 00:16:34,460
Speaker 0: But on the same token, I own a lot of those khakis, and you know what?

239
00:16:34,961 --> 00:16:36,920
Speaker 0: They don't stain, and they don't wrinkle.

240
00:16:37,521 --> 00:16:41,180
Speaker 0: And I see a great future for technology like this.

241
00:16:41,240 --> 00:16:45,040
Speaker 0: It's kind of like how the space program brought us a bunch of great stuff, but you know what?

242
00:16:45,702 --> 00:16:46,859
Speaker 0: It also brought us Tang.

243
00:16:48,082 --> 00:16:52,500
Speaker 0: And you get a lot of very mundane technology from very sci-fi cool-sounding things.

244
00:16:52,600 --> 00:16:53,959
Speaker 0: This is just one aspect of that.

245
00:16:54,420 --> 00:16:54,740
Speaker 1: Alright, you go.

246
00:16:55,921 --> 00:16:56,980
Speaker 0: Alright, this question.

247
00:16:57,260 --> 00:17:02,533
Speaker 0: There were a bunch of questions people asked that were basically, "Hey Raymond Scott, something about science that you probably don't

248
00:17:02,594 --> 00:17:02,796
Speaker 0: know.".

249
00:17:03,280 --> 00:17:04,299
Speaker 1: Well, we know.

250
00:17:04,920 --> 00:17:08,940
Speaker 0: Why does a mirror appear to invert the left-right directions, but not the up-down?

251
00:17:09,104 --> 00:17:09,378
Speaker 1: I know.

252
00:17:10,022 --> 00:17:10,439
Speaker 0: Do you know?

253
00:17:10,579 --> 00:17:12,680
Speaker 0: I think everyone who's ever studied physics knows.

254
00:17:13,040 --> 00:17:15,499
Speaker 1: A mirror bounces light straight out.

255
00:17:15,781 --> 00:17:19,280
Speaker 1: So the light comes in, the light goes out the way it came in, directly.

256
00:17:19,720 --> 00:17:22,740
Speaker 0: So it doesn't invert left-right or up-down or anything.

257
00:17:22,839 --> 00:17:24,700
Speaker 0: It inverts front to back.

258
00:17:25,221 --> 00:17:35,300
Speaker 1: So if light bounces off your left arm and goes to the mirror, it then bounces straight back off the mirror, and thus you see your left arm on your left.

259
00:17:36,120 --> 00:17:43,518
Speaker 1: But normally when you look at a human being, their right arm is on your left because they're turned around looking at you.

260
00:17:43,880 --> 00:17:45,180
Speaker 1: And that's how it goes.

261
00:17:45,280 --> 00:17:51,058
Speaker 0: It's as though the image were put on a two-dimensional plane that was then inverted front to back and you view that.

262
00:17:51,701 --> 00:17:52,217
Speaker 1: That's how it works.

263
00:17:55,080 --> 00:18:00,160
Speaker 1: Why are the strengths of the fundamental forces, electromagnetism, weak and strong forces, and gravity what they are?

264
00:18:00,220 --> 00:18:07,120
Speaker 1: For example, why is the fine structure constant that measures the strength of electromagnetism about 1/137.036?

265
00:18:07,120 --> 00:18:10,840
Speaker 1: Where do such dimensionless constants come from, or is this an unanswerable question?

266
00:18:12,125 --> 00:18:13,220
Speaker 0: It's actually pretty simple.

267
00:18:13,780 --> 00:18:16,540
Speaker 0: Those are the four things because that's what we've observed.

268
00:18:17,180 --> 00:18:20,260
Speaker 0: Those numbers are what they are because that's what we've observed.

269
00:18:20,702 --> 00:18:23,300
Speaker 0: We've observed them as long as we've been observing these numbers.

270
00:18:23,601 --> 00:18:25,760
Speaker 0: The better we've been able to measure, the better they've been.

271
00:18:26,241 --> 00:18:27,560
Speaker 0: We see these numbers everywhere.

272
00:18:27,940 --> 00:18:29,200
Speaker 0: We see these forces everywhere.

273
00:18:29,664 --> 00:18:30,016
Speaker 0: It works.

274
00:18:30,882 --> 00:18:32,080
Speaker 1: It's not really a why.

275
00:18:32,703 --> 00:18:33,639
Speaker 1: That's the way it is.

276
00:18:33,760 --> 00:18:34,558
Speaker 1: That's what we see.

277
00:18:34,940 --> 00:18:37,160
Speaker 1: And it's like, why is a basketball orange?

278
00:18:37,740 --> 00:18:39,460
Speaker 1: Because you look at it and it looks orange.

279
00:18:40,266 --> 00:18:40,840
Speaker 0: It's arbitrary.

280
00:18:40,960 --> 00:18:42,479
Speaker 0: We've measured four kinds of forces.

281
00:18:42,601 --> 00:18:43,760
Speaker 0: We've never observed anything else.

282
00:18:43,840 --> 00:18:52,120
Speaker 0: We basically took everything we've observed, discovered that we can break them up into these four ways, and that if we just stick these numbers in, the math all works.

283
00:18:52,320 --> 00:18:52,532
Speaker 0: That's it.

284
00:18:52,780 --> 00:18:53,438
Speaker 1: There's no why.

285
00:18:53,660 --> 00:18:54,497
Speaker 1: It's just that's what it is.

286
00:18:55,222 --> 00:18:55,415
Speaker 0: All right.

287
00:18:55,980 --> 00:18:57,360
Speaker 0: Why is there an arrow of time?

288
00:18:57,621 --> 00:19:00,400
Speaker 0: That is, why is the future so much different from the past?

289
00:19:00,860 --> 00:19:02,900
Speaker 0: Well, why is the past so much different from the future?

290
00:19:04,043 --> 00:19:08,960
Speaker 0: We don't even really understand what time is, and time in some ways can act like a spatial dimension.

291
00:19:09,121 --> 00:19:13,240
Speaker 0: So whether or not there is an arrow of time doesn't matter.

292
00:19:13,740 --> 00:19:19,320
Speaker 0: We as thinking beings that may or may not just be the emergence of a complex system perceive time.

293
00:19:19,481 --> 00:19:21,077
Speaker 0: And as far as we know, that's the end of it.

294
00:19:22,881 --> 00:19:25,000
Speaker 1: Would you guys recommend a Mac to other people?

295
00:19:25,340 --> 00:19:32,520
Speaker 1: I would recommend a Mac to someone who knows nothing about computers, so they couldn't possibly like, you know, set one up very easily.

296
00:19:33,021 --> 00:19:40,840
Speaker 1: And they don't need to do anything that a Mac doesn't do, because there are many things a Mac doesn't do, like play games, record podcasts.

297
00:19:41,441 --> 00:19:59,099
Speaker 1: If you're just a normal user who's, you know, going to do some web browsing and some IMing and all that stuff and iTunes-ing, and you got money to burn and you're not interested in learning anything or doing, you know, doing anything difficult or anything at all, and you care what your computer looks like, then a Mac is for you.

298
00:19:59,562 --> 00:20:02,000
Speaker 0: Or if you need a little PC to go in your living room.

299
00:20:02,703 --> 00:20:03,279
Speaker 1: Yeah, I guess.

300
00:20:03,722 --> 00:20:11,719
Speaker 0: Or if you're an artist, because if you're an artist and you don't want to deal with the crap of a PC, all that software runs on the Mac just as well.

301
00:20:12,520 --> 00:20:15,180
Speaker 1: Well, at least Photoshop and some things, but some things don't.

302
00:20:15,380 --> 00:20:18,780
Speaker 0: Most of the things that artists are going to use, except for very specific fields.

303
00:20:19,741 --> 00:20:21,000
Speaker 0: Yeah, Macs are pretty cool.

304
00:20:21,201 --> 00:20:21,715
Speaker 0: I mean, we own one.

305
00:20:23,223 --> 00:20:23,293
Speaker 1: Yes.

306
00:20:23,940 --> 00:20:27,740
Speaker 0: Though audio too, as long as you're not doing exactly what we're doing.

307
00:20:29,783 --> 00:20:35,400
Speaker 0: Alright, this one might seem a little out there, but do you guys believe that humanity will eventually be able to live on other planets?

308
00:20:36,100 --> 00:20:36,798
Speaker 1: In other planets?

309
00:20:37,425 --> 00:20:37,758
Speaker 1: It says in.

310
00:20:38,140 --> 00:20:38,272
Speaker 0: Yes.

311
00:20:38,720 --> 00:20:39,479
Speaker 0: Probably not.

312
00:20:40,921 --> 00:20:44,260
Speaker 0: Well, maybe inside of a gas giant, like the cloud city.

313
00:20:44,800 --> 00:20:52,400
Speaker 1: I think the problem is not so much living in the planet or on the planet, but is getting there with the stuff to live there.

314
00:20:52,540 --> 00:20:54,900
Speaker 0: And there are really two main components to that.

315
00:20:55,322 --> 00:20:58,840
Speaker 0: Will humans be able to put forth that monumental effort?

316
00:20:58,980 --> 00:21:03,799
Speaker 0: I mean, we think, oh, we went to the moon, you know, so long ago in the 60s, how come we don't go back?

317
00:21:03,980 --> 00:21:12,140
Speaker 0: And I don't think people realize the sheer amount of human resource and opportunity costs and just money and time.

318
00:21:12,741 --> 00:21:13,083
Speaker 0: And it was.

319
00:21:13,344 --> 00:21:19,659
Speaker 0: it was one of the most concentrated and concerted efforts humanity's ever put forth to get to the moon once or twice.

320
00:21:20,881 --> 00:21:27,060
Speaker 0: And the moon is very, very, very close to us compared to any other planet out there.

321
00:21:28,180 --> 00:21:35,220
Speaker 0: And I think we could get there if, one, humans don't destroy each other, humans stop wasting resources on bullshit.

322
00:21:36,040 --> 00:21:38,700
Speaker 0: And even then, it might not be possible, like podcast.

323
00:21:39,663 --> 00:21:40,860
Speaker 0: It might even not be possible.

324
00:21:40,980 --> 00:21:46,436
Speaker 0: There might not be enough accessible energy in our planet to escape in any meaningful way.

325
00:21:46,823 --> 00:21:48,519
Speaker 0: It's very hard to know if we can or not.

326
00:21:49,162 --> 00:21:59,879
Speaker 0: And I think all we can do is try, because we have to think kind of, you know, that the famous sci fi short story, The Last Question, you always have to kind of think about, all right, what do we do in the long term?

327
00:21:59,960 --> 00:22:02,939
Speaker 0: And by the long term, I mean when the sun runs out.

328
00:22:04,301 --> 00:22:10,919
Speaker 0: And I don't know if humans with our short lifespans are relatively short lifespans compared to the world around us are capable of that.

329
00:22:11,000 --> 00:22:14,019
Speaker 0: And I want to be optimistic and say that we are.

330
00:22:14,161 --> 00:22:16,259
Speaker 0: But I'm also kind of pessimistic and think that we aren't.

331
00:22:17,260 --> 00:22:18,960
Speaker 0: Osamu Tezuka talks about that a lot.

332
00:22:19,060 --> 00:22:19,444
Speaker 0: He does.

333
00:22:19,485 --> 00:22:19,828
Speaker 1: All right.

334
00:22:20,596 --> 00:22:20,980
Speaker 1: Keep going.

335
00:22:21,641 --> 00:22:22,368
Speaker 0: All right.

336
00:22:22,388 --> 00:22:23,540
Speaker 0: What does it take on multivitamins?

337
00:22:23,760 --> 00:22:24,249
Speaker 0: Are they fluff?

338
00:22:24,270 --> 00:22:24,780
Speaker 0: Do we need them?

339
00:22:24,860 --> 00:22:27,040
Speaker 0: Are we getting everything we need from a proper, well-balanced diet?

340
00:22:27,200 --> 00:22:31,360
Speaker 0: Well, if you're eating a proper, well-balanced diet, then you don't need multivitamins.

341
00:22:31,840 --> 00:22:31,981
Speaker 1: Yeah.

342
00:22:32,162 --> 00:22:35,300
Speaker 1: I mean, there are certain vitamins that, yes, you need to eat them.

343
00:22:35,340 --> 00:22:38,940
Speaker 1: For example, if you never eat vitamin C, you will get scurvy.

344
00:22:39,122 --> 00:22:40,018
Speaker 1: That is the end of it.

345
00:22:40,220 --> 00:22:50,442
Speaker 1: So if you do not eat any oranges or fruits or anything with vitamin C in it, you should probably eat a vitamin C pill now and then consult a doctor for exactly how much and how often.

346
00:22:51,225 --> 00:22:56,345
Speaker 1: But in general, I think a lot of people take in multivitamins who also eat properly.

347
00:22:56,366 --> 00:22:58,280
Speaker 1: They you know, because they think they're all healthy.

348
00:22:58,360 --> 00:23:04,060
Speaker 1: They're getting a lot of extra vitamins, which can sometimes be good, sometimes not do anything at all, and sometimes be bad.

349
00:23:04,340 --> 00:23:05,399
Speaker 1: It's ask a nutritionist.

350
00:23:05,480 --> 00:23:06,084
Speaker 1: What do I look like?

351
00:23:06,144 --> 00:23:11,180
Speaker 0: I don't think multivitamins are terribly dangerous because they don't like they're not in and of themselves in overdose.

352
00:23:11,321 --> 00:23:16,360
Speaker 0: But I think the worst problem is people who take like a 10,000 percent dose of vitamin C. Yeah.

353
00:23:16,381 --> 00:23:20,523
Speaker 1: You see, yeah, like taking like a Flintstones vitamin you were in a kid is probably a good idea.

354
00:23:20,603 --> 00:23:25,160
Speaker 1: Taking like the 1000 milligram vitamin B is probably a bad idea.

355
00:23:25,240 --> 00:23:25,441
Speaker 1: Yeah.

356
00:23:25,562 --> 00:23:28,700
Speaker 0: And vitamin A is toxic in large quantities, like super toxic.

357
00:23:29,020 --> 00:23:29,181
Speaker 0: Yeah.

358
00:23:29,462 --> 00:23:33,900
Speaker 0: But I mean, I take a multivitamin about every three or four days.

359
00:23:34,041 --> 00:23:37,880
Speaker 0: And part of the reason I do that is just that I don't eat the best diet all the time.

360
00:23:37,960 --> 00:23:40,740
Speaker 0: And I know there's things I'm missing and I figure that kind of rounds me out.

361
00:23:40,780 --> 00:23:44,100
Speaker 0: If I'm if my body's really missing something, it'll get it from there.

362
00:23:44,320 --> 00:23:46,373
Speaker 1: I just don't take vitamins because I do it unless I had.

363
00:23:46,433 --> 00:23:47,862
Speaker 1: I mean, I'll get some Flintstones vitamins.

364
00:23:47,962 --> 00:23:48,204
Speaker 1: Yeah.

365
00:23:48,304 --> 00:23:52,312
Speaker 1: Oh, and if anyone tries to tell you the vitamin B 16 cures cancer, just kick him in the balls.

366
00:23:52,434 --> 00:23:52,678
Speaker 1: Yes.

367
00:23:52,941 --> 00:23:54,500
Speaker 1: If they have them, otherwise punch him in the face.

368
00:23:54,883 --> 00:23:55,658
Speaker 0: Oh, here's a good one.

369
00:23:56,761 --> 00:24:02,125
Speaker 1: OK, you mentioned before about how bad the aluminum and deodorant is and recommend the natural kind.

370
00:24:02,547 --> 00:24:05,000
Speaker 1: I couldn't find this at the local grocery store the last time I went.

371
00:24:05,100 --> 00:24:08,540
Speaker 1: Do you have a link or the name of the brand you use that you could share?

372
00:24:09,441 --> 00:24:12,820
Speaker 1: OK, so we don't recommend the, quote, natural kind.

373
00:24:12,900 --> 00:24:13,847
Speaker 1: What's the name of the chemical?

374
00:24:14,230 --> 00:24:15,580
Speaker 0: Oh, well, there's a bunch of chemicals.

375
00:24:15,860 --> 00:24:16,122
Speaker 1: Right.

376
00:24:16,264 --> 00:24:17,980
Speaker 0: But basically triclosan is one of them.

377
00:24:18,100 --> 00:24:18,865
Speaker 0: But that's also.

378
00:24:19,066 --> 00:24:21,179
Speaker 1: triclosan is not the one I'm thinking of.

379
00:24:21,340 --> 00:24:22,385
Speaker 0: Yeah, but there's a bunch.

380
00:24:22,606 --> 00:24:25,159
Speaker 0: You want generally it's always made of dipropylene glycol.

381
00:24:25,822 --> 00:24:26,588
Speaker 1: And that's the one.

382
00:24:26,749 --> 00:24:28,120
Speaker 0: And there's a bunch of other chemicals.

383
00:24:28,621 --> 00:24:30,180
Speaker 0: Really, all you need to look at is one.

384
00:24:30,701 --> 00:24:36,759
Speaker 0: You don't want something that says antiperspirant because that means it basically contains aluminum shards that plug your pores up.

385
00:24:37,001 --> 00:24:37,667
Speaker 1: That's how.

386
00:24:37,708 --> 00:24:39,020
Speaker 1: that's how antiperspirant works.

387
00:24:39,521 --> 00:24:46,980
Speaker 1: Pretty much any antiperspirant you buy at the store is shards of aluminum and they shred up your pores in your armpits or any other part.

388
00:24:47,200 --> 00:24:52,520
Speaker 0: Well, really, what they do is they react with the salts in your sweat and they form plugs that block your pores.

389
00:24:52,840 --> 00:24:53,749
Speaker 1: Yeah, it's not good.

390
00:24:53,972 --> 00:24:54,719
Speaker 1: It's bad for you.

391
00:24:54,840 --> 00:24:58,202
Speaker 1: And in fact, if you use antiperspirant a lot, the more you use it, the more you need it.

392
00:24:58,770 --> 00:24:59,460
Speaker 0: I'll give you an anecdote.

393
00:24:59,520 --> 00:25:04,079
Speaker 0: When I was a kid, I used to get super sweat and I had sweat stains all the time and I used antiperspirant and tried to stop that.

394
00:25:04,562 --> 00:25:08,080
Speaker 0: And if I didn't, if I didn't like smear antiperspirant, I got horrible sweat.

395
00:25:08,180 --> 00:25:10,480
Speaker 0: And then I started sweating through the antiperspirant, it was really bad.

396
00:25:11,200 --> 00:25:14,280
Speaker 0: I went to a doctor and he said, just stop using antiperspirant.

397
00:25:14,360 --> 00:25:15,960
Speaker 0: And I said, but then I'll sweat a lot.

398
00:25:16,020 --> 00:25:17,239
Speaker 0: He's like, yeah, for about a week.

399
00:25:17,661 --> 00:25:21,620
Speaker 0: And then your body will adjust and you'll sweat like a normal human being and you won't need antiperspirant anymore.

400
00:25:21,800 --> 00:25:26,540
Speaker 1: It's sort of like if your hair is oily just and, you know, you keep washing it gets oilier, you keep washing it gets oilier.

401
00:25:26,580 --> 00:25:30,200
Speaker 1: If you just let it stay oily for a few days, your head will just reabsorb the extra oil.

402
00:25:30,860 --> 00:25:35,500
Speaker 0: Well, it's more that your body will just kind of react and not do what Donnie Don't does.

403
00:25:35,800 --> 00:25:40,040
Speaker 1: Your head releases all that grease because you just washed all the grease away and your head goes, oh, my God, there's no grease.

404
00:25:40,460 --> 00:25:41,060
Speaker 1: Grease it up, woman.

405
00:25:41,800 --> 00:25:43,979
Speaker 1: Yeah, so get any grease.

406
00:25:44,520 --> 00:25:44,755
Speaker 1: So good.

407
00:25:45,081 --> 00:25:45,798
Speaker 0: I smell from it.

408
00:25:46,121 --> 00:25:47,540
Speaker 1: So just go to the grocery store.

409
00:25:47,800 --> 00:25:52,261
Speaker 1: I roll out anyway, buy anything that says deodorant and doesn't say antiperspirant on it.

410
00:25:52,301 --> 00:25:53,780
Speaker 1: It doesn't have to be natural.

411
00:25:54,141 --> 00:25:56,680
Speaker 1: That's just a word for marketing to try to trick hippies.

412
00:25:56,700 --> 00:26:00,400
Speaker 0: Basically, what you want is anything that can take is the way deodorant works.

413
00:26:00,700 --> 00:26:09,580
Speaker 0: Real deodorant is that it contains a bunch of chemicals that are usually harmless and they kill or inhibit the growth of bacteria.

414
00:26:10,040 --> 00:26:14,080
Speaker 0: As a result, the smelly bacteria, you still sweat, but the sweat doesn't smell.

415
00:26:14,462 --> 00:26:24,046
Speaker 0: And if you use deodorant and you still smell, then that means that you've got some sort of chemical imbalance or you're not eating enough and you're in the early stages stages of ketosis.

416
00:26:24,086 --> 00:26:25,660
Speaker 1: You should see a doctor or something.

417
00:26:25,801 --> 00:26:29,065
Speaker 0: Or I mean, if you're working out and losing weight, then that's just kind of the natural thing.

418
00:26:29,105 --> 00:26:30,059
Speaker 0: But yeah, yeah.

419
00:26:30,380 --> 00:26:34,620
Speaker 1: And I use a degree, the body heat activated, whatever.

420
00:26:34,820 --> 00:26:35,626
Speaker 1: I just pick a color.

421
00:26:35,646 --> 00:26:37,440
Speaker 1: There's like green, blue and different blue.

422
00:26:37,660 --> 00:26:40,080
Speaker 0: I use the Adidas barely scented deodorant.

423
00:26:40,200 --> 00:26:41,360
Speaker 1: Well, don't use the arm and hammer.

424
00:26:41,721 --> 00:26:42,940
Speaker 0: I also use the arm and hammer.

425
00:26:43,100 --> 00:26:43,180
Speaker 0: What?

426
00:26:43,201 --> 00:26:43,562
Speaker 0: You know what?

427
00:26:43,643 --> 00:26:47,000
Speaker 0: I use whatever you can get completely odorless deodorant.

428
00:26:47,182 --> 00:26:48,360
Speaker 0: All it is, is nanobacterial.

429
00:26:48,480 --> 00:26:49,435
Speaker 0: There's no smell at all.

430
00:26:49,940 --> 00:26:50,040
Speaker 1: Yeah.

431
00:26:50,462 --> 00:26:57,700
Speaker 1: And don't buy anything that's too like if it says like quartz crystal magic something or that's super hippie stuff that doesn't really work.

432
00:26:57,840 --> 00:27:01,660
Speaker 0: I mean, you can use certain kinds of salt crystals and they actually work really well.

433
00:27:01,820 --> 00:27:05,059
Speaker 0: The problem is they don't work as well as real deodorant, but they do work.

434
00:27:05,501 --> 00:27:07,440
Speaker 1: And so dipropylene glycol is what you're looking for.

435
00:27:07,620 --> 00:27:11,524
Speaker 0: And the ingredients, the ingredients, a lot of them have triclosan in them, just any kind of antibacterial.

436
00:27:11,544 --> 00:27:13,099
Speaker 1: Make sure the ingredients doesn't say aluminum.

437
00:27:13,500 --> 00:27:13,846
Speaker 1: All right.

438
00:27:14,252 --> 00:27:14,720
Speaker 1: Next question.

439
00:27:15,040 --> 00:27:15,361
Speaker 0: All right.

440
00:27:15,723 --> 00:27:20,999
Speaker 0: I have a hardware raid and I never could get Ubuntu outside of VMware because there weren't any drivers.

441
00:27:21,660 --> 00:27:23,160
Speaker 0: I came across some I'm paraphrasing.

442
00:27:23,582 --> 00:27:28,239
Speaker 0: I came across some source code, but I have no idea how to compile it, what to do with it if I do compile it.

443
00:27:28,501 --> 00:27:30,439
Speaker 0: Don't know anything about Linux I want.

444
00:27:30,800 --> 00:27:32,480
Speaker 0: So which is why I want to install it in the first place.

445
00:27:32,560 --> 00:27:33,489
Speaker 0: I can learn how to use it.

446
00:27:33,852 --> 00:27:34,680
Speaker 0: Any other option.

447
00:27:35,021 --> 00:27:36,460
Speaker 0: So I just emulate blah, blah, blah, blah, blah.

448
00:27:36,600 --> 00:27:43,100
Speaker 1: This is this is a common problem, not this particular thing, but in general that someone wants to do something right.

449
00:27:43,260 --> 00:27:46,420
Speaker 1: And if you just want to learn things one step at a time.

450
00:27:46,480 --> 00:27:51,854
Speaker 1: For example, a guy the other day was having a problem with like an HD access file on his web server.

451
00:27:51,895 --> 00:27:52,080
Speaker 1: Right.

452
00:27:52,440 --> 00:28:00,840
Speaker 1: And and, you know, if you already know a whole bunch of stuff and you just need to learn HD access files on their own, that's not a difficult concept to grasp.

453
00:28:00,960 --> 00:28:05,542
Speaker 1: The problem is you need a lot of prerequisite knowledge before you can learn that easily.

454
00:28:06,004 --> 00:28:21,040
Speaker 1: So unless you already know, like how to get around a Linux command line and how to compile a program and how to, you know, use make and how to, you know, you know your way around the Linux file system and how to configure a Linux kernel, then I can teach you how to do this very easily.

455
00:28:21,141 --> 00:28:22,740
Speaker 1: It's just, you know, one more thing to learn.

456
00:28:22,880 --> 00:28:25,012
Speaker 1: The problem is you don't know any of the prerequisite.

457
00:28:25,032 --> 00:28:26,822
Speaker 1: knowledge is like this mountain of knowledge.

458
00:28:27,044 --> 00:28:27,486
Speaker 1: The only.

459
00:28:27,526 --> 00:28:33,923
Speaker 1: you only want to know one thing, the thing in the top of the mountain and which is really easy once you're already a step away from the top of the mountain.

460
00:28:33,964 --> 00:28:35,199
Speaker 1: But you're at the bottom of the mountain.

461
00:28:35,601 --> 00:28:39,320
Speaker 1: So for me to teach you, I'd have to carry you up the whole mountain like a fucking Sherpa.

462
00:28:40,520 --> 00:28:52,459
Speaker 1: So either spend a whole lot of time learning a whole lot of stuff so that you can learn to build the Linux kernel and configure it and how to compile source code and everything or just keep using your VMware until someone does it for you.

463
00:28:53,241 --> 00:28:53,322
Speaker 1: I

464
00:28:53,382 --> 00:29:08,939
Speaker 0: hate to say this, but the simple answer, like Scott was saying, is basically just if you don't want to deal with all the crap about Linux and the Linux you try to install doesn't just work with your hardware without like or maybe just work with like really simple stuff you find on a forum somewhere.

465
00:29:10,120 --> 00:29:15,780
Speaker 0: I hate to say this, but it's probably not worth it to bother unless you really want to learn, in which case start climbing.

466
00:29:16,424 --> 00:29:16,808
Speaker 0: All right.

467
00:29:16,950 --> 00:29:17,779
Speaker 0: I think that's enough of that.

468
00:29:19,001 --> 00:29:24,242
Speaker 1: Well, how far off do you think we are from a world like that in the Ghost in the Shell universe?

469
00:29:24,685 --> 00:29:27,600
Speaker 1: What, if any, cyber enhancements would you guys get installed?

470
00:29:28,281 --> 00:29:32,400
Speaker 0: Well, we'll tackle the first one first, because this is something I think about a lot.

471
00:29:32,520 --> 00:29:44,920
Speaker 0: I really, really, really like the Ghost in the Shell universe and all the writing and the shows, the anime and everything, because I think it's a good balance of action and procedural cop stuff and hard, good sci-fi.

472
00:29:45,460 --> 00:29:46,118
Speaker 1: Yep, I like it, too.

473
00:29:46,281 --> 00:29:49,400
Speaker 0: Also, a lot of shirotasm, which means more things than you might think.

474
00:29:49,520 --> 00:29:54,740
Speaker 1: Not as much shirotasm as, say, Dominion or the most shirotastic Orion.

475
00:29:55,400 --> 00:29:59,400
Speaker 0: God, Dominion, where it's like funny, funny, funny, four pages of talking about that.

476
00:29:59,500 --> 00:30:07,000
Speaker 0: But anyway, the Ghost in the Shell universe is interesting because in some ways our world is nowhere near it or even close to it.

477
00:30:07,060 --> 00:30:14,417
Speaker 0: But in other ways, I think our world is already there or scarily closer to it than I'm almost comfortable with.

478
00:30:14,781 --> 00:30:15,102
Speaker 1: Yep.

479
00:30:15,503 --> 00:30:20,303
Speaker 0: I mean, in terms of the technology, like cyber brains and all that, that's a long ways off.

480
00:30:20,343 --> 00:30:23,240
Speaker 0: But at the same time, it's not as far off as you might think.

481
00:30:23,300 --> 00:30:27,060
Speaker 0: I don't think we're going to get there in our lifetime in terms of, you know, cyber brains and all that stuff.

482
00:30:27,180 --> 00:30:33,443
Speaker 0: But at the same time, I really think we're only a generation or two away from a world like that.

483
00:30:34,447 --> 00:30:37,080
Speaker 1: Now, what cyber enhancements would I get installed personally?

484
00:30:37,461 --> 00:30:40,240
Speaker 1: Like, I think it's cool, you know, people with cyber stuff.

485
00:30:40,500 --> 00:30:41,123
Speaker 1: That's awesome.

486
00:30:41,184 --> 00:30:46,380
Speaker 1: But I'm like the thing that I. the only thing I fear is, like, you know, like surgeries and medical action.

487
00:30:46,680 --> 00:30:58,700
Speaker 1: So I would really fear getting any sort of unnecessary medical surgery, especially some sort of electronic like the things that I would want to like, you know, Internet in the brain would be really dangerous.

488
00:30:58,780 --> 00:31:02,580
Speaker 1: Like what if there's, you know, a bug problem, a virus or, you know, I don't want that.

489
00:31:02,862 --> 00:31:04,159
Speaker 1: You know, it's too risky for me.

490
00:31:04,480 --> 00:31:09,399
Speaker 0: So, well, it's like in Ghost in the Shell where the people who have a cyber brain every now and then the major hacks then.

491
00:31:09,680 --> 00:31:10,042
Speaker 1: Yeah.

492
00:31:10,062 --> 00:31:15,079
Speaker 1: And it's like their control software for their arm doesn't work, so they need to upgrade it or, you know, stuff like that.

493
00:31:15,380 --> 00:31:17,480
Speaker 0: So, well, I think for me, I would be like Togusa.

494
00:31:17,660 --> 00:31:19,300
Speaker 1: I would hold off as long as possible.

495
00:31:19,540 --> 00:31:19,620
Speaker 0: Yeah.

496
00:31:19,842 --> 00:31:32,418
Speaker 0: I think for me, it's more that, well, I'll assume the Ghost in the Shell universe is true because the one thing about this universe that I find interesting is that there's a lot of questions about what is consciousness and what is there a soul?

497
00:31:32,458 --> 00:31:35,300
Speaker 0: and if there is, like what defines it and all that sort of thing.

498
00:31:35,400 --> 00:31:54,544
Speaker 0: And if you go with what the Ghost in the Shell universe's science works like, meaning consciousness is a thing that can be transferred verifiably, then I would probably when I was old or when my body was dying or I would totally just dump my consciousness into a cyborg.

499
00:31:54,947 --> 00:31:56,680
Speaker 1: Oh, if I'm dying, everything changes.

500
00:31:56,840 --> 00:32:03,700
Speaker 0: Even if I wasn't dying, I could see myself going fully cyberized relatively early because if I'm old, everything changed.

501
00:32:03,880 --> 00:32:09,820
Speaker 0: Even if I wasn't old, even now, when I got, you know, my mid 20s, I'd already be thinking about fully cyberizing.

502
00:32:09,941 --> 00:32:11,178
Speaker 1: No, I wouldn't be doing that now.

503
00:32:11,540 --> 00:32:11,681
Speaker 1: But

504
00:32:12,344 --> 00:32:33,969
Speaker 0: on a more fundamental level, back to the first part of the question, while we're not there in terms of technology, in terms of the social theory of the Ghost in the Shell universe and information dissemination and a lot of what they talk about in terms of terrorism and ideas and memes and, you know, second order simulacra and all those, you know, phenomenon and social theory that they talk about,

505
00:32:34,893 --> 00:32:34,973
Speaker 1: I

506
00:32:35,133 --> 00:32:37,983
Speaker 0: see those things happening in our world now.

507
00:32:38,023 --> 00:32:47,600
Speaker 0: And I think that the world right now in 2007, if you really watch Ghost in the Shell, is scarily similar to that in terms of how ideas disseminate.

508
00:32:47,700 --> 00:32:52,100
Speaker 0: And I think that our world is changing a lot faster than a lot of us realize.

509
00:32:52,824 --> 00:32:53,068
Speaker 1: All right.

510
00:32:53,088 --> 00:32:53,840
Speaker 1: That's a nice question.

511
00:32:54,140 --> 00:32:54,362
Speaker 0: All right.

512
00:32:54,884 --> 00:32:59,857
Speaker 0: If you guys had the choice of any one hard science to study and get into, no matter how broad or specialized, what would you pick?

513
00:32:59,877 --> 00:33:00,179
Speaker 0: and why?

514
00:33:00,740 --> 00:33:00,923
Speaker 1: Physics?

515
00:33:01,004 --> 00:33:02,120
Speaker 1: It's the only hard science.

516
00:33:02,861 --> 00:33:03,685
Speaker 1: Physics.

517
00:33:03,705 --> 00:33:06,980
Speaker 0: I would argue that all science boils down to physics in the end.

518
00:33:07,000 --> 00:33:07,162
Speaker 1: Yeah.

519
00:33:07,183 --> 00:33:08,340
Speaker 1: Biology is organic.

520
00:33:08,380 --> 00:33:10,020
Speaker 1: Chemistry is chemistry is physics.

521
00:33:10,320 --> 00:33:15,820
Speaker 0: To me, chemistry is literally just a kind of simpler, simplified macro view of physics.

522
00:33:15,860 --> 00:33:19,580
Speaker 0: It's like we look at it at a high level and it works, but it can all be explained physically.

523
00:33:19,980 --> 00:33:20,698
Speaker 1: Bring it on, biologists.

524
00:33:20,901 --> 00:33:23,979
Speaker 1: I know you're going to come at me on this one, but physics is the only hard science.

525
00:33:24,060 --> 00:33:24,562
Speaker 1: end of story.

526
00:33:24,642 --> 00:33:28,280
Speaker 0: And honestly, I was really good at physics and I almost went into it.

527
00:33:28,640 --> 00:33:29,483
Speaker 1: I was OK.

528
00:33:29,523 --> 00:33:36,260
Speaker 0: I mean, I I had physics parties in high school and calculus parties and I was super into like integrating stuff for fun.

529
00:33:36,780 --> 00:33:38,679
Speaker 0: And that sounds really nerdy, but fuck you.

530
00:33:39,963 --> 00:33:40,649
Speaker 0: All right.

531
00:33:40,951 --> 00:33:41,960
Speaker 0: Oh, I guess you can do this.

532
00:33:42,100 --> 00:33:46,766
Speaker 1: What do you think is the biggest technological problem humans will face in the coming years?

533
00:33:46,907 --> 00:33:47,980
Speaker 0: I think that's a really good question.

534
00:33:48,360 --> 00:33:49,600
Speaker 1: Yeah, it is a really good question.

535
00:33:49,681 --> 00:33:50,860
Speaker 1: And it's kind of tough.

536
00:33:51,201 --> 00:33:56,724
Speaker 1: I mean, there could be a few technological problems because the problem is, is things we don't know now.

537
00:33:56,764 --> 00:33:59,720
Speaker 1: Like if I knew now, well, I guess then it wouldn't be a problem.

538
00:33:59,860 --> 00:34:02,540
Speaker 1: Like it could be running out of energy.

539
00:34:02,600 --> 00:34:08,237
Speaker 1: It could be, I don't know, we can't get we can't make.

540
00:34:08,317 --> 00:34:12,800
Speaker 1: it could be the fact that just technology slows down, like it stops improving because we hit some sort of wall.

541
00:34:13,222 --> 00:34:15,600
Speaker 1: You know, we can't make these transistors any smaller.

542
00:34:15,719 --> 00:34:17,099
Speaker 1: We've hit our limit of what we can do.

543
00:34:17,420 --> 00:34:17,500
Speaker 0: Yeah.

544
00:34:17,520 --> 00:34:23,978
Speaker 0: I mean, ignoring non-technical, like purely tech problems, ignoring humanity and all the crap we do to each other all the time.

545
00:34:25,281 --> 00:34:29,100
Speaker 0: My guess and I mean, this is there's no way to answer this with any authority.

546
00:34:29,541 --> 00:34:36,940
Speaker 0: My random guess would be that energy is going to be the biggest problem we're going to face in the coming years, like in the near future.

547
00:34:37,840 --> 00:34:46,480
Speaker 0: Long term, I think the problem we're going to face is that it takes increasing amounts of energy to observe smaller and smaller particles and quantum things.

548
00:34:47,179 --> 00:34:53,480
Speaker 0: And I think we're going to get to the point where it becomes prohibitively difficult to observe smaller quanta.

549
00:34:53,920 --> 00:35:01,657
Speaker 1: In the long run, I think the general problem is going to be limits, like, for example, limits to how much data we can get per square inch or per square centimeter.

550
00:35:01,677 --> 00:35:06,903
Speaker 1: or once we hit the limit, we can't get any more data in any less space, no matter how much we compress it.

551
00:35:07,305 --> 00:35:10,380
Speaker 1: Then we still might need to store even more data.

552
00:35:10,440 --> 00:35:13,560
Speaker 1: We're just going to run out of physical room and there's nothing we could do about it.

553
00:35:13,780 --> 00:35:31,300
Speaker 0: See, there's a there's this whole theory of the the simulation hypothesis that if we understood the physics of our world perfectly, then we could create an emulator of our physics, then there's nothing to say that a higher that we couldn't just be a simulation and someone else's world somewhere and all that business.

554
00:35:31,961 --> 00:35:50,280
Speaker 0: But there's an alternative idea as a kind of a corollary or a question that goes along those lines that it's possible that the amount of energy it takes to make those calculations is, in effect, the combined effort of the universe as a whole, meaning that the emulation is the system itself.

555
00:35:50,402 --> 00:35:51,320
Speaker 0: And it's kind of the circular.

556
00:35:51,340 --> 00:35:54,780
Speaker 1: Well, that's the the assumptions that we want to emulate our existing universe.

557
00:35:54,880 --> 00:35:59,920
Speaker 1: We could emulate a smaller part of the universe and then the things in that universe would say, is there a limit to our universe?

558
00:36:00,001 --> 00:36:01,899
Speaker 1: And we'd be like, yes, it's only like two solar systems.

559
00:36:02,060 --> 00:36:02,743
Speaker 1: That's all we can do.

560
00:36:02,904 --> 00:36:10,440
Speaker 0: But I guess what Scott was getting at is that the longest term problem I think humanity is going to face are like Scott was getting at those hard constants.

561
00:36:10,620 --> 00:36:18,199
Speaker 0: I mean, quite literally, I think the end run of humanity is going to be the second law of thermodynamics, Planck's constant and the speed of light.

562
00:36:18,943 --> 00:36:22,599
Speaker 0: And I don't think we have the capability of thinking beyond that.

563
00:36:23,855 --> 00:36:23,896
Speaker 0: OK.

564
00:36:23,916 --> 00:36:24,100
Speaker 0: All right.

565
00:36:24,601 --> 00:36:28,800
Speaker 0: What do you think are some important non tech skills in the tech world job school?

566
00:36:30,441 --> 00:36:33,740
Speaker 0: Talking to people, communication, number one, far and away.

567
00:36:33,920 --> 00:36:39,383
Speaker 0: If you can't give a business presentation without getting nervous, if you can't write effectively, if

568
00:36:39,725 --> 00:36:47,665
Speaker 1: you can't go up and if you're a technologist, if you can't go up to a non technologist, talk to them and figure out what the hell they really want, that's going to be a problem.

569
00:36:48,550 --> 00:36:50,440
Speaker 1: Some manager is going to come up and tell you to do something.

570
00:36:50,560 --> 00:36:51,525
Speaker 1: You're going to be sitting there.

571
00:36:51,545 --> 00:36:55,045
Speaker 1: The third or the second thing I think you need to do is research.

572
00:36:55,326 --> 00:36:57,560
Speaker 1: You need to be able to learn shit fast.

573
00:36:57,820 --> 00:36:57,981
Speaker 0: Yes.

574
00:36:58,081 --> 00:37:12,100
Speaker 0: Like that's one thing that was great about going to RIT is when we learned about routing and switching, we didn't learn jack all about Cisco and they avoided talking about the specifics of any implementation of pretty much any technology at all.

575
00:37:12,682 --> 00:37:22,420
Speaker 0: And the point they made was that if you know the fundamentals of coding, of networking, of anything computer wise, then it's trivial to learn the specifics of any one protocol.

576
00:37:22,700 --> 00:37:24,940
Speaker 1: Like I learned object oriented programming.

577
00:37:25,080 --> 00:37:30,800
Speaker 1: They taught it with Java, but they taught us object oriented programming in class and the fundamentals thereof.

578
00:37:30,961 --> 00:37:35,460
Speaker 1: So I could get a book with an animal on it for any object oriented programming language.

579
00:37:35,800 --> 00:37:40,944
Speaker 1: Look in the book to get the syntax and I can write software in any object oriented programming language.

580
00:37:41,105 --> 00:37:44,140
Speaker 0: I learned routing and switching and network design.

581
00:37:44,542 --> 00:37:47,900
Speaker 0: It doesn't matter if I'm using Cisco or Linux boxes with Nix in them.

582
00:37:48,041 --> 00:37:48,970
Speaker 0: I know the fundamentals.

583
00:37:49,071 --> 00:37:50,040
Speaker 0: I can make anything network.

584
00:37:50,420 --> 00:37:51,740
Speaker 1: So research and communications.

585
00:37:52,223 --> 00:37:52,485
Speaker 1: OK.

586
00:37:53,110 --> 00:37:54,240
Speaker 0: Oh, this is a good one for Scott.

587
00:37:54,380 --> 00:37:58,440
Speaker 1: What do you think about a the technological singularity?

588
00:37:58,580 --> 00:38:00,079
Speaker 1: Is it possible we reach it?

589
00:38:00,443 --> 00:38:01,680
Speaker 1: If so, in our lifetime.

590
00:38:01,820 --> 00:38:02,121
Speaker 1: All right.

591
00:38:02,865 --> 00:38:12,859
Speaker 1: This is an interesting idea to think about the technological singularity, the idea that, you know, somehow I guess an Evangelion type of thing, they'll be like Google will become God or some shit like that.

592
00:38:12,960 --> 00:38:14,640
Speaker 1: And all the knowledge will join together.

593
00:38:14,900 --> 00:38:20,726
Speaker 0: It's like the idea of could humanity, because of information sharing or because of information technology, not

594
00:38:20,867 --> 00:38:21,289
Speaker 0: I.T.,

595
00:38:21,309 --> 00:38:28,574
Speaker 0: but like information technology in a broad sense, fundamentally change humanity kind of to the point that a human today couldn't comprehend it.

596
00:38:28,615 --> 00:38:28,799
Speaker 1: Right.

597
00:38:30,642 --> 00:38:37,400
Speaker 1: The people who are going around like, oh, it's coming, it's coming like that Ray Kurzweil asshole, you're all full of shit and you're a bunch of nut jobs.

598
00:38:37,780 --> 00:38:37,941
Speaker 1: Right.

599
00:38:38,102 --> 00:38:40,920
Speaker 1: It's one thing to say, oh, this is interesting to think about, like The Matrix.

600
00:38:41,220 --> 00:38:43,899
Speaker 1: Oh, this is interesting to think about, to say we're in it for sure.

601
00:38:44,200 --> 00:38:44,708
Speaker 1: It's coming.

602
00:38:44,851 --> 00:38:45,339
Speaker 1: We're in there.

603
00:38:45,981 --> 00:38:46,832
Speaker 1: You're a nut job.

604
00:38:47,054 --> 00:38:47,520
Speaker 1: Go home.

605
00:38:47,902 --> 00:38:48,164
Speaker 1: I'm tired.

606
00:38:48,345 --> 00:38:48,688
Speaker 0: I'll make.

607
00:38:48,728 --> 00:38:50,080
Speaker 0: this point is a point I make a lot.

608
00:38:50,180 --> 00:39:00,380
Speaker 0: If you took a scholar from ancient Rome or hell, Greece, ancient Greece, and you took them to our modern world and they would look around and say, that's a road.

609
00:39:00,722 --> 00:39:01,820
Speaker 0: That's some kind of chariot.

610
00:39:02,101 --> 00:39:02,788
Speaker 0: That's a house.

611
00:39:03,071 --> 00:39:03,900
Speaker 0: That's a bathroom.

612
00:39:04,341 --> 00:39:08,440
Speaker 0: They I don't think humans are that fundamentally different from those humans.

613
00:39:08,620 --> 00:39:20,000
Speaker 0: And if there was a technological singularity, I think that the the last one that happened was probably cavemen to hunter gatherer, like something that fundamental.

614
00:39:22,005 --> 00:39:22,186
Speaker 1: Yeah.

615
00:39:22,306 --> 00:39:28,125
Speaker 0: OK, it's just that technological singularity is a lot of technobabble and not a lot of actual.

616
00:39:28,667 --> 00:39:33,108
Speaker 1: it's kind of like the stuff of Neil Stevenson novels and not the stuff of the real world.

617
00:39:33,612 --> 00:39:34,157
Speaker 0: Oh, here we go.

618
00:39:35,300 --> 00:39:41,603
Speaker 0: Would did the Native Americans treat trade with the Europeans in when they first made contact?

619
00:39:41,844 --> 00:39:44,960
Speaker 0: What that sentence was a masterpiece.

620
00:39:46,001 --> 00:39:46,343
Speaker 1: OK.

621
00:39:46,383 --> 00:39:53,120
Speaker 0: In what ways did the two cultures differ in trading technology and how did the trade practice affect the dissemination of technology among Native Americans?

622
00:39:53,721 --> 00:39:54,365
Speaker 0: Blah, blah, blah, blah.

623
00:39:54,385 --> 00:39:57,919
Speaker 1: This sounds like someone's asking us the question from their homework that they have to write an essay on.

624
00:39:58,040 --> 00:40:00,060
Speaker 0: I'm not going to answer the question, but I do.

625
00:40:00,160 --> 00:40:07,940
Speaker 0: I'm going to make the point that it kind of relates to the previous question in that there seems to be this trend in humanity for as long as humans have existed.

626
00:40:08,943 --> 00:40:12,460
Speaker 0: And I never really thought about it much until the other day.

627
00:40:12,883 --> 00:40:15,160
Speaker 0: I have this book that's a collection of essays on colonialism.

628
00:40:15,401 --> 00:40:23,039
Speaker 0: And I was reading about the ancient Egyptians and their colonial relationship with what was effectively called Nubia or miserable Kush.

629
00:40:25,080 --> 00:40:27,480
Speaker 0: And I'm not going to get into that, but it's kind of funny.

630
00:40:28,102 --> 00:40:42,419
Speaker 0: But it seems that the history of humanity has always had this pattern of one culture will be effectively beyond another culture in all ways in terms of civilization, in terms of technology, in current terms of strength.

631
00:40:43,301 --> 00:40:53,300
Speaker 0: And I don't think there has really ever been a case where a very primitive society has met with a relatively advanced society and come out better for it.

632
00:40:53,860 --> 00:40:54,001
Speaker 1: Yeah.

633
00:40:54,022 --> 00:40:55,859
Speaker 1: I mean, and you really think about this, right?

634
00:40:56,602 --> 00:41:08,542
Speaker 1: If aliens, let's say extraterrestrials of some sort, come to Earth and they are an advanced race that is that is to us the same way that, say, colonial Europeans were to Native Americans.

635
00:41:09,084 --> 00:41:16,440
Speaker 1: That's what's going to happen to us most likely unless the aliens are just so different from humanity in ways we can't comprehend currently.

636
00:41:17,381 --> 00:41:20,660
Speaker 0: And also, I mean, from I don't I don't want to get into it.

637
00:41:20,680 --> 00:41:34,100
Speaker 0: I could do a whole show about this crap, but I don't know how I feel about these sort of interactions, because on one hand, I almost weep at the horrible things that colonial powers have done to primitive people pretty much as long as humanity's existed.

638
00:41:34,260 --> 00:41:37,140
Speaker 0: I mean, the ancient Greeks got rid of the natives there.

639
00:41:37,260 --> 00:41:44,200
Speaker 0: And, you know, there's the dark invasions and that, you know, when Britain colonized India, not much good came of that and then partition.

640
00:41:44,320 --> 00:41:44,963
Speaker 0: That was horrible.

641
00:41:45,906 --> 00:41:58,200
Speaker 0: But on the other hand, and I hate to say this, but I look at these civilizations that were so, I guess, relatively primitive and I wonder if we're better off having been civilized or not.

642
00:41:58,380 --> 00:42:00,339
Speaker 0: And sometimes I feel yes and sometimes I feel no.

643
00:42:00,640 --> 00:42:01,985
Speaker 0: Unabomber.

644
00:42:02,306 --> 00:42:04,515
Speaker 0: I look at the great works that civilization like

645
00:42:04,736 --> 00:42:05,157
Speaker 1: the Roman

646
00:42:05,238 --> 00:42:22,520
Speaker 0: Empire, the Byzantine Empire, the Greeks, the Egyptians, the Persians and the ancient China and, you know, the art and the literature and all these beautiful things and the civilization that none of this could have happened without the kind of subjugation and conquering of the weaker powers around.

647
00:42:23,262 --> 00:42:27,443
Speaker 0: And I don't know, it's a complicated issue and I can't talk about more without derailing this whole thing.

648
00:42:27,463 --> 00:42:36,472
Speaker 1: Doesn't the Heisenberg uncertainty principle state that as you increase the precision of your measurement of position, you lose accuracy on the particles velocity and vice versa?

649
00:42:36,554 --> 00:42:36,980
Speaker 0: Pretty much.

650
00:42:37,160 --> 00:42:37,481
Speaker 0: Pretty much.

651
00:42:37,521 --> 00:42:37,762
Speaker 1: Yeah.

652
00:42:37,842 --> 00:42:43,984
Speaker 1: I mean, it's you look at by by measuring one thing, you are uncertain about the other.

653
00:42:44,306 --> 00:42:46,820
Speaker 0: But it's not just I mean, people think of it as just that one thing.

654
00:42:47,400 --> 00:42:55,460
Speaker 0: The uncertainty principle really relates to a whole bunch of these kind of binary pairs of if we measure this, then we screw up that and vice versa.

655
00:42:55,661 --> 00:43:00,161
Speaker 0: And it's actually a lot more complicated than that and is really outside of the purview of this.

656
00:43:00,463 --> 00:43:00,785
Speaker 0: Yeah.

657
00:43:00,886 --> 00:43:03,160
Speaker 1: To simplify it in a way a commoner can understand.

658
00:43:03,341 --> 00:43:03,562
Speaker 1: Right.

659
00:43:04,005 --> 00:43:06,800
Speaker 1: Imagine you're looking at something in a microscope, right?

660
00:43:07,140 --> 00:43:10,501
Speaker 1: You're looking at it, but the light comes through the microscope and gets focused on the thing.

661
00:43:10,521 --> 00:43:13,640
Speaker 1: You're looking at it and the light kind of zaps it and now it's different.

662
00:43:13,820 --> 00:43:16,240
Speaker 1: So by looking at it, you sort of changed it.

663
00:43:16,300 --> 00:43:22,619
Speaker 1: So you can't look at it with a microscope in the way it was before you put it under the microscope because looking at it changes it.

664
00:43:22,861 --> 00:43:28,100
Speaker 0: Now, the simpler but scarier part of that is that that's a good analogy.

665
00:43:28,221 --> 00:43:30,620
Speaker 0: But the problem is analogies don't work for quantum physics.

666
00:43:30,840 --> 00:43:33,272
Speaker 0: I mean, I think the famous quote trying to make it so I know.

667
00:43:33,494 --> 00:43:38,459
Speaker 0: I think the famous quote is if you think you understand quantum physics, then you obviously don't.

668
00:43:38,640 --> 00:43:42,058
Speaker 1: I think or I think it was more like something like, you know, any something about.

669
00:43:42,159 --> 00:43:43,128
Speaker 1: anyone understands it.

670
00:43:43,209 --> 00:43:44,179
Speaker 1: No one understands it.

671
00:43:44,540 --> 00:43:44,761
Speaker 0: Yeah.

672
00:43:45,041 --> 00:43:56,740
Speaker 0: But the scarier answer is kind of that the ideas of causality start to break down on that micro scale to the point that we really can't know where a particle is.

673
00:43:56,880 --> 00:43:59,680
Speaker 0: We only know that it's like particles aren't just particles.

674
00:43:59,801 --> 00:44:03,380
Speaker 0: They're also waves and they act like a wave sometimes in a particle other times.

675
00:44:03,461 --> 00:44:04,599
Speaker 0: And we don't know why.

676
00:44:04,941 --> 00:44:05,968
Speaker 0: We really don't know.

677
00:44:06,109 --> 00:44:07,580
Speaker 0: And it's scary to a lot of people.

678
00:44:08,244 --> 00:44:08,847
Speaker 0: OK, right.

679
00:44:09,370 --> 00:44:11,060
Speaker 0: Will there ever be a working quantum computer?

680
00:44:11,260 --> 00:44:11,890
Speaker 0: There already is.

681
00:44:11,951 --> 00:44:12,560
Speaker 0: It's very slow.

682
00:44:13,100 --> 00:44:17,960
Speaker 1: OK, if you were going to try to design a Linux based virus, how would you go about it?

683
00:44:18,320 --> 00:44:19,779
Speaker 1: It sounds like a whole episode to me.

684
00:44:19,880 --> 00:44:23,540
Speaker 1: But generally, the thing about that, I mean, there are Linux, I guess, quote viruses.

685
00:44:23,820 --> 00:44:28,401
Speaker 1: There are malwares for Linux, there are rootkits and there are spy things and all sorts of stuff.

686
00:44:28,862 --> 00:44:33,679
Speaker 1: The problem is the how do you get it onto the computer and how do you get it?

687
00:44:33,719 --> 00:44:34,403
Speaker 1: root permissions?

688
00:44:34,503 --> 00:44:37,480
Speaker 1: That's the trick, because every Linux machine is different.

689
00:44:38,826 --> 00:44:40,140
Speaker 1: And they're all really secure.

690
00:44:40,320 --> 00:44:45,380
Speaker 1: And it's very difficult to get things to run with super user permissions without that super user password.

691
00:44:45,560 --> 00:44:50,959
Speaker 0: Yeah, I mean, all viruses do is if you can ever execute code with any level of authority on a computer, you've compromised it.

692
00:44:51,120 --> 00:44:52,419
Speaker 0: All viruses are the same at that point.

693
00:44:52,620 --> 00:44:53,879
Speaker 1: Yeah, it's just on Linux.

694
00:44:54,160 --> 00:44:58,640
Speaker 1: It is very, very difficult to pick a random Linux box that could be running.

695
00:44:58,680 --> 00:45:07,060
Speaker 1: Who knows what version of the kernel, who knows what version of SSH and if they're updated all the way, you know, how are you going to find a hole in it that you can exploit to get access to the machine?

696
00:45:07,060 --> 00:45:18,857
Speaker 0: Plus, just on a general sense, the security schema and how Linux and Unix is and all those things handle security and permissions is very robust and it's very difficult to get around that.

697
00:45:19,020 --> 00:45:31,160
Speaker 1: So what I would do is I would wait for there to be an announced bug in like Red Hat something and then already have machines like, you know, I know that, hey, that server I want is running Red Hat version X and then go for it.

698
00:45:31,240 --> 00:45:37,940
Speaker 1: But to get something to spread to all Linux machines around almost impossible because they're all running different versions of everything.

699
00:45:38,200 --> 00:45:57,408
Speaker 0: Now, what I would do is a lot of people are starting to use Linux and don't understand it is I'd set up websites that explained how people in a common thing like Red Hat or Ubuntu could get a bunch of cool software by adding a certain repository or installing a certain dev as root and I just make it a Trojan horse and I could only get stupid people or inexperienced people

700
00:45:57,710 --> 00:46:01,819
Speaker 1: until someone made an announcement about it, which case you just move somewhere else and try the same trick again.

701
00:46:01,940 --> 00:46:06,800
Speaker 0: But even then that it it's tough to do that, because even then you get all the nub.

702
00:46:06,900 --> 00:46:14,320
Speaker 0: Ubuntu, but not even that, because the people who aren't savvy enough to know that that's bad aren't savvy enough to add a repository.

703
00:46:14,442 --> 00:46:15,699
Speaker 1: Well, you make it like automatics.

704
00:46:16,344 --> 00:46:18,020
Speaker 1: All those dumb people install automatics.

705
00:46:18,160 --> 00:46:19,960
Speaker 1: It just screws you up and isn't necessary anymore.

706
00:46:20,060 --> 00:46:22,359
Speaker 1: You just make something like that and put a virus in it.

707
00:46:22,500 --> 00:46:22,681
Speaker 1: True.

708
00:46:22,742 --> 00:46:26,407
Speaker 0: The problem is there'd be more Google hits on this is bad than there would be on this.

709
00:46:26,510 --> 00:46:26,860
Speaker 1: It's true.

710
00:46:27,602 --> 00:46:27,806
Speaker 1: OK.

711
00:46:28,294 --> 00:46:28,599
Speaker 0: All right.

712
00:46:30,142 --> 00:46:37,540
Speaker 0: Why is the world we live in today so different from the world of the future that all old sci fi authors wrote about?

713
00:46:37,700 --> 00:46:45,100
Speaker 0: Pocket supercomputers are nice and all, but I was really looking forward to space colonies and personal hovercars period space colon right paren.

714
00:46:45,760 --> 00:46:54,080
Speaker 1: Well, because when you think about you write science fiction, you anything that you can conceive of being in the future, you make science fiction about.

715
00:46:54,160 --> 00:46:55,459
Speaker 1: And that's what we conceived of.

716
00:46:55,520 --> 00:46:57,240
Speaker 1: We can conceive of moon bases.

717
00:46:57,420 --> 00:47:00,920
Speaker 1: We can conceive of bases on all sorts of planets and rocket ships.

718
00:47:01,140 --> 00:47:08,540
Speaker 0: I think a lot of it is when you look unless you're very forward thinking, you look at what exists around you and try to extend that into the future.

719
00:47:08,700 --> 00:47:10,340
Speaker 0: Like we've got driving cars.

720
00:47:10,500 --> 00:47:12,100
Speaker 0: Well, why not flying cars?

721
00:47:12,462 --> 00:47:14,540
Speaker 0: We've got very primitive televisions.

722
00:47:14,700 --> 00:47:16,380
Speaker 0: Why not bigger television?

723
00:47:16,680 --> 00:47:16,760
Speaker 1: Yeah.

724
00:47:16,780 --> 00:47:22,384
Speaker 1: And what is possible and what actually is practical versus what you can conceive of are very different.

725
00:47:22,645 --> 00:47:30,442
Speaker 0: I think the other part of it is that science is not this kind of linear progression of just, you know, we want it, we get it, we want it, we get it.

726
00:47:30,622 --> 00:47:35,101
Speaker 0: It's more this things progress at a really like fast and slow than fast and slow.

727
00:47:35,121 --> 00:47:40,199
Speaker 0: There'll be a period of very little advancement and then suddenly there'll be a breakthrough and then a crazy rush.

728
00:47:40,961 --> 00:47:49,720
Speaker 0: And also the fact that science has been advancing in pretty much all fields exponentially to the point that the world of I mean, think about it.

729
00:47:50,181 --> 00:47:53,900
Speaker 0: It was less than 10 years ago that hardly anyone had a cell phone.

730
00:47:54,202 --> 00:47:57,100
Speaker 0: It was less than 20 years ago that fucking no one had a cell phone.

731
00:47:57,923 --> 00:47:58,104
Speaker 0: Yep.

732
00:47:58,265 --> 00:48:00,160
Speaker 0: Think about how dependent we are in cell phones now.

733
00:48:00,320 --> 00:48:02,277
Speaker 0: Like conceive of a world where you...

734
00:48:02,560 --> 00:48:06,520
Speaker 1: Meanwhile, it took thousands of years just to get the normal phone and a shitty one at that.

735
00:48:06,720 --> 00:48:12,566
Speaker 0: And yet that fundamentally changed the world in ways almost as much as how the Internet has changed the world.

736
00:48:13,491 --> 00:48:14,758
Speaker 0: Yeah, that's pretty much it.

737
00:48:15,921 --> 00:48:16,405
Speaker 1: All right.

738
00:48:16,466 --> 00:48:17,636
Speaker 1: Let's see what we got here.

739
00:48:18,760 --> 00:48:19,479
Speaker 0: Tell it the sex one.

740
00:48:19,681 --> 00:48:20,022
Speaker 1: OK.

741
00:48:20,404 --> 00:48:23,840
Speaker 1: How has technology changed the way we have an experienced sex?

742
00:48:24,320 --> 00:48:25,960
Speaker 1: How do you perceive it changing in the future?

743
00:48:26,120 --> 00:48:28,760
Speaker 1: Well, how has it changed the way we have an experienced sex?

744
00:48:28,980 --> 00:48:31,040
Speaker 1: Well, you got all sorts of fancy sex toys.

745
00:48:31,260 --> 00:48:35,220
Speaker 1: You got people spreading in, you know, info about their fetishes on the Internet.

746
00:48:35,420 --> 00:48:37,459
Speaker 1: So you got porns all over the place now.

747
00:48:38,360 --> 00:48:40,160
Speaker 0: Very scarily specific porn.

748
00:48:40,460 --> 00:48:40,581
Speaker 1: Yeah.

749
00:48:40,601 --> 00:48:42,713
Speaker 1: Anyone with a kink, you know, used to be.

750
00:48:42,733 --> 00:48:44,443
Speaker 1: if you had a kink, you just kind of kept it to yourself.

751
00:48:44,504 --> 00:48:47,942
Speaker 1: Now with the Internet, you can find someone who has the same kink and get it on.

752
00:48:48,002 --> 00:48:55,599
Speaker 1: So everyone's, you know, dirty sex, whatnots or clean sex, whatnots are all coming out into the open and everyone's letting loose.

753
00:48:56,064 --> 00:48:57,140
Speaker 0: And I think that's great.

754
00:48:57,300 --> 00:49:04,558
Speaker 0: I think this kind of prudish, you know, Victorian style, Puritan, you know, Victorian era, they didn't have sex then.

755
00:49:05,041 --> 00:49:05,242
Speaker 0: Yeah.

756
00:49:05,262 --> 00:49:07,352
Speaker 0: But at the same time, there was such a stigma and it was.

757
00:49:07,754 --> 00:49:09,503
Speaker 0: it was hard to be open about sex.

758
00:49:09,543 --> 00:49:15,079
Speaker 0: And I think that just the biggest change technology has made in terms of sex is the increased openness about it.

759
00:49:15,624 --> 00:49:17,340
Speaker 1: How will it change in the future?

760
00:49:18,462 --> 00:49:21,120
Speaker 1: I think there's going to be a. I don't know, really.

761
00:49:21,260 --> 00:49:22,727
Speaker 1: I mean, it's how much more.

762
00:49:22,808 --> 00:49:25,300
Speaker 1: I mean, sex is one thing that really hasn't changed.

763
00:49:25,420 --> 00:49:28,700
Speaker 1: All we can do is help people have more of it and help people have it better.

764
00:49:28,840 --> 00:49:31,720
Speaker 0: Well, unless we get the ghost in the shell world where then I guess.

765
00:49:31,940 --> 00:49:32,020
Speaker 1: Yeah.

766
00:49:32,040 --> 00:49:34,591
Speaker 1: But sex is just going to be more.

767
00:49:34,651 --> 00:49:38,280
Speaker 1: people who have it, want it, are going to get it and they're going to have it better.

768
00:49:38,380 --> 00:49:44,620
Speaker 1: It's going to feel better and there's going to be new ways to do it, like all sorts of sex machines and toys and porns and God knows what.

769
00:49:45,123 --> 00:49:45,304
Speaker 0: Right.

770
00:49:45,384 --> 00:49:51,420
Speaker 0: So in his book, The Fountains of Paradise by Arthur C. Clarke, you describe the construction of a, quote, space elevator.

771
00:49:52,184 --> 00:49:53,340
Speaker 0: What do you think about this idea?

772
00:49:54,222 --> 00:49:57,180
Speaker 0: I think it's a great idea in terms of the science and technology.

773
00:49:57,322 --> 00:49:58,479
Speaker 0: I don't know how feasible it is.

774
00:49:58,580 --> 00:50:03,820
Speaker 0: I'm not a space engineer, but we really need a practical purpose for it.

775
00:50:03,940 --> 00:50:05,880
Speaker 0: And I really am not an authority.

776
00:50:05,941 --> 00:50:07,079
Speaker 0: So I can't say more than that.

777
00:50:07,320 --> 00:50:07,461
Speaker 1: Yeah.

778
00:50:07,481 --> 00:50:10,700
Speaker 1: Well, Rims said generally I like the idea, I guess, theoretically, right?

779
00:50:11,004 --> 00:50:12,240
Speaker 1: You could take some sort of cable.

780
00:50:12,341 --> 00:50:18,580
Speaker 1: And because the earth spins, if you put the cable in the right spot, you could have the just cable stay out just by the centripetal force.

781
00:50:18,680 --> 00:50:23,559
Speaker 1: You put a weight on the end of it and you could just send satellites up and you could just send stuff up and down this cable.

782
00:50:23,661 --> 00:50:25,179
Speaker 1: That's theoretical that you could do that.

783
00:50:25,321 --> 00:50:27,219
Speaker 1: And that sounds like a good idea to me.

784
00:50:27,441 --> 00:50:29,320
Speaker 1: But how feasible is it really?

785
00:50:29,980 --> 00:50:30,828
Speaker 1: Who knows?

786
00:50:30,989 --> 00:50:32,100
Speaker 1: Someone else figured that out.

787
00:50:32,160 --> 00:50:32,584
Speaker 1: Not me.

788
00:50:32,705 --> 00:50:34,380
Speaker 1: I don't know about aerospace engineering.

789
00:50:34,680 --> 00:50:34,903
Speaker 1: All right.

790
00:50:36,137 --> 00:50:36,400
Speaker 1: All right.

791
00:50:36,942 --> 00:50:37,912
Speaker 1: I'm losing my spot here.

792
00:50:37,972 --> 00:50:38,760
Speaker 0: I know it's possible.

793
00:50:39,364 --> 00:50:39,526
Speaker 1: Mm hmm.

794
00:50:39,788 --> 00:50:41,340
Speaker 0: It's your question.

795
00:50:42,002 --> 00:50:51,204
Speaker 1: Oh, I know it's possible, but is it practical to build a Linux based home file server that goes to standby or hibernate when not in use and use the wake on land function when it is needed again?

796
00:50:51,245 --> 00:50:53,560
Speaker 1: Well, I guess that could be possible.

797
00:50:53,700 --> 00:50:56,620
Speaker 1: I see no reason why it is not technologically possible.

798
00:50:56,740 --> 00:51:04,363
Speaker 1: However, in Linux, in Linux kernel in general, wake on LAN, standby and hibernate are kind of fickle.

799
00:51:04,484 --> 00:51:13,420
Speaker 1: I mean, depending on exactly what motherboard I mean, the desktop I have at work, this Dell, if I shut down in Ubuntu, it doesn't actually power down the machine.

800
00:51:13,741 --> 00:51:14,588
Speaker 1: It just kind of stops.

801
00:51:14,629 --> 00:51:15,799
Speaker 1: And then I have to push the power button.

802
00:51:16,380 --> 00:51:25,360
Speaker 1: So handling the powering on and off of a machine in Linux, it does work in many cases, but it is quite fickle and you're going to have to fiddle with a lot of stuff.

803
00:51:25,881 --> 00:51:30,083
Speaker 1: And you're just better off just make a Linux home file server and leave it on all the time.

804
00:51:30,406 --> 00:51:32,400
Speaker 1: Is it really killing you that much to leave it on?

805
00:51:32,720 --> 00:51:48,349
Speaker 1: So if you really want to save electricity, I guess, you know, you could just turn it off manually or you can spend a lot of time and figure out how to figure out exactly what hardware is very compatible with wake on LAN and hibernate and then figure out how to configure that.

806
00:51:48,370 --> 00:51:48,900
Speaker 1: It's possible.

807
00:51:49,080 --> 00:51:54,170
Speaker 0: I think a better solution, if you want that kind of functionality, is seriously to just buy a consumer NAS.

808
00:51:54,210 --> 00:51:55,700
Speaker 0: that'll handle all that for you.

809
00:51:55,720 --> 00:51:57,240
Speaker 1: Yeah, you can get like the Drobo or something.

810
00:51:58,060 --> 00:51:58,950
Speaker 0: All right.

811
00:51:59,011 --> 00:51:59,719
Speaker 0: This is an easy one.

812
00:52:00,122 --> 00:52:02,720
Speaker 0: As an intermediate computer user, I've never gotten into using Linux.

813
00:52:03,140 --> 00:52:05,375
Speaker 0: What's the best way to keep my current PC functionality?

814
00:52:05,415 --> 00:52:06,080
Speaker 0: but try out Linux?

815
00:52:06,282 --> 00:52:07,960
Speaker 1: I've gone over this like a zillion times.

816
00:52:08,400 --> 00:52:09,519
Speaker 0: Ubuntu boot CD, live CD.

817
00:52:09,740 --> 00:52:10,043
Speaker 0: Yes.

818
00:52:10,245 --> 00:52:11,779
Speaker 1: The concept of a live CD.

819
00:52:12,041 --> 00:52:12,958
Speaker 1: You burn a CD.

820
00:52:13,300 --> 00:52:15,860
Speaker 1: It's very easy, even though a lot of people seem to screw that part up.

821
00:52:16,180 --> 00:52:17,940
Speaker 1: Learn how to deal with an ISO file.

822
00:52:18,060 --> 00:52:19,660
Speaker 1: Get an ISO file from Ubuntu dot com.

823
00:52:20,100 --> 00:52:20,634
Speaker 1: Burn it to a CD.

824
00:52:20,960 --> 00:52:24,160
Speaker 1: If you can't handle that, they'll send you a CD for free that's already burned.

825
00:52:24,620 --> 00:52:25,960
Speaker 1: Put the CD in your computer.

826
00:52:26,340 --> 00:52:27,539
Speaker 1: Turn your computer on.

827
00:52:28,061 --> 00:52:30,680
Speaker 1: Let this while the CD is in there and that's it.

828
00:52:30,780 --> 00:52:31,860
Speaker 1: You can try out Linux.

829
00:52:32,040 --> 00:52:33,560
Speaker 1: It won't touch your computer.

830
00:52:33,822 --> 00:52:36,040
Speaker 1: You could take the CD out, restart your computer.

831
00:52:36,180 --> 00:52:37,139
Speaker 1: It's like you never had Linux.

832
00:52:37,680 --> 00:52:39,680
Speaker 1: You can try it out for no risk and no money.

833
00:52:40,040 --> 00:52:41,259
Speaker 1: That's all I ask from people.

834
00:52:41,640 --> 00:52:41,882
Speaker 1: Do it.

835
00:52:42,749 --> 00:52:44,180
Speaker 1: God, how many times does it say this?

836
00:52:45,300 --> 00:52:45,624
Speaker 0: All right.

837
00:52:46,374 --> 00:52:46,839
Speaker 0: That was easy.

838
00:52:47,141 --> 00:52:49,080
Speaker 1: On my computer, video doesn't play well.

839
00:52:49,160 --> 00:52:51,120
Speaker 1: It lags badly or it's pink and orange.

840
00:52:51,540 --> 00:52:55,480
Speaker 1: I tried lots of media players, got codex and googled the problem with no success.

841
00:52:55,941 --> 00:52:57,160
Speaker 1: Is it just the video card?

842
00:52:57,520 --> 00:53:00,100
Speaker 1: Some other problem with my PC, something I should install.

843
00:53:00,201 --> 00:53:04,000
Speaker 1: I love this question because there's something a lot of people don't know about.

844
00:53:04,341 --> 00:53:10,780
Speaker 0: I didn't know about it when I was in high school and I had problems with some MPEG decoder cards and I finally found out.

845
00:53:11,181 --> 00:53:12,105
Speaker 1: And there are there.

846
00:53:12,527 --> 00:53:15,380
Speaker 1: this could be a spyware or a virus or something.

847
00:53:15,480 --> 00:53:16,780
Speaker 1: It could be broken hardware.

848
00:53:16,963 --> 00:53:17,940
Speaker 1: It could be a lot of things.

849
00:53:18,020 --> 00:53:20,060
Speaker 1: However, there's something I want to teach you about right now.

850
00:53:20,121 --> 00:53:21,039
Speaker 1: This is called the overlay.

851
00:53:22,041 --> 00:53:27,235
Speaker 1: When your computer draws video on the screen in memory, on the video card is called the frame buffer.

852
00:53:27,317 --> 00:53:27,460
Speaker 1: Right.

853
00:53:27,480 --> 00:53:32,879
Speaker 1: And basically, let's say you have a screen that's four pixels by four pixels and they could each be black or white.

854
00:53:33,283 --> 00:53:35,200
Speaker 1: So that's one bit per pixel.

855
00:53:35,260 --> 00:53:39,780
Speaker 1: So that's either one for black or one for white and zero for black and four by four.

856
00:53:39,940 --> 00:53:40,865
Speaker 1: So it's 16.

857
00:53:40,865 --> 00:53:43,460
Speaker 1: So there'll be 16 bits of data in your video card.

858
00:53:43,861 --> 00:53:48,360
Speaker 1: And if, you know, the first one is a one, then the top left pixel will be white.

859
00:53:48,661 --> 00:53:53,240
Speaker 1: And if the second one is a zero, this top, the second to top left pixel will be black.

860
00:53:53,301 --> 00:53:54,799
Speaker 1: And that's how your video card works.

861
00:53:55,201 --> 00:53:55,623
Speaker 1: Is it just?

862
00:53:55,884 --> 00:54:05,360
Speaker 1: it has enough memory to store all the colors for your entire screen and it just changes that memory and then that memory gets sent to your monitor, which draws it.

863
00:54:05,680 --> 00:54:06,600
Speaker 0: Scout took a class on this.

864
00:54:06,720 --> 00:54:07,324
Speaker 0: So listen to yes.

865
00:54:07,505 --> 00:54:12,880
Speaker 1: And when you say double buffering, when they talk about double buffering, you actually have twice as much of that memory.

866
00:54:13,221 --> 00:54:20,780
Speaker 1: You draw the next frame to be rendered to the monitor, to the one to one of them, and then you swap them and then you draw and then you swap.

867
00:54:20,941 --> 00:54:23,179
Speaker 1: That way you don't like draw half the screen.

868
00:54:23,604 --> 00:54:24,980
Speaker 1: You draw the whole screen at once.

869
00:54:25,160 --> 00:54:26,299
Speaker 1: You draw, swap, draw, swap.

870
00:54:27,100 --> 00:54:34,045
Speaker 1: Now, for when you playing video on your computer, there's actually another buffer that's separate.

871
00:54:34,065 --> 00:54:44,900
Speaker 1: That's why when you try to take a screenshot, when your video player is playing the screenshot program, all it does is copy the data in the normal frame buffer to a file like a bitmap or a ping or a JPEG.

872
00:54:45,981 --> 00:54:48,900
Speaker 1: The video is not in the frame buffer, the normal frame buffer.

873
00:54:48,981 --> 00:54:51,400
Speaker 1: It's in the overlay buffer, which is completely separate.

874
00:54:51,500 --> 00:55:01,279
Speaker 1: If you go into the control panel for your video card, you will notice all these overlay settings and that will change settings only for video playing and stuff like that.

875
00:55:02,220 --> 00:55:28,121
Speaker 1: So if you're having color problems on video only, if you're having crashing problems on video only, there might be a problem with the overlay part of your video card or the settings for the overlay in your video card driver, which is a separate buffer that is written to very quickly because video is, you know, when you playing video, it's not like your monitor where maybe a small part will change, a small part will change, a small part will change, you know, where your mouse is or where you're moving a window around.

876
00:55:28,162 --> 00:55:35,780
Speaker 1: It's an area of the screen that is constantly changing very rapidly with very lots of colors and lots of maybe not lots of resolution.

877
00:55:36,302 --> 00:55:41,038
Speaker 1: So that's put in a separate buffer that works differently, that is optimized for video play and you need to fix it.

878
00:55:41,300 --> 00:55:47,839
Speaker 0: Partly a lot of this was much more of an issue back in the day when computers weren't fast enough to play MPEG or DVDs.

879
00:55:47,900 --> 00:56:02,137
Speaker 0: You had to have a separate hardware chip that did that for you and your screen, if you like, if you played a video that was running in one of those overlays and you tried to take a screenshot, if you looked at the screenshot where the overlay was, would be just like a gray box.

880
00:56:02,760 --> 00:56:08,399
Speaker 1: Yep, because in your frame buffer, your normal frame buffer that draws everything else in your computer, it is just a gray box.

881
00:56:08,540 --> 00:56:11,199
Speaker 1: But the overlay is drawing video on top of it.

882
00:56:11,903 --> 00:56:12,612
Speaker 1: OK, all right.

883
00:56:12,652 --> 00:56:13,219
Speaker 0: I'm going to warn you.

884
00:56:13,320 --> 00:56:18,191
Speaker 0: This next one might sound a little bit like an ego stroke, but we're really freaking good at what we do.

885
00:56:18,212 --> 00:56:18,760
Speaker 0: All right.

886
00:56:18,940 --> 00:56:20,318
Speaker 0: So it's a long question, too.

887
00:56:20,961 --> 00:56:25,520
Speaker 0: I heard you guys mention at the end of the show that getting your podcast out is automatic, a push of a button.

888
00:56:26,260 --> 00:56:33,540
Speaker 0: I can see how scripts work for most of this, but does that automation include audio editing, for example, removing long a's and ums or editing out other parts?

889
00:56:34,122 --> 00:56:35,780
Speaker 0: Or are you guys that good?

890
00:56:36,120 --> 00:56:37,479
Speaker 0: You don't need to take second takes.

891
00:56:37,862 --> 00:56:42,020
Speaker 0: If the latter is too, I'm pretty impressed since you guys always seem so prepared each show, no floundering and smooth.

892
00:56:42,240 --> 00:56:44,980
Speaker 0: One, yes, we are that awesome.

893
00:56:45,061 --> 00:56:47,860
Speaker 0: We really don't say I'm an odd in a bad way.

894
00:56:48,160 --> 00:56:50,060
Speaker 1: We used to be not so awesome.

895
00:56:50,100 --> 00:56:52,960
Speaker 0: Listen to old geek nights and you can hear where I edited shit out.

896
00:56:53,080 --> 00:56:54,799
Speaker 0: But we haven't done that for over a year.

897
00:56:55,080 --> 00:56:57,060
Speaker 1: Yeah, I'm doing a podcast four nights a week.

898
00:56:57,120 --> 00:56:57,545
Speaker 1: You know what?

899
00:56:57,565 --> 00:56:58,940
Speaker 1: You get fucking good at it.

900
00:56:59,060 --> 00:57:00,280
Speaker 1: That's it's called practice.

901
00:57:00,460 --> 00:57:01,839
Speaker 0: I mean, I'm going to say this right now.

902
00:57:01,960 --> 00:57:08,800
Speaker 0: This current show that you've been listening to for about an hour, we have not edited a single thing out.

903
00:57:09,020 --> 00:57:09,819
Speaker 0: It's already an hour.

904
00:57:10,200 --> 00:57:10,710
Speaker 0: Yeah.

905
00:57:10,873 --> 00:57:11,240
Speaker 0: Don't worry.

906
00:57:11,360 --> 00:57:14,828
Speaker 0: I figured out where we're going to stop and the rest is going to be in a separate show in the future.

907
00:57:15,092 --> 00:57:15,560
Speaker 1: Oh, my God.

908
00:57:15,640 --> 00:57:16,939
Speaker 1: We're not even like page three.

909
00:57:17,280 --> 00:57:17,682
Speaker 0: I know.

910
00:57:18,043 --> 00:57:36,760
Speaker 0: But seriously, in the previous hour, not only we did not edit anything out other than the, you know, shortened silences filter, which grew maybe 15 seconds total of silence, not a single word, not a single cough, not a single um and or literally I'm going to hit stop and then I'm going to make an MP3 out of that.

911
00:57:37,461 --> 00:57:45,021
Speaker 1: So if you want to get, you know, avoid the audio editing because basically the automatic part is just filters and publishing and ID threes and stuff like that.

912
00:57:45,523 --> 00:57:51,020
Speaker 1: If you want to not have to edit out um's and ah's, don't um and ah, keep practicing podcast a lot.

913
00:57:51,600 --> 00:57:54,720
Speaker 1: Podcasting once a week is probably not enough to get your good practice out.

914
00:57:55,020 --> 00:57:56,518
Speaker 0: I mean, we don't edit anything out.

915
00:57:57,061 --> 00:58:04,280
Speaker 0: And even further, I just bring this up for this question show, other than, you know, just going through the questions real quick to weed out the stupid ones.

916
00:58:04,943 --> 00:58:06,160
Speaker 0: We didn't do research.

917
00:58:06,542 --> 00:58:07,779
Speaker 0: We didn't look anything up.

918
00:58:07,981 --> 00:58:10,220
Speaker 0: And in fact, Scott's sitting there with no computer.

919
00:58:10,582 --> 00:58:14,221
Speaker 0: And the only thing I've had open for the last hour is resound so I can watch the levels.

920
00:58:14,302 --> 00:58:17,800
Speaker 0: And we both just have a piece of paper with a bunch of questions on it.

921
00:58:18,201 --> 00:58:19,060
Speaker 0: No research, no nothing.

922
00:58:19,160 --> 00:58:20,919
Speaker 0: We answered this stuff off the top of our heads.

923
00:58:21,280 --> 00:58:21,481
Speaker 1: All right.

924
00:58:21,964 --> 00:58:24,480
Speaker 0: And in terms of the filter, I will talk about this a little bit.

925
00:58:25,241 --> 00:58:30,159
Speaker 0: What the filter does is it's actually I think, well, not the filter, but, you know, the automatic podcasting.

926
00:58:30,942 --> 00:58:32,840
Speaker 0: We make the show in three files.

927
00:58:32,961 --> 00:58:34,320
Speaker 0: So we record the first half of the show.

928
00:58:34,440 --> 00:58:35,247
Speaker 0: We stop for a second.

929
00:58:35,550 --> 00:58:36,740
Speaker 0: We record the second half of the show.

930
00:58:36,840 --> 00:58:37,586
Speaker 0: We stop for a second.

931
00:58:37,949 --> 00:58:39,180
Speaker 0: Then we record, you know, the opener.

932
00:58:39,342 --> 00:58:39,829
Speaker 0: I'm rim.

933
00:58:40,153 --> 00:58:40,640
Speaker 0: I'm Scott.

934
00:58:40,740 --> 00:58:41,584
Speaker 0: And this is nice.

935
00:58:42,127 --> 00:58:45,211
Speaker 0: Tonight we talked about your mom and all the things about your mom and like.

936
00:58:45,232 --> 00:58:45,476
Speaker 0: Yeah.

937
00:58:46,281 --> 00:58:53,560
Speaker 0: And then I have a script that just takes all these files, runs all inside of resounds like a macro, runs all the filters that need to be run.

938
00:58:54,121 --> 00:59:03,802
Speaker 0: And then because the show's pretty straightforward, it just takes and copy paste and overlays and puts the whole show together, throws all the sound effects in, makes an MP3.

939
00:59:03,822 --> 00:59:10,579
Speaker 0: And then I run a Python script that adds the ID three, does all the other stuff and then uploads the file.

940
00:59:11,520 --> 00:59:16,920
Speaker 1: And then we make a blog post in WordPress by hand because I haven't found a way to make that easier because WordPress actually kind of shitty.

941
00:59:17,460 --> 00:59:17,621
Speaker 0: Yep.

942
00:59:18,987 --> 00:59:21,960
Speaker 1: What's the least expensive way to start and host a forum?

943
00:59:22,540 --> 00:59:27,139
Speaker 1: Well, you go to one of those websites that says like free forum and you sign up.

944
00:59:28,460 --> 00:59:35,640
Speaker 0: Can you please comment on why evolutionists continue to believe in the dogmatic principles of Darwinism instead of embracing the obvious truth of his magnificence?

945
00:59:35,720 --> 00:59:43,460
Speaker 1: Well, evolutionists, they stay so stubborn, they refuse to believe things unless they have physical, you know, empirical evidence.

946
00:59:43,500 --> 00:59:44,548
Speaker 0: I mean, how crazy is that?

947
00:59:44,588 --> 00:59:46,280
Speaker 0: They want evidence before they believe something.

948
00:59:46,543 --> 00:59:47,979
Speaker 0: That's why they're so dogmatic.

949
00:59:48,440 --> 00:59:48,681
Speaker 1: Right.

950
00:59:48,721 --> 00:59:55,780
Speaker 1: So, you know, they find all these evidence of Darwinism and they haven't found, according to them, any evidence for his magnificence.

951
00:59:56,720 --> 01:00:02,544
Speaker 0: So I guess he in proving his magnificence, I mean, he'd really only have to find one piece of evidence.

952
01:00:02,625 --> 01:00:05,988
Speaker 0: And then the dogmatic principles of Darwinism would just come crashing down.

953
01:00:06,028 --> 01:00:06,959
Speaker 0: But they haven't yet.

954
01:00:07,464 --> 01:00:07,749
Speaker 0: All right.

955
01:00:08,074 --> 01:00:08,339
Speaker 0: All right.

956
01:00:08,903 --> 01:00:09,979
Speaker 0: I guess Scott can ask this one.

957
01:00:10,260 --> 01:00:12,000
Speaker 1: When will this DRM crap end?

958
01:00:12,100 --> 01:00:16,760
Speaker 0: When you stop buying it, it's consumers have the ultimate power in terms of media.

959
01:00:17,101 --> 01:00:21,100
Speaker 0: If you don't buy DRM crap, DRM will disappear practically overnight.

960
01:00:21,380 --> 01:00:23,112
Speaker 1: And the thing is, I don't you got to think about.

961
01:00:23,152 --> 01:00:24,220
Speaker 1: DRM is the whole right.

962
01:00:24,480 --> 01:00:24,641
Speaker 1: Sure.

963
01:00:24,661 --> 01:00:29,500
Speaker 1: If we stop buying DRM MP3s and stop buying DRM movies, then those will stop.

964
01:00:29,800 --> 01:00:36,126
Speaker 1: But DRM also means iPhone that's locked down or iPod that you can't copy MP3s off of.

965
01:00:36,166 --> 01:00:38,540
Speaker 1: You know, there's other things that DRM means.

966
01:00:38,680 --> 01:00:47,643
Speaker 1: And as long as you keep buying products that are restricted in functionality, then companies will continue to say, hey, people will buy stuff that doesn't have the full functionality.

967
01:00:47,763 --> 01:00:51,259
Speaker 0: Apple had released the iPod, the iPhone, and no one had bought it.

968
01:00:51,621 --> 01:00:53,520
Speaker 1: And they end with market research.

969
01:00:53,641 --> 01:00:55,573
Speaker 1: They found out it's because it didn't.

970
01:00:55,875 --> 01:00:56,559
Speaker 1: it wasn't open.

971
01:00:57,101 --> 01:01:01,580
Speaker 1: Then you bet your ass they would open that iPhone with firmware update number one.

972
01:01:01,881 --> 01:01:03,611
Speaker 0: Apple and Verizon, all these companies will not.

973
01:01:03,631 --> 01:01:06,260
Speaker 0: maybe not Verizon, but Apple, at least it's not like they're evil.

974
01:01:06,642 --> 01:01:08,840
Speaker 0: It's just that they know you'll buy it anyway.

975
01:01:09,163 --> 01:01:09,910
Speaker 0: So why bother?

976
01:01:09,970 --> 01:01:11,020
Speaker 0: It's the same thing with Nintendo.

977
01:01:11,200 --> 01:01:13,540
Speaker 1: It's only more work for them to not restrict stuff.

978
01:01:13,800 --> 01:01:17,460
Speaker 1: The Wii could be better than it is, but DRM on music and movies is already ending.

979
01:01:17,680 --> 01:01:20,720
Speaker 1: But DRM, you know, that DRM requires them to do extra.

980
01:01:20,960 --> 01:01:26,222
Speaker 1: But DRM that requires them to do more is not going to go away until we make them with money.

981
01:01:26,605 --> 01:01:28,480
Speaker 0: So this is kind of related.

982
01:01:28,640 --> 01:01:31,200
Speaker 0: Will the music industry ever get their shit together?

983
01:01:31,423 --> 01:01:32,800
Speaker 1: No, they're already dying.

984
01:01:32,880 --> 01:01:34,359
Speaker 1: Look at what's going on right now.

985
01:01:34,740 --> 01:01:37,180
Speaker 0: We have to clarify by the music industry.

986
01:01:37,360 --> 01:01:43,420
Speaker 0: I'm going to take that to mean the current system of basically the music industry is comprised of three components.

987
01:01:43,880 --> 01:01:47,120
Speaker 0: On one end, we have consumers and then the other end we have content producers.

988
01:01:47,621 --> 01:01:49,689
Speaker 0: The industry is the middle part.

989
01:01:49,930 --> 01:01:52,039
Speaker 0: that does all the marketing and promotion and crap.

990
01:01:52,079 --> 01:01:55,660
Speaker 0: that is because of the Internet largely becoming obsolete.

991
01:01:55,981 --> 01:02:05,660
Speaker 1: I think in time people who make music and are talented at doing so will be able to live off of that in by doing clever things to make money.

992
01:02:06,020 --> 01:02:07,347
Speaker 1: I mean, Madonna made like.

993
01:02:07,407 --> 01:02:16,239
Speaker 1: they said something on Twitter that I listened to this morning that she made like 380 million from concerts and only like a few like 10 million per album or something like that.

994
01:02:16,340 --> 01:02:16,842
Speaker 1: Ridiculous.

995
01:02:17,485 --> 01:02:21,583
Speaker 1: So, yeah, they're going to find ways to make money if they're talented musicians.

996
01:02:21,783 --> 01:02:26,545
Speaker 1: Other than that, current record companies, current record business, not going to stick around.

997
01:02:26,605 --> 01:02:30,839
Speaker 1: It's been going downhill since Napster and it's really starting to drop off now.

998
01:02:30,980 --> 01:02:31,482
Speaker 1: Big time.

999
01:02:31,542 --> 01:02:35,820
Speaker 0: The current music industry exists solely to exploit the lack of a long tail.

1000
01:02:36,121 --> 01:02:46,900
Speaker 0: They realized a long time ago that they make a lot more money if they sell a million copies of two albums than if they sell a thousand copies of ten thousand albums, because it's, you know, economy of scale.

1001
01:02:47,001 --> 01:02:48,240
Speaker 0: It's easier to print a million.

1002
01:02:48,920 --> 01:02:53,523
Speaker 1: That's why with as a musician, you were either shit in the poorhouse or shit in the rich house.

1003
01:02:53,603 --> 01:02:57,364
Speaker 1: Now there's just going to be a lot of musicians who are in the normal looking house.

1004
01:02:58,069 --> 01:02:59,780
Speaker 1: And that's good as far as I'm concerned.

1005
01:02:59,840 --> 01:03:01,831
Speaker 1: But it also means you're never going to.

1006
01:03:01,851 --> 01:03:05,580
Speaker 1: you're probably never going to see another Elvis or another Beatles or anything.

1007
01:03:05,881 --> 01:03:08,860
Speaker 1: That's going to be incredibly difficult to come by in the years to come.

1008
01:03:08,980 --> 01:03:14,205
Speaker 1: There isn't going to be some huge, mega hit, wide appeal musician that everyone loves and makes history.

1009
01:03:15,051 --> 01:03:16,240
Speaker 1: I think those days might be over.

1010
01:03:16,722 --> 01:03:18,920
Speaker 0: I think we should really just do two more and end it here.

1011
01:03:19,540 --> 01:03:22,840
Speaker 1: All right, we'll do two more and then we'll have to make the rest into another show.

1012
01:03:23,022 --> 01:03:23,185
Speaker 0: Yep.

1013
01:03:23,205 --> 01:03:23,940
Speaker 0: You'll hear that show.

1014
01:03:24,180 --> 01:03:28,606
Speaker 0: I imagine what we'll do is the rest of this, which will probably be just as long as what we've just done.

1015
01:03:28,626 --> 01:03:30,100
Speaker 0: And there's good questions in the rest of it.

1016
01:03:30,180 --> 01:03:31,580
Speaker 0: It's not like we put them in good order.

1017
01:03:31,840 --> 01:03:32,879
Speaker 1: No, we just put them in order.

1018
01:03:33,221 --> 01:03:35,715
Speaker 0: Yeah, we are pretty much arbitrary ordering pretty much in the order.

1019
01:03:35,756 --> 01:03:37,199
Speaker 0: they came with a few exceptions.

1020
01:03:37,480 --> 01:03:37,621
Speaker 1: Yep.

1021
01:03:38,505 --> 01:03:39,549
Speaker 0: I imagine it'll be.

1022
01:03:39,810 --> 01:03:44,080
Speaker 0: we'll probably just make one for each day of the week and just there'll be a filler for a busy or something.

1023
01:03:44,200 --> 01:03:46,557
Speaker 0: We'll throw one of these up because I hope you like this.

1024
01:03:47,021 --> 01:03:47,949
Speaker 0: You seem to like him before.

1025
01:03:48,917 --> 01:03:49,200
Speaker 0: All right.

1026
01:03:49,841 --> 01:03:50,324
Speaker 0: Well, Scott.

1027
01:03:50,827 --> 01:03:57,423
Speaker 1: Oh, can you explain why we don't need to worry about the dudes messing with the large Hadron Collider destroying our little blue planet?

1028
01:03:57,504 --> 01:04:12,459
Speaker 0: The answer to that is really simple, because on a academic sense, we do need to worry because there is a very real possibility of high energy particle physics experiments literally destroying the the fabric of space time around us and killing us all.

1029
01:04:12,640 --> 01:04:19,140
Speaker 0: But there's no way we could possibly know if that happened because we would all be destroyed instantaneously.

1030
01:04:19,201 --> 01:04:20,599
Speaker 0: So there's no point in worrying about it.

1031
01:04:21,121 --> 01:04:28,306
Speaker 0: The odds are so small and the benefit to humanity is so great that we we really don't need to worry about it.

1032
01:04:28,386 --> 01:04:30,500
Speaker 0: And there's nothing we can do to stop the experiments.

1033
01:04:31,061 --> 01:04:35,542
Speaker 1: And the benefits from the experiments are necessary if we're going to stay around in the long term.

1034
01:04:35,924 --> 01:04:44,363
Speaker 1: In addition, if the experiments cause some sort of problem that wasn't instantaneous like death for all of us, that we wouldn't even notice because we just die instantly.

1035
01:04:44,423 --> 01:04:47,019
Speaker 1: Everybody that we just learned a hell of a lot about the world.

1036
01:04:47,281 --> 01:04:53,420
Speaker 1: Not only that, but we would notice that like if it was still being dangerous, we would notice that people near it would start dying.

1037
01:04:53,520 --> 01:04:56,080
Speaker 1: And we'd say, huh, a lot of people near the large Hadron Collider are dying.

1038
01:04:56,140 --> 01:04:59,140
Speaker 1: And then we figure that out and we wouldn't die living so far away from it.

1039
01:04:59,420 --> 01:05:01,619
Speaker 1: So it's kind of a unless you live on top of it.

1040
01:05:02,160 --> 01:05:05,500
Speaker 0: Experiments like this are effectively very forward thinking.

1041
01:05:05,680 --> 01:05:10,401
Speaker 0: These are the kinds of experiments that will help us answer questions 10,000 years from now.

1042
01:05:10,803 --> 01:05:25,660
Speaker 0: These are the experiments that while there's a tiny, tiny, tiny chance that will destroy ourselves now, the odds are low and success is like one more component in the puzzle that will eventually, hopefully allow us to tackle the questions of a hundred thousand year civilization.

1043
01:05:25,740 --> 01:05:29,540
Speaker 1: It's sort of like when those guys set off the nuke thinking it could have set the atmosphere on fire.

1044
01:05:29,820 --> 01:05:29,921
Speaker 0: Yeah.

1045
01:05:30,184 --> 01:05:31,700
Speaker 0: Or just nuclear power in general.

1046
01:05:31,880 --> 01:05:36,503
Speaker 0: We didn't I mean, the Germans and when they were we didn't know what was going to happen.

1047
01:05:36,523 --> 01:05:38,920
Speaker 0: That was a scary time for a lot of scientists.

1048
01:05:39,081 --> 01:05:42,600
Speaker 0: And science is risky and science is scary.

1049
01:05:42,981 --> 01:05:45,120
Speaker 0: But the alternative is to not advance.

1050
01:05:46,120 --> 01:05:52,459
Speaker 0: And I think we as a collective consciousness have decided time and time again that advancing is worth the risk.

1051
01:05:53,960 --> 01:05:55,618
Speaker 1: If you disagree, go with the Unabomber.

1052
01:05:56,980 --> 01:05:59,040
Speaker 1: Unabomber two times, I'm going for three Unabombers.

1053
01:05:59,320 --> 01:06:03,080
Speaker 0: So should we send people back to the moon, to Mars, elsewhere?

1054
01:06:03,520 --> 01:06:06,280
Speaker 0: I really don't want NASA messing with my secret new moon base.

1055
01:06:06,864 --> 01:06:09,020
Speaker 0: What do you think about space exploration in general?

1056
01:06:09,140 --> 01:06:10,759
Speaker 0: That's a good open ended question to end on.

1057
01:06:11,740 --> 01:06:13,760
Speaker 1: I like I'd like to go into space.

1058
01:06:13,960 --> 01:06:14,487
Speaker 1: It's fun.

1059
01:06:14,690 --> 01:06:15,319
Speaker 1: It could be cool.

1060
01:06:15,700 --> 01:06:19,360
Speaker 1: We're eventually going to have to, I guess, if we run out of stuff on Earth, I guess.

1061
01:06:19,701 --> 01:06:24,222
Speaker 0: I hate to say this, but I feel like right now there are much more pressing problems on Earth.

1062
01:06:24,907 --> 01:06:26,740
Speaker 1: There are much more pressing problems on Earth.

1063
01:06:26,820 --> 01:06:29,680
Speaker 1: But in the long term, I think to say it's all in the long term.

1064
01:06:29,700 --> 01:06:36,760
Speaker 0: But I think in the short term, like on one hand, I really like the the push to the moon was this amazing feat.

1065
01:06:36,860 --> 01:06:54,420
Speaker 0: And I'm not going to say what I said before about how awe inspiring it was, but I feel like the push to Mars or the push to go back to the moon, while it would be a great thing, I feel like the cost and the risk are not really worth it compared to what we could spend that shit.

1066
01:06:54,500 --> 01:07:14,163
Speaker 0: Like imagine if we put the effort that it would take to go to the moon again toward fixing our economy on a fundamental level or fixing, I don't know, the health care issues on a fundamental level, the amount of resources that it would take to do these things put in any other direction could see a lot more benefit for a lot more people in the short term.

1067
01:07:14,203 --> 01:07:20,220
Speaker 0: And I think as a result, give us a wider base of resources to then explore these longer term questions later.

1068
01:07:21,602 --> 01:07:24,200
Speaker 1: All right, so do we have to stop here?

1069
01:07:24,604 --> 01:07:25,599
Speaker 0: I think we should stop there.

1070
01:07:25,780 --> 01:07:26,284
Speaker 1: All right, we'll stop.

1071
01:07:26,385 --> 01:07:28,644
Speaker 1: And then the other rest of the questions will be answered another time.

1072
01:07:28,665 --> 01:07:30,080
Speaker 0: I hope you enjoyed this.

1073
01:07:30,240 --> 01:07:31,439
Speaker 0: We're going to continue this all week.

1074
01:07:31,842 --> 01:07:33,640
Speaker 0: I don't think we'll do another week of this.

1075
01:07:33,760 --> 01:07:38,100
Speaker 0: We'll just throw in the extra episodes whenever we need to do an extra episode somewhere.

1076
01:07:38,660 --> 01:07:39,044
Speaker 1: Sounds good.

1077
01:07:39,670 --> 01:07:40,719
Speaker 0: So I hope you liked it.

1078
01:07:40,820 --> 01:07:45,581
Speaker 0: If you have any follow up questions, ask them and maybe someday in the next 10 or 15 years, we'll get to them.

1079
01:07:51,935 --> 01:07:54,020
Speaker 0: This has been Geek Nights with Rim and Scott.

1080
01:07:54,260 --> 01:07:56,620
Speaker 0: Special thanks to DJ Pretzel for the opening music.

1081
01:07:57,380 --> 01:08:08,579
Speaker 1: Be sure to visit our website at www.frontroadcrew.com where you'll find show notes, links, our awesome forum, a link to our Frapper map and links to all the RSS feeds.

1082
01:08:09,142 --> 01:08:14,819
Speaker 0: We say feeds plural because Geek Nights airs four nights a week covering four different brands of geekery.

1083
01:08:15,380 --> 01:08:16,879
Speaker 0: Mondays are science and technology.

1084
01:08:17,040 --> 01:08:19,479
Speaker 0: Tuesdays we have video games, board games and RPGs.

1085
01:08:20,060 --> 01:08:25,439
Speaker 0: Wednesdays are anime, manga, comic nights and Thursdays are the catch alls for various rants and tomfoolery.

1086
01:08:26,000 --> 01:08:33,919
Speaker 1: You can send us feedback by email to geeknights@frontroadcrew.com or you can send audio feedback via Odeo.

1087
01:08:34,340 --> 01:08:37,479
Speaker 1: Just click the link that says send me an Odeo on the right side of our website.

1088
01:08:37,902 --> 01:08:42,979
Speaker 0: If you like what you hear, you can catch the last 100 episodes in iTunes or in your favorite podcatcher.

1089
01:08:43,279 --> 01:08:46,319
Speaker 0: For the complete archives, visit the website, which has everything.

1090
01:08:47,140 --> 01:08:51,868
Speaker 1: Geek Nights is distributed under a Creative Commons attribution, non-commercial, share alike 2.5 license.

1091
01:08:53,460 --> 01:08:59,500
Speaker 1: This means you can do whatever you want with it as long as you give us credit, don't make money and share it in kind.

1092
01:09:00,359 --> 01:09:03,800
Speaker 1: Geek Nights is recorded live with no studio and no audience.

1093
01:09:04,220 --> 01:09:07,359
Speaker 1: But unlike those other late shows, it's actually recorded at night.

