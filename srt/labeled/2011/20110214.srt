1
00:00:08,940 --> 00:00:10,438
Rym: It's Monday, February 14th, 2011.

2
00:00:10,438 --> 00:00:10,680
Rym: I'm Rym.

3
00:00:12,673 --> 00:00:13,109
Scott: I'm Scott.

4
00:00:13,310 --> 00:00:14,698
Rym: And this is GeekNights.

5
00:00:14,779 --> 00:00:16,610
Rym: Tonight, IBM's Watson.

6
00:00:20,300 --> 00:00:21,218
Rym: Let's do this.

7
00:00:25,581 --> 00:00:25,987
Rym: Perhaps Dr.

8
00:00:26,008 --> 00:00:26,292
Rym: Watson?

9
00:00:28,716 --> 00:00:28,758
Scott: No.

10
00:00:29,201 --> 00:00:29,448
Rym: No?

11
00:00:29,551 --> 00:00:29,838
Rym: You sure?

12
00:00:30,100 --> 00:00:30,312
Scott: Yeah.

13
00:00:32,084 --> 00:00:34,200
Scott: You remember that on Windows 3.1?

14
00:00:34,200 --> 00:00:36,041
Rym: I do remember that on Windows 3.1.

15
00:00:36,041 --> 00:00:37,079
Scott: That didn't even do anything.

16
00:00:38,120 --> 00:00:41,420
Scott: It was just like you would run it and a little doctor would appear and that didn't do anything.

17
00:00:41,962 --> 00:00:45,936
Rym: Of course, actually the first version of Windows I ever had was Windows 3.1.1 with networking.

18
00:00:47,920 --> 00:00:50,544
Scott: The first one I had was just 3.1.

19
00:00:50,544 --> 00:00:51,540
Rym: Oh, did you upgrade?

20
00:00:52,360 --> 00:00:52,406
Rym: No.

21
00:00:53,080 --> 00:00:56,421
Scott: It's a 95.

22
00:00:56,421 --> 00:00:59,479
Rym: Man, I stood in line and bought Windows 2000 like right when it came out.

23
00:01:00,380 --> 00:01:01,179
Scott: Yeah, I didn't do that.

24
00:01:01,300 --> 00:01:05,080
Rym: That was the last time I bought any software at a store, I think.

25
00:01:05,140 --> 00:01:08,820
Scott: I bought Windows 98 SE at a store, but then I bought it online.

26
00:01:08,921 --> 00:01:11,800
Rym: Well, that and Tribes 2 I bought in a store.

27
00:01:12,580 --> 00:01:14,780
Scott: Yeah, but I've actually bought Tribes 2 online.

28
00:01:15,400 --> 00:01:17,449
Rym: Yeah, I bought it in a store because I did not buy it.

29
00:01:17,550 --> 00:01:19,740
Rym: I did not have the money when it came out and you got it.

30
00:01:20,840 --> 00:01:25,640
Scott: In fact, you bought it for me and then you gave me the copy and then I gave you the money.

31
00:01:26,642 --> 00:01:32,260
Rym: Yep, and then realizing the mistake of having not bought it, I forewent food in order to afford my own copy.

32
00:01:33,580 --> 00:01:35,299
Scott: You had a meal plan by then.

33
00:01:36,080 --> 00:01:40,780
Rym: Yeah, I had a meal plan, but it was all debit and I spent it all on coffee and ice cream.

34
00:01:41,160 --> 00:01:42,217
Scott: Why didn't you spend it at Gracie's?

35
00:01:44,101 --> 00:01:45,958
Rym: I was very happy to be done with Gracie's.

36
00:01:46,706 --> 00:01:47,399
Scott: You needed food.

37
00:01:47,780 --> 00:01:48,405
Rym: Plus, all debit.

38
00:01:48,606 --> 00:01:50,420
Rym: A Gracie's dinner was like 20 bucks.

39
00:01:51,200 --> 00:01:52,719
Scott: Well, with all debit it was.

40
00:01:54,529 --> 00:01:55,700
Scott: I think it was 14.

41
00:01:55,700 --> 00:01:58,640
Rym: I'm thinking about busting out the rollerblades, going back to work outside.

42
00:01:59,160 --> 00:01:59,743
Scott: Do not do.

43
00:01:59,945 --> 00:02:02,600
Scott: Do not, because as soon as you do that, the snow is going to just appear.

44
00:02:02,981 --> 00:02:05,288
Rym: See, the thing is, the rollerblades are safe.

45
00:02:05,369 --> 00:02:08,960
Rym: With a bike, if I commit to biking to work, I'm fucked if it gets cold.

46
00:02:09,440 --> 00:02:12,900
Rym: If it gets cold, I can just take off the rollerblades and get on the subway.

47
00:02:13,200 --> 00:02:14,640
Scott: That's not a bad strategy.

48
00:02:14,960 --> 00:02:15,960
Rym: So I don't think winner.

49
00:02:16,861 --> 00:02:22,960
Scott: I'm not, you know, while that might be a safe bet for you, like you test the weather in the morning and then blade to work real fast.

50
00:02:23,380 --> 00:02:30,380
Scott: While it might be a safe bet, you may, you still, whether you can blade to work or not, you don't want to risk it being cold again.

51
00:02:30,501 --> 00:02:32,380
Scott: So you don't want to tempt the weather guy.

52
00:02:32,480 --> 00:02:36,600
Rym: Yeah, but I feel like rollerblades are not quite as prominent as a bike.

53
00:02:37,080 --> 00:02:38,259
Rym: A woman might not see me.

54
00:02:38,682 --> 00:02:39,330
Scott: No, they'll see.

55
00:02:39,391 --> 00:02:40,120
Scott: They see everything.

56
00:02:40,880 --> 00:02:41,764
Scott: It's like trying to hide.

57
00:02:41,824 --> 00:02:44,436
Scott: If you try to set up a Tetris, the Tetris guy will be like,

58
00:02:44,577 --> 00:02:44,657
Scott: "Oh.".

59
00:02:45,320 --> 00:02:46,450
Rym: Line piece.

60
00:02:46,470 --> 00:02:47,135
Rym: Line piece.

61
00:02:49,422 --> 00:02:49,445
Scott: L.

62
00:02:50,540 --> 00:02:51,339
Rym: Reverse squiggly.

63
00:02:51,700 --> 00:02:52,588
Scott: Alright, he blocked it up.

64
00:02:52,648 --> 00:02:53,939
Scott: Line piece.

65
00:02:55,803 --> 00:02:58,020
Scott: The weather guy is the same evil guy.

66
00:02:58,602 --> 00:03:00,900
Scott: The same pantheon of evil guys.

67
00:03:00,900 --> 00:03:01,524
Rym: There's something up.

68
00:03:01,544 --> 00:03:03,839
Rym: We've been referencing the Tetris guy a lot lately.

69
00:03:04,600 --> 00:03:07,460
Scott: Because the pantheon of evil guys have been making their works lately.

70
00:03:07,700 --> 00:03:07,963
Rym: I think so.

71
00:03:08,450 --> 00:03:08,875
Rym: I think so.

72
00:03:09,720 --> 00:03:14,279
Rym: Though there's a, I know you're still the sheriff, but times they are a-changin'.

73
00:03:14,440 --> 00:03:15,174
Scott: How are they changin'?

74
00:03:15,621 --> 00:03:18,019
Rym: Let's see how today's combat goes.

75
00:03:18,660 --> 00:03:19,620
Scott: We're not playing combat.

76
00:03:20,180 --> 00:03:21,086
Rym: Combat in Outlaw.

77
00:03:21,187 --> 00:03:23,160
Rym: What we do in Outlaw is in fact combat.

78
00:03:24,380 --> 00:03:25,470
Scott: Combat has tanks.

79
00:03:25,712 --> 00:03:26,540
Scott: Outlaw has pretzels.

80
00:03:26,620 --> 00:03:28,045
Rym: It's the trouble with Atari games.

81
00:03:28,065 --> 00:03:32,120
Rym: They have names like hockey, football, shooting.

82
00:03:34,885 --> 00:03:36,459
Scott: They also have names like Solar Jetman.

83
00:03:38,100 --> 00:03:38,385
Scott: Solar Fox.

84
00:03:40,121 --> 00:03:42,300
Rym: Solar Jetman, however, was an awesome game.

85
00:03:42,701 --> 00:03:43,156
Scott: Solar Fox.

86
00:03:43,881 --> 00:03:45,320
Rym: Not that awesome of a game.

87
00:03:46,241 --> 00:03:48,259
Rym: My grandpa really liked that one, though.

88
00:03:49,521 --> 00:03:50,179
Scott: Okay, sure.

89
00:03:51,882 --> 00:03:54,079
Rym: There's kind of big news, so I figure we can talk about that.

90
00:03:55,846 --> 00:03:57,379
Rym: I believe it was your news.

91
00:03:57,860 --> 00:03:58,024
Scott: Was it?

92
00:03:58,146 --> 00:03:58,799
Scott: Alright, yeah.

93
00:03:59,783 --> 00:04:06,340
Scott: The most gigantic-est tech news of the whole week that people are pooping all over because it affects things in like 30 different areas.

94
00:04:07,041 --> 00:04:09,599
Scott: Almost as big as the Oracle Sun news.

95
00:04:10,220 --> 00:04:10,905
Rym: Oh my god.

96
00:04:10,925 --> 00:04:12,879
Rym: To this day, I can think of a few.

97
00:04:13,260 --> 00:04:18,560
Rym: I mean, when the DMCA passed, when Oracle and Sun had sex, are some of the darkest days I can remember.

98
00:04:18,959 --> 00:04:19,262
Rym: Right.

99
00:04:19,283 --> 00:04:21,200
Scott: So now it's Nokia and Microsoft.

100
00:04:22,285 --> 00:04:23,060
Rym: Together at last.

101
00:04:23,201 --> 00:04:25,780
Scott: Right, so problem number one, right?

102
00:04:26,460 --> 00:04:30,740
Scott: Well, step number one was Nokia was pretty much king of the world in cell phones.

103
00:04:30,861 --> 00:04:33,380
Scott: Mostly because their candy bar phone took the world by storm.

104
00:04:33,540 --> 00:04:34,880
Scott: Just regular old phones, right?

105
00:04:35,300 --> 00:04:42,980
Scott: And they had Symbian phones and such out and about in the world before anyone else really had smartphones.

106
00:04:43,300 --> 00:04:46,680
Rym: Yeah, they were basically like top of the line, super nice mobile phones.

107
00:04:46,780 --> 00:04:47,840
Scott: It was pretty much, right?

108
00:04:47,900 --> 00:04:53,260
Scott: You had Windows, the original Windows Mobile, which is terrible.

109
00:04:54,423 --> 00:04:59,780
Scott: You had the original, you know, the Blackberries, and they were, you know, they haven't changed that much.

110
00:05:01,003 --> 00:05:02,336
Scott: It's kind of funny that they haven't.

111
00:05:03,121 --> 00:05:06,120
Scott: And you had Palm, the Trios, and those were the smartphones, right?

112
00:05:06,781 --> 00:05:16,300
Scott: And just, you know, even though they were almost as functional as the ones we had the Androids and iPhones we have now, they really just, they didn't take the world by storm.

113
00:05:16,320 --> 00:05:19,679
Scott: It was pretty much big time business users and nerds using them.

114
00:05:19,820 --> 00:05:22,439
Scott: They weren't that much more expensive than they are now.

115
00:05:23,103 --> 00:05:27,059
Rym: Yeah, but they were expensive compared to, you know, the landlines that most people had.

116
00:05:27,500 --> 00:05:28,250
Scott: I guess, yeah.

117
00:05:28,777 --> 00:05:29,040
Scott: Anyway.

118
00:05:29,400 --> 00:05:36,080
Rym: I mean, when a cell phone itself is a luxury, the smart cell phone with the data is going to be a lot more, anyway.

119
00:05:36,523 --> 00:05:38,040
Scott: And you had Symbian OS, right?

120
00:05:38,100 --> 00:05:43,800
Scott: Which was, you know, probably the most open of them, except for maybe the Palm one, right?

121
00:05:44,021 --> 00:05:46,880
Scott: And, you know, it actually worked pretty well in its day.

122
00:05:46,960 --> 00:05:53,460
Scott: And you could get phones with it that weren't necessarily, you know, like crazy expensive phones.

123
00:05:53,460 --> 00:05:57,760
Scott: You can get Symbian on sort of like weaker phones for reasonable prices.

124
00:05:57,800 --> 00:06:01,800
Scott: So it was, you know, it had all the abilities of, you know, I guess to qualify as a smartphone.

125
00:06:01,921 --> 00:06:08,060
Scott: It's pretty much just a phone that you can install software on, which is why Symbian counts as, I guess, a smartphone OS or whatever.

126
00:06:08,680 --> 00:06:12,547
Scott: So Symbian was actually incredibly popular all around the world, not so much in the U.S.

127
00:06:12,587 --> 00:06:17,800
Scott: where Nokia could never really get its phones carried by any of the carriers.

128
00:06:18,340 --> 00:06:21,620
Scott: But everywhere else in the world, you know, Symbian was kind of huge.

129
00:06:21,760 --> 00:06:27,359
Scott: I remember people were using like those, you know, Nokia like N97, whatever phones those were.

130
00:06:27,480 --> 00:06:31,600
Scott: And they were doing like, you know, kick and streaming video and stuff, right?

131
00:06:31,700 --> 00:06:33,018
Scott: You know, and Symbian was huge.

132
00:06:34,962 --> 00:06:46,040
Scott: But now that it's been like two years or so with the iPhone, two or three years with the iPhone and, you know, Android for a couple of years, Nokia really fell off the bus and they didn't advance their shit.

133
00:06:46,280 --> 00:06:51,399
Scott: They started making like the phones that had like ridiculous horsepower, but the software was poop.

134
00:06:52,562 --> 00:06:54,760
Scott: And, you know, they just they weren't keeping up.

135
00:06:54,820 --> 00:07:06,120
Scott: And there was, you know, even in the rest of the world where Nokia could, you know, was sold and popular, they were losing on the bottom end because some Chinese people were making, you know, better cheap phones.

136
00:07:06,441 --> 00:07:10,740
Scott: And they were losing on the high end because Android phones were doing better than Nokia phones.

137
00:07:10,880 --> 00:07:12,239
Rym: So what's a company to do?

138
00:07:12,540 --> 00:07:15,075
Scott: Well, the CEO proved that he was not a moron.

139
00:07:15,095 --> 00:07:15,860
Scott: I was quite impressed.

140
00:07:16,221 --> 00:07:17,071
Scott: He sent out this letter.

141
00:07:17,091 --> 00:07:17,900
Scott: that's on a gadget.

142
00:07:18,241 --> 00:07:24,059
Scott: And the letter is basically like, look, we're on fire and we're throwing gas on the fire.

143
00:07:26,142 --> 00:07:28,920
Scott: It's like, you know, we're basically years behind the competition.

144
00:07:29,021 --> 00:07:30,239
Scott: We need to do something, right?

145
00:07:30,682 --> 00:07:33,980
Scott: And Nokia was doing on paper some stuff that was looking good.

146
00:07:34,000 --> 00:07:41,760
Scott: They were investing in this sort of, you know, Linux platform with like, you know, Migo, which is, you know, a Linux smartphone OS and stuff like that.

147
00:07:41,900 --> 00:07:49,959
Scott: And they bought Trolltech, which makes QT, which is an open source GUI library that, you know, is used on KDE on the Linux desktop.

148
00:07:50,281 --> 00:07:51,346
Scott: And, you know, they were.

149
00:07:51,367 --> 00:07:57,460
Scott: they were, you know, pushing in that right direction, I guess philosophically with the open source Linuxness.

150
00:07:57,641 --> 00:08:12,920
Scott: But the reality was that they totally failed to actually produce something that had, A, the functionality, B, the smooth hardware, and C, good interface or usable in any actual way.

151
00:08:13,221 --> 00:08:17,780
Scott: It was just these horrible, you know, phones that weren't any cheaper and were many times actually more expensive.

152
00:08:17,800 --> 00:08:24,100
Rym: I think what really hurt is that they weren't used to competing with the kinds of companies you have to compete with in the modern smartphone market.

153
00:08:24,560 --> 00:08:27,240
Rym: I mean, they were used to competing with, you know, other crappy cell phone manufacturers.

154
00:08:27,240 --> 00:08:28,980
Scott: Yeah, like Motorola and HTC.

155
00:08:29,723 --> 00:08:34,500
Rym: And then now they've got to compete with, you know, Microsoft and Google and Apple.

156
00:08:34,860 --> 00:08:41,193
Scott: Well, now HP, because inside news, HP's finally gotten rid of the word Palm forever, and it's now just HP.

157
00:08:42,200 --> 00:08:42,280
Rym: Yeah.

158
00:08:42,301 --> 00:08:45,480
Rym: Meanwhile, there are no updates to web OS and no apps.

159
00:08:45,762 --> 00:08:48,200
Rym: So my pre is still pretty goddamn useless.

160
00:08:49,521 --> 00:08:52,591
Scott: Anyway, the right.

161
00:08:52,772 --> 00:08:59,900
Scott: So what Nokia has done here, right, is they said, all right, look, you know, we can't be like, you know, let's stop throwing gas on the fire.

162
00:09:00,000 --> 00:09:03,260
Scott: What we'll do is Apple, obviously, we can't do anything with them.

163
00:09:03,400 --> 00:09:06,000
Scott: They're not going to let us put iOS in a Nokia phone.

164
00:09:06,221 --> 00:09:07,313
Scott: That's not going to happen.

165
00:09:07,637 --> 00:09:07,880
Scott: Right.

166
00:09:08,621 --> 00:09:11,380
Scott: We could just install Android on Nokia phones.

167
00:09:11,620 --> 00:09:16,700
Rym: And be, you know, one among many generic Android phones that no one would seek out.

168
00:09:17,360 --> 00:09:21,420
Scott: So what, you know, so what we're going to do is we'll partner with Microsoft.

169
00:09:21,761 --> 00:09:22,002
Scott: Right.

170
00:09:22,043 --> 00:09:26,160
Scott: And we'll get the Windows Phone 7 on some Nokia phones.

171
00:09:26,380 --> 00:09:35,099
Scott: So maybe if we, you know, can combine, you know, even though Microsoft's mobile OS isn't so popular, it's still got something going on.

172
00:09:35,280 --> 00:09:42,700
Rym: I would call the Windows Phone 7 a huge kind of unpredictable dark horse in the cell phone market because it's the only one that's different.

173
00:09:43,282 --> 00:09:46,019
Rym: But at the same time, no one seems to care about it.

174
00:09:46,381 --> 00:09:49,620
Rym: And it's not doing anything different enough to make anyone say, oh, I want one of those.

175
00:09:50,122 --> 00:09:54,000
Rym: It didn't penetrate the enterprise market because BlackBerry still got that locked down.

176
00:09:54,480 --> 00:09:59,280
Rym: It's not penetrating the normal user because they're going to either get an Apple or whatever their cell phone company gives it.

177
00:09:59,300 --> 00:10:00,144
Scott: And if the iPhone.

178
00:10:00,184 --> 00:10:02,252
Scott: nano rumors are true, that's the end.

179
00:10:02,272 --> 00:10:02,734
Scott: Game over.

180
00:10:04,380 --> 00:10:08,860
Rym: Meanwhile, this weird aside that, you know, I've got my pre and my contracts running out and I'm looking at phones.

181
00:10:08,980 --> 00:10:14,220
Rym: And I was poking at pretty much every Android phone that Verizon or Sprint has available.

182
00:10:14,902 --> 00:10:16,209
Rym: And I was also poking at iPhones.

183
00:10:16,270 --> 00:10:17,999
Rym: And WebOS has fucking ruined me.

184
00:10:18,604 --> 00:10:20,800
Rym: I hate every other interface on every phone.

185
00:10:21,620 --> 00:10:21,802
Scott: Really?

186
00:10:21,843 --> 00:10:23,260
Scott: They just feel sluggish.

187
00:10:23,900 --> 00:10:24,940
Scott: What's sluggish about the iPhone?

188
00:10:25,240 --> 00:10:26,169
Rym: The iPhone doesn't feel sluggish.

189
00:10:26,229 --> 00:10:27,380
Rym: The Androids all feel sluggish.

190
00:10:27,500 --> 00:10:27,796
Rym: Yeah, they do.

191
00:10:28,060 --> 00:10:32,140
Rym: The iPhone feels restricting, but I think part of it is that I have this visceral feel.

192
00:10:32,240 --> 00:10:37,100
Rym: I'm so used to, I've got these cards all over the place and I just flick them off the top of the screen and flick them around.

193
00:10:37,741 --> 00:10:41,320
Rym: And not being able to do that keeps messing me up in a big way.

194
00:10:41,840 --> 00:10:45,940
Scott: Yeah, I guess, you know, you just got to double tap the home button and you slide on the bottom.

195
00:10:46,262 --> 00:10:49,680
Rym: I guess it's hard to tell at this juncture how much of that is me being used to.

196
00:10:49,741 --> 00:10:51,019
Scott: That's just a used to thing.

197
00:10:51,340 --> 00:10:54,700
Rym: It's hard to tell if it's a used to thing or if it is just a clearly better interface.

198
00:10:56,066 --> 00:10:56,534
Rym: Uh, whatever.

199
00:10:56,880 --> 00:11:00,760
Rym: Because I do feel like there are things WebOS does that are better than everyone else.

200
00:11:01,060 --> 00:11:03,380
Scott: Well, yeah, like integrating all the mails properly.

201
00:11:03,420 --> 00:11:05,999
Rym: Oh my god, the fact that that just works still amazes me.

202
00:11:06,620 --> 00:11:14,959
Rym: But I think Windows, you know, in my tradition of getting the phone that ends up being the minority shit phone, I think Windows 7 phone is going to be where I might go.

203
00:11:15,564 --> 00:11:17,520
Rym: You know, to counterbalance.

204
00:11:17,620 --> 00:11:18,697
Scott: It does some Xbox stuff.

205
00:11:19,808 --> 00:11:20,719
Scott: Yeah, they might need that.

206
00:11:20,940 --> 00:11:25,080
Scott: But I think, you know, if Nokia partners with Microsoft, well, they did partner with Microsoft, right?

207
00:11:25,361 --> 00:11:27,400
Rym: I wouldn't bet any money on that partnership.

208
00:11:27,420 --> 00:11:38,400
Scott: No, but if they can somehow get the magic of the software with, Microsoft has generally failed at hardware, with Nokia hardware that somehow makes, if they somehow make a not sucky hardware, they might go somewhere.

209
00:11:38,741 --> 00:11:40,100
Scott: Especially in the rest of the world.

210
00:11:40,501 --> 00:11:46,240
Scott: I think it could do well in places like India where Microsoft is still, you know, so powerful.

211
00:11:46,802 --> 00:11:48,219
Scott: Or even South Korea.

212
00:11:48,400 --> 00:11:52,280
Rym: I think what they should really gun for is the destroying the BlackBerry market.

213
00:11:52,460 --> 00:12:00,340
Rym: Because BlackBerry is not, like, it's only powerful and existent today due to the fact that most enterprises are too afraid to drop it.

214
00:12:00,963 --> 00:12:02,097
Rym: They've got too much invested in it.

215
00:12:02,660 --> 00:12:07,240
Rym: Yet, most people hate their Blackberries unless they're people who never had a smartphone and the company gave them a BlackBerry.

216
00:12:07,240 --> 00:12:08,820
Scott: Blackberries is one of the only ones who can attack.

217
00:12:09,220 --> 00:12:14,500
Scott: You know, they pretty much eat, the BlackBerry stronghold has pretty much been eaten away at as much as it can be eaten away at.

218
00:12:14,880 --> 00:12:19,020
Scott: To kill the rest, the only one who can kill the rest is Microsoft because they have Outlook.

219
00:12:19,441 --> 00:12:21,200
Scott: And the companies aren't going to give up Outlook.

220
00:12:21,362 --> 00:12:21,450
Scott: Nope.

221
00:12:21,780 --> 00:12:24,500
Scott: So they're pretty much only choices are Blackberries or, right?

222
00:12:24,540 --> 00:12:39,780
Rym: If Microsoft can come in with a Nokia phone and they have a huge kind of enterprise suite of, check it out, just turn this on, auto-migration from BlackBerry Enterprise server to an Outlook, Enterprise, Windows 7 phone, whatever server, they would destroy Rym almost overnight.

223
00:12:39,960 --> 00:12:43,640
Scott: The thing is, iPhones and Androids can also do all that exchange stuff.

224
00:12:43,820 --> 00:12:45,371
Rym: Yeah, but that doesn't matter.

225
00:12:45,411 --> 00:12:46,680
Rym: The technological reality.

226
00:12:46,760 --> 00:12:49,060
Scott: I see a lot of people who switch from BlackBerry to Android.

227
00:12:49,540 --> 00:12:52,380
Rym: Yeah, that's such a tiny minority of the Enterprise market.

228
00:12:52,960 --> 00:12:59,200
Rym: Because the only reason people use BlackBerry is that suits think that BlackBerry is safe, and they're right to a degree.

229
00:12:59,541 --> 00:13:05,680
Rym: If Rym gets compromised, the entire industry, whatever your industry is, was compromised at the same time.

230
00:13:06,080 --> 00:13:07,340
Rym: So you have no culpability.

231
00:13:07,680 --> 00:13:14,080
Rym: But if you're using Android phones and you set up your own security, and there's a security problem, you're not going to get blamed.

232
00:13:14,620 --> 00:13:22,540
Scott: No, because the thing is, BlackBerry actually has its own server, the BlackBerry Enterprise server that you have to install on your company's machine.

233
00:13:23,380 --> 00:13:25,680
Scott: And the thing is, that goes next to the exchange server.

234
00:13:25,960 --> 00:13:27,840
Scott: So now you've actually created two points of failure.

235
00:13:28,161 --> 00:13:34,960
Scott: If you use Android or Apple or iPhone or Windows, they just connect directly to the exchange server with ActiveSync.

236
00:13:35,200 --> 00:13:40,880
Scott: So actually, you're just removing the BlackBerry server entirely, and you have the same point of failure exchange that you had before.

237
00:13:41,060 --> 00:13:42,345
Rym: Yeah, I'm not talking about point of failure.

238
00:13:42,485 --> 00:13:46,520
Rym: I'm talking about, say there was a breach, like a user lost their phone.

239
00:13:47,200 --> 00:13:54,020
Rym: And before you could wipe it out remotely from your server, delete all the data, encrypt it or whatever, someone got some data.

240
00:13:54,602 --> 00:13:59,194
Rym: If you're using a BlackBerry, you can pretty much get away with saying, "We were using best of breed.

241
00:13:59,214 --> 00:14:01,059
Rym: We used BlackBerry, and we got compromised

242
00:14:01,139 --> 00:14:01,420
Rym: anyway.".

243
00:14:01,922 --> 00:14:06,018
Rym: If you're not using that, people could come after you saying, "Why aren't you using what the rest of your sector is

244
00:14:06,098 --> 00:14:06,299
Rym: using?".

245
00:14:07,201 --> 00:14:09,599
Rym: That's the kind of bullshit that shareholders and suits will do.

246
00:14:11,960 --> 00:14:17,480
Rym: Also, most people who are in the position to make the decisions don't realize that they can set things up like that.

247
00:14:17,640 --> 00:14:20,950
Rym: They think that BlackBerry is the only way to have a phone.

248
00:14:21,211 --> 00:14:24,320
Rym: that's a company phone that they can remotely wipe out if you lose it.

249
00:14:24,460 --> 00:14:25,638
Scott: Sounds like they didn't hire any tech people.

250
00:14:26,862 --> 00:14:29,040
Rym: No, it's because they don't listen to the tech people.

251
00:14:30,160 --> 00:14:33,740
Rym: BlackBerry's got the market locked down, and they think BlackBerry is the market.

252
00:14:34,700 --> 00:14:38,069
Rym: So Microsoft is the only one that has enough clout to say, "Look, we're enterprise.

253
00:14:38,290 --> 00:14:39,092
Rym: You use Outlook.

254
00:14:39,513 --> 00:14:41,359
Rym: We'll handle it just the same as Rym

255
00:14:41,379 --> 00:14:41,639
Rym: does.".

256
00:14:43,742 --> 00:14:50,640
Scott: The thing that really gets me about this Microsoft Nokia deal, and I'm not going to make any predictions or anything like that.

257
00:14:50,900 --> 00:14:55,880
Scott: There were some deals with the Nokia employees who work on software getting pissed because they're basically throwing all their work away.

258
00:14:57,101 --> 00:15:01,600
Rym: I predict non-newsworthy, mediocre success.

259
00:15:02,240 --> 00:15:07,519
Scott: What I think is the real big issue here is something I think is a bigger issue in the world as a whole.

260
00:15:08,404 --> 00:15:10,979
Scott: You look at this deal and look at the money behind this deal.

261
00:15:11,660 --> 00:15:14,700
Scott: And basically the situation here is Nokia not to look so good.

262
00:15:15,100 --> 00:15:19,039
Scott: So a bunch of money comes from Microsoft to Nokia, so now they look so good.

263
00:15:19,620 --> 00:15:21,899
Scott: Because Microsoft paid them a bajillion dollars for this deal.

264
00:15:23,342 --> 00:15:26,035
Scott: But that money doesn't come from customers.

265
00:15:26,115 --> 00:15:27,120
Scott: It came from Microsoft.

266
00:15:27,661 --> 00:15:31,940
Scott: And I think what's happening, I can see it at my company and a lot of other companies in the world.

267
00:15:33,103 --> 00:15:34,639
Scott: They're sitting there doing their business.

268
00:15:35,763 --> 00:15:40,619
Scott: And some other company comes along and says, "We will give you X dollars to do

269
00:15:40,679 --> 00:15:40,840
Scott: this.".

270
00:15:41,861 --> 00:15:48,220
Scott: But whatever this is, is not necessarily good for employees and/or customers.

271
00:15:48,782 --> 00:15:49,748
Rym: Oh hell no!

272
00:15:49,788 --> 00:15:51,860
Rym: It's good for the company that's paying for it.

273
00:15:52,080 --> 00:16:00,420
Scott: But you look at the balance sheet and you say, "Okay, maybe somebody... Microsoft is going to pay us this much to use their OS.

274
00:16:00,681 --> 00:16:02,685
Scott: That will lose us ex-customers.

275
00:16:02,765 --> 00:16:08,137
Scott: The money they are paying us is more than the money we will lose by losing those

276
00:16:08,277 --> 00:16:09,119
Scott: ex-customers.".

277
00:16:10,000 --> 00:16:11,179
Scott: And it's good on the balance sheet.

278
00:16:11,962 --> 00:16:16,560
Scott: So in a short term balance sheet decision, how could you not do that?

279
00:16:17,302 --> 00:16:19,874
Scott: But in the long term, you're killing your brand.

280
00:16:19,914 --> 00:16:23,900
Scott: You're doing all these other hard... You're making your software... You're doing something bad.

281
00:16:24,061 --> 00:16:28,420
Rym: And thus the kind of endgame of large corporations and investment.

282
00:16:28,780 --> 00:16:36,200
Rym: Where the real customers of a company in the end are the shareholders who want short to medium term gains.

283
00:16:37,141 --> 00:16:40,754
Scott: Right, but look at companies such as Apple.

284
00:16:41,055 --> 00:16:42,399
Scott: Apple doesn't do shit like that.

285
00:16:43,260 --> 00:16:51,699
Scott: Apple's not going to be like, "Okay, you paid us two billion dollars so we're going to put your ugly ass icon on the

286
00:16:51,839 --> 00:16:52,100
Scott: iPhone.".

287
00:16:52,100 --> 00:16:53,871
Rym: Do you want to know why Apple doesn't do stuff like that?

288
00:16:53,911 --> 00:16:55,420
Rym: Because they're already making money.

289
00:16:55,740 --> 00:16:57,006
Rym: Successful companies don't do it.

290
00:16:57,207 --> 00:16:59,820
Rym: The ones that are failing are the ones that end up in these situations.

291
00:17:00,300 --> 00:17:05,560
Scott: Right, but it's basically a stupid move because all you're doing is prolonging your death.

292
00:17:05,700 --> 00:17:07,549
Rym: Yes, which is exactly what you want to do.

293
00:17:07,589 --> 00:17:09,599
Rym: That is the best interest for the shareholders.

294
00:17:10,079 --> 00:17:14,420
Rym: You keep the company afloat and looking like it's profitable for as long as possible.

295
00:17:14,640 --> 00:17:20,680
Scott: No, what you want to do is you want to actually start actually caring about the customers.

296
00:17:21,202 --> 00:17:26,599
Scott: And then in the short term there might even be a loss, but in the long term you might actually compete and win out.

297
00:17:26,839 --> 00:17:32,860
Rym: And Scott, in some cases shareholders can sue the board of directors and the company saying that you're not acting in their self-interest.

298
00:17:33,781 --> 00:17:36,019
Scott: Which is why you shouldn't make a company public.

299
00:17:37,763 --> 00:17:38,878
Scott: Ah, ding ding ding ding ding ding.

300
00:17:39,440 --> 00:17:40,310
Scott: But anyway, right?

301
00:17:42,222 --> 00:17:46,020
Rym: I would say there's one other thing going on here, and this is kind of a tangent so I won't dwell on it.

302
00:17:46,842 --> 00:17:59,880
Rym: A lot of the things, the differences between the three or four cell platforms we have, especially in UI, are only different due to the fact that everyone has patent encumbering bullshit on their things.

303
00:18:00,540 --> 00:18:04,060
Rym: And there's that huge clusterfuck of everybody can sue everybody at any time over everything.

304
00:18:05,582 --> 00:18:12,819
Rym: So if one OS will have a good feature or a good thing and no one else can use that because there's a patent on it.

305
00:18:13,444 --> 00:18:14,839
Rym: Even though it's a fairly obvious thing.

306
00:18:15,360 --> 00:18:23,020
Rym: And if we really relaxed or broke down these software and UI patents, I feel like there would be a rapid convergence toward the good decisions.

307
00:18:23,920 --> 00:18:40,780
Rym: And I think a lot of the fake innovation that's going on in the companies that are doing so well, not saying that what Nokia is doing is fake innovation, but the situations like that, is that because they can't attack directly because of patents, they basically have to go in all the directions that everyone else said will fail because that's all that's left.

308
00:18:42,982 --> 00:18:50,900
Rym: So very briefly, talking about IPOs and companies doing things, Pandora is filing for an IPO for whatever reason.

309
00:18:52,382 --> 00:18:53,608
Rym: What do they need the capital for?

310
00:18:53,668 --> 00:18:54,612
Rym: What are they going to do?

311
00:18:55,336 --> 00:18:56,280
Rym: Online radio is...

312
00:18:56,340 --> 00:19:00,340
Scott: First of all, they're behind Last.fm technology-wise and music-wise.

313
00:19:00,500 --> 00:19:05,500
Scott: But Last.fm is now charging for mobile access and some other things, so that kills them, right?

314
00:19:05,600 --> 00:19:11,620
Rym: Ah, but mobile access means less and less for me, because I listen mostly when I'm sedentary at a computer.

315
00:19:12,280 --> 00:19:17,900
Scott: Right, but Grooveshark is killing them both, and Spotify kills everybody.

316
00:19:18,120 --> 00:19:29,640
Rym: Spotify is the second highest source of income for record labels in Europe, but Spotify isn't available in the U.S But at the same time, it's all the weird cyclical problem that TV has, too, where, like, how does Pandora make money?

317
00:19:29,680 --> 00:19:31,253
Rym: They have to pay for everything they stream.

318
00:19:31,314 --> 00:19:31,778
Rym: Last.fm, too.

319
00:19:32,020 --> 00:19:33,200
Scott: They sell ads on Pandora.

320
00:19:33,280 --> 00:19:36,680
Rym: Yes, they sell ads, but at the same time, do those ads even work?

321
00:19:37,121 --> 00:19:41,380
Rym: Is it just another kind of advertising model propping up a dying industry?

322
00:19:44,362 --> 00:19:45,164
Rym: What are they going to do?

323
00:19:45,224 --> 00:19:50,080
Rym: What could they possibly use $100 million for to make Pandora better?

324
00:19:50,480 --> 00:19:52,977
Scott: Maybe what they'll do is they'll just take the $100 million and then quit.

325
00:19:53,500 --> 00:19:55,579
Rym: And then everyone's going to sell their stock and get the hell away.

326
00:19:56,160 --> 00:19:56,522
Scott: Right.

327
00:19:56,542 --> 00:19:58,771
Scott: It's like, "Shit, Pandora's starting to lose money.

328
00:19:59,314 --> 00:20:00,740
Scott: This is never going to be successful.

329
00:20:01,281 --> 00:20:02,334
Scott: Let's get a bunch of money and

330
00:20:02,375 --> 00:20:02,577
Scott: leave.".

331
00:20:03,480 --> 00:20:05,400
Rym: Well, do you want to be a king or do you want to be rich?

332
00:20:05,540 --> 00:20:08,440
Rym: And if you're in the online music industry, you pretty much want to be rich.

333
00:20:09,706 --> 00:20:09,807
Scott: Yeah.

334
00:20:09,828 --> 00:20:10,960
Scott: Spotify is already the king.

335
00:20:11,100 --> 00:20:12,708
Rym: I mean, I used to use Pandora.

336
00:20:13,030 --> 00:20:15,020
Rym: I stopped because they played ads.

337
00:20:15,420 --> 00:20:17,279
Scott: And because it's the same music over and over again?

338
00:20:17,460 --> 00:20:17,701
Scott: Yeah.

339
00:20:17,882 --> 00:20:19,149
Rym: Well, it'd be fine.

340
00:20:19,229 --> 00:20:21,220
Rym: And then, like, one techno song would, like, break in.

341
00:20:21,420 --> 00:20:22,324
Rym: Like, "Oh, it played a techno

342
00:20:22,344 --> 00:20:22,625
Rym: song.".

343
00:20:23,067 --> 00:20:25,800
Rym: And then it was nothing but Darude for, like, an hour.

344
00:20:27,082 --> 00:20:27,990
Rym: Also, they played an ad.

345
00:20:28,011 --> 00:20:28,778
Rym: And I was like, "What the fuck is

346
00:20:28,798 --> 00:20:28,940
Rym: this?".

347
00:20:28,980 --> 00:20:32,437
Rym: And I stopped using it and I started using Last.fm just because I never heard ads on Last.fm.

348
00:20:33,260 --> 00:20:37,637
Scott: Well, Last.fm is actually owned by CVS, which is why they're starting to charge money.

349
00:20:37,657 --> 00:20:38,520
Scott: It's a Hulu situation.

350
00:20:38,780 --> 00:20:42,800
Rym: Ah, but while they charge money for the app, they don't charge money for the browser and ads.

351
00:20:43,260 --> 00:20:43,420
Scott: Not yet.

352
00:20:43,922 --> 00:20:44,325
Rym: And you know what?

353
00:20:44,345 --> 00:20:44,767
Rym: if they do?

354
00:20:45,271 --> 00:20:46,700
Rym: I'm not going to use them anymore.

355
00:20:47,540 --> 00:20:55,240
Scott: You know what I've been using is I've just been going to listen to traditional, like, shoutcast streaming music servers on my iPhone.

356
00:20:55,889 --> 00:20:56,640
Scott: And on my computer.

357
00:20:57,061 --> 00:21:01,760
Rym: I also dip into my substantial music collection and occasionally go to the Pirate Bay.

358
00:21:02,961 --> 00:21:11,050
Rym: And if I really want to hear a specific song, like, right now, and it's not a song that needs the high quality, I just go to YouTube, listen to it, and then I'm good.

359
00:21:11,070 --> 00:21:11,452
Rym: I'm set.

360
00:21:11,532 --> 00:21:13,220
Rym: I heard the song, got it, out of my head.

361
00:21:14,260 --> 00:21:25,060
Rym: So, I don't know where the online music streaming industry is going to go, but I feel like the whole thing is destined for this gigantic, long-term disaster.

362
00:21:25,521 --> 00:21:25,722
Scott: Yeah.

363
00:21:26,123 --> 00:21:31,380
Scott: It doesn't help that the law is not really helping them out, you know, making them pay royalties and other bullshit.

364
00:21:31,680 --> 00:21:33,259
Rym: Oh, so they shouldn't pay royalties at all?

365
00:21:33,780 --> 00:21:33,850
Scott: Huh?

366
00:21:34,501 --> 00:21:35,287
Rym: No royalties at all?

367
00:21:35,328 --> 00:21:35,832
Rym: What should they do?

368
00:21:35,872 --> 00:21:36,699
Rym: What's bad about the law?

369
00:21:38,542 --> 00:21:41,220
Scott: It's about the numbers in the law are the problem.

370
00:21:41,582 --> 00:21:43,260
Rym: Oh, the statutory royalties, you mean?

371
00:21:43,440 --> 00:21:49,018
Scott: Yeah, you know, every once in a while it comes around and it's like, you know, "Oh, they're trying to kill streaming music on the internet

372
00:21:49,058 --> 00:21:49,460
Scott: again!".

373
00:21:49,641 --> 00:21:51,499
Scott: And that's happened like two or three times so far.

374
00:21:51,680 --> 00:21:56,380
Rym: The thing is, I hope they do kill streaming music on the internet, because then they will kill themselves, and you know what's going to be left?

375
00:21:57,020 --> 00:21:57,399
Rym: Jamendo!

376
00:22:05,400 --> 00:22:07,449
Rym: But anyway, things of the day!

377
00:22:07,469 --> 00:22:10,100
Rym: You know what Detroit needs, according to the internet?

378
00:22:11,124 --> 00:22:11,669
Scott: Uh, people.

379
00:22:12,355 --> 00:22:12,859
Scott: To live there.

380
00:22:13,240 --> 00:22:17,455
Rym: There was a tweet, and someone said something to the effect of, "You know what Detroit needs right now?

381
00:22:17,495 --> 00:22:17,776
Rym: They need

382
00:22:17,816 --> 00:22:18,399
Rym: Robocop.".

383
00:22:18,900 --> 00:22:25,240
Rym: And apparently, Mer Bing responded to that tweet, saying that they had no plans to make a Robocop statue, you know, there's a little conversation.

384
00:22:26,441 --> 00:22:33,440
Rym: And then a Kickstarter got started to build a life-size, ultra-realistic statue of Robocop in Detroit.

385
00:22:33,780 --> 00:22:37,500
Rym: And in four days, they have raised over $18,000.

386
00:22:37,500 --> 00:22:39,480
Scott: How much does it cost to make a Robocop statue?

387
00:22:40,001 --> 00:22:40,870
Rym: That is 35% of the project.

388
00:22:42,640 --> 00:22:43,178
Scott: What's the rest?

389
00:22:43,178 --> 00:22:47,400
Rym: 35% of it is $18,000.

390
00:22:47,400 --> 00:22:48,464
Rym: Whoa, what?

391
00:22:48,485 --> 00:22:52,480
Scott: I thought you said that the statue would cost 35% of the $18,000.

392
00:22:52,480 --> 00:22:54,500
Rym: No, they raised $18,000.

393
00:22:54,500 --> 00:22:56,293
Rym: How much the fuck is a statue?

394
00:22:56,354 --> 00:22:57,200
Rym: What's it made out of?

395
00:22:57,425 --> 00:22:58,120
Rym: It's got metal.

396
00:22:59,966 --> 00:23:02,060
Scott: You can definitely build multiple Robocop statues.

397
00:23:02,500 --> 00:23:06,634
Rym: No, high quality statues that are going to last and look good are very expensive.

398
00:23:06,654 --> 00:23:08,019
Rym: You need to get an artist to make it.

399
00:23:09,082 --> 00:23:10,880
Scott: You can definitely do it for less than $18,000.

400
00:23:10,880 --> 00:23:13,693
Rym: Also the land, the permanent maintenance, you know, all those things.

401
00:23:13,754 --> 00:23:14,960
Rym: I mean, statues cost money.

402
00:23:15,900 --> 00:23:16,618
Scott: It sits there in the park.

403
00:23:16,760 --> 00:23:19,159
Rym: How much do you think the Sentinel cost at RIT?

404
00:23:19,380 --> 00:23:22,960
Scott: Didn't cost RIT anything because other people paid for it.

405
00:23:23,660 --> 00:23:27,579
Scott: And that's gigantic and it requires cranes and construction and shit.

406
00:23:28,020 --> 00:23:29,671
Scott: A Robocop is the size of a person.

407
00:23:29,712 --> 00:23:30,900
Scott: You can make it in your studio.

408
00:23:31,721 --> 00:23:33,740
Scott: And then you have to pay for a truck to drive it to the park.

409
00:23:34,141 --> 00:23:37,839
Rym: I don't think you understand what's actually involved in making a statue like that.

410
00:23:39,461 --> 00:23:43,019
Rym: Anyway, I think this is cool and I actually donated some money to it.

411
00:23:43,520 --> 00:23:44,650
Rym: Well, I pledged some money.

412
00:23:44,731 --> 00:23:45,337
Rym: I'm part of it.

413
00:23:46,154 --> 00:23:46,360
Scott: Alright.

414
00:23:47,160 --> 00:23:54,076
Rym: And my favorite comment on this whole thing, someone on Twitter was like, "Yeah, I can kick that statue of Rocky Balboa's

415
00:23:54,297 --> 00:23:54,458
Rym: ass.".

416
00:23:55,640 --> 00:23:56,169
Scott: Yeah, that's right.

417
00:23:56,230 --> 00:23:56,780
Scott: Philly sucks.

418
00:23:57,440 --> 00:23:59,695
Rym: Plus Detroit, look, you've got a statue of Rocky Balboa.

419
00:23:59,735 --> 00:24:00,400
Rym: You know what we have?

420
00:24:00,820 --> 00:24:03,068
Rym: We have a statue of Joe Louis's fist.

421
00:24:03,650 --> 00:24:04,594
Rym: Just his fist.

422
00:24:04,754 --> 00:24:06,360
Rym: It's bigger than you can imagine.

423
00:24:06,840 --> 00:24:09,520
Rym: It's just hanging with a fist and a little bit of a wrist coming off of it.

424
00:24:09,881 --> 00:24:11,980
Scott: The Rocky statue's in Philly, not Detroit.

425
00:24:12,326 --> 00:24:12,638
Rym: I know.

426
00:24:12,981 --> 00:24:13,680
Scott: You said Detroit.

427
00:24:14,082 --> 00:24:14,122
Rym: No.

428
00:24:14,343 --> 00:24:18,240
Rym: Yeah, because in Detroit we have a statue of Joe Louis's fist.

429
00:24:18,320 --> 00:24:19,469
Scott: No, before that you said Detroit.

430
00:24:19,489 --> 00:24:20,093
Scott: What you got?

431
00:24:20,113 --> 00:24:20,899
Scott: Anyway.

432
00:24:21,840 --> 00:24:22,200
Rym: Anyway.

433
00:24:23,126 --> 00:24:23,338
Scott: Anyway.

434
00:24:24,268 --> 00:24:24,439
Rym: So?

435
00:24:25,225 --> 00:24:25,519
Scott: So what?

436
00:24:25,762 --> 00:24:26,759
Rym: You've got a thing of the day?

437
00:24:27,401 --> 00:24:28,508
Scott: Oh, that was a thing of the day?

438
00:24:28,528 --> 00:24:30,078
Scott: I didn't realize you did things of the day already.

439
00:24:30,158 --> 00:24:30,460
Scott: Oh shit.

440
00:24:31,447 --> 00:24:31,580
Scott: Okay.

441
00:24:31,880 --> 00:24:35,640
Scott: So last week on Monday night I went to this Hack and Tell thing, which I've been going to.

442
00:24:35,780 --> 00:24:37,207
Scott: It's been going on for six months.

443
00:24:37,267 --> 00:24:42,040
Scott: It's like a little, you know, there's one in New York and I think there's one in California now that just started.

444
00:24:42,261 --> 00:24:50,020
Scott: Basically you meet there and some nerds spend five minutes showing you something they made and then it's like show and tell, but it's something you hacked, right?

445
00:24:50,620 --> 00:24:57,120
Scott: So this one kid, he gets up there and he's like, here's Madden 2011 for the Xbox, right?

446
00:24:57,761 --> 00:25:01,580
Scott: He plays it online against people and he doesn't win all the time.

447
00:25:01,980 --> 00:25:03,471
Scott: He wins rarely.

448
00:25:03,531 --> 00:25:04,699
Scott: His record was pretty bad.

449
00:25:05,480 --> 00:25:09,880
Scott: So he found a way to cheat that won't get him kicked off Xbox Live.

450
00:25:10,382 --> 00:25:15,680
Scott: And it's his little blog post that tells you exactly how to cheat and always win at Madden.

451
00:25:16,481 --> 00:25:17,339
Scott: And here's what he does.

452
00:25:17,780 --> 00:25:27,440
Scott: Apparently, when you're Xbox, right, once you're playing Madden against somebody, the packets actually go directly between your Xbox and their Xbox, right?

453
00:25:27,761 --> 00:25:30,000
Scott: So he puts on the Wireshark on a computer, right?

454
00:25:30,861 --> 00:25:35,680
Scott: And then he can see the IP address of his opponent by looking at the packets from the Xbox.

455
00:25:36,263 --> 00:25:41,840
Rym: If this ends and you playing a game with a stranger online and while they're about to do something, you call their cell phone.

456
00:25:42,260 --> 00:25:42,581
Scott: Right, no.

457
00:25:42,662 --> 00:25:49,458
Scott: And then as soon as he plays and he tries to win, but if he's going to lose, what he does is...

458
00:25:49,680 --> 00:25:50,079
Rym: Is he in flood?

459
00:25:50,500 --> 00:25:54,180
Scott: Yeah, he just goes to a computer that he has on a hosting account.

460
00:25:54,400 --> 00:25:57,740
Scott: So it's not coming from his IP, it's coming from out on the internet.

461
00:25:58,701 --> 00:26:04,319
Scott: And he has a really simple, it's pretty much while true, send a UDP packet to...

462
00:26:04,802 --> 00:26:06,480
Rym: I'm going to make an admission.

463
00:26:06,880 --> 00:26:16,180
Rym: When I used to play Action Quake back in the day in high school, I would occasionally sin-flood the IPs of people that I was trying to beat.

464
00:26:16,880 --> 00:26:24,820
Scott: Right, so basically what it does is it just destroys the other person's router or their Xbox directly and then they disconnect.

465
00:26:25,860 --> 00:26:32,789
Scott: And then as soon as they've disconnected, Madden gives you a choice of... You know, they disconnected.

466
00:26:32,930 --> 00:26:34,880
Scott: Either I win or the game doesn't count.

467
00:26:35,484 --> 00:26:37,160
Scott: Because you're still connected, you get to choose.

468
00:26:37,340 --> 00:26:39,060
Scott: Either I win or the game doesn't count.

469
00:26:39,761 --> 00:26:42,378
Scott: So basically if he plays against someone who is a jerk, he's like, "I

470
00:26:42,419 --> 00:26:42,519
Scott: win.".

471
00:26:43,940 --> 00:26:44,131
Rym: Alright.

472
00:26:45,661 --> 00:26:53,100
Scott: Right, so like one guy was running up the score on him and was winning by a whole lot and was pulling an onside kick and all sorts, you know, basically trying to run up the score before.

473
00:26:53,580 --> 00:26:54,651
Scott: So he's just like, "Yeah, I

474
00:26:54,691 --> 00:26:54,833
Scott: win.".

475
00:26:56,582 --> 00:27:00,417
Scott: And he hasn't been banned or anything from Xbox because there's no way for them to know him.

476
00:27:00,800 --> 00:27:04,540
Scott: Because there just happened to be a DOS coming from some other IP address.

477
00:27:04,740 --> 00:27:17,700
Rym: See, the funny thing is that's the kind of bullshit you'd expect from PC gaming where people would also expect it, but using a technique like that against a console gamer is like punching a baby in the face.

478
00:27:18,440 --> 00:27:21,060
Scott: Yeah, he says once, usually people don't have voice chats.

479
00:27:21,420 --> 00:27:23,700
Scott: You know, most people don't, so you can't really hear their reaction.

480
00:27:24,322 --> 00:27:28,633
Scott: But once he said the voice chat was on and he heard something sort of along the lines of, "Oh no!

481
00:27:28,955 --> 00:27:28,995
Scott: Oh

482
00:27:29,035 --> 00:27:29,176
Scott: no!"

483
00:27:32,703 --> 00:27:33,880
Scott: Before it cut out, obviously.

484
00:27:34,900 --> 00:27:40,940
Rym: But before we get to the main bit, of course, the meta moment, we are going to be at PAX East doing five panels in three panel rooms.

485
00:27:41,401 --> 00:27:47,820
Rym: We will have our combined panel schedule of us and all the other good panels, at least the panels that are done by friends of ours.

486
00:27:48,621 --> 00:27:52,280
Rym: And we'll put them online for your PAX planning, perusal pleasure.

487
00:27:52,640 --> 00:27:52,707
Scott: Yep.

488
00:27:53,203 --> 00:27:56,700
Rym: The weekend after that, we will be at Zenkai Con doing a whole bunch of panels on Saturday.

489
00:27:57,460 --> 00:27:59,740
Rym: Surprisingly, we're doing a bunch of gaming panels.

490
00:27:59,940 --> 00:28:04,340
Rym: In fact, we're doing the kind of gaming panels that we've done at previous PAXes and then retired.

491
00:28:04,680 --> 00:28:07,140
Rym: So, if you can't make it to PAX, come to Zenkai Con.

492
00:28:07,401 --> 00:28:09,720
Scott: Why don't you let us do our interesting new panels?

493
00:28:09,820 --> 00:28:11,419
Scott: Always reprising the old panels.

494
00:28:11,640 --> 00:28:18,640
Rym: Well, we're doing actually a new panel there because you might remember our first debut PAX panel many years ago was Beyond Dungeons & Dragons.

495
00:28:19,462 --> 00:28:26,079
Rym: We've come a long way since then and despite the fact that we retired that panel years ago, it's probably the most requested thing we've ever done.

496
00:28:26,781 --> 00:28:33,040
Rym: So, we've rewritten it and we have a new version that we're going to test out at Zenkai Con and we're probably going to do it at the next PAX Prime.

497
00:28:33,889 --> 00:28:34,220
Scott: We'll see.

498
00:28:34,420 --> 00:28:34,747
Rym: We'll see.

499
00:28:34,768 --> 00:28:35,259
Rym: We'll see.

500
00:28:35,641 --> 00:28:38,539
Scott: Anyway, so other meta things.

501
00:28:38,960 --> 00:28:42,020
Rym: The Book Club book is still Michio Kaku's hyperspace that Scott has to finish reading.

502
00:28:42,742 --> 00:28:43,647
Scott: I'm going to start reading it.

503
00:28:43,828 --> 00:28:45,660
Scott: I'm going to start with chapter two today.

504
00:28:48,882 --> 00:28:50,200
Scott: Also, you should go to our website.

505
00:28:51,927 --> 00:28:59,420
Scott: Also, you should go to the forum and the Twitter and there's an unofficial IRC and, you know, Facebook and every internet thing.

506
00:28:59,740 --> 00:29:02,740
Scott: Look for us and friend us and join us and grab us.

507
00:29:03,240 --> 00:29:03,915
Rym: Also, a shout out.

508
00:29:04,260 --> 00:29:12,000
Rym: We go to these Nerd NYC board game nights once a month and due to our repeated calls, many awesome listeners have showed up and hung out and played games with us.

509
00:29:12,362 --> 00:29:13,780
Rym: So, mad props to all of you.

510
00:29:13,880 --> 00:29:15,000
Rym: Not one of you has smelled.

511
00:29:15,663 --> 00:29:17,580
Scott: I also want to point out one thing, right?

512
00:29:18,380 --> 00:29:25,758
Scott: Apparently, because any tweet on Twitter that has the word GeekNights in it, I see it, so I learn all about the Oxford GeekNights, which has nothing to do with us.

513
00:29:26,000 --> 00:29:26,090
Scott: Yeah.

514
00:29:26,380 --> 00:29:33,720
Scott: But also, it seems like there is some internet radio station, you know, just like I said in the beginning of the show, the old school shoutcast style, right?

515
00:29:34,684 --> 00:29:35,580
Scott: Named Tune Radio.

516
00:29:36,347 --> 00:29:37,020
Rym: I know them.

517
00:29:37,100 --> 00:29:40,499
Rym: They've emailed us a million times asking for permission and things and I've always ignored them.

518
00:29:40,700 --> 00:29:45,600
Scott: Right, so basically, they broadcast GeekNights at some time.

519
00:29:45,640 --> 00:29:50,879
Scott: I don't even know when, but GeekNights, they put it up on their station, which is absolutely okay.

520
00:29:51,220 --> 00:29:55,020
Rym: Yes, GeekNights is under a Creative Commons attribution license.

521
00:29:55,460 --> 00:29:58,220
Scott: Yeah, so they put GeekNights on their radio station.

522
00:29:58,220 --> 00:29:59,260
Rym: We're not even non-commercial.

523
00:29:59,420 --> 00:30:01,180
Rym: You can do whatever the fuck you want with GeekNights.

524
00:30:01,462 --> 00:30:01,680
Rym: Right.

525
00:30:02,182 --> 00:30:03,359
Rym: As long as you say it's ours.

526
00:30:03,740 --> 00:30:06,100
Scott: Right, so it doesn't look like they're not saying it's ours.

527
00:30:07,724 --> 00:30:10,367
Rym: They cut out, it's like, "It's September 24th, 2011.

528
00:30:10,367 --> 00:30:10,508
Rym: I'm

529
00:30:10,548 --> 00:30:10,649
Rym: Joe.".

530
00:30:13,102 --> 00:30:26,740
Scott: Yeah, I mean, I guess if you like shoutcast and you want to listen to GeekNights days after it comes out, you can listen to it on Tune Radio, but I just want to make sure that people know that it's not something we're doing.

531
00:30:26,860 --> 00:30:28,500
Scott: There's no partnership between us.

532
00:30:28,580 --> 00:30:32,860
Scott: It's just they're taking advantage of our liberal Creative Commons license.

533
00:30:33,180 --> 00:30:33,878
Rym: I'll put it straight up.

534
00:30:34,041 --> 00:30:40,099
Rym: If you ever run into any GeekNights thing that is not on frontrowcrew.com, it is not official and we don't care.

535
00:30:40,490 --> 00:30:40,699
Scott: Yeah.

536
00:30:40,923 --> 00:30:41,236
Rym: That's it.

537
00:30:41,762 --> 00:30:47,039
Rym: Well, I guess my Google checkout is not technically on frontrowcrew.com, but the e-commerce itself is.

538
00:30:47,340 --> 00:30:54,997
Scott: If you want to make a GeekNights, you know, merchandise, if you want to make a GeekNights, you know...

539
00:30:55,620 --> 00:30:56,273
Rym: No, no, no.

540
00:30:57,261 --> 00:31:04,220
Rym: The trademark for GeekNights, you will need a license from us if you want to use our trademark logos for things, but that's a separate issue.

541
00:31:04,240 --> 00:31:04,900
Rym: Don't worry about that.

542
00:31:05,200 --> 00:31:11,078
Scott: Yeah, but it's like, you know, if you want to do GeekNights unofficial wiki or whatever, just go for it.

543
00:31:12,420 --> 00:31:16,400
Rym: So tonight on that TV thing that none of us seem to have anymore.

544
00:31:16,640 --> 00:31:18,819
Scott: Actually, I do have it because it's on network TV, isn't it?

545
00:31:19,703 --> 00:31:21,680
Rym: I have no idea what channel Jeopardy is on.

546
00:31:21,860 --> 00:31:22,599
Scott: I'm pretty sure it's on ABC.

547
00:31:23,000 --> 00:31:23,268
Rym: Maybe.

548
00:31:23,372 --> 00:31:23,640
Rym: I don't know.

549
00:31:23,921 --> 00:31:26,760
Rym: I've never in my life watched an entire episode of Jeopardy.

550
00:31:26,840 --> 00:31:27,101
Rym: Really?

551
00:31:27,142 --> 00:31:30,540
Scott: We used to have Jeopardy on on the tiny TV in the kitchen during dinner.

552
00:31:31,520 --> 00:31:35,100
Rym: I guess part of it is that as a kid, I did Quiz Bowl in high school.

553
00:31:35,503 --> 00:31:39,880
Rym: So whenever I watched Jeopardy, I just was amazed at the fact that you couldn't buzz in before he finished talking.

554
00:31:40,340 --> 00:31:44,180
Rym: And it seems so arbitrary that, you know, you can't buzz in until he utters the last syllable.

555
00:31:44,966 --> 00:31:46,160
Rym: And I don't know, that bothered me.

556
00:31:46,160 --> 00:31:50,520
Scott: Well, that's actually from what everyone tells me and from what you read on the Internet, right?

557
00:31:50,600 --> 00:31:52,240
Rym: It's because people watching would hate it otherwise.

558
00:31:52,700 --> 00:31:55,680
Scott: Almost all the people on Jeopardy, right?

559
00:31:56,102 --> 00:32:00,479
Scott: Almost all the contestants, at least the good ones, they know the answer to almost every clue, right?

560
00:32:00,581 --> 00:32:01,597
Scott: Almost all the time, right?

561
00:32:01,960 --> 00:32:04,040
Scott: You know, people like Ken Jennings, they just know every clue.

562
00:32:04,161 --> 00:32:07,640
Scott: And winning and losing Jeopardy isn't about whether you know the clue or not.

563
00:32:07,660 --> 00:32:08,540
Scott: It's about buzzing in.

564
00:32:08,680 --> 00:32:16,819
Scott: And the way it works is there is a producer or someone that you can't see that manually activates the buzzers at a certain time.

565
00:32:17,280 --> 00:32:22,979
Scott: So ringing in first, because you try to ring in early, it'll like disable you for a little bit.

566
00:32:23,342 --> 00:32:25,800
Scott: So you can't just jam the button Nintendo finger, right?

567
00:32:26,341 --> 00:32:35,740
Scott: So you basically have to either psychologically figure out when the producer is going to activate his buzzer and activate immediately after him and get a feel for the system.

568
00:32:36,501 --> 00:32:37,708
Scott: That's how to win at.

569
00:32:37,748 --> 00:32:42,560
Scott: Jeopardy is basically to figure out the buzzer system, which makes me wonder, right?

570
00:32:42,620 --> 00:32:47,659
Scott: This Watson computer that's going to be playing Jeopardy, how does it buzz in?

571
00:32:47,941 --> 00:32:49,620
Rym: I couldn't find anything on that, actually.

572
00:32:50,121 --> 00:32:50,242
Rym: Yeah.

573
00:32:50,926 --> 00:32:58,715
Scott: And not only how does it buzz in, but sometimes on Jeopardy, they'll be like, "Can you be more specific because you're almost

574
00:32:58,796 --> 00:32:58,998
Scott: right?".

575
00:32:59,461 --> 00:33:01,699
Scott: So they can't say no yet, you know?

576
00:33:02,584 --> 00:33:11,920
Rym: I guess the real reason I'm pretty sure, at least for the buzzing in, is that TV audiences are not going to enjoy a show where it's like, "This drug found recently to cure...".

577
00:33:12,520 --> 00:33:14,500
Rym: And someone buzzes in and is like thalidomide.

578
00:33:15,060 --> 00:33:20,938
Scott: Especially because they can read it on the little screen in front of them, you know, the clue.

579
00:33:21,481 --> 00:33:24,320
Scott: And I can read the clue faster than Alex Trebek reads it.

580
00:33:24,400 --> 00:33:28,760
Rym: In fact, in Quiz Bowl, I remember this great moment when it was kind of down to this championship round.

581
00:33:28,840 --> 00:33:32,240
Rym: We were in the semifinals or whatever, and the question was, "This Roman...".

582
00:33:33,481 --> 00:33:36,758
Rym: And Arnold on my team buzzed in, and he was like, "Emperor

583
00:33:36,778 --> 00:33:37,200
Rym: Claudius."

584
00:33:37,261 --> 00:33:38,840
Rym: He just totally guessed a Roman emperor.

585
00:33:39,488 --> 00:33:40,080
Rym: And it was right.

586
00:33:40,340 --> 00:33:40,483
Rym: Yep.

587
00:33:40,933 --> 00:33:41,260
Scott: Why not?

588
00:33:41,782 --> 00:33:41,868
Scott: Yeah.

589
00:33:42,320 --> 00:33:43,019
Scott: There's not that many.

590
00:33:43,721 --> 00:33:44,138
Scott: Odds are good.

591
00:33:44,420 --> 00:33:46,380
Rym: Jeopardy always seemed kind of wussy to me as a result.

592
00:33:46,540 --> 00:33:50,140
Rym: But anyway, the IBM Watson computer is going to be playing Jeopardy.

593
00:33:50,423 --> 00:33:51,399
Rym: I don't know how I feel about that.

594
00:33:52,200 --> 00:33:56,010
Scott: Yeah, I mean, on the one hand, it's like, "Well, it's just going to

595
00:33:56,051 --> 00:33:56,233
Scott: win.".

596
00:33:57,331 --> 00:34:01,139
Scott: Nobody can beat it, especially with the buzzing... Who knows what the buzzing in situation is like?

597
00:34:01,460 --> 00:34:04,860
Scott: But I do wonder how it handles certain special cases, right?

598
00:34:04,940 --> 00:34:13,219
Scott: Not only the "be more specific," but also like, "Okay, so it tries to ring in, and someone else rings in, so it knows not to try to ring in anymore.

599
00:34:13,904 --> 00:34:15,056
Scott: But what if that person gets it

600
00:34:15,097 --> 00:34:15,360
Scott: wrong?".

601
00:34:15,581 --> 00:34:17,760
Scott: Then you have another opportunity to ring in, right?

602
00:34:18,321 --> 00:34:23,338
Scott: And then how does it know what to wager when there's like a double Jeopardy or whatever?

603
00:34:23,379 --> 00:34:34,199
Scott: it is where you can, you know... Or what does it do when there's one of those video questions where it's not just a regular question, but they have some celebrity on videos doing something?

604
00:34:34,621 --> 00:34:35,618
Scott: Like, can it do that too?

605
00:34:36,400 --> 00:34:38,679
Scott: Or can it handle the final Jeopardy, right?

606
00:34:39,920 --> 00:34:40,228
Scott: It's like...

607
00:34:40,719 --> 00:34:45,060
Rym: See, I feel like the way to make this legit, it should have to watch the videos through a camera.

608
00:34:45,440 --> 00:34:54,560
Scott: Yeah, I think it should have to have a physical clamp on the buzzer, and it should have to have a camera, and it should have to have a microphone.

609
00:34:54,621 --> 00:34:55,799
Rym: I couldn't find any info on this.

610
00:34:55,960 --> 00:34:59,560
Rym: I'll bet a human handler's gonna ring in on its behalf, or some BS like that.

611
00:34:59,681 --> 00:35:00,328
Scott: I don't know.

612
00:35:00,348 --> 00:35:01,379
Scott: I don't know how it works.

613
00:35:01,860 --> 00:35:05,100
Scott: But at least the part that gets the answers, right?

614
00:35:05,280 --> 00:35:07,578
Scott: It's basically just using the internet, right?

615
00:35:07,880 --> 00:35:10,057
Rym: I mean, kind of a Wolfram, Alpha/Google.

616
00:35:11,368 --> 00:35:11,619
Rym: Yeah.

617
00:35:11,980 --> 00:35:13,300
Rym: I mean, at least a human intelligence.

618
00:35:14,566 --> 00:35:20,879
Rym: You can answer any question ever asked on Jeopardy within about five seconds of seeing it if you've got Google in front of you.

619
00:35:20,980 --> 00:35:30,359
Rym: But the tricky part, I think, would not be finding where the answer is necessarily, but being able to, based on the question, figure out what noun it's actually asking for.

620
00:35:31,240 --> 00:35:32,035
Scott: Yeah, it's like...

621
00:35:32,401 --> 00:35:37,300
Rym: It's an interesting problem, actually, and I'm kind of ambivalent.

622
00:35:37,540 --> 00:35:45,555
Rym: I think it'll win, but I think the only reason I think that is because I know that IBM would not put it forth if they had not tested it thoroughly internally and see it win.

623
00:35:45,720 --> 00:35:48,400
Scott: Well, I mean, this thing isn't exactly the most expensive.

624
00:35:48,481 --> 00:35:50,340
Scott: It's not like a super-duper computer, right?

625
00:35:50,400 --> 00:35:53,480
Scott: It's just a bunch of Power7 servers, which are about a year old.

626
00:35:53,581 --> 00:35:59,140
Rym: A real test would be three contestants -- Ken Jennings, me with Google, and Watson.

627
00:35:59,660 --> 00:36:02,680
Scott: Well, it is Ken Jennings and another guy who's also the second best.

628
00:36:02,820 --> 00:36:03,699
Rym: Yeah, but the other guy, no.

629
00:36:03,960 --> 00:36:07,039
Rym: Replace it with just me or someone like me with a laptop and Google.

630
00:36:07,100 --> 00:36:10,419
Scott: But you can't type into Google faster than they can, you know...

631
00:36:10,520 --> 00:36:14,700
Rym: Yeah, but the way the buzzing is, someone's gonna buzz in an answer wrong, and then I'll have the answer, and I might notice that.

632
00:36:14,700 --> 00:36:15,719
Scott: But you're not gonna win that way.

633
00:36:16,401 --> 00:36:18,820
Scott: Basically, they'll buzz in and have it right immediately.

634
00:36:19,003 --> 00:36:19,196
Scott: Maybe.

635
00:36:20,422 --> 00:36:21,140
Scott: Almost certainly.

636
00:36:21,482 --> 00:36:23,760
Rym: Or I'll just memorize all the answers like I used to do in Quiz Bowl.

637
00:36:24,161 --> 00:36:26,900
Scott: But they don't know the questions, so how can you memorize them beforehand?

638
00:36:26,920 --> 00:36:29,312
Rym: For one, I remember reading a thing on, like, what Jeopardy!

639
00:36:29,332 --> 00:36:38,020
Rym: contestants get, and basically they're given areas of study and references to study, but then the questions and the topics are a small subset of everything they were given.

640
00:36:38,648 --> 00:36:38,778
Scott: Yeah.

641
00:36:39,482 --> 00:36:41,200
Rym: It's not quite as spontaneous as everyone thinks it is.

642
00:36:41,241 --> 00:36:45,060
Scott: Oh, I wonder, though, if the Watson -- Does the Watson get to pre-study like the contestants do?

643
00:36:45,240 --> 00:36:46,660
Scott: 'Cause that would make it way easy.

644
00:36:46,780 --> 00:36:47,699
Scott: That would make it way easy.

645
00:36:47,800 --> 00:36:50,500
Scott: It'd be like, "All right, we know there's gonna be something about Rome.

646
00:36:50,620 --> 00:36:54,794
Scott: Well, let's load the Rome database in, and we'll scan in this book on Rome with

647
00:36:54,894 --> 00:36:55,075
Scott: OCR.".

648
00:36:56,304 --> 00:36:58,580
Scott: It's, like, that's totally too easy if they do that.

649
00:36:59,201 --> 00:37:03,880
Scott: It's got to be able to handle, you know, any arbitrary question at any time in order for it to really count.

650
00:37:04,640 --> 00:37:18,120
Rym: One thing I am curious about is how, if this sort of research, you know, trying to make a computer that will parse the text and answer a question directly like this, I wonder if it is down the road of passing Turing tests or not.

651
00:37:18,661 --> 00:37:23,720
Rym: I mean, one of the biggest problems with AI is that it really can't pass itself off for human.

652
00:37:23,940 --> 00:37:24,326
Rym: No.

653
00:37:24,346 --> 00:37:28,240
Rym: But at the same time, many humans cannot pass themselves off for human on the Internet anymore.

654
00:37:29,000 --> 00:37:42,600
Scott: Well, I think, you know, what you've got, right, is we've managed to make a lot of computers that -- or systems that, you know, 'cause really what Watson is all about is the software, not so much the hardware, right -- is that, you know, do one human thing, right?

655
00:37:42,680 --> 00:37:57,580
Scott: So, for example, have an AI that plays "Counter-Strike" like a human, or we'll have an AI that plays "Jeopardy" like a human, or we'll have something that converses like a human to try to pass the Turing test, or we'll have something, you know, a robot that flips pancakes like a human, right?

656
00:37:58,000 --> 00:38:01,880
Scott: But what we haven't made is sort of the general case, right?

657
00:38:02,020 --> 00:38:07,480
Scott: Give me the computer/robot software/hardware combination that can do all the things of a human, right?

658
00:38:07,600 --> 00:38:09,340
Rym: Well, because that would be a human.

659
00:38:09,780 --> 00:38:13,520
Scott: 'Cause a human -- It's almost like a ship of Theseus, right?

660
00:38:13,740 --> 00:38:14,125
Scott: Yeah.

661
00:38:14,145 --> 00:38:22,918
Scott: If it can do -- If it can see and hear and taste and touch and play "Jeopardy" and flip pancakes, you know, it can do all the things a human can do, but it doesn't have DNA.

662
00:38:23,201 --> 00:38:25,300
Scott: Is it a human, or is it the ship of Theseus?

663
00:38:25,500 --> 00:38:27,820
Rym: Well, that's the old question we have to go even further of what is human.

664
00:38:27,920 --> 00:38:30,440
Rym: Does human mean species, or does human mean intelligence?

665
00:38:31,101 --> 00:38:36,970
Rym: Because if we go the species route, the people with mutations and, you know, you can argue that there are people who aren't actually human.

666
00:38:36,990 --> 00:38:37,760
Rym: Probably.

667
00:38:38,020 --> 00:38:42,080
Rym: And also, what do you do about intelligences that eventually are more advanced than humans or when humans evolve?

668
00:38:42,563 --> 00:38:49,140
Rym: If we go the intelligence route, I mean, there are chimps and dogs, and a lot of animals have the intelligence of small human children.

669
00:38:49,900 --> 00:38:57,500
Scott: The thing is I want to see, right, is they've got Deep Blue, which plays chess, and they've got Watson, which plays "Jeopardy," right?

670
00:38:58,201 --> 00:38:59,540
Scott: Show me a computer.

671
00:38:59,941 --> 00:39:04,960
Scott: At least for starters, right, let's have something that can play any game, right?

672
00:39:05,140 --> 00:39:07,380
Scott: You know, it's like if you obviously can't get the same --.

673
00:39:07,420 --> 00:39:09,900
Rym: Because, Scott, that's clearly such an easy thing to do.

674
00:39:10,100 --> 00:39:12,972
Rym: I mean, someone just has to think, "Oh, I'll make a computer that can play any

675
00:39:13,013 --> 00:39:13,416
Rym: game.".

676
00:39:13,940 --> 00:39:17,299
Scott: Football, chess, paper, rock, scissors.

677
00:39:17,900 --> 00:39:20,880
Scott: Well, not sports necessarily, but any game where it's just, you know, decisions.

678
00:39:21,220 --> 00:39:23,700
Rym: So, chess checkers and Starfarers of Catan.

679
00:39:23,820 --> 00:39:34,620
Scott: You know, any game where you could -- You know, and what would be super cool, right, is if you actually went up to the computer, and it had, like, a camera and a microphone, and you pretty much -- you taught it the rules the same way you teach the rules to a person, right?

680
00:39:34,660 --> 00:39:37,040
Scott: So, it'd be like, "Here, computer, this is Puerto Rico.

681
00:39:37,323 --> 00:39:39,347
Scott: On your turn, if you're the governor, you select a

682
00:39:39,367 --> 00:39:39,671
Scott: role.".

683
00:39:40,923 --> 00:39:46,319
Scott: And it actually learned how to play, and then it could, like, watch a game of people playing and learn how to play based on that.

684
00:39:46,440 --> 00:39:48,420
Scott: That would be -- I think that's the next step.

685
00:39:48,440 --> 00:39:49,239
Rym: It would be an interesting step.

686
00:39:49,360 --> 00:39:57,119
Rym: Basically, it'd almost be a logic processor, where all you do is give it a series of constraints, and then once it has all the known constraints, give it an outcome.

687
00:39:57,421 --> 00:39:58,900
Scott: Yeah, I mean, we already have that, right?

688
00:39:58,900 --> 00:40:05,600
Scott: We've got, like -- You can run a thing on your computer where it'll design, you know, a car based on, you know, genetic algorithms over time.

689
00:40:05,760 --> 00:40:07,560
Rym: Well, genetic algorithms are a little different.

690
00:40:07,640 --> 00:40:10,979
Rym: That's the, you know, discarding the least fit and enhancing the most fit.

691
00:40:11,020 --> 00:40:14,980
Scott: Yeah, but a human puts in the fitness algorithm, you know?

692
00:40:15,340 --> 00:40:16,126
Scott: Yeah.

693
00:40:16,146 --> 00:40:17,899
Scott: We tell it what fitness is.

694
00:40:18,080 --> 00:40:24,679
Rym: Yeah, but in a case like that, you'd be putting in different algorithms for beating a game, as opposed to just giving it the rules of the game.

695
00:40:25,200 --> 00:40:27,459
Rym: The rules of the game are not the strategy to beat the game.

696
00:40:28,121 --> 00:40:38,480
Rym: And I don't know if there's any way to have a computer now that, given only the rules, will come about to an algorithm that solves the game short of doing some sort of tedious genetic process.

697
00:40:38,480 --> 00:40:39,399
Scott: Oh, that is sort of true.

698
00:40:39,561 --> 00:40:44,720
Scott: Both the Deep Blue and the Watson, right, were sort of programmed for the specific game purpose.

699
00:40:44,920 --> 00:40:50,980
Scott: So the algorithm to beat the game was basically typed in by people, right, who figured out what that algorithm was.

700
00:40:51,280 --> 00:40:54,154
Rym: Yeah, we need an algorithm that generates an algorithm.

701
00:40:55,681 --> 00:40:57,696
Scott: The computer didn't figure out how to win at

702
00:40:57,737 --> 00:40:58,140
Scott: "Jeopardy!".

703
00:40:58,281 --> 00:41:00,014
Scott: Pretty much someone who already knew how to win at

704
00:41:00,055 --> 00:41:00,357
Scott: "Jeopardy!"

705
00:41:00,941 --> 00:41:04,038
Scott: went in and said, "Okay, buzz in as soon as possible,".

706
00:41:04,119 --> 00:41:06,159
Scott: right, as part of the program, you know?

707
00:41:06,701 --> 00:41:13,654
Scott: So that's actually -- When you think about it that way, it's far less impressive, because pretty much someone went to the computer and typed in, "Here is how to win at

708
00:41:13,694 --> 00:41:14,039
Scott: "Jeopardy!".

709
00:41:14,140 --> 00:41:15,958
Scott: Do this, do this, do this, do this, do this, do

710
00:41:15,978 --> 00:41:16,120
Scott: this.".

711
00:41:16,343 --> 00:41:17,699
Scott: And the computer does that.

712
00:41:17,780 --> 00:41:19,037
Rym: It's no different than writing the A.I.

713
00:41:19,400 --> 00:41:23,660
Rym: to be good at, say, "Settlers," except that it's a much more complex problem with a much larger problem space.

714
00:41:23,940 --> 00:41:33,060
Scott: Yeah, the impressive parts of the technology are pretty much only in the parts that understand, you know, the human language, the natural language processing.

715
00:41:33,100 --> 00:41:35,140
Scott: It's really just natural language processing and the output.

716
00:41:35,140 --> 00:41:39,160
Scott: And then the second part of looking up the answer and make sure you get the right one, you know?

717
00:41:39,260 --> 00:41:41,500
Scott: That's pretty much the only interesting parts of Watson.

718
00:41:41,620 --> 00:41:43,636
Scott: The rest of it is actually pretty lame.

719
00:41:44,500 --> 00:41:50,420
Rym: What I will say is I will call bullshit on the whole scenario if it does not ring in first on every single question.

720
00:41:50,623 --> 00:41:50,939
Scott: Oh, yeah.

721
00:41:51,120 --> 00:41:56,140
Rym: Because if it doesn't, that means that they're not actually -- You know, they didn't go full-on in this experiment.

722
00:41:56,441 --> 00:42:03,740
Scott: I'd be really interested to see just exactly how it buzzes in, how it, you know, determines when -- You know, all this stuff.

723
00:42:04,463 --> 00:42:06,919
Scott: If they wired up any extra inputs to it, that's bullshit.

724
00:42:08,241 --> 00:42:10,100
Scott: How does it know how much to wager, right?

725
00:42:10,200 --> 00:42:11,239
Scott: What did they program for that?

726
00:42:11,820 --> 00:42:14,080
Rym: Obviously, if it knows the answer, all the money.

727
00:42:14,180 --> 00:42:16,541
Rym: If it doesn't know the answer, $1.

728
00:42:16,541 --> 00:42:17,595
Scott: You can wager zero.

729
00:42:17,615 --> 00:42:18,000
Scott: Yeah.

730
00:42:18,520 --> 00:42:19,120
Rym: You got to wager the $1.

731
00:42:19,120 --> 00:42:21,759
Scott: But you also have to look at how much the other people have, right?

732
00:42:22,041 --> 00:42:28,060
Scott: So if you wager zero and the other guy's got more than you right now, he could just wager zero and win even if he gets it wrong.

733
00:42:28,280 --> 00:42:31,639
Scott: So you have to wager at least the difference between you and the lead guy if you're not in first.

734
00:42:31,780 --> 00:42:39,980
Rym: You know what would be a much more interesting problem for me because it's a problem that I would -- It is easier to solve, I think, because the problem space is actually more constrained.

735
00:42:40,941 --> 00:42:46,240
Rym: I would like to see a robot that competes at the price is right because it's constrained in one way.

736
00:42:46,380 --> 00:42:48,015
Rym: It's got to just look up prices, MSRP.

737
00:42:49,160 --> 00:42:54,078
Rym: But it's also difficult in that it's got to be able to beat all those crazy minigames.

738
00:42:55,082 --> 00:42:55,970
Rym: It's got to be able to putt.

739
00:42:57,860 --> 00:42:58,687
Scott: Play some Plinko.

740
00:42:58,707 --> 00:43:00,140
Scott: It's got to climb up the Plinko stairs.

741
00:43:00,320 --> 00:43:02,820
Rym: Oh, Plinko would be really easy for it to figure out, I think.

742
00:43:03,080 --> 00:43:05,299
Scott: It'd have to climb up the stairs, though, to drop the Plinkos.

743
00:43:06,322 --> 00:43:12,859
Rym: I would be okay with them carrying it up the stairs because you can't tell me that if someone in a wheelchair was on the price is right, they would not help them up.

744
00:43:13,120 --> 00:43:13,987
Scott: No, the price is right.

745
00:43:14,088 --> 00:43:15,520
Scott: is, I believe, ADA accessible.

746
00:43:15,900 --> 00:43:16,405
Rym: Yeah.

747
00:43:16,425 --> 00:43:20,500
Scott: In fact, I think if you're in a wheelchair, though, I'm pretty sure they'll make you play a game that doesn't have stairs.

748
00:43:20,800 --> 00:43:21,408
Rym: Yeah, they're not going to --.

749
00:43:21,429 --> 00:43:21,956
Rym: Well, yeah.

750
00:43:23,540 --> 00:43:25,380
Scott: You know, they'll let you play an easier game.

751
00:43:25,480 --> 00:43:26,740
Rym: That would be much more impressive.

752
00:43:26,881 --> 00:43:27,408
Rym: I want to see.

753
00:43:27,428 --> 00:43:28,380
Rym: the price is right robot.

754
00:43:29,040 --> 00:43:29,667
Scott: Yeah, sure.

755
00:43:29,728 --> 00:43:33,340
Scott: I mean, the thing is, right, price is right is about memory.

756
00:43:33,421 --> 00:43:36,380
Scott: It's like, did you remember this piece of information, right?

757
00:43:36,500 --> 00:43:42,620
Scott: So does Watson look things up on Google, or does it have its own database of information, right?

758
00:43:42,920 --> 00:43:44,660
Scott: And then what was put in that database?

759
00:43:44,941 --> 00:43:51,105
Scott: If I load -- I could take my computer and load it up with a list of price database on MySQL, and it could win.

760
00:43:51,125 --> 00:43:52,359
Scott: the price is right, no problem.

761
00:43:52,520 --> 00:43:53,650
Scott: That'd be really easy to do.

762
00:43:53,670 --> 00:43:54,618
Scott: So it's like --.

763
00:43:54,880 --> 00:44:00,640
Rym: Well, well, figuring out the prices part, but not, for example, the -- Because the showcase showdown is a lot more fuzzy.

764
00:44:00,740 --> 00:44:02,279
Rym: There's too many -- There's almost a Fermi equation.

765
00:44:02,320 --> 00:44:05,500
Scott: No, it just adds all the prices of all the different, separate things together.

766
00:44:05,820 --> 00:44:10,860
Rym: Yeah, but at the same time, there's no listed MSRP for a particular trip to a particular hotel.

767
00:44:10,980 --> 00:44:11,771
Rym: You got to figure that out.

768
00:44:12,034 --> 00:44:12,460
Rym: It orbits.

769
00:44:13,240 --> 00:44:13,846
Scott: Yeah, it's all right.

770
00:44:14,190 --> 00:44:14,978
Scott: But the thing is --.

771
00:44:15,120 --> 00:44:15,747
Rym: And you got to putt.

772
00:44:16,192 --> 00:44:16,758
Rym: How do you get to putt?

773
00:44:17,200 --> 00:44:18,030
Scott: There's putting robots.

774
00:44:18,051 --> 00:44:18,719
Scott: You got to putt.

775
00:44:18,861 --> 00:44:20,460
Rym: Yeah, it's all got to be the same robot.

776
00:44:20,640 --> 00:44:21,164
Rym: That's right.

777
00:44:22,172 --> 00:44:23,119
Scott: Make a computer with legs.

778
00:44:23,821 --> 00:44:24,062
Rym: Anyway.

779
00:44:24,849 --> 00:44:25,998
Scott: But, yeah, you know, it's --.

780
00:44:27,322 --> 00:44:28,297
Scott: What was I trying to say?

781
00:44:28,378 --> 00:44:28,500
Scott: Right.

782
00:44:28,560 --> 00:44:35,220
Scott: So it's not necessarily any sort of fancy program you've written or fancy algorithm or algorithm-generating algorithm.

783
00:44:35,260 --> 00:44:36,328
Scott: It's just data.

784
00:44:36,691 --> 00:44:38,748
Scott: Was the data in the computer, or was it not?

785
00:44:38,829 --> 00:44:39,900
Scott: Unless it has Internet access.

786
00:44:40,161 --> 00:44:42,160
Scott: So how much data did they put in Watson?

787
00:44:42,460 --> 00:44:46,640
Scott: You know, that could determine whether it wins or loses how much data was inserted beforehand.

788
00:44:47,081 --> 00:44:51,369
Scott: And is it fair to insert some obscene amount of data on terabytes of hard drives?

789
00:44:51,591 --> 00:44:55,360
Scott: that is more than, like, any nonautistic human can possibly remember?

790
00:44:55,540 --> 00:44:58,040
Rym: Ah, but what if we have a human who just memorizes all that somehow?

791
00:44:58,540 --> 00:45:02,571
Scott: Yeah, but that's -- You know, if it's a game of memory, you know, how fair --.

792
00:45:02,592 --> 00:45:07,900
Scott: You know, because there are certain things a computer is better at than a person, and certain things a person is better at than a computer, right?

793
00:45:08,100 --> 00:45:14,080
Scott: If you're talking about just memorizing a ton of information and looking it up, a computer is way better than humans, right?

794
00:45:14,422 --> 00:45:19,339
Scott: But if you're talking about something like, "Walk down this crowded street without bumping into anyone,".

795
00:45:19,621 --> 00:45:21,880
Scott: a computer is terrible at that, you know?

796
00:45:22,300 --> 00:45:23,338
Scott: I mean, you'd have to have, like, some --.

797
00:45:23,460 --> 00:45:28,380
Rym: Scott, I note that the majority of the people I see on the street on a daily basis are also terrible at that.

798
00:45:28,440 --> 00:45:30,338
Scott: They're a lot better than a computer would be.

799
00:45:30,580 --> 00:45:32,919
Rym: I almost disagree with you there.

800
00:45:33,240 --> 00:45:35,020
Scott: But I'm just saying, you know, it's those kinds of --.

801
00:45:35,040 --> 00:45:36,051
Rym: Well, let's zoom out.

802
00:45:36,091 --> 00:45:37,726
Rym: We're talking about -- Because, you know, we can --.

803
00:45:38,310 --> 00:45:42,180
Rym: From a practical perspective, a game versus a sport are very different.

804
00:45:42,541 --> 00:45:51,320
Rym: But, really, they're not, because what's going on in a human brain is a physicality that is no different fundamentally from electrons moving around in a computer.

805
00:45:52,225 --> 00:45:55,599
Rym: It's just a physicality, and we have these giant abstractions on top of it.

806
00:45:56,002 --> 00:46:01,839
Rym: At its core, if I'm trying to figure out the answer to your question, there are chemical and electrical reactions going on in my brain.

807
00:46:02,160 --> 00:46:02,443
Rym: Mm.

808
00:46:02,464 --> 00:46:03,840
Rym: It's just a big physical thing.

809
00:46:04,340 --> 00:46:07,280
Rym: So, why don't we make the baseball robot?

810
00:46:07,581 --> 00:46:10,660
Rym: Is it fair for the baseball robot to compete against a human?

811
00:46:10,760 --> 00:46:11,709
Scott: There was a baseball robot.

812
00:46:11,729 --> 00:46:12,255
Scott: It's in "Bots

813
00:46:12,275 --> 00:46:12,699
Scott: Masters."

814
00:46:12,921 --> 00:46:13,853
Scott: [ Laughs ].

815
00:46:13,853 --> 00:46:14,440
Scott: "Zib-Zoo" landing.

816
00:46:14,580 --> 00:46:20,040
Rym: Now, I think the only reason we don't do this is because we can make a robot that bats better than any human could ever bat.

817
00:46:20,721 --> 00:46:23,060
Rym: That same robot is not going to be able to run the bases.

818
00:46:24,660 --> 00:46:28,700
Scott: Yeah, it's 'cause we keep making -- Yeah, if we keep making robots that are specialized at one task --.

819
00:46:28,700 --> 00:46:34,700
Rym: I think it'd be much more fun to start having much more generic robots, even though they will fail miserably.

820
00:46:35,801 --> 00:46:37,280
Rym: It'll be more interesting to watch.

821
00:46:37,500 --> 00:46:49,474
Rym: Like, "Robot Wars," all those kind of competitions, were always boring as fuck because the problem space was so constrained, and the solutions would always come down to things like, "I have a robot that's really flat and just flips the other robots

822
00:46:49,595 --> 00:46:49,777
Rym: over.".

823
00:46:50,444 --> 00:46:51,514
Scott: Oh, you mean -- Oh, that's --.

824
00:46:52,120 --> 00:46:56,560
Rym: Yeah, I want to see things that are like, "All right, your robot's got to just play goddamn baseball.

825
00:46:56,964 --> 00:46:57,772
Rym: It's got to bet.

826
00:46:57,853 --> 00:46:58,520
Rym: It's got to pitch.

827
00:46:58,740 --> 00:46:59,107
Rym: It's got to run.

828
00:46:59,127 --> 00:46:59,575
Scott: It's got to

829
00:46:59,616 --> 00:46:59,779
Scott: catch.".

830
00:46:59,840 --> 00:47:01,860
Scott: There's a soccer-playing-robot competition every year.

831
00:47:02,020 --> 00:47:03,180
Rym: Yeah, I want to see baseball.

832
00:47:03,960 --> 00:47:04,242
Scott: Sure.

833
00:47:04,584 --> 00:47:08,760
Scott: I would like to see just, you know, the battle bots, but no restrictions.

834
00:47:09,320 --> 00:47:11,440
Scott: You know, as long as it doesn't hurt the audience.

835
00:47:11,500 --> 00:47:12,440
Scott: That's the only restriction.

836
00:47:12,480 --> 00:47:13,620
Rym: No, you put it in some sort of cage.

837
00:47:14,000 --> 00:47:17,540
Scott: It can't just be a bomb or a rocket launcher 'cause that would hurt the audience.

838
00:47:17,700 --> 00:47:20,239
Rym: A bomb wouldn't work 'cause it would win the first round.

839
00:47:20,259 --> 00:47:23,397
Rym: - No, it would get a draw in the first round and lose all the following rounds.

840
00:47:23,620 --> 00:47:25,600
Scott: But, you know, it could throw the bomb at the enemy.

841
00:47:25,681 --> 00:47:27,120
Rym: It better have enough bombs.

842
00:47:27,260 --> 00:47:28,519
Rym: You want to put a machine gun in your robot?

843
00:47:28,680 --> 00:47:29,266
Rym: That's fine.

844
00:47:29,550 --> 00:47:30,500
Rym: Don't run out of bullets.

845
00:47:30,560 --> 00:47:31,759
Scott: As long as it doesn't hurt the audience.

846
00:47:32,060 --> 00:47:34,250
Scott: You know, anything that doesn't hurt the audience, I think, should be allowed.

847
00:47:34,271 --> 00:47:34,858
Rym: Bulletproof glass.

848
00:47:35,720 --> 00:47:37,286
Scott: How about this?

849
00:47:37,307 --> 00:47:40,540
Scott: Just no explosives or projectiles, right?

850
00:47:41,040 --> 00:47:47,997
Scott: So, it would basically punch and kick and smash and do whatever in any shape and any size as long as it fits in the ring, you know?

851
00:47:48,963 --> 00:47:50,139
Scott: And just go for it.

852
00:47:50,221 --> 00:47:51,280
Scott: That, I think, would be interesting.

853
00:47:52,520 --> 00:47:52,643
Scott: Anyway.

854
00:47:52,664 --> 00:47:53,320
Scott: Anyway.

855
00:47:54,104 --> 00:47:55,540
Rym: I don't know how much else we can say about this.

856
00:47:55,680 --> 00:48:04,720
Rym: I guess the TLDR version or the TLDL, I guess, in this case, is that this is actually not that interesting of an experiment.

857
00:48:06,240 --> 00:48:08,760
Scott: Yeah, it's, like, it seems really interesting.

858
00:48:09,300 --> 00:48:12,180
Scott: Yeah, but it's not actually that interesting under the hood.

859
00:48:12,240 --> 00:48:15,280
Scott: It's a lot farther away from real AI than it appears.

860
00:48:15,280 --> 00:48:19,599
Rym: Well, no, I guess it's more that it is a very, very interesting problem, and they're using a very unique --.

861
00:48:19,680 --> 00:48:22,199
Scott: Well, the language-processing problem and the lookup problem.

862
00:48:22,280 --> 00:48:24,940
Rym: Yeah, all the stuff that's interesting about it is really interesting.

863
00:48:25,363 --> 00:48:34,058
Rym: But it's primarily only interesting to computer scientists, and all the media interest in it, you know, human-versus-computer aspect-wise, is actually kind of lame.

864
00:48:34,520 --> 00:48:34,703
Rym: Yeah.

865
00:48:34,723 --> 00:48:35,312
Rym: So, watch.

866
00:48:35,433 --> 00:48:35,880
Rym: Watch and learn.

867
00:48:36,121 --> 00:48:41,520
Rym: If it does not buzz in itself and always buzz in first, bullshit.

868
00:48:42,000 --> 00:48:42,182
Scott: Yep.

869
00:48:42,747 --> 00:48:57,720
Scott: Anyway, there's also, right, there's a game-theory aspect to it that I want to investigate, right, which is, you know, in game theory, right, game theory is all about you're making a decision, right, based -- and you have to take someone else's decision into account in your decision, right?

870
00:48:57,780 --> 00:48:58,619
Scott: That's what it's all about.

871
00:48:59,240 --> 00:49:05,960
Scott: And that's why a single-player game isn't really a game from a game-theorist's perspective, because in a single-player game is a puzzle.

872
00:49:06,061 --> 00:49:09,320
Scott: There is an answer, and it's just all about figuring out that answer, right?

873
00:49:10,001 --> 00:49:15,497
Scott: Now, you think of a single player when there's an AI, even if it's, you know, just the kind of simple AIs we have today, right?

874
00:49:16,602 --> 00:49:22,458
Scott: Is that a single-player game, or are you actually making decisions against the decisions of the AI?

875
00:49:22,740 --> 00:49:26,760
Scott: I mean, it's a pretty good simulation of a game against a real person, right?

876
00:49:26,920 --> 00:49:27,666
Scott: But is it really?

877
00:49:27,687 --> 00:49:31,120
Scott: Because there is still -- It's still a digital binary computer.

878
00:49:31,502 --> 00:49:32,699
Scott: It's still an algorithm.

879
00:49:33,060 --> 00:49:35,159
Scott: So the decisions it's making are already made.

880
00:49:35,320 --> 00:49:37,460
Scott: Well, what it does -- -It's already deterministic.

881
00:49:37,640 --> 00:49:40,300
Rym: What it has is a strategy, just like me playing Stratego.

882
00:49:40,800 --> 00:49:41,333
Rym: I have a strategy.

883
00:49:41,354 --> 00:49:41,559
Rym: Right.

884
00:49:41,620 --> 00:49:52,160
Scott: So does it then not -- It's not -- While it looks, you know, like it is a player, it's actually just a part of the puzzle in the game, a very perhaps complex part, you know?

885
00:49:52,320 --> 00:49:58,600
Rym: Scott, but the breakdown there is that me as a human, if I'm playing, say, "The Prisoner's Dilemma," I have a strategy.

886
00:49:58,861 --> 00:50:00,940
Rym: Every decision that could possibly be made, I've already decided.

887
00:50:01,405 --> 00:50:02,500
Rym: I am following an algorithm.

888
00:50:02,841 --> 00:50:03,548
Scott: That is true.

889
00:50:03,568 --> 00:50:05,640
Rym: So that doesn't make me less a part of the game.

890
00:50:06,100 --> 00:50:11,500
Scott: There's also the trick -- But what if you're a deterministic computer instead of a biological computer?

891
00:50:11,661 --> 00:50:15,540
Scott: Is your strategy not, you know, where they set algorithm for selecting a strategy?

892
00:50:16,081 --> 00:50:23,380
Scott: Are you not now, you know, limited in some way, and now you are no longer -- You are now no longer a deciding party.

893
00:50:23,560 --> 00:50:31,540
Rym: There's no fundamental difference because there's no way for you to justify saying that I have any more or less free will or determinism than the computer.

894
00:50:32,181 --> 00:50:35,440
Scott: Ah, but there are quite significant differences between you and the computer.

895
00:50:35,540 --> 00:50:37,200
Rym: But on a fundamental level, causality.

896
00:50:37,640 --> 00:50:40,757
Scott: For example, in a dollar auction, for example, against a computer, right?

897
00:50:41,862 --> 00:50:43,954
Scott: A human is probably gonna play, right?

898
00:50:45,422 --> 00:50:49,699
Scott: But the computer doesn't find any value in money, so it doesn't give a shit.

899
00:50:50,080 --> 00:50:54,160
Rym: Yeah, but me, as a human, if there's a dollar auction, I know better.

900
00:50:54,300 --> 00:50:55,820
Rym: My strategy is don't bid.

901
00:50:56,220 --> 00:50:57,780
Scott: Right, but other people don't know better.

902
00:50:57,920 --> 00:51:01,340
Scott: Actually, yeah, because there's -- But a computer is yet a third way.

903
00:51:02,423 --> 00:51:09,552
Rym: I would argue that it isn't actually a third way because you could program a computer whose algorithm is, "Hells yeah, dollar

904
00:51:09,694 --> 00:51:09,998
Rym: auction.".

905
00:51:11,663 --> 00:51:15,440
Rym: I mean, there's no difference between a human and a computer in that way.

906
00:51:15,823 --> 00:51:22,078
Rym: If causality is true, then they're both equally deterministic machines, and their starting state --.

907
00:51:22,260 --> 00:51:29,979
Rym: The only difference is that we can see the origin of the state machine that is the computer insofar as we created it.

908
00:51:30,360 --> 00:51:36,280
Rym: What we cannot see is the state machine of the universe or the state machine that was our entire past leading up to us making the robot.

909
00:51:36,601 --> 00:51:38,719
Rym: In fact, the robot is nothing more than an extension of us.

910
00:51:40,283 --> 00:51:43,099
Scott: So isn't Watson, then, actually -- A human.

911
00:51:44,001 --> 00:51:45,540
Rym: No, one step further.

912
00:51:45,903 --> 00:51:52,660
Rym: Watson is an outgrowth of the humans, which themselves are nothing more than outgrowths of the causal chain leading back to the Big Bang.

913
00:51:53,000 --> 00:52:00,900
Scott: Right, but no, the people who made Watson, at least, you know, right, isn't it actually sort of like a team playing Jeopardy, which is sort of unfair.

914
00:52:01,000 --> 00:52:03,740
Scott: It's all those humans together playing Jeopardy on the same team.

915
00:52:03,780 --> 00:52:07,860
Rym: But would it be any different if all those humans coached another human into a strategy?

916
00:52:08,644 --> 00:52:09,278
Scott: Oh, would it be?

917
00:52:09,500 --> 00:52:15,160
Rym: No, because there's no way to differentiate between the deterministic behavior of a machine and algorithm or a human.

918
00:52:16,042 --> 00:52:19,618
Rym: Because we believe that causality exists and have no reason not to believe so.

919
00:52:20,240 --> 00:52:20,433
Scott: Uh-huh.

920
00:52:20,720 --> 00:52:22,839
Rym: Which also proves that we don't have free will, if that's true.

921
00:52:24,465 --> 00:52:26,560
Rym: Ah, it all comes down to solipsism.

922
00:52:26,901 --> 00:52:29,799
Scott: Anyway, but yeah, Watson is cheating.

923
00:52:31,489 --> 00:52:31,859
Rym: We'll see.

924
00:52:32,060 --> 00:52:34,320
Rym: If he doesn't buzz in first, then he's playing suboptimally.

925
00:52:34,800 --> 00:52:36,019
Rym: He's not playing to win the game.

926
00:52:36,820 --> 00:52:36,900
Rym: Nah.

927
00:52:42,170 --> 00:52:44,290
Rym: This has been GeekNights with Rym and Scott.

928
00:52:44,490 --> 00:52:49,430
Rym: Special thanks to DJ Pretzel for the opening music, Kat Lee for web design, and Brando K for the logos.

929
00:52:49,850 --> 00:52:54,830
Scott: Be sure to visit our website at FrontRowCrew.com for show notes, discussion news, and more.

930
00:52:55,450 --> 00:52:57,770
Rym: Remember, GeekNights is not one, but four different shows.

931
00:52:57,990 --> 00:53:02,489
Rym: Sci-Tech Mondays, Gaming Tuesdays, Anime Comic Wednesdays, and Indiscriminate Thursdays.

932
00:53:02,910 --> 00:53:06,045
Scott: GeekNights is distributed under a Creative Commons Attribution 3.0 license.

933
00:53:07,330 --> 00:53:10,330
Scott: GeekNights is recorded live with no studio and no audience.

934
00:53:10,590 --> 00:53:13,450
Scott: But unlike those other late shows, it's actually recorded at night.

