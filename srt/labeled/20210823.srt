1
00:00:07,980 --> 00:00:10,165
Rym: It's Monday, August 23rd, 2021.

2
00:00:10,165 --> 00:00:10,406
Rym: I'm Rym.

3
00:00:10,446 --> 00:00:12,191
Rym: I'm Scott and this is GeekNights.

4
00:00:12,251 --> 00:00:21,979
Rym: tonight We're talking about Apple see Sam and privacy, you know, one of the biggest stories in the last few weeks.

5
00:00:23,142 --> 00:00:25,614
Scott: We could actually done the main bit on computer sleeping.

6
00:00:26,519 --> 00:00:30,254
Rym: Oh We should save that for another one Because I already set all this up.

7
00:00:31,303 --> 00:00:31,989
Rym: Write it down.

8
00:00:32,432 --> 00:00:33,339
Rym: I will write it down.

9
00:00:35,130 --> 00:00:37,638
Rym: All right Let's do this.

10
00:00:38,761 --> 00:00:44,669
Rym: So we went down to a private beach house with some friends to get away for a week And then we didn't have to race.

11
00:00:44,750 --> 00:00:46,940
Rym: like it was easy to get home before the hurricane.

12
00:00:47,443 --> 00:00:57,759
Rym: but that tropical storm escalated pretty quickly and Actually hit New York and if there's some I say fun flooding because the flooding in New York was not like super bad.

13
00:00:57,799 --> 00:01:01,452
Rym: in the end We actually got pretty lucky and the storm petered out and hit other places worse.

14
00:01:01,653 --> 00:01:02,857
Scott: It was just a whole bunch of rain.

15
00:01:03,198 --> 00:01:06,291
Rym: Yep It was enough rain though to where I thought.

16
00:01:06,311 --> 00:01:08,360
Rym: you know, it would be cool like what I've done in the past.

17
00:01:08,761 --> 00:01:12,095
Rym: I'll go out for a run during the tropical storm or the hurricane like it won't be.

18
00:01:12,135 --> 00:01:16,452
Rym: that sounds like a bad idea But okay, I mean unless the winds super bad like that's fine.

19
00:01:16,552 --> 00:01:18,018
Rym: If it's warm like what I'm wet.

20
00:01:18,078 --> 00:01:18,540
Rym: who cares?

21
00:01:18,600 --> 00:01:23,060
Scott: Yeah, but it's not as bad of an idea as the people who go like surfing when the hurricane is coming, right?

22
00:01:23,180 --> 00:01:32,720
Rym: But that is the best surfing Yeah, but it's also the deadliest Yeah, you do taking your life in your own hands in that case like like the one who's always in your own hands.

23
00:01:33,703 --> 00:01:41,680
Scott: Sometimes it's in someone else's hands Sure, but it's still in your own hands, even when it's in someone else's hands, but so we get home.

24
00:01:41,781 --> 00:01:43,028
Rym: I think maybe I'll go run.

25
00:01:43,089 --> 00:01:50,295
Rym: I got on the balcony and it is raining Hard enough to or even I am like, yeah, I'm just not gonna go outside at all.

26
00:01:50,315 --> 00:01:51,539
Rym: You know, it's not gonna work out.

27
00:01:52,282 --> 00:01:52,964
Scott: No surprise.

28
00:01:53,466 --> 00:01:59,162
Rym: I've biked home in similar rain, but that's different from doing like an hour-long run Mm-hmm.

29
00:01:59,884 --> 00:02:00,766
Rym: So yeah, there is.

30
00:02:01,007 --> 00:02:03,575
Rym: we missed a week of shows because I was out of town.

31
00:02:03,976 --> 00:02:08,699
Rym: we came back for a brief One show week and we went out of town again.

32
00:02:09,222 --> 00:02:17,748
Rym: we're finally back and with pretty much on a regular schedule for the foreseeable future and of course a ton of Honestly really important big deal.

33
00:02:17,788 --> 00:02:19,695
Rym: tech news happened the one time.

34
00:02:19,735 --> 00:02:21,039
Rym: We're not around to talk about it.

35
00:02:22,245 --> 00:02:22,649
Scott: It happened.

36
00:02:22,689 --> 00:02:28,554
Scott: I think before we left We just didn't have a Monday show between then exactly between the last Monday show we did.

37
00:02:28,654 --> 00:02:36,336
Rym: and now on three Major stories happened and I'm not allowed to call for a tech news roundup.

38
00:02:36,376 --> 00:02:39,192
Scott: I'm sure more stories It's more major stories than that happened.

39
00:02:39,253 --> 00:02:40,240
Rym: But oh, yeah a bunch happened.

40
00:02:40,280 --> 00:02:42,636
Rym: But these three were the biggest three that we got something to say.

41
00:02:42,656 --> 00:02:48,060
Rym: Yep So instead of doing a normal main bit, well, basically the news we have the most to say about became the main bit.

42
00:02:48,120 --> 00:02:49,000
Rym: We'll see how that goes.

43
00:02:50,602 --> 00:02:52,760
Rym: So first things first, we'll dive right into it.

44
00:02:53,887 --> 00:02:58,062
Rym: Only fans Basically pulled a tumbler Right.

45
00:02:58,122 --> 00:02:58,984
Scott: So only fans.

46
00:02:59,024 --> 00:03:16,489
Scott: I'm sure you know what this website is, but just in case you didn't it's a social network type site Where you pay to follow someone and most of the people that you're going to be paying to follow our porn stars or sex workers and That you know, it was.

47
00:03:16,509 --> 00:03:18,400
Scott: it was a site that a lot of people used.

48
00:03:18,561 --> 00:03:21,517
Scott: There's a lot of competition for it now that I've seen some people using.

49
00:03:21,618 --> 00:03:23,063
Scott: but yeah It was it's a thing.

50
00:03:23,705 --> 00:03:26,795
Scott: It was a thing and it's soon gonna not be a thing.

51
00:03:26,815 --> 00:03:34,195
Rym: Yep, and Effectively with a bunch of caveats and a lot more complexity than we really want to get into.

52
00:03:34,617 --> 00:03:43,240
Rym: they're banning Pornographic content the likes of which the most people who use only fans use it for that is what they seek out.

53
00:03:43,300 --> 00:03:44,686
Rym: That is why that platform grew.

54
00:03:44,746 --> 00:03:45,670
Rym: That's why it was there.

55
00:03:45,690 --> 00:03:48,039
Rym: That was the primary reason people use it.

56
00:03:48,882 --> 00:03:49,484
Scott: Yeah, a lot of.

57
00:03:49,544 --> 00:03:52,393
Scott: I saw a lot of jokes on Twitter that were the equivalent of like.

58
00:03:52,954 --> 00:03:55,664
Scott: oh in the news today orchard stop Selling apples.

59
00:03:55,745 --> 00:03:56,327
Rym: It's help.

60
00:03:57,031 --> 00:03:59,000
Rym: What's interesting is only fans.

61
00:03:59,800 --> 00:04:01,424
Scott: McDonald's stop selling burgers.

62
00:04:01,544 --> 00:04:02,787
Rym: the company acted like.

63
00:04:02,807 --> 00:04:09,383
Rym: they were surprised that this announcement was met with people just dropping their platform Like they were.

64
00:04:09,584 --> 00:04:18,103
Rym: they seemed surprised at the huge amount of vitriol anger and basically the fact that their business is done now Like they're just destroyed Mm-hmm.

65
00:04:18,644 --> 00:04:32,171
Scott: But yeah, so I Mean, it's really surprised me and that usually the pattern of a Silicon Valley business is to start out completely ignoring laws Regulations rules of any kind.

66
00:04:32,191 --> 00:04:37,653
Scott: right the way, you know You see uber continuing to do uber way of trying to change the rules.

67
00:04:37,733 --> 00:04:39,460
Scott: In fact, they went far above and beyond.

68
00:04:41,262 --> 00:04:45,540
Scott: That's another news that their rule change was ruled unconstitutional in the California court.

69
00:04:45,661 --> 00:04:48,960
Scott: But usually you see a crunchyroll style pattern, right?

70
00:04:49,020 --> 00:05:00,660
Scott: It's like start out with just a pirate anime website and then become legitimate anime website and then eventually they're bought into Funimation slash Sony and it doesn't matter anymore that they were once committing crimes, right?

71
00:05:00,900 --> 00:05:05,497
Scott: So and many many Silicon Valley businesses operate this way.

72
00:05:05,598 --> 00:05:06,180
Scott: just you know.

73
00:05:06,200 --> 00:05:07,195
Scott: They start off that.

74
00:05:07,236 --> 00:05:20,420
Scott: you know You can't afford you if you try to start any business even a small normal little business like say a restaurant And you try to follow every single fucking rule right right out of the gate from day one.

75
00:05:20,801 --> 00:05:25,474
Scott: You know paying every tax getting every inspection, you know everything.

76
00:05:25,494 --> 00:05:27,800
Scott: you're the costs to start the business.

77
00:05:27,880 --> 00:05:28,963
Scott: We'll just ruin the business.

78
00:05:29,004 --> 00:05:34,460
Rym: Yep, pretty much every convention you've ever been to started running like directly illegally.

79
00:05:35,547 --> 00:05:38,004
Rym: Yeah, every day Even packs.

80
00:05:39,027 --> 00:05:49,791
Scott: I can think of very few businesses that start just doing everything completely by the book 100% kosher and succeeding and going far.

81
00:05:50,051 --> 00:05:51,716
Scott: It just doesn't happen that often right?

82
00:05:51,736 --> 00:05:51,916
Scott: so?

83
00:05:51,936 --> 00:05:55,540
Scott: and but in Silicon Valley It's to a greater extreme of the illegalness, right?

84
00:05:55,640 --> 00:05:59,353
Scott: Just blatant disregard for all laws to get your business off the ground.

85
00:05:59,373 --> 00:06:05,308
Scott: just straight capitalist extortion Exploitation not extortion and then whatnot.

86
00:06:05,348 --> 00:06:09,560
Scott: So that's what only fans did just you know, ignoring all the porn laws, right?

87
00:06:09,580 --> 00:06:11,823
Scott: They couldn't afford to actually Verify.

88
00:06:11,943 --> 00:06:13,228
Scott: every single person is a man.

89
00:06:13,248 --> 00:06:21,729
Scott: you imagine if every single person who went to only fans and said new account Right point my webcam at myself get naked Make money, right?

90
00:06:21,769 --> 00:06:26,344
Scott: That's like a 10-minute process or at least it was You know very quick process.

91
00:06:26,384 --> 00:06:42,463
Scott: if only fans actually verified and checked on every single person who was either a customer or a service provider On their site the cost and time required to do that what they would have been impossible to surmount They just go under

92
00:06:42,643 --> 00:06:47,240
Rym: yeah, but what I what's interesting is that it appears pornhub had a similar problem.

93
00:06:47,280 --> 00:06:50,479
Rym: You might remember last year where their payment processor went after them.

94
00:06:50,981 --> 00:06:56,000
Rym: But they actually changed their policies to comply with the payment processor rules.

95
00:06:56,502 --> 00:07:01,400
Rym: And if you have it, I'm if you're unaware pornhub is still around and doing fine.

96
00:07:02,182 --> 00:07:03,788
Scott: Yeah, well, I mean because they're doing.

97
00:07:03,828 --> 00:07:07,580
Scott: I don't know how well they're doing but they removed a lot of the porn on their site.

98
00:07:07,640 --> 00:07:16,459
Scott: They basically don't let people just upload, you know, look at something like YouTube, right and you know Pornhub's doing a better job moderating its content than YouTube is.

99
00:07:17,323 --> 00:07:21,100
Scott: Well, I mean pornhub but used to just allow people to upload whatever the hell horn be.

100
00:07:21,160 --> 00:07:23,170
Rym: So what pornhub now it's like?

101
00:07:23,210 --> 00:07:24,919
Scott: yeah, no almost no one can upload anything.

102
00:07:25,140 --> 00:07:29,054
Rym: So what pornhub did to comply with those rules was pretty simple.

103
00:07:29,395 --> 00:07:38,352
Rym: They only allow like verify ID users to post videos and No one can download videos directly from the site.

104
00:07:38,432 --> 00:07:40,279
Rym: Like obviously there's an analog hole and everything.

105
00:07:41,043 --> 00:07:46,165
Rym: analog hole for the analog hole but you can't actually download the videos.

106
00:07:46,687 --> 00:07:52,950
Rym: and there's a couple other minor changes they made around moderation and that seemed to Get them around the new rules.

107
00:07:53,533 --> 00:07:57,620
Rym: It's unclear to me Why I mean, there's so many things going on in the story.

108
00:07:57,901 --> 00:08:11,000
Rym: But if we just focus on OnlyFans what I don't understand is if OnlyFans has such a user base and is so big Why could they not now that they're established do what pornhub did?

109
00:08:12,280 --> 00:08:12,922
Scott: I don't know that's.

110
00:08:13,143 --> 00:08:18,100
Scott: you think that would just be the common sense thing to do because the narrative of why this happened.

111
00:08:19,021 --> 00:08:24,340
Rym: Someone who knows more about this than us could probably do an entire like YouTube series just on this space.

112
00:08:24,702 --> 00:08:42,635
Rym: But essentially there is a long history of politicians Conservative interests and a variety of industries not just banking Generally just trying to keep porn out of the public discourse and the legacy of that and the damage of that All not just porn but also sex work is clearly a factor here.

113
00:08:42,695 --> 00:08:43,799
Rym: that legacy continues.

114
00:08:43,960 --> 00:08:49,337
Rym: There are very conservative forces in these spaces, but there's a bunch of other factors at play.

115
00:08:49,798 --> 00:09:24,699
Rym: For example Pornographic content is one of the primary causes of chargebacks, charge disputes, lawsuits, escrow problems, extortion, money laundering, like all the things that even if you are the kind of payment Processor or bank who literally doesn't care about the content and all you care about is handling transactions for a fee It costs so much money to deal with that kind of nonsense that even if you think porn is fine as a business You're probably better off not allowing it so you don't have to deal with that space and all the problems that come up within it.

116
00:09:25,060 --> 00:09:37,374
Scott: Yeah, well, I think also it's that you know, we see by you know, designating pornography even you know Legal consenting adult pornography as sort of like this special thing, right?

117
00:09:37,434 --> 00:09:38,116
Scott: Yeah, you know, it's.

118
00:09:38,176 --> 00:09:39,620
Scott: it's you have to go to a sex shop.

119
00:09:39,781 --> 00:09:41,880
Scott: It's not just you know, you want to get a pornographic book.

120
00:09:41,980 --> 00:09:42,562
Scott: It's not at.

121
00:09:42,964 --> 00:09:45,493
Scott: you know Barnes and Noble borders doesn't exist anymore.

122
00:09:45,513 --> 00:09:49,150
Scott: All right, you get it at the special shop I remember going to a Walden books.

123
00:09:49,371 --> 00:10:04,260
Rym: You want to go you want to buy a book for a pseudo-girlfriend I had in like sixth grade because she was really into Danielle Steele and I went to buy it and the Walden books wouldn't Sell it to me because I was a sixth grader and they both share pornographic.

124
00:10:05,101 --> 00:10:06,428
Scott: Right, but that wasn't poor.

125
00:10:06,468 --> 00:10:12,551
Scott: but the point it was according to Walden books Whatever, but you can't buy a sex toy at Walmart.

126
00:10:12,893 --> 00:10:14,980
Scott: For example, they don't sell dildos unless you're brave.

127
00:10:17,004 --> 00:10:20,646
Scott: Sure depends what you want to use But you can't buy.

128
00:10:20,666 --> 00:10:22,193
Scott: you know, it's like they just don't have those there.

129
00:10:22,274 --> 00:10:31,560
Scott: and if that wasn't the case Right, if you just had porn as an accepted societal thing then porn would just be mixed in with other stuff.

130
00:10:31,680 --> 00:10:37,820
Scott: You would write then it's like a payment processor isn't gonna cut off Walmart because there's a porn section at the Walmart.

131
00:10:38,202 --> 00:10:45,618
Scott: But it's when there's an entire business and it's like the entire business is porn only Then it's very easy for the payment processor to cut it off.

132
00:10:45,739 --> 00:11:04,052
Rym: Yep So I suspect in this case and again, we have no insider knowledge what OnlyFans was attempting to do this is just my personal guess is They started with porn They they ran into the problems I just described and eventually their payment processor was like look buddies enough is enough.

133
00:11:04,373 --> 00:11:21,470
Rym: even pornhub follows these rules and rather than Continue to double down on trying to be in that space They tried to pivot to all the other kinds of things such a platform could do like Fitness instructors and tutoring and all that other stuff and just back away from the whole space.

134
00:11:23,264 --> 00:11:28,459
Rym: Of course this led to a lot of backlash But also I don't know how much money there is in the rest of that.

135
00:11:28,861 --> 00:11:43,020
Scott: Compared to it would be one thing if you if you intend, you know Put that up as your as your front and everybody knows wink wink The front and then the facade fell down and it's fitness instructors right in that facade now, right?

136
00:11:43,160 --> 00:11:44,614
Scott: That's the wrong way to do it.

137
00:11:46,784 --> 00:11:59,480
Scott: But I mean there is clearly I think it is a good core idea to have a somehow Some sort of site where people upload content and then people pay to access that content.

138
00:11:59,763 --> 00:12:00,854
Scott: It's called patreon.

139
00:12:00,875 --> 00:12:06,820
Rym: it exists Similarly had to deal with a lot of these issues back in 2017 and they're successfully navigated.

140
00:12:06,901 --> 00:12:09,704
Rym: But as you note even to this day There's all that.

141
00:12:09,764 --> 00:12:19,700
Rym: many of you we listen to GeekNights are probably aware of a lot of pornography on patreon But it's not easy to search for that patreon pornography via patreon for a reason.

142
00:12:20,541 --> 00:12:30,499
Scott: Yeah, you know Twitter is supposedly gonna try to do their super follow, which is effectively the same thing which is like yeah, if you pay you to follow me, you'll see more tweets that only people who pay to follow me see.

143
00:12:30,519 --> 00:12:33,018
Scott: and Twitter does have a lot of porn on it.

144
00:12:33,962 --> 00:12:37,153
Scott: Twitter is mostly okay with as long as you know, it's within certain lines.

145
00:12:37,935 --> 00:12:39,219
Scott: So we'll see how that goes.

146
00:12:39,721 --> 00:12:40,342
Scott: So I

147
00:12:40,402 --> 00:12:42,728
Rym: found an article on xbiz that see

148
00:12:42,768 --> 00:12:53,636
Scott: and also Facebook speaking of which right a lot of people correctly pointed out Facebook basically has more child porn another garbage on it than like any of these other platforms

149
00:12:53,857 --> 00:12:59,436
Rym: with a possible Exception when we get to the main bit that Apple might have had more at least for a maybe.

150
00:12:59,496 --> 00:13:01,447
Scott: but the point is Nobody's either.

151
00:13:01,467 --> 00:13:04,264
Scott: the payment processors weren't cutting off Facebook.

152
00:13:04,888 --> 00:13:07,159
Scott: right payments for ads and such?

153
00:13:07,541 --> 00:13:10,328
Rym: Yeah, well for ads but there were.

154
00:13:10,448 --> 00:13:15,789
Rym: I get the impression there were things that happen behind the scenes in these other websites as well.

155
00:13:16,643 --> 00:13:22,062
Rym: I what I did learn Mastercard, I actually found the rules They're listed on this website I'll link to.

156
00:13:22,463 --> 00:13:28,340
Rym: that are at stake here for the MasterCard part of the payment processing lifecycle that are affecting only fans.

157
00:13:28,702 --> 00:13:29,728
Rym: So it's only.

158
00:13:29,748 --> 00:13:30,855
Rym: it's not that many bullet points.

159
00:13:30,915 --> 00:13:31,800
Rym: It's pretty straightforward.

160
00:13:32,921 --> 00:13:34,487
Rym: One that one section.

161
00:13:34,848 --> 00:13:38,040
Rym: This is the section that applies to what they call tube sites.

162
00:13:38,140 --> 00:13:42,234
Rym: So pornhub x-video only lands anything you like.

163
00:13:42,354 --> 00:13:47,942
Rym: Yeah anything that's live streams or direct interaction and stuff like that One.

164
00:13:48,363 --> 00:13:55,359
Rym: you must enter a written contractual agreement with any individual contributing content that includes their consent their identity and their age.

165
00:13:56,587 --> 00:13:57,494
Rym: That seems reasonable.

166
00:13:58,159 --> 00:14:07,360
Rym: all Depicted in the content must in themselves give independent verifiable consent For the content to be distributed and downloaded.

167
00:14:08,885 --> 00:14:14,424
Scott: You know if I can't if I sign an agreement and get an account and suddenly I invite someone over to be in a video It's like whoa, we got to know who that is.

168
00:14:14,444 --> 00:14:16,089
Rym: Yeah, never mind.

169
00:14:16,229 --> 00:14:26,560
Rym: a big part of the problem in this space is non-consensual pornography Where someone surreptitiously films say an encounter with a one-night stand and then that is the porn they publish.

170
00:14:26,863 --> 00:14:28,578
Rym: That is a huge growing problem.

171
00:14:29,700 --> 00:14:33,940
Rym: Wrench porns all kinds only verified users can upload content.

172
00:14:34,563 --> 00:14:47,616
Rym: the big one I think is all content must be reviewed prior to publication or Real time if it's live streams and no content can violate the Mastercard brand Bram policies.

173
00:14:47,656 --> 00:14:48,440
Rym: I'll get to that in a minute.

174
00:14:48,802 --> 00:14:59,860
Rym: I dug into what that is a little more business risk assessment and mitigation policies Which is mostly around Mastercard saying these are the things that you cannot let happen with your payments because they are literally illegal.

175
00:15:01,602 --> 00:15:05,320
Rym: The website must have a complaint process for reporting and removing material.

176
00:15:05,761 --> 00:15:10,574
Rym: They must have policies to make sure the website cannot be used for human trafficking effectively.

177
00:15:11,155 --> 00:15:23,139
Rym: They must provide monthly reports of flag content and what was taken down and No search terms or marketing partners or anything in their ecosystem can give the illusion that child porn is there.

178
00:15:24,082 --> 00:15:25,446
Rym: They can't hit at child porn.

179
00:15:26,269 --> 00:15:27,613
Scott: if someone searches for child porn.

180
00:15:27,633 --> 00:15:29,058
Scott: It's got to say zero results.

181
00:15:29,278 --> 00:15:29,760
Scott: Sorry, bro.

182
00:15:30,683 --> 00:15:35,080
Scott: And that if someone searches for like, you know hot teens, it's got to be like no.

183
00:15:35,440 --> 00:15:39,840
Rym: So as best I can tell with the caveat that this is like a couple days of research.

184
00:15:40,402 --> 00:15:45,179
Rym: Those are the rules that OnlyFans is unwilling or unable to comply with.

185
00:15:46,206 --> 00:15:47,859
Scott: Well, then that's it.

186
00:15:48,201 --> 00:15:59,345
Scott: I think the real-time moderation one might be the hardest one for them Which is definitely the most expensive because you need so like you just need to pay people to sit there and watch it all day And that's not a job.

187
00:15:59,385 --> 00:15:59,928
Scott: That's so.

188
00:16:00,329 --> 00:16:02,720
Rym: what are those brand policies on Mastercard?

189
00:16:02,841 --> 00:16:28,220
Rym: Well, that's a lot more complicated, but it seems to come into having controls to prevent directly like explicitly illegal activity from being paid for like if I buy a hitman or illegal drugs or illegal tobacco Coerce transactions, which is a euphemism for Blackmail or like literally just going up to an ATM and forcing someone to buy something or take money bribes.

190
00:16:28,543 --> 00:16:31,824
Rym: Yeah, child trafficking Cryptocurrencies are covered by that.

191
00:16:31,884 --> 00:16:35,032
Rym: buying and selling cryptocurrencies is heavily restricted by Mastercard.

192
00:16:35,072 --> 00:16:55,280
Rym: similarly for all the reasons you can expect illegal gambling and There's a slightly more nebulous class of what they call offensive adult pornography but as far as I can tell it mostly applies to Explicitly illegal pornography or pornography that doesn't comply with those other rules that we were talking about.

193
00:16:55,802 --> 00:17:01,160
Scott: Yeah, they're not they're talk they're not talking about, you know, just somebody's, you know, freaky kink or you're talking about.

194
00:17:01,240 --> 00:17:04,579
Scott: You know really stuff that you know is shouldn't be.

195
00:17:05,602 --> 00:17:22,319
Rym: So this is a really complicated space and it is a little bit too much of a simplification To say that Mastercard is directly anti porn or trying to censor Though that there that is definitely a factor considering the history of this industry and this space and these.

196
00:17:22,358 --> 00:17:41,022
Scott: well Just you know the law right requiring certain things and as part of the problem is that you know a lot of the laws that are you know, well-meaning in an attempt to prevent or hinder job child porn and also Other crimes like, you know extortion bribery Etc.

197
00:17:41,363 --> 00:17:47,920
Scott: black male right that the laws are not, you know, very sharp and delicate instruments.

198
00:17:48,101 --> 00:17:50,578
Scott: They are blunt hammer and cause.

199
00:17:50,598 --> 00:17:58,220
Scott: you know They cause a great deal of collateral damage mostly to consensual adult sex workers.

200
00:17:58,641 --> 00:18:09,213
Scott: Because we have all these things in place, you know, not just because of companies But also because of the laws that make those company do do things right.

201
00:18:10,965 --> 00:18:12,682
Scott: As a result, it's like yeah We're not.

202
00:18:12,702 --> 00:18:16,819
Scott: we're gonna try to stop these things and as a result the thing that we don't want to stop is also stops.

203
00:18:17,401 --> 00:18:20,732
Rym: Yep, so it's not just conservative agitation.

204
00:18:20,772 --> 00:18:22,177
Rym: There's a lot more going on here.

205
00:18:22,237 --> 00:18:25,789
Rym: There's a lot of Self-interested I don't want to deal with the sector.

206
00:18:25,829 --> 00:18:29,320
Rym: that is extremely dangerous to deal with based on it like real kind.

207
00:18:29,360 --> 00:18:35,427
Scott: Oh, yeah, of course also capitalism right because in socialism you would just have You know government sex workers.

208
00:18:35,548 --> 00:18:36,009
Rym: Yeah.

209
00:18:36,049 --> 00:18:38,920
Rym: Well, no no that that gets into another dicey territory.

210
00:18:39,080 --> 00:18:43,699
Rym: I think a better way to look at it is in a you know, truly socialist society that was constructed.

211
00:18:43,759 --> 00:18:48,943
Rym: Well Nobody would be doing sex work unless they wanted to Exactly.

212
00:18:48,963 --> 00:18:50,086
Rym: That's a better way to put it.

213
00:18:50,406 --> 00:19:01,020
Rym: government sex workers gets into a far more terrifying consequence of poorly written laws and This is a. this is a an argument that would need to be addressed by better laws.

214
00:19:01,402 --> 00:19:08,145
Rym: But imagine if sex work were completely legal and regulated Arguably under existing laws.

215
00:19:08,466 --> 00:19:15,426
Rym: someone could be forced to do it if they found a job in that sector and we're currently collecting unemployment Or risk losing their unemployment.

216
00:19:15,888 --> 00:19:16,811
Rym: That doesn't feel right.

217
00:19:16,852 --> 00:19:17,193
Rym: Does it?

218
00:19:17,956 --> 00:19:18,579
Scott: No, it doesn't.

219
00:19:18,619 --> 00:19:20,846
Rym: Yep This is why this is such a complicated space.

220
00:19:21,408 --> 00:19:36,260
Rym: So only fans really shit the bed and fucked up here because they as from everything I can tell they could have taken steps to comply with these rules and other sites like Pornhub have indeed Complyed with these steps and continue to take payments.

221
00:19:36,741 --> 00:19:47,588
Rym: so only fans pivoted away from the demographic and the people that made them a success and I kind of hope they go out of business because they really should have had those people's back.

222
00:19:47,808 --> 00:19:51,158
Rym: their platform only got to the scale it got to because of those people.

223
00:19:51,459 --> 00:19:55,909
Rym: if you're Gonna if you're gonna go into that industry You'd better be there for the people you're working with.

224
00:19:56,110 --> 00:20:09,198
Rym: at least the people who invested in it are gonna get burned Yep, because I don't think OnlyFans is gonna survive on people paying to get a hockey player to chat with them like an old Call the hotline to talk to Corey Haim thing from the 80s?

225
00:20:10,374 --> 00:20:12,864
Scott: Yeah Pretty sure.

226
00:20:12,884 --> 00:20:14,654
Scott: the hotline just talked to a recording, right?

227
00:20:14,694 --> 00:20:14,976
Rym: Yeah.

228
00:20:15,096 --> 00:20:18,228
Scott: Yeah There has been at the phone that eat that I saw.

229
00:20:18,328 --> 00:20:25,109
Rym: I watched a YouTube video a while ago talking about like that whole or like Preteen 900 number ecosystem from the 80s.

230
00:20:25,731 --> 00:20:28,419
Rym: What a weird world that was the late 80s.

231
00:20:29,901 --> 00:20:33,393
Rym: But there's a ton more here that we do not have time or expertise to get into.

232
00:20:33,454 --> 00:20:37,693
Rym: but I'm gonna link to a whole bunch Resources if you want to learn more about that space.

233
00:20:37,975 --> 00:20:40,690
Rym: and if you think to yourself Why don't I just make a website?

234
00:20:40,711 --> 00:20:41,395
Rym: that does it right?

235
00:20:41,837 --> 00:20:42,260
Rym: Good luck.

236
00:20:42,722 --> 00:20:46,039
Rym: And if you think why don't I just make a payment processor and a bank?

237
00:20:47,802 --> 00:20:48,567
Rym: I thought about that.

238
00:20:48,848 --> 00:20:50,216
Rym: We were talking about that a lot.

239
00:20:50,236 --> 00:20:50,719
Scott: Good luck.

240
00:20:52,369 --> 00:21:05,128
Rym: in my Professional opinion it is possibly possible to do it without committing a felony and I Don't think I think of it like this, right?

241
00:21:05,148 --> 00:21:08,940
Scott: There's this big, you know, there's this big field of lava, right?

242
00:21:09,442 --> 00:21:11,932
Scott: And there's yes, you can cross this lava field.

243
00:21:11,972 --> 00:21:13,820
Scott: There is clearly some stepping stones.

244
00:21:15,466 --> 00:21:18,840
Rym: Few other people in metal boats like making their way around the lava.

245
00:21:18,920 --> 00:21:20,669
Rym: They're out there, but there's not many touching.

246
00:21:20,750 --> 00:21:23,544
Scott: touching the lava means federal prison Right.

247
00:21:23,826 --> 00:21:26,480
Scott: and the other side is is you know what we want, right?

248
00:21:26,680 --> 00:21:37,414
Scott: Which is you know consensual adult sex workers get paid as they deserve to be Right and can sexual adult customers are able to pay them as they you know, should right.

249
00:21:37,895 --> 00:21:44,840
Scott: and yet to cross that Someone's got to cross the fire the lava with the stepping stones without touching the lava.

250
00:21:45,464 --> 00:21:46,270
Scott: Someone else is doing it.

251
00:21:46,311 --> 00:21:46,613
Scott: Not me.

252
00:21:46,653 --> 00:21:51,812
Rym: I'm not touching the lava Ah, so before we go to the next news the list is not gonna risk it Oh, but also it's not just that.

253
00:21:51,933 --> 00:21:57,154
Rym: even if you're looking to lava You see boats flipping over and sinking in the lava constantly big ones.

254
00:21:57,294 --> 00:21:59,140
Scott: The only fans one is like on fire.

255
00:21:59,481 --> 00:22:05,557
Rym: Yep, the Titanic has flipped over and is sinking on fire and you're sitting there and your little dinghy thinking I gotta get me some of that.

256
00:22:07,381 --> 00:22:08,827
Scott: I'm gonna be the one who makes it across.

257
00:22:09,248 --> 00:22:12,080
Scott: all these big guys didn't make it but I'm the one who's gonna make it.

258
00:22:12,280 --> 00:22:16,213
Rym: Yep, so but possibly possible is what I would say, but the listener it just asked.

259
00:22:16,674 --> 00:22:18,580
Rym: What about cryptocurrency one?

260
00:22:18,980 --> 00:22:40,740
Rym: Cryptocurrency needs to be banned for a bunch of other reasons like so many reasons I can't get into but to The infrastructure bill that the US government is about to pass includes and this is a whole topic for another day Includes language that allows the federal government to regulate cryptocurrencies and guess what those regulations will will effectively do.

261
00:22:41,322 --> 00:22:59,520
Rym: They'll require the same kinds of things that MasterCard is requiring of porn sites Verifying the identities verifying where the money came from and what is being used for all the things that all the other banks do Which literally remove all the quote good aspects unquote of cryptocurrency that libertarian shitbags like to talk about.

262
00:23:00,002 --> 00:23:12,040
Scott: The failure of cryptocurrency to be used as a currency even if you forget about its environmental damage Even if you forget about all the other nonsense and whatnot, right is that it's not being used as a currency.

263
00:23:12,281 --> 00:23:14,289
Scott: No one will accept it for anything.

264
00:23:14,329 --> 00:23:15,694
Scott: You can't pay your rent with it.

265
00:23:15,714 --> 00:23:17,100
Scott: You can't buy groceries with it.

266
00:23:17,120 --> 00:23:21,660
Scott: So at some point it needs to be converted to dollars and at the point it could be converted to dollars.

267
00:23:22,364 --> 00:23:25,220
Scott: The government can get you and in fact, they don't even need to get to that point.

268
00:23:25,280 --> 00:23:32,840
Scott: They've seized plenty of bitcoins from plenty of people before they converted to dollars or after I know when it was still in Bitcoin form.

269
00:23:32,961 --> 00:23:42,799
Scott: So it actually provides none and almost nobody Right is actually using any cryptocurrency in the dis in the purely distributed way that you know.

270
00:23:43,301 --> 00:23:56,918
Scott: The one benefit of it is like oh, you know, you can just anonymously transfer it between point A and point B. Yeah, that's if you with your computer with your wallet on your computer Directly interact with the blockchain from your computer with no one.

271
00:23:56,958 --> 00:24:07,586
Scott: in between 99.99% of cryptocurrency transactions people are using some cloud service middleman to hold their wallet for them and that's Effectively no different than using Chase Bank.

272
00:24:07,646 --> 00:24:11,400
Scott: So that's how you're getting caught and no one does it the real way.

273
00:24:11,500 --> 00:24:17,580
Scott: So they've just thrown out the Bennett who the one paper on paper, but not in reality benefit of cryptocurrency.

274
00:24:17,882 --> 00:24:18,688
Scott: It's just all bullshit.

275
00:24:18,991 --> 00:24:20,180
Scott: see our episode on cryptocurrency.

276
00:24:20,841 --> 00:24:25,760
Rym: So in some other big news and this really escalated in the weeks while we were gone.

277
00:24:25,880 --> 00:24:27,669
Rym: So I was I was only barely following.

278
00:24:27,729 --> 00:24:30,220
Scott: I saw it escalating but it's continued to escalate.

279
00:24:30,302 --> 00:24:36,720
Rym: So now we got to talk about yeah And and the one thing I'll say before we get into this is that I am shocked this did not happen sooner.

280
00:24:38,742 --> 00:24:40,551
Scott: Like I don't know why this took so long to have.

281
00:24:40,631 --> 00:24:42,400
Rym: I know it's kind of like way back when I was a kid.

282
00:24:42,480 --> 00:24:49,891
Rym: I was like, why doesn't someone just make a virus that instead of fucking up your computer Just like steals money or spies on you or something.

283
00:24:49,931 --> 00:24:50,794
Rym: Like why don't you buy this?

284
00:24:51,055 --> 00:24:52,580
Rym: Why isn't someone making money with this?

285
00:24:52,720 --> 00:24:55,136
Rym: Why are they just making viruses that they did eventually?

286
00:24:55,156 --> 00:25:04,860
Rym: Yep so Effectively, there is a there is a culture in twitch which not to stray from the point and definitely not to blame the victims.

287
00:25:05,362 --> 00:25:10,260
Rym: But I think this culture is a broken and toxic result of how twitch makes money in the first place.

288
00:25:10,802 --> 00:25:13,993
Scott: I think this see our ancient talk about.

289
00:25:14,153 --> 00:25:18,660
Scott: you know, the game makes the community In this case the user interface.

290
00:25:19,982 --> 00:25:29,777
Scott: If you consider twitch to be a game right all the rules of twitch and the way the software works Causes the community that is on there in my understanding.

291
00:25:29,818 --> 00:25:34,736
Rym: So So basically the the culture at stake here.

292
00:25:34,896 --> 00:25:35,860
Rym: Is that on twitch?

293
00:25:36,780 --> 00:25:42,375
Rym: People will raid other channels and by raid which is usually a positive thing.

294
00:25:42,455 --> 00:25:48,010
Scott: It's like I'm done streaming There's still 20 there's still a bunch of people watching me.

295
00:25:48,030 --> 00:25:53,367
Scott: right I will raid which you know Even though it's it's a negative term.

296
00:25:53,427 --> 00:25:54,792
Scott: It sounds like a bad thing.

297
00:25:55,314 --> 00:25:57,120
Scott: It's actually in twitch terms a good thing.

298
00:25:57,462 --> 00:26:04,380
Scott: I will send them to this other person that I like and Even if they keep watching me, they'll just be sent to this other person.

299
00:26:04,822 --> 00:26:09,600
Scott: They'll probably watch them for at least a little bit and if they like them, maybe they'll stay there, right?

300
00:26:10,060 --> 00:26:12,560
Scott: But if not, then they'll go somewhere else on their own.

301
00:26:12,600 --> 00:26:15,666
Scott: No one can force them to watch this other channel But it's still.

302
00:26:15,706 --> 00:26:19,826
Scott: it's giving that other person like a boost of attention And you the most.

303
00:26:19,887 --> 00:26:26,760
Scott: it's usually a very good thing when a very popular streamer Right will raid a very small channel.

304
00:26:27,543 --> 00:26:28,827
Rym: Well, it's good.

305
00:26:29,088 --> 00:26:32,740
Rym: like twitch users and content creators perceive it as being good.

306
00:26:33,141 --> 00:26:37,718
Rym: But I've seen a lot of evidence that those audiences don't actually stick around.

307
00:26:37,758 --> 00:26:41,537
Scott: they primarily But for the most part they don't stick around.

308
00:26:41,577 --> 00:26:46,021
Scott: but you know You just get one or two people can be a bit, you know a big deal for somebody It can.

309
00:26:46,322 --> 00:26:56,640
Rym: but a big part of rating too is people will do raid campaigns to help someone they like Get twitch partner verified or whatever like get their account above the line so they can model.

310
00:26:56,680 --> 00:27:05,100
Scott: So you'll you'll often see a community of streamers that are all friends with each other and they basically raid each other in like a circle And that sort of merges their communities together.

311
00:27:05,140 --> 00:27:13,993
Scott: Yeah So that like you get the same viewers will follow all of them and watch whoever is online at a given time and they'll stagger Their stream schedules and make like a little.

312
00:27:14,174 --> 00:27:18,109
Scott: you know a little thing You know, so it's a good functionality.

313
00:27:18,150 --> 00:27:20,159
Scott: the term raid isn't helpful, but you know.

314
00:27:21,421 --> 00:27:26,516
Rym: Yep, so but the problem there is that someone's account will get just barely above the line.

315
00:27:26,577 --> 00:27:27,720
Rym: They get partner status.

316
00:27:27,800 --> 00:27:31,454
Rym: They feel like they made it but those people mostly don't stick around.

317
00:27:31,796 --> 00:27:37,820
Rym: now weeks later Their account falls way below the line and they're making basically no money and they're not any better off.

318
00:27:38,861 --> 00:27:41,791
Scott: Well, you know, I'm just saying it's a there's a there's a.

319
00:27:41,931 --> 00:27:44,680
Rym: there is a just due to the sheer number of streams.

320
00:27:45,261 --> 00:27:52,140
Rym: It's not a strictly zero-sum game, but an individual person can only watch so many minutes of twitch per day.

321
00:27:52,601 --> 00:27:56,819
Rym: so there is a zero sum of how many eyeballs you can get on your twitch stream.

322
00:27:56,839 --> 00:28:06,960
Rym: and For a lot of smaller creators the cert the raid ecosystem is a turn of the same people Through a set of channels and it doesn't make anything sustainable.

323
00:28:07,281 --> 00:28:07,984
Scott: But that's not.

324
00:28:08,045 --> 00:28:08,788
Scott: it is a key.

325
00:28:08,808 --> 00:28:09,390
Scott: It is a cute.

326
00:28:09,511 --> 00:28:11,700
Scott: It is a cute sometimes helpful feature.

327
00:28:11,740 --> 00:28:14,400
Rym: Oh, yeah uses but I have long-term concerns about it.

328
00:28:14,545 --> 00:28:22,792
Rym: but What started happening and it appears that this is the work of a very small number of people who have written bots and built Infrastructure to make this happen.

329
00:28:22,812 --> 00:28:23,518
Rym: They've written code.

330
00:28:24,061 --> 00:28:38,252
Rym: then it appears even that the primary person or the smaller people involved with it are joining people's channels and even doing things like warning them they're about to run the racism bot or Asking for feedback on the racism bot posting change logs on.

331
00:28:38,533 --> 00:28:40,078
Rym: hey, this is version 2.1 of the bot.

332
00:28:40,841 --> 00:28:43,269
Rym: I hope you enjoy it before the Nazi stuff starts coming out.

333
00:28:43,770 --> 00:29:00,627
Rym: The bot will basically cause huge numbers of random automatically generated Twitter account or twitch accounts to join your channel and Just start spouting extremely racist nonsense Like since your content you can imagine

334
00:29:01,209 --> 00:29:06,302
Scott: and since twitch puts moderation on the shoulders of the streamers and their moderators and not on Themselves

335
00:29:06,362 --> 00:29:09,371
Rym: yet also gives them almost no tools to actually money

336
00:29:09,391 --> 00:29:09,572
Scott: gives.

337
00:29:09,652 --> 00:29:12,140
Scott: it gives them tools, but it gives them very weak tools.

338
00:29:12,160 --> 00:29:14,060
Rym: Oh, those tools are unusable garbage.

339
00:29:14,361 --> 00:29:19,237
Rym: I've actually been working on a spec and like what those tools we need to look like and it does give.

340
00:29:19,257 --> 00:29:23,994
Scott: it does provide Apis to let people build better tools, which you usually would use.

341
00:29:24,054 --> 00:29:25,860
Scott: but even those tools are weak sauce.

342
00:29:26,442 --> 00:29:31,378
Scott: So in the absence of strong enough tools and the absence of twitch not doing anything on their own.

343
00:29:31,659 --> 00:29:43,530
Scott: really You know if this happens to you, the only recourse you really have as a streamer right is You can just turn your stream chat into sub only mode.

344
00:29:43,551 --> 00:29:47,647
Scott: because yeah, go ahead subscribe to me with all those boss five bucks each I'll take it.

345
00:29:48,032 --> 00:29:52,780
Scott: It's like You know, you don't really have a lot of things you can do about it.

346
00:29:54,122 --> 00:29:58,840
Scott: Or you could put your chat it's like slow mode I guess and then try to ban them one at a time.

347
00:29:59,941 --> 00:30:01,108
Scott: That's really a pain in the ass.

348
00:30:01,128 --> 00:30:01,994
Scott: You don't want to be doing that.

349
00:30:02,014 --> 00:30:04,185
Scott: You want to be playing the video game You're playing right?

350
00:30:04,205 --> 00:30:05,350
Scott: You don't be clicking.

351
00:30:05,411 --> 00:30:07,379
Scott: ban on a hundreds and hundreds of chats in there.

352
00:30:08,344 --> 00:30:09,720
Scott: I guess you could turn off chat completely.

353
00:30:10,041 --> 00:30:19,439
Rym: I don't even know if that's an option on but again the raid culture and the culture of twitch is that No streamer wants to make their stream subs only they want it to be open to anyone.

354
00:30:20,203 --> 00:30:23,099
Scott: So you'd only usually streamers like don't want.

355
00:30:23,139 --> 00:30:29,160
Scott: yeah You don't want to be sub only because that's gonna be a turn-off for you know, people who just come across your channel.

356
00:30:29,220 --> 00:30:32,075
Scott: They're not gonna want to stay if they can't chat anything.

357
00:30:32,095 --> 00:30:33,120
Scott: They're just stuck watching you.

358
00:30:33,160 --> 00:30:35,033
Scott: I guess watching you isn't entertaining enough.

359
00:30:35,516 --> 00:30:37,023
Scott: for some reason They need to.

360
00:30:37,043 --> 00:30:40,332
Scott: they need to spam emojis to feel like they belong like.

361
00:30:40,372 --> 00:30:45,812
Rym: that is such a part of that culture that I Understand it, but I all but I don't enjoy it.

362
00:30:46,053 --> 00:30:46,475
Rym: I like.

363
00:30:46,555 --> 00:30:52,330
Rym: obviously I'm old I don't care anymore, but also That culture is start is.

364
00:30:52,351 --> 00:30:58,679
Rym: I don't want to blame the victims here But the culture of how twitch is used is making this problem worse rather than better.

365
00:30:59,542 --> 00:31:03,965
Scott: Yeah, it's like the only time I ever chat on twitch is If you know what

366
00:31:04,005 --> 00:31:06,997
Rym: if it's a small stream and I'm like chatting with like a small

367
00:31:07,037 --> 00:31:13,480
Scott: small stream And I'm legitimately talking to the person who's streaming, you know, like I actually have something to say to them.

368
00:31:13,581 --> 00:31:14,229
Rym: Well, like what are we doing?

369
00:31:14,249 --> 00:31:15,100
Rym: the live stream on gig now?

370
00:31:15,100 --> 00:31:18,475
Rym: It's like I'm usually chatting and text in the live chat while we're doing the show.

371
00:31:18,495 --> 00:31:28,672
Scott: Scott can't even see that right but if our chat if we were super popular and our chat became a stream of emojis that was just provided that would I mean I Would just turn it off at that point was devoid of content.

372
00:31:28,712 --> 00:31:30,260
Scott: Well, we might as well just turn it off then it doesn't.

373
00:31:30,361 --> 00:31:31,071
Scott: It's doing nothing.

374
00:31:31,091 --> 00:31:34,847
Scott: Yeah Right, so it's like I don't know.

375
00:31:35,127 --> 00:31:35,368
Rym: Yep.

376
00:31:35,628 --> 00:31:40,220
Scott: But yeah, the twitch chat itself is separate from this raid bot problem.

377
00:31:40,220 --> 00:31:44,665
Scott: Yep, but the raid bot problem has been going on and it's mostly Targeting.

378
00:31:45,274 --> 00:31:54,884
Scott: right Yes, yes, but also LGBTQ people right they're going after Targeting white dude.

379
00:31:54,945 --> 00:32:02,808
Rym: No, they're going after us to say that primarily and almost exclusively Underrepresented and oppressed minorities.

380
00:32:03,551 --> 00:32:09,497
Scott: Yeah and and posting, you know insult, you know slurs right in there in their bots, right.

381
00:32:09,517 --> 00:32:14,477
Scott: so The question is a right Twitch?

382
00:32:15,146 --> 00:32:15,328
Scott: Right.

383
00:32:15,348 --> 00:32:16,600
Scott: It's like what the hell are you doing about this?

384
00:32:16,780 --> 00:32:21,760
Scott: Why is it so easy to make a twitch account that you can just make a zillion of them once someone does this?

385
00:32:21,900 --> 00:32:24,120
Scott: It should be really easy to identify.

386
00:32:24,502 --> 00:32:28,863
Scott: Shouldn't all of those accounts just be perma banned Right instantly?

387
00:32:29,063 --> 00:32:34,640
Rym: if I someone is of twitch and if someone is programmatically creating so many new accounts as they get banned?

388
00:32:38,680 --> 00:32:40,249
Scott: Yeah, there's like, you know, it's quit.

389
00:32:40,289 --> 00:32:43,525
Scott: and Twitter if you try to do API stuff It's like you have an API key.

390
00:32:43,545 --> 00:32:44,992
Scott: They just turn your key off.

391
00:32:45,032 --> 00:32:45,213
Scott: great.

392
00:32:45,233 --> 00:32:46,920
Scott: You can't make any more API commands.

393
00:32:47,001 --> 00:32:48,150
Scott: Yeah, and all right.

394
00:32:48,170 --> 00:32:55,871
Rym: What else you gonna do like The one it's twitch needs to take an extreme action And instead they're making the slowest most miltoast actions possible.

395
00:32:55,891 --> 00:32:58,500
Scott: Like if I and twitch has the resources of Amazon.

396
00:32:58,500 --> 00:33:09,120
Rym: Yeah if I were the product manager for twitch like overall like the head of product the first thing I would do is literally Ban like I would halt for a couple weeks all new account creation.

397
00:33:09,582 --> 00:33:19,480
Rym: May have a team dedicated to banning all the accounts that are doing this big forensic analysis Like I like I would treat this as an existential crisis for the company.

398
00:33:20,941 --> 00:33:23,270
Rym: Yeah, which is saying like oh, well, we have tools.

399
00:33:23,290 --> 00:33:24,154
Rym: We're gonna make more tools.

400
00:33:24,395 --> 00:33:25,820
Rym: Those tools do not work at all.

401
00:33:25,820 --> 00:33:29,394
Rym: We don't have time to get into all the examples if you want to see the one.

402
00:33:29,695 --> 00:33:30,940
Scott: just one example, right?

403
00:33:31,020 --> 00:33:35,000
Scott: There are many many many examples, but the one example in a tweet I saw going.

404
00:33:35,323 --> 00:33:36,534
Rym: I know which one you're about to talk about.

405
00:33:36,575 --> 00:33:36,999
Rym: I think I have it.

406
00:33:37,341 --> 00:33:39,792
Scott: Someone was like, hey, what if I post the word?

407
00:33:39,832 --> 00:33:41,600
Scott: I want to post the word jogger, right?

408
00:33:41,860 --> 00:33:45,200
Scott: Obviously they were referencing another word that has two G's in it, right?

409
00:33:45,400 --> 00:33:48,494
Scott: But like hey, what if I want to post the word jogger in somebody's chat?

410
00:33:48,936 --> 00:33:49,740
Scott: It's like well, okay.

411
00:33:49,780 --> 00:33:53,656
Scott: So they go in and they type in their block list the word joggers that it cannot.

412
00:33:53,697 --> 00:33:58,160
Scott: so anyone who types It is automatically that that message is automatically blocked, right?

413
00:33:58,685 --> 00:34:17,621
Scott: Okay So but the problem is is you can type any Unicode character you want into twitch and there's several Characters in Unicode that look like J several that look like Oh several that look like G Several that look like E and several that look like are right in Cyrillic and several other alphabets that are available in the Unicode character Space.

414
00:34:18,203 --> 00:34:31,288
Scott: so the actual number of ways you could type the word jogger that would be recognizable in English right to an English speaker is many many many many and You can't type them all in right.

415
00:34:31,389 --> 00:34:36,928
Scott: and twitch doesn't automatically block all the variations To block all of them.

416
00:34:36,989 --> 00:34:45,235
Scott: You would have to do it with an automated, you know API calls right to your own twitch account to add all the variations of just one word.

417
00:34:45,737 --> 00:35:00,111
Scott: and that would take you Even if you did all that and wrote the code to do it or someone provided a tool to do it with a limit on API calls that you can make to twitch would take you like several several many days Just to add one word to your block list if you wanted to block all

418
00:35:00,191 --> 00:35:00,712
Rym: possible.

419
00:35:00,793 --> 00:35:02,839
Scott: Yeah visual variations of it.

420
00:35:03,100 --> 00:35:03,785
Rym: now Look at twitch.

421
00:35:04,409 --> 00:35:05,720
Rym: How do you solve this one?

422
00:35:06,401 --> 00:35:11,158
Rym: Really simplistic machine learning models can handle that like an exit.

423
00:35:11,178 --> 00:35:13,605
Scott: We already have For decades.

424
00:35:13,666 --> 00:35:14,809
Scott: It's called a spam filter.

425
00:35:14,829 --> 00:35:15,792
Scott: We use it on email.

426
00:35:15,832 --> 00:35:17,116
Scott: Yeah, right if somebody just

427
00:35:17,698 --> 00:35:18,179
Rym: apply

428
00:35:18,199 --> 00:35:33,905
Scott: a basic email spam filter technology to twitch chats Right if the kinds of twitch chats that are getting blocked consider that mark as spam and if you see an account that is Getting a lot of their chats marked as spam Automatically ban it

429
00:35:34,185 --> 00:35:34,306
Rym: from.

430
00:35:34,346 --> 00:35:36,934
Rym: so this gets back to that that original conversation.

431
00:35:37,195 --> 00:35:42,040
Rym: because the twitch culture likes an extremely spammy chat and likes raids.

432
00:35:42,882 --> 00:35:49,480
Rym: The the fact that the creators are unwilling to entertain solutions that end either of those things, right?

433
00:35:49,520 --> 00:35:55,445
Scott: It's like you could just make for example, you could make all of twitch just all of twitch no chat No chat.

434
00:35:55,485 --> 00:35:56,794
Scott: Why is chat have to be a thing?

435
00:35:56,814 --> 00:35:57,740
Scott: I'm just streaming.

436
00:35:57,820 --> 00:36:01,680
Scott: Why do I have to have a chat if I don't want to let people run their own discord or their own chat or something?

437
00:36:02,081 --> 00:36:04,289
Scott: That's a people on twitch would not like that.

438
00:36:04,349 --> 00:36:04,570
Scott: Okay.

439
00:36:04,590 --> 00:36:07,360
Scott: Well, you could make all chats sub only by default.

440
00:36:07,380 --> 00:36:12,360
Scott: Well, that should actually encourage people to pay because you every chat is just always sub only all the time.

441
00:36:12,400 --> 00:36:13,624
Scott: There is no public chat.

442
00:36:13,905 --> 00:36:14,848
Scott: It's sub only chat.

443
00:36:15,209 --> 00:36:19,064
Scott: You want to talk to me pay five bucks or use your prime sub right for the month.

444
00:36:19,450 --> 00:36:19,653
Scott: it's like.

445
00:36:20,860 --> 00:36:32,640
Scott: Streamers don't like that either because even though that might get some people more people to sub It would really hurt their engagement with people who have not subbed yet and getting them to sub right because they can't chat.

446
00:36:32,880 --> 00:36:37,997
Rym: Yeah, but a lot of marginalized creators reach an audience of other marginalized people who couldn't afford.

447
00:36:38,037 --> 00:36:39,061
Rym: you don't have $5.

448
00:36:39,061 --> 00:36:39,940
Rym: Yeah, exactly.

449
00:36:40,462 --> 00:36:41,244
Rym: So they don't want.

450
00:36:41,565 --> 00:36:43,492
Rym: it's kind of like with the problems with Twitter.

451
00:36:43,612 --> 00:36:50,120
Rym: as I always said the only ways To stop the mass abuse that happens on Twitter in an open platform.

452
00:36:50,301 --> 00:36:52,288
Rym: There's really only two fundamental ways you can go.

453
00:36:52,730 --> 00:36:58,921
Rym: you either make some sort of cost However small to create an account You.

454
00:36:59,062 --> 00:37:06,420
Rym: well, I guess there's three ways you have a verifiable identity required to create an account or you accept verifiable identities.

455
00:37:06,741 --> 00:37:08,970
Scott: Actually don't you know, they make it so that you can.

456
00:37:08,990 --> 00:37:14,641
Scott: they make it easier to block someone right because you've have But they don't prevent the behavior There's.

457
00:37:14,742 --> 00:37:20,580
Scott: there have been a studies that show that like yeah, most of the people on Twitter saying awful things Just have their real identities right there.

458
00:37:20,881 --> 00:37:28,203
Rym: Because if we're willing to actually follow through and like go after those people with on available bands But they're not.

459
00:37:28,745 --> 00:37:32,120
Rym: the third way to go is to do what we did with email.

460
00:37:32,502 --> 00:37:36,100
Rym: They all and I say this a lot because younger people do not appreciate this.

461
00:37:36,641 --> 00:37:52,480
Rym: The only reason email exists today and works at all is because as a society we collectively agreed that 99.99999% of all emails are vile spam and we're willing to let Lots of legitimate emails get blocked rather than see a single spam.

462
00:37:53,613 --> 00:37:55,927
Scott: Yeah The email system is like you could.

463
00:37:56,147 --> 00:38:03,700
Scott: no one can stop you from making an email server and just start sending emails to other email Servers, you know, there's absolutely nothing in the world that can stop you.

464
00:38:03,780 --> 00:38:04,162
Rym: But what?

465
00:38:04,222 --> 00:38:04,464
Rym: no one?

466
00:38:04,484 --> 00:38:07,399
Rym: all your emails if you do that at all because no one will none you.

467
00:38:08,305 --> 00:38:10,320
Scott: Yep, no one will get your emails right there neat.

468
00:38:10,440 --> 00:38:23,944
Scott: You need to pass a rigorous sort of thing before any other email server will say, okay I will allow you to email but if twitch was like you must pass a very rigorous trial before we will allow a streamer to See your chats.

469
00:38:24,467 --> 00:38:25,754
Scott: No one would pass that trial.

470
00:38:25,975 --> 00:38:29,366
Scott: They want to get users So they had to lower their barrier to entry.

471
00:38:29,707 --> 00:38:29,848
Scott: right.

472
00:38:29,888 --> 00:38:31,472
Scott: that fundamental conflict is.

473
00:38:31,512 --> 00:38:40,560
Scott: what's belying our entire all of our social networks Is that the networks want to lower the barrier to entry to get more users, but lowering the barrier to entry let's in shit

474
00:38:40,822 --> 00:38:54,329
Rym: yep, and I think with twitch in particular There are no good ways to deal with this without harming some aspect of the twitch community Culture and interaction space that people enjoy though.

475
00:38:54,350 --> 00:38:55,172
Scott: Well not harming.

476
00:38:55,212 --> 00:39:04,980
Rym: not harming by some definitions way that drastically Drastically altered in a way that a huge percentage of twitch users would dislike.

477
00:39:06,124 --> 00:39:07,272
Scott: and yeah, probably.

478
00:39:07,574 --> 00:39:25,657
Rym: but I think the Avenue of least pain and harm would be for twitch to provide one provide actual effective moderation tools which all platforms are avoiding like something so simple as building block chains and shared block lists into the platform directly.

479
00:39:25,678 --> 00:39:34,877
Scott: Twitter Blockchain like Bitcoin blockchain as like everyone that I've everyone that I've blocked and everyone that you've blocked are now blocked on both of us.

480
00:39:34,997 --> 00:39:45,760
Rym: automatically then marginalized creators could band together and share a gigantic block list that would automatically update and Honestly solve a huge percentage of this problem that Twitter.

481
00:39:46,041 --> 00:39:47,546
Scott: But why do they even have to do that?

482
00:39:47,627 --> 00:39:50,878
Scott: The moderation should come from the platform itself.

483
00:39:51,059 --> 00:39:53,043
Rym: No Band that.

484
00:39:53,765 --> 00:39:57,898
Scott: if someone's banned from all these channels, why aren't they just banned from all of twitch forever?

485
00:39:57,959 --> 00:40:01,730
Scott: Yeah, right It's if the hundred people block some shithead on Twitter.

486
00:40:01,770 --> 00:40:04,460
Scott: Why is their Twitter account still allowed to continue existing up?

487
00:40:04,680 --> 00:40:10,420
Rym: Why are Republican politicians who say literal lies about kovat still allowed to tweet like it's the same exactly?

488
00:40:11,264 --> 00:40:14,440
Scott: The platform is should be responsible for the mud not you know.

489
00:40:14,520 --> 00:40:19,439
Scott: The user shouldn't have to sit there right there and moderate and to do all this stuff.

490
00:40:20,582 --> 00:40:22,008
Scott: It's you know, it's not their job.

491
00:40:22,049 --> 00:40:24,340
Scott: they're there to watch streams or to stream.

492
00:40:24,761 --> 00:40:29,056
Scott: They shouldn't have to be responsible for keeping racists and bots out of their chat.

493
00:40:29,096 --> 00:40:30,020
Scott: Why is that their job?

494
00:40:31,180 --> 00:40:48,220
Rym: yep, so twitch bears 100% of the blame for allowing this to happen because There are simple things twitch could have done or could still do that would not solve this but would have drastically Reduce this or even prevented the scale that is now occurring.

495
00:40:48,602 --> 00:40:56,172
Rym: This is only gonna get worse and I have no confidence that twitch is gonna do anything Substantial to address it in the first anyway future.

496
00:40:56,634 --> 00:41:13,608
Scott: But anyway on September 1st The all of these people who are you know, not happy about twitch not doing anything about this, you know racist raid problem Yeah are going to basically do a one-day twitch, you know One day twitch, I guess boycott right?

497
00:41:13,668 --> 00:41:14,430
Scott: No streaming.

498
00:41:14,631 --> 00:41:16,196
Scott: Yeah, no watching twitch.

499
00:41:16,236 --> 00:41:21,351
Scott: don't cross the picket line Alright, so in September 1st, don't go to twitch.com.

500
00:41:21,411 --> 00:41:22,775
Scott: Don't do any twitch anything.

501
00:41:22,835 --> 00:41:26,165
Scott: Don't even watch like a VOD Right don't watch a clip.

502
00:41:26,586 --> 00:41:28,873
Scott: don't do anything on September 1st.

503
00:41:28,933 --> 00:41:39,183
Scott: No twitch streaming or watching whatsoever things Of the day.

504
00:41:39,203 --> 00:41:39,750
Rym: What do you got?

505
00:41:40,770 --> 00:41:49,662
Scott: So you go to the hardware store, right and such a simple thing You see like a big old piece of plywood right like a big flat piece of wood Right and every time in my life.

506
00:41:49,723 --> 00:41:56,901
Scott: I saw such a piece of wood You know, I thought to myself for a second like man That obviously didn't come from a tree.

507
00:41:57,183 --> 00:42:04,864
Rym: That was eight feet wide Right Where pieces of wood that big did in fact come?

508
00:42:04,884 --> 00:42:05,005
Rym: from?

509
00:42:05,046 --> 00:42:05,629
Rym: a tree that pig.

510
00:42:06,632 --> 00:42:08,005
Scott: Sure, that time is not now.

511
00:42:08,086 --> 00:42:10,457
Scott: Nope And you know, how did that?

512
00:42:10,538 --> 00:42:12,690
Scott: how did that piece of wood come to be right?

513
00:42:12,830 --> 00:42:14,557
Scott: Was it you know a particle board?

514
00:42:14,598 --> 00:42:15,361
Scott: I understand right?

515
00:42:15,381 --> 00:42:17,670
Scott: You can just get like wood chips and like compress them together.

516
00:42:17,730 --> 00:42:20,190
Scott: You know with glue or something right up a particle board sucks.

517
00:42:21,193 --> 00:42:25,316
Scott: It sucks ass but plywood doesn't suck is right And it's just sort of like.

518
00:42:25,356 --> 00:42:26,885
Scott: hey, how did that fuck?

519
00:42:26,905 --> 00:42:27,830
Scott: did they make that right?

520
00:42:28,070 --> 00:42:32,510
Scott: What you know what was going on at the lumber mill that produced that eight feet wide piece of wood?

521
00:42:33,370 --> 00:42:48,330
Scott: well Finally somehow I remembered to google that And on YouTube I found a video and the answer to the question of hey How did just some fucking logs that are about the size of like telephone poles end up as you know?

522
00:42:48,610 --> 00:42:50,014
Scott: Ultra wide pieces of wood?

523
00:42:50,235 --> 00:42:53,283
Scott: the answer is about at the three-minute mark a very ingenious device.

524
00:42:53,644 --> 00:42:55,570
Scott: That was so simple and so obvious.

525
00:42:56,453 --> 00:42:59,143
Scott: Why did I not just think of imagine that on my own?

526
00:42:59,183 --> 00:43:01,110
Scott: but no at the three around the three-minute mark?

527
00:43:01,250 --> 00:43:03,424
Scott: I saw the machine and I said, oh, that's how they fucking do it.

528
00:43:03,786 --> 00:43:04,289
Scott: God damn it.

529
00:43:04,554 --> 00:43:07,134
Scott: Yeah Why did I think of that?

530
00:43:07,294 --> 00:43:13,486
Rym: So I find as I older I increasingly enjoy learning how very simple things that you don't think about are done.

531
00:43:14,332 --> 00:43:20,010
Scott: Yeah, but also this video shows everything from literal tree with bark on it up to delivering.

532
00:43:20,030 --> 00:43:22,190
Rym: Oh, yeah barkers like the first part of the video.

533
00:43:22,970 --> 00:43:29,550
Scott: Yeah, it shows you everything from tree all the way to piece of wood that's on its way to the hardware store already packaged.

534
00:43:29,932 --> 00:43:31,282
Scott: so it's pretty fascinating.

535
00:43:31,322 --> 00:43:36,708
Scott: all the other steps and Things that go on in the the lumber mill of you know, a modern lumber mill.

536
00:43:36,909 --> 00:43:38,633
Scott: so Check it out.

537
00:43:39,236 --> 00:43:40,200
Rym: So check this out.

538
00:43:40,461 --> 00:43:48,306
Rym: This is if this were something that was for sale It's it's in the same category as that the game and watch that you got the Nintendo one.

539
00:43:48,687 --> 00:43:50,522
Rym: if this was for sale I would just buy it.

540
00:43:51,311 --> 00:43:56,369
Rym: Supposedly instructions for making one are coming soon from the creator and I think I'm gonna make one.

541
00:43:57,091 --> 00:44:03,310
Rym: It's this tiny little TV and it is 3d printed to look exactly like the TV from The Simpsons the original one.

542
00:44:03,390 --> 00:44:04,455
Rym: Okay, it's got two little.

543
00:44:04,475 --> 00:44:04,757
Rym: and then what?

544
00:44:04,777 --> 00:44:06,786
Scott: you take a little LCD screen and stick it in there.

545
00:44:06,807 --> 00:44:12,629
Rym: So It has a tiny little computer in it a 640 bar for a Raspberry Pi a Raspberry Pi.

546
00:44:12,649 --> 00:44:18,730
Rym: Yeah It has d card on it And basically it has of one of the dot the knob on the bottom with the volume slider.

547
00:44:19,232 --> 00:44:21,564
Rym: It has the speaker in it and the knob on the top.

548
00:44:21,685 --> 00:44:30,550
Rym: if you turn it on It'll start playing a random Simpsons episode from the first 11 seasons and if you try it could be it could play anything.

549
00:44:30,691 --> 00:44:32,221
Scott: But they chose to put the first 11.

550
00:44:32,221 --> 00:44:35,354
Rym: Oh, yes, but I'm saying they The the.

551
00:44:35,394 --> 00:44:42,236
Rym: what I like about this device is this is the exact kind of neat social currency Slash desk toy that I love.

552
00:44:42,677 --> 00:44:50,987
Rym: it's like an advanced form of that game and watch just flick the little switch and a tiny TV Is just playing a random episode from the good run of The Simpsons.

553
00:44:51,248 --> 00:44:51,630
Scott: turn it off.

554
00:44:52,172 --> 00:44:55,790
Scott: Nothing stops you from putting in any essay later in there or anything else that you know.

555
00:44:56,211 --> 00:45:07,290
Rym: But I like the idea that it just plays The Simpsons and I really love the fact that when this when this person made it They literally just compressed 11 seasons of The Simpsons and just stuck them on there.

556
00:45:07,370 --> 00:45:08,013
Rym: And that's the only.

557
00:45:08,073 --> 00:45:09,900
Scott: don't really have to compress them.

558
00:45:09,960 --> 00:45:15,396
Scott: You could just put full-on, you know, mp4 H.264 videos in 1080p.

559
00:45:15,416 --> 00:45:17,061
Rym: Well, they fit they have they fit 11.

560
00:45:17,061 --> 00:45:25,239
Rym: So 11 seasons times the number of episodes a season of Roughly 640 by 480 video though.

561
00:45:25,419 --> 00:45:30,357
Scott: It's probably I feel like you could fit the entire run of The Simpsons Just everything on a micro SD card.

562
00:45:30,478 --> 00:45:36,730
Scott: Oh probably but I guess since you're since it's an art piece You probably only want the 4 by 3, you know episodes.

563
00:45:36,790 --> 00:45:38,336
Scott: You don't want the 16 by 9 one.

564
00:45:38,457 --> 00:45:39,702
Rym: and also because there's an art piece.

565
00:45:39,722 --> 00:45:41,469
Rym: You probably only want the first 11 seasons.

566
00:45:43,133 --> 00:45:52,917
Scott: Let's be clear about that As your screen is also probably not 16 by 9, you know what I would say, I think it's neat Good idea in the meta moment.

567
00:45:53,138 --> 00:46:08,848
Rym: We will not be at PAX West 2021. in case you were wondering I feel like we have to announce that a few times because Most of the people who see us at cons don't bother going to our website and seem to watch our YouTube channel more than listen To the podcast itself, but we will not be there.

568
00:46:09,951 --> 00:46:15,190
Rym: It is too soon for me to cram myself into a building with tens of thousands of nerds indoors.

569
00:46:16,510 --> 00:46:19,359
Rym: So we're not gonna be the first packs in the u.s.

570
00:46:19,500 --> 00:46:23,791
Rym: We've skipped since our first packs in 2008.

571
00:46:23,791 --> 00:46:26,302
Rym: It's weird that there will be a packs that I am NOT at.

572
00:46:26,423 --> 00:46:27,950
Rym: I even went to the first two PAX Australia's.

573
00:46:28,570 --> 00:46:38,468
Scott: So that's right Cuz even if I went and you know the even if I was you know We're willing to take the risk of getting a horrible disease, which I'm not Or giving it to someone else, which I'm not.

574
00:46:39,571 --> 00:46:47,369
Scott: It feels like because of the horrible disease the packs itself will be greatly diminished and not worth paying the money to fly across the entire country to go to.

575
00:46:48,310 --> 00:46:52,985
Scott: so if I lived in Seattle, there might be some amount of consideration.

576
00:46:53,026 --> 00:46:56,055
Scott: probably still wouldn't go but Chances of going would be higher.

577
00:46:56,677 --> 00:46:57,921
Rym: Yep, so we will not be there.

578
00:46:58,563 --> 00:47:02,576
Rym: our panel from the last PAX East online Can't packs Atari game design.

579
00:47:02,937 --> 00:47:03,680
Rym: It's just on YouTube.

580
00:47:03,860 --> 00:47:06,068
Rym: You can just watch it slides everything.

581
00:47:06,108 --> 00:47:06,550
Rym: It's all there.

582
00:47:07,172 --> 00:47:09,985
Rym: We're still reading the tale of Genji powered red.

583
00:47:10,045 --> 00:47:11,070
Scott: I read a bunch of the beach.

584
00:47:11,110 --> 00:47:14,150
Rym: Yeah, I think by the end of September we can do this show October at the latest.

585
00:47:14,752 --> 00:47:15,777
Scott: You said August last?

586
00:47:16,239 --> 00:47:16,399
Rym: Yeah.

587
00:47:16,420 --> 00:47:18,408
Scott: Well, then the end of August is in a week.

588
00:47:18,709 --> 00:47:20,797
Rym: Yep Well, I'll be I'll be more.

589
00:47:20,818 --> 00:47:23,629
Rym: I'll be past the halfway point in the next week at the rate.

590
00:47:23,669 --> 00:47:24,010
Rym: I'm going.

591
00:47:25,443 --> 00:47:30,570
Rym: but Some notes, you know, cuz I've said the same thing about the book a few times along the way.

592
00:47:30,691 --> 00:47:36,408
Rym: So to be a little more specific There were more ghost murders than I expected in the tale of Genji.

593
00:47:36,669 --> 00:47:37,533
Scott: ghosts It's also.

594
00:47:37,553 --> 00:47:41,249
Scott: there's also, you know more Hamlet style goes coming to talk.

595
00:47:41,711 --> 00:47:46,890
Rym: Yep, ghosts played more of a factor than I expected from the tale of Genji and I'm here for that.

596
00:47:47,662 --> 00:47:51,062
Rym: I also Did not expect on a modern reading like again.

597
00:47:51,142 --> 00:48:03,418
Rym: as you get further into the book and you think back to Who's sick when and what they complain about being sick with it's clear that half the characters in this fucking book literally have malaria Mmm, like specifically malaria or

598
00:48:03,459 --> 00:48:11,430
Scott: be just be well, yeah, I mean there are people who have malaria, but there's also Just because it's such an old time before modern medicine people are sick a lot.

599
00:48:11,490 --> 00:48:14,501
Scott: So it's true to you know, it's true to life in that sense.

600
00:48:15,123 --> 00:48:16,247
Rym: So we'll get right into it.

601
00:48:17,613 --> 00:48:19,179
Rym: We're gonna talk about the Apple thing.

602
00:48:19,260 --> 00:48:20,987
Rym: that has honestly.

603
00:48:21,208 --> 00:48:24,317
Rym: interestingly I have a very mixed and ambivalent opinion on this.

604
00:48:24,698 --> 00:48:33,761
Rym: but the people in technology spaces that I know professionally or that I follow drastically out Like I know some I know of some.

605
00:48:33,901 --> 00:48:39,824
Rym: these are some people I know and I've talked to about this and they're also People I just follow because I respect like Lawrence Lessig.

606
00:48:39,844 --> 00:48:42,234
Rym: I respect like there's people I respect Yeah, they're.

607
00:48:42,314 --> 00:48:44,564
Rym: all of them are pretty much 50/50 on this issue.

608
00:48:44,584 --> 00:48:59,267
Rym: half of them are Demanding that Apple not do this extremely afraid of the negative consequences and the other half of them are basically arguing It's not really that much different from what everyone else is doing and we don't really care that much.

609
00:48:59,749 --> 00:49:02,399
Rym: So This is authority issue.

610
00:49:02,640 --> 00:49:05,069
Scott: I'm pretty much seeing only outrage from everyone except me.

611
00:49:05,830 --> 00:49:14,184
Rym: I've seen a number of privacy advocates argue that it's not a big deal Mostly citing the fact that pretty much every other platform already does this.

612
00:49:14,384 --> 00:49:16,170
Scott: So let's explain what's going on.

613
00:49:16,250 --> 00:49:20,670
Scott: Yeah, so first of all, so what Apple is doing is they're doing three things, right?

614
00:49:20,810 --> 00:49:33,750
Scott: The second and I'm gonna do them in a different date they explain them in this page on their website Apple comm slash child - safety and I'll talk about the two not so exciting ones first and then the big deal one last even though on the website the big deal.

615
00:49:34,872 --> 00:49:36,599
Scott: So the first one is there.

616
00:49:36,699 --> 00:49:53,390
Scott: it's called Apple calls it communication safety in messages And basically what it is is if you are a child and you have an iPhone that's hooked up to your parents iPhone But the parental protections and everything in which case your parents can already just unlock your phone and see everything is going on in There anyway, right?

617
00:49:55,056 --> 00:49:57,346
Scott: Your entire Apple stuff is beholden to your parents.

618
00:49:57,446 --> 00:50:02,529
Scott: if that is the case So It's not really a change from that.

619
00:50:02,991 --> 00:50:07,988
Scott: But what the system they have added does is it allows the parents to you know?

620
00:50:08,470 --> 00:50:22,249
Scott: Enable a thing where it'll be enabled by default and I guess you could disable it if you really want to but basically use machine Learning to see if the child has received or sent a photo that very likely has nakedness in it.

621
00:50:23,491 --> 00:50:24,214
Scott: Right which?

622
00:50:24,254 --> 00:50:32,130
Scott: and if a child is getting it is either a child looking at porn They shouldn't be or a child sending child porn of themselves usually, right?

623
00:50:32,671 --> 00:50:36,888
Scott: Yeah, which shouldn't be and all it does is it will blur it to.

624
00:50:37,149 --> 00:50:40,202
Scott: you know Make it so the child can't doesn't see it immediately.

625
00:50:40,443 --> 00:50:42,170
Scott: So someone sends a dick pic to your kid.

626
00:50:42,210 --> 00:50:45,226
Scott: They don't just immediately see the dick or your dick pic to someone.

627
00:50:46,030 --> 00:50:50,150
Scott: They know they'll get a blurry image and like a warning like are you sure you want to see this?

628
00:50:50,330 --> 00:50:53,890
Scott: Which I think is a feature that you just enable for everybody like hey, someone sent you a photo.

629
00:50:53,950 --> 00:50:54,814
Scott: That's probably a dick.

630
00:50:54,875 --> 00:50:55,860
Scott: Are you sure you want to see it?

631
00:50:55,900 --> 00:50:56,121
Scott: Yes.

632
00:50:56,201 --> 00:50:58,010
Scott: No, why is that for kids only?

633
00:50:58,150 --> 00:50:58,431
Scott: That's just me.

634
00:50:58,452 --> 00:51:02,150
Scott: for everybody if they want to enable that that should be enabled by default.

635
00:51:03,450 --> 00:51:10,169
Scott: Regardless, it'll tell the parent like hey your kid You know got a message that might be naked.

636
00:51:11,011 --> 00:51:14,986
Scott: Letting you know right and I don't really see the problem.

637
00:51:15,046 --> 00:51:17,369
Scott: I don't see this as a problem It's just a helpful thing.

638
00:51:17,791 --> 00:51:22,104
Scott: That's not any different because parents already effectively have complete control of their children's phones.

639
00:51:22,425 --> 00:51:24,110
Scott: that they're paying that the adults are paying for.

640
00:51:24,892 --> 00:51:26,398
Rym: So one avenue.

641
00:51:26,478 --> 00:51:40,688
Rym: I see that these the chatter I saw on that was primarily around young under 18 still under their parents control children who have conservative religious parents who don't approve of their sexuality or lifestyle.

642
00:51:40,709 --> 00:51:47,430
Rym: and Yep, this was one of the few truly encrypted avenues they would have to communicate with people.

643
00:51:48,012 --> 00:51:52,930
Scott: Well a as I said that I completely agree with what you just said.

644
00:51:53,070 --> 00:51:59,204
Scott: But the parents already had complete control of the phones because that their kids phone is not the parent It's the parents phone that the kid is using.

645
00:51:59,224 --> 00:52:03,850
Scott: with the parental controls The parents could already just I assume just unlock the kids phone and see whatever.

646
00:52:03,991 --> 00:52:05,239
Rym: I think in that case we need to.

647
00:52:05,279 --> 00:52:14,590
Rym: we need more of the old awareness Awareness campaigns that used to happen in the 90s among nerds Around how to do encryption when you don't trust the devices and how to do encryption.

648
00:52:14,710 --> 00:52:17,540
Rym: Yes, now that is difficult and that will require some work.

649
00:52:17,921 --> 00:52:24,788
Rym: like you can almost make a nonprofit around teaching Especially marginalized kids how to use encryption that is platform agnostic.

650
00:52:25,672 --> 00:52:29,350
Rym: So I think there are effective ways around that for kids who need it, right?

651
00:52:29,410 --> 00:52:32,405
Scott: But also Apple has informed everyone of this.

652
00:52:32,466 --> 00:52:33,310
Scott: This isn't a secret.

653
00:52:33,510 --> 00:52:42,569
Scott: So there I don't know if a kid is in that situation and afraid of their parents finding out their Sexuality because their parents are pieces of shit.

654
00:52:43,212 --> 00:52:47,049
Scott: You're just not going to be sending any of that stuff on your iMessage now.

655
00:52:47,331 --> 00:52:50,369
Scott: You'll find another way to send it if you're gonna send it at all.

656
00:52:50,971 --> 00:52:52,195
Scott: Because you know about this.

657
00:52:52,275 --> 00:52:53,359
Scott: Apple told you that it's there.

658
00:52:53,399 --> 00:52:54,643
Scott: It's not like surprise.

659
00:52:54,703 --> 00:52:57,010
Scott: We told you we told your parents that you're gay.

660
00:52:58,334 --> 00:52:58,843
Scott: It's you know.

661
00:53:00,019 --> 00:53:01,734
Scott: so It could be.

662
00:53:01,754 --> 00:53:03,421
Scott: it could cause a problem for somebody.

663
00:53:03,482 --> 00:53:05,974
Scott: I guess it was unaware or something But I don't.

664
00:53:06,437 --> 00:53:10,854
Scott: I'm not too worried about that You know given that everyone knows.

665
00:53:10,894 --> 00:53:12,297
Scott: they just announced it to the world.

666
00:53:12,998 --> 00:53:15,391
Scott: All right, the second thing Really?

667
00:53:15,452 --> 00:53:17,718
Scott: Not a big deal at all barely even worth mentioning.

668
00:53:18,179 --> 00:53:22,330
Scott: is that if you go to Siri or search on your phone?

669
00:53:24,551 --> 00:53:30,989
Scott: If you try to search for see Sam, which I guess is the new term for instead of saying child porn You're supposed to say see Sam.

670
00:53:32,052 --> 00:53:34,343
Rym: So it's the child sexual abuse material.

671
00:53:34,484 --> 00:53:37,172
Rym: It usually refers to Databases.

672
00:53:37,393 --> 00:53:40,421
Rym: governments maintain there's a the whole this to get a whole thing on this.

673
00:53:40,983 --> 00:54:02,210
Rym: but basically law enforcement agencies maintain Databases of all the child porn that's ever been uncovered Partly to help study it to identify victims to find victims who have not been helped yet like traffic kids and Also to be able to identify it when someone else is found to be distributing it.

674
00:54:02,391 --> 00:54:10,610
Scott: There's a lot of reasons why these databases exist Sure, but child sexual abuse material is just like the phrase that you know, they're using instead of saying out for it.

675
00:54:10,750 --> 00:54:16,010
Scott: So there are databases that because I guess they like that term better because it's more specific, right?

676
00:54:16,210 --> 00:54:16,290
Scott: It's.

677
00:54:16,652 --> 00:54:33,599
Rym: but it's also more generic and that it covers all the different Ways like all the kinds of material that could be abusive in this manner Sure, but anyway if you try to search for a child sexual abuse material On your iPhone or as Siri about it, right?

678
00:54:33,679 --> 00:54:37,450
Scott: It is now going to give you better help in in those regards.

679
00:54:38,475 --> 00:54:41,109
Scott: So that's I guess only positive, right?

680
00:54:42,552 --> 00:54:46,270
Scott: So the big thing that Apple's doing right is the see Sam detection.

681
00:54:46,831 --> 00:54:49,799
Scott: So first of all, let's talk about how it works.

682
00:54:49,879 --> 00:54:56,578
Scott: The way it works is this you have some photos on your phone And not only do you have photos on your phone?

683
00:54:56,979 --> 00:54:59,248
Scott: You have enabled iCloud photo.

684
00:54:59,268 --> 00:54:59,890
Scott: You're not right.

685
00:55:00,070 --> 00:55:06,570
Scott: So that's probably by default on most iPhones, but you could disable it if you wanted to but you have iCloud photo enabled.

686
00:55:07,234 --> 00:55:09,770
Scott: What they're gonna do is on your phone.

687
00:55:10,551 --> 00:55:13,263
Scott: It's going to take hashes of all your photos.

688
00:55:13,303 --> 00:55:14,930
Scott: It's not going to share your photos with Apple.

689
00:55:15,091 --> 00:55:18,250
Scott: No one will see the picture of your birthday cake, right?

690
00:55:18,470 --> 00:55:20,236
Scott: They're just gonna see a number and they'll have.

691
00:55:20,316 --> 00:55:25,635
Scott: no I there'll be no mathematical way to figure out what fucking photo that number came from.

692
00:55:25,816 --> 00:55:26,639
Scott: just like no way.

693
00:55:26,799 --> 00:55:32,749
Scott: it's impossible mathematically impossible, but They have a database of child porn, right?

694
00:55:33,650 --> 00:55:36,867
Scott: Because the government has it and what they'll do is they'll see huh?

695
00:55:37,910 --> 00:55:42,706
Scott: Did any of the numbers on any of your photos match any of this?

696
00:55:43,047 --> 00:55:43,850
Scott: see Sam, right?

697
00:55:44,191 --> 00:55:47,190
Scott: That's not so try not to say child porn now because they told me not to right.

698
00:55:47,371 --> 00:55:52,027
Scott: We have these numbers from photos of see Sam and we have the numbers from your photos.

699
00:55:52,067 --> 00:55:59,803
Scott: if there's any matches It is mathematically Extremely likely that you have that shit on your phone.

700
00:56:00,004 --> 00:56:03,661
Scott: It would be almost impossible For you to have a photo.

701
00:56:03,983 --> 00:56:11,370
Scott: not absolutely impossible But almost impossible for you to have a photo on your phone and have the hash produced from that photo match.

702
00:56:11,774 --> 00:56:13,169
Scott: One of the hash is in that database.

703
00:56:13,954 --> 00:56:17,290
Scott: Right and even if there is some kind of match, right?

704
00:56:17,650 --> 00:56:22,356
Scott: They've set up this whole system to where like yeah Apple's computers are doing this part.

705
00:56:22,757 --> 00:56:24,784
Scott: someone else's computers are doing this part.

706
00:56:25,045 --> 00:56:27,272
Scott: humans are looking at this part Right.

707
00:56:27,553 --> 00:56:39,007
Scott: for it to actually reach the point at which you're in trouble because of this It would have to be like, you know almost guaranteed that like yeah, you got that shit on your phone.

708
00:56:39,027 --> 00:56:39,589
Scott: what's wrong with you?

709
00:56:41,271 --> 00:56:44,600
Scott: So I'm really confident there aren't gonna be false positives.

710
00:56:44,660 --> 00:56:46,706
Scott: So what are people worried about?

711
00:56:46,826 --> 00:56:52,590
Scott: Well, people are worried not at This technology here itself, right?

712
00:56:53,932 --> 00:56:55,015
Scott: What's actually happening?

713
00:56:55,095 --> 00:56:58,184
Scott: They are worried about these slippery slope, right?

714
00:56:58,224 --> 00:57:07,987
Scott: Cuz once this system is in place For example just to make something up Apple could take an image of I don't know

715
00:57:08,147 --> 00:57:10,709
Rym: leaked Apple product design, let's say

716
00:57:11,532 --> 00:57:28,857
Scott: Sure, right an iPhone 13 and then they could be like well now, you know We add the hash we add that number of this photo of the iPhone 15 to our database and if anyone out there has a photo of an iPhone 15 on their iPhone Well, we know that they're a leaker, right?

717
00:57:29,238 --> 00:57:32,930
Scott: They could add, you know, they could apply this to things besides photos.

718
00:57:33,412 --> 00:57:37,509
Scott: Right because it's happening locally on your phone where decrypted things could be.

719
00:57:38,192 --> 00:57:40,241
Scott: So your decrypted iMessages right.

720
00:57:40,301 --> 00:57:52,198
Scott: Apple doesn't see your iMessages when they're in transit but if they could look at your iMessages and They could be like, yeah, what's the hash of the message that says, you know I hate the president right event?

721
00:57:52,338 --> 00:57:55,990
Scott: or if anyone has a text message as I hate the president, right?

722
00:57:56,150 --> 00:58:00,305
Scott: They could detect that specifically right without you know, because they've got.

723
00:58:00,566 --> 00:58:01,570
Scott: they don't have the messages.

724
00:58:01,651 --> 00:58:07,244
Scott: They're not seeing your messages but they have hash representations of all your messages so they can sort.

725
00:58:07,285 --> 00:58:16,070
Rym: what they can do is they can just Take messages and search for them specifically take a new message generate the hash for that message and see if anyone sent that message.

726
00:58:16,693 --> 00:58:17,900
Scott: Yeah, did anyone say this?

727
00:58:18,263 --> 00:58:19,450
Scott: Oh, we caught you, right?

728
00:58:20,150 --> 00:58:31,497
Rym: So well, so this actually gets a little bit worse in in the US in particular And I've seen a few security researchers make this point about the US federal government and gag orders national security letters.

729
00:58:31,979 --> 00:58:46,039
Rym: the US government could in theory and Has done this in the past with other platforms and technologies say I have a technology platform with end-to-end encryption and I do not have a Mechanism to decrypt that information like built-in.

730
00:58:46,461 --> 00:58:49,534
Rym: the government cannot force me to build new technology Like.

731
00:58:49,554 --> 00:58:52,249
Rym: that is not something they can do with an NSA letter or an NSA.

732
00:58:52,611 --> 00:58:58,626
Rym: They can't be like you are hereby order to build this technology for us like that That they would have to make a government contract to do that.

733
00:58:58,847 --> 00:58:59,089
Rym: Why?

734
00:59:00,210 --> 00:59:01,569
Scott: Pay it do and you have to agree to do it.

735
00:59:01,610 --> 00:59:02,494
Rym: But if Apple?

736
00:59:02,574 --> 00:59:08,270
Rym: if it is no now that Apple has this specific capability It is eminently plausible.

737
00:59:08,370 --> 00:59:18,838
Rym: the US federal government could issue a national security letter with a gag order to Apple saying add these hashes to Your list and inform us if anything hits.

738
00:59:19,179 --> 00:59:26,805
Rym: we will not tell you what the hashes are for and you under penalty of law Cannot inform anyone that you have added these hashes, right?

739
00:59:26,986 --> 00:59:27,970
Scott: They could fight it in court.

740
00:59:28,030 --> 00:59:31,690
Rym: But oh, they can fight that in a secretly a special secret court.

741
00:59:31,810 --> 00:59:32,974
Scott: Yes, guess what?

742
00:59:33,014 --> 00:59:33,957
Scott: probably are there?

743
00:59:33,997 --> 00:59:38,089
Scott: probably are many such fights happening in secret courts all the time that we don't know anything about.

744
00:59:38,189 --> 00:59:39,238
Rym: guess What you know.

745
00:59:39,258 --> 00:59:40,409
Rym: why you don't find out about those.

746
00:59:40,731 --> 00:59:45,930
Scott: Nobody ever wins their cases because they're all you wouldn't find out even if they did win because it happened in secret court.

747
00:59:45,990 --> 00:59:56,885
Rym: Yep, but the specific danger is that by having the capability they've opened themselves up to the government issuing a directive like that in a Way that if they don't have the capability the government can't force them to build it.

748
00:59:57,306 --> 01:00:03,049
Rym: That seems to be Primary Concern among the people I see who are the maddest about this.

749
01:00:03,934 --> 01:00:05,481
Scott: Sure, it is a true.

750
01:00:05,723 --> 01:00:06,647
Scott: That is a true concern.

751
01:00:06,688 --> 01:00:13,330
Scott: Yes So but yeah, that is pretty much like the only concern, right?

752
01:00:13,350 --> 01:00:16,590
Scott: It's like if Apple you know, cuz it's really a slippery slope thing, right?

753
01:00:16,690 --> 01:00:27,015
Scott: It's like you're building this system But all of the negatives that everyone comes up with whether they're plausible ones like the one you just said right or any others They're all ifs.

754
01:00:27,517 --> 01:00:30,368
Scott: it's like every single negative that anyone has come up with.

755
01:00:30,488 --> 01:00:30,870
Rym: that's true.

756
01:00:30,930 --> 01:00:32,237
Rym: But is it is a?

757
01:00:32,719 --> 01:00:32,960
Scott: is a?

758
01:00:33,061 --> 01:00:34,970
Scott: this negative could happen?

759
01:00:35,110 --> 01:00:40,902
Rym: There's one important danger of the other thing I brought up though in that There's no way to ever know if the if have.

760
01:00:40,922 --> 01:00:42,308
Scott: there is no way to know.

761
01:00:42,388 --> 01:00:45,018
Rym: that is We could find out if they happen.

762
01:00:45,038 --> 01:00:45,541
Rym: That's the one.

763
01:00:45,661 --> 01:00:50,519
Scott: if there's literally no way to know There's also no evidence that the thing did happen.

764
01:00:50,559 --> 01:00:54,210
Rym: But again there but there is evidence that the thing has happened on every other platform.

765
01:00:55,631 --> 01:00:55,993
Scott: That's true.

766
01:00:56,114 --> 01:00:59,029
Rym: so you think in that it did not have capabilities like this.

767
01:01:00,170 --> 01:01:05,286
Scott: It's Apple does, you know, right and that is a good point in Apple's favor right.

768
01:01:05,386 --> 01:01:08,798
Scott: Apple has always Said hey, look, we're not here.

769
01:01:08,818 --> 01:01:12,250
Scott: You know, we're the most privacy conscious of all your options, right?

770
01:01:12,330 --> 01:01:14,689
Scott: We're here to sell you the product for a large amount of money.

771
01:01:15,071 --> 01:01:16,376
Scott: You aren't the product right.

772
01:01:16,416 --> 01:01:20,130
Scott: the prod, you know, like you are with all those people who give you stuff for free like Google.

773
01:01:20,673 --> 01:01:23,649
Scott: Right, it's like everyone else is already doing this.

774
01:01:24,132 --> 01:01:29,348
Scott: Right, if they some of them might be telling you they do it Some of them might not be telling you they do it.

775
01:01:29,751 --> 01:01:32,883
Scott: Some of them might be doing it way worse than like Google doesn't we know?

776
01:01:32,923 --> 01:01:33,485
Rym: Google does it?

777
01:01:33,505 --> 01:01:34,810
Rym: they publish information about?

778
01:01:35,070 --> 01:01:39,650
Rym: Statistics of like things how many things they take down and how many violations?

779
01:01:40,430 --> 01:01:43,099
Rym: Looks like Google in the Latin.

780
01:01:43,280 --> 01:01:55,850
Rym: in 2020 Google disabled almost a hundred thousand accounts because CSAM material was identified mm-hmm, so 210,000 URLs were de-indexed because they included CSAM material.

781
01:01:56,554 --> 01:01:57,541
Rym: I think the difference is.

782
01:01:57,601 --> 01:02:02,981
Rym: the difference is and again I have not audited the specifics of how every different company implements this stuff.

783
01:02:03,363 --> 01:02:09,299
Rym: The difference is that all these other platforms are Inspecting unencrypted content that they have access to.

784
01:02:09,359 --> 01:02:12,590
Rym: is that a store that they have encrypted on behalf of a user?

785
01:02:13,032 --> 01:02:21,870
Rym: This is the first time an end-to-end encrypted thing itself is Inspecting Personal content not shared content and not content.

786
01:02:21,970 --> 01:02:25,502
Scott: I don't think the iCloud photos are truly end-to-end encrypted.

787
01:02:25,542 --> 01:02:30,182
Scott: the way I message or like, you know in such is I'm not actually a hundred percent sure myself because I don't have an app.

788
01:02:30,222 --> 01:02:33,974
Scott: I'm pretty sure it's just You know, I don't think it's.

789
01:02:34,075 --> 01:02:35,580
Scott: it's fully end-to-end encrypted.

790
01:02:35,600 --> 01:02:38,110
Scott: there's a point at which Apple can see your your photos.

791
01:02:38,351 --> 01:02:41,606
Rym: So there's a fascinating article on the Washington Post that I did.

792
01:02:41,666 --> 01:02:42,570
Rym: it was it was published today.

793
01:02:43,454 --> 01:02:45,188
Rym: Oh No, it's published a couple days ago.

794
01:02:45,514 --> 01:02:46,389
Rym: I just saw it today.

795
01:02:46,891 --> 01:02:54,972
Rym: but it's some researchers who built a very similar system to do almost the exact same thing and Effectively.

796
01:02:55,032 --> 01:02:56,397
Rym: how they canceled it because it was.

797
01:02:56,477 --> 01:02:59,366
Rym: they decided it was too dangerous based on what they discovered.

798
01:02:59,406 --> 01:03:05,220
Rym: building such a platform Too easily abused you get I'm gonna leave easily abused.

799
01:03:05,260 --> 01:03:05,581
Scott: Yes.

800
01:03:05,681 --> 01:03:43,638
Rym: Yep, because like I said, I have a complex and Somewhat ambivalent opinion on this in that on one hand I would argue that if you truly truly care about Powerful end-to-end encryption where you need to protect yourself from state-sponsored actors which includes the US government because the US government is the primary entity that could issue a Security letter and leverage this technology from al-fizan's you need to be doing what we talked about the beginning of the show and have Actual end-to-end encryption that is platform agnostic that you yourself are managing using their own technology,

801
01:03:43,658 --> 01:03:43,858
Scott: right?

802
01:03:44,298 --> 01:03:50,484
Scott: You should be using your own platforms Like right your own hardware your own software.

803
01:03:50,524 --> 01:04:00,910
Scott: if you're using anything Right run by some other provider at all Even if they're promising or verifying, you know giving you some sort of encryption like iMessages.

804
01:04:01,534 --> 01:04:03,063
Scott: It's like you can't bet.

805
01:04:03,123 --> 01:04:03,969
Scott: you can't trust that.

806
01:04:05,411 --> 01:04:10,124
Scott: Right, if you really need the privacy run your own Linux server in your house.

807
01:04:10,645 --> 01:04:15,200
Scott: get make your own phone Get some entropy like from your local environment.

808
01:04:17,930 --> 01:04:24,633
Scott: Yeah, it's like, you know use Wi-Fi only you can't be going over Verizon t-mobile or anything like that Right.

809
01:04:24,733 --> 01:04:25,517
Scott: It's like you can't?

810
01:04:25,537 --> 01:04:28,008
Scott: it's just you know, it's just how it is.

811
01:04:28,671 --> 01:04:31,001
Scott: As soon as you use someone else's service, that's it.

812
01:04:31,061 --> 01:04:32,910
Scott: You gave them everything the end.

813
01:04:34,964 --> 01:04:36,713
Scott: So That's one thing.

814
01:04:36,733 --> 01:04:52,890
Scott: The second thing is Apple's getting a ton of flack for this which is partially because a They've decided to tell everyone not only that they're doing it But all the details of how they're doing it and because of their privacy conscious, you know message they've had for so long.

815
01:04:53,012 --> 01:04:56,036
Scott: It's a bigger contradiction I think the latter Google to do it.

816
01:04:56,096 --> 01:05:11,027
Scott: the latter is a bigger key because but if you look at what they're doing They're sticking to their privacy conscious, you know ideas and they're doing it in a better More privacy sensitive way than anyone else is doing it.

817
01:05:11,188 --> 01:05:12,933
Rym: They are Except for.

818
01:05:13,014 --> 01:05:19,090
Rym: obviously the only concern I have is the avenue where the government could force them secretly to leverage this technology.

819
01:05:19,592 --> 01:05:23,370
Scott: But already it's been that way for Google Dropbox Microsoft Facebook.

820
01:05:23,510 --> 01:05:27,103
Scott: That's already been that way for all of them who already have had these systems up.

821
01:05:27,223 --> 01:05:29,230
Scott: Yeah in a far worse implementation.

822
01:05:29,491 --> 01:05:37,585
Rym: What it means for me as a just like a person using technology is that This platform is now the same as all of those platforms.

823
01:05:37,645 --> 01:05:38,770
Rym: It is not different or special.

824
01:05:39,494 --> 01:05:40,981
Scott: It is not different.

825
01:05:41,021 --> 01:05:41,745
Scott: It is slightly.

826
01:05:41,826 --> 01:05:43,515
Scott: it is still Better.

827
01:05:43,777 --> 01:05:47,576
Scott: it is not, you know, it is still Not private.

828
01:05:48,139 --> 01:05:50,330
Scott: So but it is better than the other option.

829
01:05:50,350 --> 01:05:54,403
Rym: What's also interesting is that Apple a gap between them has decreased.

830
01:05:54,744 --> 01:05:59,391
Rym: Apple has been doing this for iCloud mail Since 2019.

831
01:05:59,391 --> 01:06:09,590
Rym: Yep, no one cared because all the platforms that do this primarily are doing it on communication and Like storage but like storage that's shared or unencrypted.

832
01:06:09,710 --> 01:06:10,654
Rym: I guess they're like.

833
01:06:10,694 --> 01:06:16,255
Rym: this case is a slightly different twist because of Apple's Privacy message as you described.

834
01:06:16,275 --> 01:06:17,861
Rym: that message cause the dissonance.

835
01:06:18,101 --> 01:06:20,650
Scott: No Apple has also simply just told everyone.

836
01:06:20,750 --> 01:06:28,095
Scott: Hey, if you just disable iCloud photo, which is a single button press and just keep your photos on your phone only This won't happen to you.

837
01:06:28,656 --> 01:06:31,024
Scott: So there's they given you a way around it.

838
01:06:31,345 --> 01:06:32,730
Scott: They just told you how to undo it.

839
01:06:33,173 --> 01:06:41,912
Rym: I would do things I would personally Yeah, like I might switch to Apple when the next iPhones come out if the the error of the small phone But he just died.

840
01:06:41,952 --> 01:06:42,835
Rym: I might just be fucked.

841
01:06:42,855 --> 01:06:44,039
Scott: So we'll find out.

842
01:06:44,119 --> 01:06:44,962
Rym: we're gonna find out.

843
01:06:45,524 --> 01:06:51,249
Rym: I uh, I was salivating over that Supposedly leaked iPod or iPhone nano that they never made.

844
01:06:52,174 --> 01:06:52,898
Scott: Yeah, never made.

845
01:06:52,938 --> 01:06:58,990
Rym: back in the days of like in the tin 2010 I mean my iPod was still one of the best pieces of technology I ever owned in my life.

846
01:06:59,771 --> 01:07:06,911
Rym: Yeah, pretty much if they made an iPhone nano like I would pay thousands of dollars for an iPhone I would have bought if they had made it in 2011.

847
01:07:06,911 --> 01:07:09,221
Scott: I would have bought it and stuck with it forever if they made one today.

848
01:07:09,321 --> 01:07:11,511
Rym: I would pay laptop prices in 2011.

849
01:07:11,511 --> 01:07:14,542
Scott: I want I was specifically said I wanted an iPhone nano in 2010 2011.

850
01:07:14,542 --> 01:07:15,225
Scott: They never made it.

851
01:07:17,354 --> 01:07:24,630
Rym: But and if my threat because remember though They're only the avenue that I personally have the most concern about is the national security letter thing.

852
01:07:25,313 --> 01:07:33,063
Rym: If the threat you are trying to protect yourself against is the US government You have got to you've got to use platform agnostic encryption.

853
01:07:33,243 --> 01:07:35,350
Rym: Anyway, yeah there are iPhone.

854
01:07:35,972 --> 01:07:41,450
Rym: I'm not fussed about this and this will not factor into my decision to use or not use Apple products.

855
01:07:42,332 --> 01:07:52,510
Scott: Yeah as a more general point right is that almost as I said almost all the concerns Right are slippery slope concerns, right?

856
01:07:52,590 --> 01:08:02,849
Scott: They're saying You know because the system as it is if we take Apple's word for it and we assume that there is or have not been Any national security letters adding other things to this?

857
01:08:03,430 --> 01:08:09,370
Scott: Right if we just look at what it is and assume that we will not go over the slope in good faith, right?

858
01:08:09,410 --> 01:08:10,514
Scott: We're not going down the slope.

859
01:08:11,257 --> 01:08:12,562
Scott: This is only a positive thing.

860
01:08:12,583 --> 01:08:14,490
Scott: This is gonna stop shit tons of CSAM.

861
01:08:14,490 --> 01:08:16,798
Scott: Yeah, it's gonna catch all sorts of child predators.

862
01:08:16,818 --> 01:08:17,962
Scott: This is a huge benefit.

863
01:08:18,263 --> 01:08:20,652
Scott: No, it's like no one's focusing on that at all Right.

864
01:08:20,733 --> 01:08:24,729
Scott: It's like if you don't go down the slippery slope, this is great.

865
01:08:26,290 --> 01:08:33,256
Rym: However, the same argument is made by people who say we should abolish and end encryption Absolutely and require that's like.

866
01:08:33,277 --> 01:08:35,484
Scott: there is a huge difference between that and this.

867
01:08:36,327 --> 01:08:44,919
Scott: and the huge difference Is that if you abolish end-to-end encryption, right you were actually creating a Security problem, right?

868
01:08:44,939 --> 01:08:46,569
Rym: Yeah, but you don't y'all to see for him.

869
01:08:47,310 --> 01:08:50,462
Scott: Well, but you would also cause lots and lots of collateral damage.

870
01:08:50,502 --> 01:08:52,330
Scott: That wouldn't be a slippery slope.

871
01:08:52,410 --> 01:08:54,676
Scott: It would be a reality right of where.

872
01:08:54,898 --> 01:09:00,274
Scott: yeah, if there's no end-to-end encryption, then that means I can't make a bank transaction Safely, right?

873
01:09:00,576 --> 01:09:01,398
Scott: It's like you.

874
01:09:02,020 --> 01:09:05,050
Scott: it's like already a built-in consequence here.

875
01:09:05,551 --> 01:09:07,962
Scott: It's like they don't have to add more hashes.

876
01:09:08,524 --> 01:09:09,770
Rym: So I did see one other.

877
01:09:10,252 --> 01:09:10,875
Scott: It's not again.

878
01:09:10,915 --> 01:09:14,290
Scott: It's not a guaranteed thing that any collateral damage will happen.

879
01:09:14,691 --> 01:09:25,707
Rym: I found a story about a crypto audit project and a number of researchers pointed out that they were testing that had the neural hash Mechanism that Apple's using and they found lots of collisions very quickly.

880
01:09:26,913 --> 01:09:28,602
Scott: Well, what they were doing was intentionally.

881
01:09:28,703 --> 01:09:29,506
Scott: I looked at some of that.

882
01:09:29,527 --> 01:09:31,350
Rym: Yeah some Definitely.

883
01:09:32,290 --> 01:09:33,658
Rym: There's a lot of caveats on.

884
01:09:33,679 --> 01:09:35,290
Rym: they were somewhat synthetic examples.

885
01:09:36,171 --> 01:09:40,600
Scott: Well, not only that I saw someone who's like hey All of these images will make a hash collision.

886
01:09:40,621 --> 01:09:43,613
Scott: a hundred percent of those images were Clearly like.

887
01:09:44,055 --> 01:09:59,956
Scott: I didn't actually click through to the site because I had guessed what they were doing, but I saw a thumbnail of the site they had taken see Sam imagery and Just modified it to like make it blurry or whatever and it's like yeah Glad I didn't click through to you, but

888
01:09:59,976 --> 01:10:03,548
Rym: also those are the collisions that you that would be a feature of the platform.

889
01:10:05,470 --> 01:10:09,370
Scott: Exactly the point I you know, just like the more general point, right?

890
01:10:09,470 --> 01:10:14,730
Scott: Is it not only with this but with a lot of things in our in technologically in the world?

891
01:10:15,331 --> 01:10:27,287
Scott: There are slippery slopes that like yeah if you build, you know And I think we get this a lot because we've seen so many Twilight Zone episodes We've seen slippery slopes just ramp down to the bottom instantly.

892
01:10:27,327 --> 01:10:33,327
Scott: in the real world We have seen slippery slopes in reality, you know nuclear power to nuclear bomb, right?

893
01:10:33,808 --> 01:10:35,694
Scott: That's real That's not some made-up thing.

894
01:10:35,714 --> 01:10:36,155
Scott: Right?

895
01:10:36,376 --> 01:10:39,785
Rym: Well, no, actually that's not true because we went from nuclear bomb to nuclear power.

896
01:10:39,805 --> 01:10:46,320
Rym: I Guess technically we didn't have nuclear power generation until long after we had nuclear bombs.

897
01:10:47,852 --> 01:10:51,645
Rym: In fact, you get the bomb is arguably easier to make than a effective nuclear.

898
01:10:51,665 --> 01:10:51,826
Rym: Yeah.

899
01:10:52,167 --> 01:10:56,775
Scott: Anyway, I digress there have been real slippery slopes that have.

900
01:10:56,795 --> 01:11:04,333
Scott: we have gone down in real life, right and We've just read, you know, so many UM play gods sci-fis.

901
01:11:04,675 --> 01:11:22,210
Scott: right that you know, people are so worried about slippery slopes, but if We can there are many situations such as this where we can build the technology And as long as we don't go down the slippery slope We can gain a huge benefit.

902
01:11:22,685 --> 01:11:22,850
Scott: right.

903
01:11:22,930 --> 01:11:26,166
Scott: The negatives are further down the slope at the top of the slope.

904
01:11:26,226 --> 01:11:33,880
Scott: if we hold Just hold and keep the snowball way at the top of the hill and don't go down the hill There's a huge benefits to be gained.

905
01:11:33,940 --> 01:11:58,784
Scott: if we're so afraid of the bottom of the hill That we stay at the very tippy top and don't take the only one step down and stop there after one step We're actually sort of you know That's also a negative in that you can consider the positives that we would get one step down in this case lots and lots of CSAM dissemination just going to go getting off scotch-free not getting caught right.

906
01:11:58,884 --> 01:12:02,535
Scott: all this child abuse just running rampant Right is like.

907
01:12:02,555 --> 01:12:04,842
Scott: that's also a negative right?

908
01:12:05,204 --> 01:12:22,607
Scott: So we need to figure out a way that we can Recognize the true and real dangers of going down the slope more than one step because they are super real right Recognize the damage of not going down the slope at all and find a way to go down the slope.

909
01:12:22,807 --> 01:12:23,670
Scott: one step only.

910
01:12:24,256 --> 01:12:24,600
Scott: fucking.

911
01:12:24,681 --> 01:12:26,936
Scott: stay there Right.

912
01:12:27,117 --> 01:12:32,889
Scott: make our society better right and not arguing against step one.

913
01:12:33,592 --> 01:12:39,270
Scott: Be you know by pointing at step two as soon as someone goes to step two, yeah yell at them all you want.

914
01:12:39,792 --> 01:12:47,570
Rym: Well, there's the step one, but while I agree with you in principle in this case We literally cannot know if step two ever happened because of the way u.s.

915
01:12:47,690 --> 01:12:48,092
Rym: Law works.

916
01:12:48,152 --> 01:12:52,230
Scott: the way to solve this problem is only in that specific case, right?

917
01:12:54,210 --> 01:12:56,241
Rym: Primary concern of almost everyone.

918
01:12:56,282 --> 01:12:57,690
Rym: I see it was credible in this space.

919
01:12:58,092 --> 01:13:01,509
Scott: I can't imagine that becoming a huge a huge thing right?

920
01:13:01,589 --> 01:13:01,730
Scott: has?

921
01:13:01,890 --> 01:13:04,220
Scott: Have people been getting caught?

922
01:13:04,862 --> 01:13:15,232
Scott: if that if that case is always true Right that the government is sending hashes to tell them to insert into the database to catch people doing other things besides legitimate See Sam.

923
01:13:15,714 --> 01:13:21,933
Scott: then how come other people on the other platforms where these systems have been in place for a long time There should?

924
01:13:21,953 --> 01:13:26,850
Scott: we should have been seeing people who have been getting busted for other non see Sam related crime.

925
01:13:27,051 --> 01:13:29,925
Rym: You wouldn't because anything like that that's done under a gag order.

926
01:13:29,945 --> 01:13:32,892
Rym: You're never gonna find out Someone.

927
01:13:33,335 --> 01:13:36,010
Scott: if a human being goes to like is arrested you're right.

928
01:13:36,010 --> 01:13:41,138
Rym: It's like no, you know, you know, but you would not know in the general public They have that sealed evidence.

929
01:13:41,158 --> 01:13:42,928
Rym: in most cases that's never revealed to the public.

930
01:13:43,652 --> 01:13:46,406
Scott: There aren't people being disappeared right or whatever.

931
01:13:46,426 --> 01:13:46,928
Rym: How would you know?

932
01:13:48,010 --> 01:13:50,099
Scott: How have you seen anyone you know getting?

933
01:13:50,119 --> 01:13:51,626
Rym: all I all I know is stats.

934
01:13:51,686 --> 01:14:01,270
Rym: I saw on Leaks attempting to show how many national security letters and gag orders get sent and it's a lot just generally across all technology.

935
01:14:02,232 --> 01:14:05,850
Rym: But I'm saying the solution to this is to change the structure.

936
01:14:06,271 --> 01:14:13,013
Rym: The US government should be much more limited in where and how gag orders are used and we need a lot more oversight over that Whole process.

937
01:14:13,374 --> 01:14:15,303
Rym: that's the actual fundamental problem.

938
01:14:15,343 --> 01:14:16,850
Rym: that's making this issue, right?

939
01:14:16,970 --> 01:14:26,410
Scott: But the fact that we even know the system exists Right that Apple told us about it is a reason to have some measure of good faith in the system.

940
01:14:26,450 --> 01:14:29,350
Scott: They could have just done this and never told anyone a fucking thing.

941
01:14:29,971 --> 01:14:37,310
Scott: They could have implemented this whole system and never told anyone it existed that we would never even know about it.

942
01:14:37,510 --> 01:14:41,321
Scott: You wouldn't know this was happening and you would just feel right as rain.

943
01:14:41,481 --> 01:14:44,510
Scott: the fact that Apple told us that this existed and how?

944
01:14:44,610 --> 01:14:47,752
Scott: It works when they didn't have to Right.

945
01:14:47,772 --> 01:14:56,510
Scott: They didn't have to tell us is a reason to have good faith in the system unless this is like the the sort of You know double think strategy of the government, right?

946
01:14:57,693 --> 01:15:01,474
Scott: Right, that's Right.

947
01:15:01,615 --> 01:15:17,190
Scott: is a reason to believe that yeah It's gonna right until this until they say it's also a reason to believe that if things went to step two That someone would say something, you know, not necessarily Someone officially saying something but some sort of whistleblower.

948
01:15:17,390 --> 01:15:32,170
Rym: I feel much more simple if this figures into your threat profiles enough to where you have a. Specifically you are already the kind of person who needs to be using platform agnostic encryption, right?

949
01:15:32,630 --> 01:15:33,373
Scott: And yeah, I'm not gonna.

950
01:15:33,434 --> 01:15:40,518
Scott: I'm not gonna get mad about this the way other people are getting mad about it until You know something actually happens, right?

951
01:15:41,079 --> 01:15:45,210
Scott: I'm seeing this currently as a net positive of catching lots.

952
01:15:45,230 --> 01:15:48,844
Rym: I mean when I need to communicate in a way that I know is verifiably secure.

953
01:15:48,864 --> 01:15:53,424
Rym: I use Platform agnostic and an encrypted services.

954
01:15:54,088 --> 01:15:55,199
Scott: Hmm I mean it.

955
01:15:55,442 --> 01:16:07,077
Scott: you could just Seriously, if you don't want to set up fancy encryption if you just make a fucking Linux computer and two people SSH to it Yeah, and you'd write you edit a text file.

956
01:16:07,298 --> 01:16:10,770
Scott: It's like the government ain't gonna find it even if the text file is unencrypted.

957
01:16:11,532 --> 01:16:12,254
Rym: Well, so did you?

958
01:16:12,294 --> 01:16:12,896
Rym: there was a thing.

959
01:16:12,916 --> 01:16:19,732
Rym: a bunch of government people who were being investigated for corruption and other things got caught with this a Common way.

960
01:16:19,833 --> 01:16:25,228
Rym: for a long time people would communicate anonymously and avoid government regulation and oversight and even avoid cops.

961
01:16:25,650 --> 01:16:30,506
Rym: is Someone would log into a random email account write an email and not send?

962
01:16:30,567 --> 01:16:31,470
Rym: just leave it as a draft.

963
01:16:31,912 --> 01:16:40,189
Rym: Someone else logs into that same email account looks in the draft read the draft edits it But they never actually send the email anywhere.

964
01:16:40,972 --> 01:16:50,690
Rym: smart there's a lot of well that that it's not staying inography, but that's a whole class of Security through obscurity communication mechanisms that are way out of scope for the show.

965
01:16:50,710 --> 01:16:52,903
Rym: And I think we talked about it in like 2007 on GeekNights.

966
01:16:55,791 --> 01:16:57,980
Rym: Anyway, I'm hungry and I think this was a plenty long show.

967
01:16:58,021 --> 01:16:58,703
Rym: you see what happens.

968
01:16:59,085 --> 01:17:00,230
Rym: we skip a couple weeks of shows.

969
01:17:00,534 --> 01:17:01,284
Rym: It's all bottled up.

970
01:17:02,561 --> 01:17:02,729
Scott: Yep.

971
01:17:03,692 --> 01:17:05,509
Rym: So, uh, see you on Wednesday when?

972
01:17:06,671 --> 01:17:07,334
Rym: We do the show on.

973
01:17:08,177 --> 01:17:09,543
Scott: I watched all four even movies.

974
01:17:09,784 --> 01:17:12,255
Rym: Oh, I haven't watched them yet But I watched beat.

975
01:17:12,296 --> 01:17:13,642
Scott: I watched Beast are season two.

976
01:17:13,743 --> 01:17:15,049
Rym: Oh, I finished Beast our season two.

977
01:17:16,513 --> 01:17:16,835
Rym: I was.

978
01:17:17,076 --> 01:17:26,870
Rym: uh, all I will say is I was Surprised by exactly one thing and that thing was very surprising and it involved the number four.

979
01:17:28,571 --> 01:17:29,717
Rym: Yeah, I didn't think that.

980
01:17:29,958 --> 01:17:32,150
Rym: I thought I didn't think that was literally going to happen.

981
01:17:33,611 --> 01:17:38,708
Rym: Okay, and then just literally happened and the show just moved on like yep that happened that that surprised me a little bit.

982
01:17:39,714 --> 01:17:42,290
Rym: Okay, we can always review Beast our season two if we got nothing else.

983
01:17:43,191 --> 01:17:43,915
Rym: Hmm or be.

984
01:17:43,955 --> 01:17:46,248
Rym: I guess there's gonna be a third season coming to like wrap everything up.

985
01:17:47,093 --> 01:17:48,503
Scott: Yeah, Ava movies would be better.

986
01:17:48,523 --> 01:17:53,702
Scott: Beast our season two is Movies by Wednesday cuz I'm only four of them.

987
01:17:53,863 --> 01:17:56,274
Rym: Yeah, you don't even need to watch tomorrow It's 730 p.m.

988
01:17:56,354 --> 01:17:58,706
Rym: On a watch them all in two days.

989
01:18:00,132 --> 01:18:02,779
Rym: Yeah, so, let's see tomorrow one day into the next day.

990
01:18:02,960 --> 01:18:03,903
Rym: I'm working also the first.

991
01:18:04,384 --> 01:18:06,430
Rym: you've already seen the dark literally all night.

992
01:18:07,092 --> 01:18:08,979
Scott: You don't realize you've already seen the first one.

993
01:18:08,999 --> 01:18:12,210
Scott: You could just watch the last one minute of the first one.

994
01:18:12,290 --> 01:18:21,490
Scott: Oh, yeah, I figure oh wait, there's two there's another seat There's a scene in the middle of the first one That's less than like 30 seconds long and the end of the first one like literally the last less than minute.

995
01:18:21,751 --> 01:18:24,620
Rym: Oh shit, like that matters like the Ava does.

996
01:18:24,660 --> 01:18:28,710
Scott: yeah, but you can you can just watch those two scenes and otherwise I'm still not gonna.

997
01:18:28,931 --> 01:18:33,346
Rym: I'm not gonna have watched four ish movies by Wednesday when we got to do a show.

998
01:18:33,386 --> 01:18:39,010
Rym: cuz I have I Remember my entire tomorrow is taken up in the evening playing blades in the dark until like midnight.

999
01:18:39,752 --> 01:18:43,354
Scott: If you just stay there Ava, so if you start watching them Oh, yeah, I know the danger.

1000
01:18:43,415 --> 01:18:44,419
Scott: You might watch him all today.

1001
01:18:44,439 --> 01:18:47,050
Rym: the reason Ava the cowboy bebop DVDs.

1002
01:18:47,251 --> 01:18:49,217
Rym: These things are under lock and key for a reason.

1003
01:18:49,458 --> 01:18:51,926
Rym: You can't see a screen playing certain things.

1004
01:18:51,966 --> 01:18:53,230
Rym: You're gonna be trapped for it.

1005
01:18:54,132 --> 01:18:56,749
Rym: Star Wars cannot be displayed on any screen.

1006
01:18:57,352 --> 01:19:02,750
Scott: The the first movie is ninety nine point ninety nine percent a compilation of the first six episodes of the TV series.

1007
01:19:03,092 --> 01:19:12,907
Scott: But starting with episode the second movie It's almost nothing like in fact that yet while being almost nothing like it It's all basically the same thing.

1008
01:19:12,967 --> 01:19:14,850
Rym: also You know what?

1009
01:19:14,910 --> 01:19:16,114
Rym: The problem is I realized that can't.

1010
01:19:16,214 --> 01:19:20,730
Rym: I can't make that Simpsons TV because it would turn into the day killers and our IT.

1011
01:19:20,952 --> 01:19:21,748
Rym: I'll leave you all with this.

1012
01:19:22,131 --> 01:19:29,798
Rym: We had a bunch of VHS tapes from my family where we would do ad blocking by someone would record shows and then we'd all Watch the shows without the ads later.

1013
01:19:30,461 --> 01:19:32,090
Rym: So that was a chore like taking out the garbage.

1014
01:19:32,593 --> 01:19:41,839
Rym: So I had these VHS tapes that were in like the lowest quality mode So like eight hours of tape and it was just back-to-back Simpsons episodes with no openers closers or commercials.

1015
01:19:42,200 --> 01:19:45,209
Rym: and if anyone put that in the VCR we were just trapped.

1016
01:19:47,778 --> 01:19:48,708
Rym: I can't get that little TV.

1017
01:19:49,231 --> 01:20:05,157
Rym: You'll see me sitting at my decks with two 4k monitors and I'll be staring at a tiny little screen playing like episode 36 of The Simpsons in 320 by 200.

1018
01:20:05,157 --> 01:20:07,700
Rym: This has been GeekNights with Rym and Scott.

1019
01:20:07,760 --> 01:20:12,580
Rym: Special thanks to DJ pretzel for the opening music cat leave for web design and Brando K for the logos.

1020
01:20:12,801 --> 01:20:17,820
Scott: Be sure to visit our website at front row crew comm for show notes discussion news and more.

1021
01:20:18,100 --> 01:20:25,140
Rym: Remember GeekNights is not one but four different shows sci-tech Mondays gaming Tuesdays anime comic Wednesdays and indiscriminate Thursdays.

1022
01:20:25,860 --> 01:20:29,036
Scott: GeekNights is distributed under a Creative Commons attribution 3.0 license.

1023
01:20:30,301 --> 01:20:33,390
Scott: GeekNights is recorded live with no studio and no audience.

1024
01:20:33,571 --> 01:20:35,055
Scott: But unlike those other late shows.

1025
01:20:35,175 --> 01:20:45,488
Rym: It's actually recorded at night and The patreon patrons for this episode of GeekNights now that we're back are Heidi McNichol Alan Joyce linky G dread.

1026
01:20:45,528 --> 01:20:49,820
Rym: Lily Tenerbrae Chris Romer Clinton Walton Dex Finn just like a dude guy.

1027
01:20:50,161 --> 01:20:52,736
Rym: Shoshaya high 85 Rebecca Dunn review bad bull 34 cowards.

1028
01:20:53,560 --> 01:20:54,022
Rym: It's coming.

1029
01:20:54,705 --> 01:21:09,420
Rym: Ryan Baron Sam Erickson Sherman one oral Taylor Braun under program law odd-do Pierce ab threat open seat, right You hold the key to my heart and a whole bunch of people who do not want me to say their names.

1030
01:21:09,801 --> 01:21:14,380
Rym: I paused the patreon for the previous month because we missed so many shows, but we're back doing our normal thing.

1031
01:21:14,762 --> 01:21:16,232
Rym: We'll pretty much be on a normal schedule.

1032
01:21:16,614 --> 01:21:28,203
Rym: on the next Monday show We're talking about sleeping for computers and on the next Wednesday show We are very likely going to talk about all of the new Ava movies since they're all out and we've well by then We'll have seen them.

1033
01:21:28,664 --> 01:21:31,574
Rym: But anyway for right now now that we're back.

1034
01:21:32,437 --> 01:21:33,119
Rym: I leave you.

1035
01:21:33,942 --> 01:21:36,127
Rym: Where is locked if we can't get to bro?

1036
01:21:36,147 --> 01:21:40,980
Rym: Wait, I see him and it looks like he's wrestling someone.

1037
01:21:53,001 --> 01:21:56,554
Rym: What's he doing with his favorite bro, what other weapon does he have?

1038
01:21:57,116 --> 01:21:58,120
Rym: he needs his hands free.

1039
01:22:07,686 --> 01:22:11,413
Rym: Oh He's got him on his knees, it's just a matter of time now.

1040
01:22:11,734 --> 01:22:12,958
Rym: process toying with him.

1041
01:22:14,401 --> 01:22:15,852
Rym: Pretzel better rocks.

1042
01:22:15,872 --> 01:22:20,650
Scott: gotta teach me that one Fade of space may have got his helmet knocked off.

1043
01:22:21,414 --> 01:22:22,097
Scott: Oh my god.

1044
01:22:22,117 --> 01:22:22,740
Scott: He's hideous.

1045
01:22:23,701 --> 01:22:26,750
Scott: Must have been four boys on base phrase again.

1046
01:22:26,770 --> 01:22:29,017
Rym: Hey, that's not a phantom spaceman.

1047
01:22:29,037 --> 01:22:36,358
Rym: That's it Oh Right phantom spaceman.

