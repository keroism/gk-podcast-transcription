1
00:00:08,540 --> 00:00:10,028
Rym: It's Monday, November 1st, 2021.

2
00:00:10,028 --> 00:00:10,188
Rym: I'm Rym.

3
00:00:13,703 --> 00:00:14,100
Scott: I'm Scott.

4
00:00:14,360 --> 00:00:15,543
Rym: And this is GeekNights.

5
00:00:15,583 --> 00:00:21,780
Rym: Tonight, on the 16th anniversary of fucking GeekNights, we're talking about documentation.

6
00:00:23,582 --> 00:00:24,618
Scott: Let's do this.

7
00:00:25,980 --> 00:00:30,314
Rym: It's all- I'm happy that we started GeekNights back in 2005 on Halloween.

8
00:00:30,554 --> 00:00:33,449
Scott: Even though- We didn't start it on Halloween.

9
00:00:33,489 --> 00:00:34,820
Scott: We started it before Halloween.

10
00:00:34,900 --> 00:00:41,120
Scott: And then somehow, coincidentally, I don't even feel like we realized that the first real episode was Halloween.

11
00:00:41,400 --> 00:00:43,707
Scott: We just sort of were like, "That's good enough to go

12
00:00:43,807 --> 00:00:44,189
Scott: live.".

13
00:00:44,249 --> 00:00:46,696
Scott: And then later on, it was just like, "When's our anniversary?

14
00:00:46,797 --> 00:00:47,378
Scott: Oh, Halloween,

15
00:00:47,439 --> 00:00:47,720
Scott: okay.".

16
00:00:47,880 --> 00:00:52,046
Rym: So years ago, I actually told the exact story of how we did this.

17
00:00:52,087 --> 00:01:00,640
Rym: Because remember, for the Patreon people, I remastered with better audio all of the beta episodes, re-uploaded them, and I recorded commentary tracks for all of them.

18
00:01:01,521 --> 00:01:03,844
Rym: So I listened to all that early beta GeekNights.

19
00:01:04,185 --> 00:01:15,120
Rym: The decision point we made was specific- The one good news is, if anyone goes and listens to them on the Patreon now, while the content is unlistenable, the audio is at least listenable.

20
00:01:15,621 --> 00:01:23,579
Rym: I learned a lot since back then, and I also was able to salvage some of that Logitech audio in ways that I even surprised myself.

21
00:01:23,679 --> 00:01:24,080
Rym: Good lord.

22
00:01:25,842 --> 00:01:30,112
Rym: So, way back, we actually published our first episode.

23
00:01:30,173 --> 00:01:33,240
Rym: It was the following episode, like a November 1st or 2nd episode.

24
00:01:33,960 --> 00:01:39,655
Rym: We then decided, "Hey, the episode we did one before this, actually, we think it was pretty good.

25
00:01:40,056 --> 00:01:41,219
Rym: Let's also make that one

26
00:01:41,279 --> 00:01:41,560
Rym: public.".

27
00:01:41,881 --> 00:01:46,098
Rym: And we went back and published the previously unpublished October 31st episode.

28
00:01:47,803 --> 00:01:50,129
Scott: I mean, I do recommend that pattern, right?

29
00:01:50,189 --> 00:01:54,660
Scott: If you're going to make a continuing content of some kind, right?

30
00:01:55,160 --> 00:01:58,167
Scott: I guess maybe that's not right.

31
00:01:58,208 --> 00:02:03,140
Scott: Because let's say you're writing a series, like a book, and you're doing a chapter by chapter.

32
00:02:03,701 --> 00:02:09,000
Scott: You can't write some beta chapters and make chapter three actually chapter one and throw out chapter one and two.

33
00:02:09,161 --> 00:02:10,896
Rym: Maybe you could, but...

34
00:02:12,161 --> 00:02:16,239
Scott: Yeah, but like a podcast, they're all standalone, so yeah, you can throw some out.

35
00:02:17,020 --> 00:02:27,079
Scott: But it's like, I guess the art process is generally going to be like sketches, whether it's literal sketches or just practice drawings, practice whatever it is you do.

36
00:02:28,521 --> 00:02:33,112
Scott: Make short movies, songs, practice meh ones.

37
00:02:33,854 --> 00:02:36,560
Scott: You start out by not sharing them with anyone because they're too awful.

38
00:02:37,282 --> 00:02:43,240
Scott: And then people seem to jump from not sharing with anyone to share with the world, and I guess you can do that.

39
00:02:43,480 --> 00:02:53,880
Scott: But I guess the path we took of share with no one, share with close people only to make sure if they give you the thumbs up, then go to the world.

40
00:02:54,100 --> 00:03:02,100
Scott: It's like you can hide some more of your trash from the world and also have some beta episodes hidden away for fun times in the future.

41
00:03:02,401 --> 00:03:09,138
Rym: But also, this quote gets misused more and more lately, but the idea of making the machine.

42
00:03:09,178 --> 00:03:10,020
Rym: that makes the machine.

43
00:03:10,461 --> 00:03:14,200
Rym: Those episodes, the purpose wasn't to make content for us and every process is different.

44
00:03:15,202 --> 00:03:19,100
Rym: Our goal there was specifically to figure out how to make a podcast at all.

45
00:03:19,500 --> 00:03:20,865
Rym: We were learning a process.

46
00:03:21,407 --> 00:03:24,900
Rym: The episodes that got recorded were just artifacts of that process.

47
00:03:25,781 --> 00:03:27,027
Scott: Yep.

48
00:03:27,087 --> 00:03:29,860
Scott: You might be wondering why I'm wearing sunglasses inside of a podcast.

49
00:03:30,161 --> 00:03:33,292
Rym: I mean, you might be wondering why I have a mustache like.

50
00:03:33,332 --> 00:03:35,600
Rym: it's the year 1997 and I'm back in high school.

51
00:03:36,521 --> 00:03:42,580
Scott: Yeah, but it's that time of year where the earth tilts upwards in the wrong direction, so up away from the sun.

52
00:03:45,221 --> 00:03:57,420
Scott: So the sun now, because I have a south facing window right here to my right, the sun late in the day, like currently five, but I guess starting next week, it'll be around like four.

53
00:03:58,801 --> 00:04:05,380
Scott: There's a period right before sunset where the sun just blasts right straight through these giant windows, right into my face, my monitors.

54
00:04:06,121 --> 00:04:11,416
Scott: And it caught me today at like an even worse angle than last Friday and blasted me right in the fucking eyes.

55
00:04:11,436 --> 00:04:12,620
Scott: So my eyes hurt.

56
00:04:13,381 --> 00:04:22,380
Rym: It's even funnier because around that time is when, because the buildings around the garden behind our building are set up, it's pitch black out the window right now.

57
00:04:22,620 --> 00:04:22,760
Scott: Oh yeah.

58
00:04:22,780 --> 00:04:23,402
Scott: It's dark now.

59
00:04:23,462 --> 00:04:23,602
Scott: Yeah.

60
00:04:23,722 --> 00:04:27,248
Rym: But, uh, but even though the lights on, yeah, it gets dark before then.

61
00:04:27,268 --> 00:04:28,009
Rym: So yeah.

62
00:04:28,069 --> 00:04:34,520
Rym: Anyway, uh, so my mustache is because I did something that I've threatened to do for years, but I never did it.

63
00:04:34,600 --> 00:04:37,125
Rym: You know, there's a history in RIT anime of I was poor.

64
00:04:37,145 --> 00:04:41,813
Rym: I was also lazy and I had very little free time despite being so lazy.

65
00:04:42,234 --> 00:04:45,500
Scott: So I tend to, well, you also, I think you, you didn't care that much.

66
00:04:45,640 --> 00:04:49,585
Scott: I also did not care, but, but you were, but you were up for it.

67
00:04:49,665 --> 00:05:02,060
Rym: You were like, you know, there's, there's this weird dichotomy of, or not dichotomy, the duality of not caring about something enough to do a good job, but caring enough to do the thing at all.

68
00:05:03,100 --> 00:05:16,620
Scott: So like, yes, I want to do that thing as, but not if it requires any work or effort or investment, but if I could just do it, it's like, yeah, it's like, would I love to drive a formula one car if I didn't have to practice driving to not die?

69
00:05:16,780 --> 00:05:17,041
Scott: Yeah.

70
00:05:17,161 --> 00:05:17,461
Scott: Yeah.

71
00:05:18,002 --> 00:05:19,525
Scott: I remember you had to drive one.

72
00:05:19,865 --> 00:05:20,346
Scott: I'll die.

73
00:05:20,386 --> 00:05:21,207
Scott: Therefore I don't.

74
00:05:21,388 --> 00:05:21,608
Scott: Wasn't?

75
00:05:21,628 --> 00:05:26,877
Rym: there's a robotics club at RIT and you asked them, Hey, can I join, but just be the driver of your little robot car?

76
00:05:26,917 --> 00:05:27,758
Rym: And they were like, fuck you.

77
00:05:27,818 --> 00:05:28,860
Rym: No, of course not.

78
00:05:30,381 --> 00:05:34,067
Scott: Well, no, I think that was literally just a race car, the formula, SAE, whatever.

79
00:05:34,087 --> 00:05:34,548
Scott: Yeah.

80
00:05:34,568 --> 00:05:39,416
Scott: I don't remember what that, exactly the details there, but yeah, but they weren't looking for a driver only.

81
00:05:39,536 --> 00:05:39,717
Scott: Right.

82
00:05:39,737 --> 00:05:41,680
Rym: They're looking for engineers to work on a car.

83
00:05:42,100 --> 00:05:56,300
Rym: So I, I've threatened for years while a listener even photoshopped me at one point, but, uh, the costume I wore is basically my own body because at least in a photo, my own body looks very close to Sean Connery in the 1974.

84
00:05:56,300 --> 00:05:58,622
Rym: Well, movie Zardoz.

85
00:05:59,303 --> 00:05:59,483
Scott: Right.

86
00:05:59,503 --> 00:06:05,087
Scott: So long ago, someone took the famous Zardoz Sean Connery photo and photoshopped Rym's head onto it.

87
00:06:05,107 --> 00:06:06,468
Scott: I don't know who originally did that.

88
00:06:07,669 --> 00:06:10,491
Scott: Uh, it was too, it was too uncanny.

89
00:06:11,252 --> 00:06:11,412
Scott: Yeah.

90
00:06:11,432 --> 00:06:16,256
Scott: Whoever did it, uh, it must, it must've been some listener or someone we know.

91
00:06:16,296 --> 00:06:16,956
Scott: I don't know who it is.

92
00:06:17,016 --> 00:06:18,217
Scott: Claim credit, whoever you are.

93
00:06:19,018 --> 00:06:21,400
Scott: Um, I could probably find it if I put in a lot of effort.

94
00:06:22,080 --> 00:06:28,886
Scott: Whoever it was, uh, you know, posted that Photoshop with, uh, you know, Zed from Zardoz, Sean Connery with Rym's head on it.

95
00:06:29,466 --> 00:06:37,913
Scott: And it's like, Oh, you didn't even realize it was not a great job of photoshopping, but it was so, uh, so it's such a match that it didn't need to be a good job.

96
00:06:37,973 --> 00:06:46,160
Scott: It's like, Oh, I didn't even realize that that wasn't, you know, um, so I basically made it real thanks to that person.

97
00:06:46,440 --> 00:06:46,680
Rym: Yup.

98
00:06:46,741 --> 00:06:50,765
Rym: And Emily actually printed out a papercraft Zardoz head and, uh, it was a whole thing.

99
00:06:51,225 --> 00:06:55,930
Rym: So, uh, our friends had to see this and now you have to see this too.

100
00:06:56,390 --> 00:06:59,373
Rym: It looks exactly like everyone predicted and expected.

101
00:06:59,934 --> 00:07:05,099
Scott: And, uh, the only thing is I think you got the, you know, get the red suspenders instead of the, the bandolier aspect.

102
00:07:07,161 --> 00:07:11,666
Rym: I constructed this costume basically by getting three things.

103
00:07:11,706 --> 00:07:17,812
Scott: that will four things on Amazon, but that's more effort than I think any costume you've ever worn.

104
00:07:17,872 --> 00:07:20,194
Rym: The boots were $29.

105
00:07:20,194 --> 00:07:21,896
Rym: That costs more than I said.

106
00:07:21,916 --> 00:07:26,200
Rym: I mean, every costume I wore at RIT over the course of five years combined.

107
00:07:27,341 --> 00:07:31,636
Scott: I mean, that's not like cheap, but for a boot, that is the cheap, a cheap boot.

108
00:07:31,656 --> 00:07:32,840
Scott: That is such a cheap boot.

109
00:07:33,460 --> 00:07:43,008
Rym: Uh, I had, I already had a red Speedo and I bought a, I bought Japanese traditional underwear to use as the loincloth and I bought red suspenders and a cheap metal gun.

110
00:07:43,728 --> 00:07:44,369
Rym: So there you go.

111
00:07:45,029 --> 00:07:56,277
Rym: Uh, if I want to approve this, I could, I'd have to make the bandolier or buy it from a place that's not like shadow gray market Amazon because there are no red bandoliers on Amazon.

112
00:07:56,318 --> 00:07:57,558
Rym: I'd have to get a real bandolier.

113
00:07:57,598 --> 00:07:59,580
Rym: that probably costs actual dollars.

114
00:08:00,160 --> 00:08:07,986
Rym: Yeah, I think you could, you could probably for something like that, it's like, yeah, you could be, I'll get two red belts and just put like loops on it and put some like shells and it would be fine.

115
00:08:08,006 --> 00:08:09,247
Scott: You could do something like that.

116
00:08:09,347 --> 00:08:10,288
Scott: That wouldn't be too bad.

117
00:08:10,328 --> 00:08:15,412
Scott: But I think if you wanted it to be like better find another person who's a cosplayer, we might know some.

118
00:08:15,692 --> 00:08:16,533
Rym: Oh yeah.

119
00:08:16,553 --> 00:08:19,255
Scott: Hey, I'll pay you to make a red bandoliers, right?

120
00:08:19,275 --> 00:08:19,855
Scott: Just two of them.

121
00:08:20,016 --> 00:08:20,276
Scott: Yep.

122
00:08:21,096 --> 00:08:25,760
Rym: I could probably find a red bandolier if I looked anywhere other than the bottom of the barrel on Amazon.

123
00:08:26,340 --> 00:08:35,423
Scott: There might also be, you know, you might be able to get a white one and just dunk it in some red dye from the craft store, but they're going to be brown.

124
00:08:35,443 --> 00:08:36,323
Scott: They're going to be brown though.

125
00:08:36,403 --> 00:08:39,823
Scott: Usually they're all, they're all black or camouflage.

126
00:08:39,924 --> 00:08:40,865
Rym: The ones that I found.

127
00:08:41,445 --> 00:08:43,626
Scott: Well, a leather one's going to be brown, like an old school one.

128
00:08:45,066 --> 00:08:48,247
Rym: So yeah, we had a little Halloween gathering and that was, that was what came out of that.

129
00:08:49,408 --> 00:08:51,388
Scott: All right, let's move on to some news action.

130
00:08:51,568 --> 00:08:55,409
Rym: We'll see how long I keep this mustache cause I look exactly like how I looked in high school.

131
00:08:55,489 --> 00:08:57,070
Rym: It's, it's actually kind of creepy.

132
00:08:57,450 --> 00:09:00,573
Rym: I look identical to like my senior photos from high school.

133
00:09:00,593 --> 00:09:02,655
Scott: All right, so news.

134
00:09:02,715 --> 00:09:08,539
Scott: So the biggest tech news sort of, uh, you know, this is one of those items where like, is it really a tech news, right?

135
00:09:08,579 --> 00:09:10,361
Scott: It's a business news about a tech company.

136
00:09:10,881 --> 00:09:15,005
Scott: But yeah, everybody knows Facebook is pulling a Google, changing the name.

137
00:09:15,345 --> 00:09:17,667
Scott: So Facebook is the social network now.

138
00:09:17,687 --> 00:09:21,370
Scott: The company is called meta or something like that.

139
00:09:21,711 --> 00:09:22,999
Rym: There's a lot going on here.

140
00:09:23,019 --> 00:09:24,550
Rym: We even talked about this a little bit on Thursday.

141
00:09:24,910 --> 00:09:30,694
Scott: Oculus brand is gone and they've got, you know, they're going to use the meta brand over for all that other stuff.

142
00:09:31,295 --> 00:09:40,582
Scott: And basically, you know, I think this plays into what a lot of people have been saying about Facebook, which is like, yeah, you see them doing all these desperate things, right?

143
00:09:40,622 --> 00:09:52,771
Scott: Trying to get children to use Facebook, you know, fighting, you know, allow, you know, allow it, you know, being so permissive of, uh, uh, bad people, you know, posting bad things on Facebook just to keep the user counts up.

144
00:09:52,911 --> 00:09:53,131
Scott: Right.

145
00:09:53,171 --> 00:09:59,636
Scott: It's like, it seems like the evidence suggests, like Facebook itself is not the social network is not doing well.

146
00:10:00,157 --> 00:10:07,963
Scott: They sort of, you know, even though it's so large, it will take a long time for it to like become small and dead, like MySpace.

147
00:10:08,624 --> 00:10:14,048
Scott: But, you know, which wasn't, I guess, if not, if MySpace had been the size of Facebook, it'd probably still be around.

148
00:10:14,188 --> 00:10:15,349
Scott: But it seems to be.

149
00:10:15,389 --> 00:10:16,470
Scott: Facebook is in decline.

150
00:10:16,750 --> 00:10:16,990
Scott: Yeah.

151
00:10:17,030 --> 00:10:34,404
Rym: And they recognize, I've seen multiple, there's been multiple stories just recently, like the last couple of days of insiders leaking and revealing that even internally, basically everyone in Facebook agrees that the brand, the word Facebook is just pure poison to the outside world.

152
00:10:34,424 --> 00:10:41,790
Rym: Like it is seen like it has shockingly, well, not shockingly, expectedly negative connotations to almost everyone.

153
00:10:42,570 --> 00:10:42,770
Scott: Yep.

154
00:10:43,371 --> 00:10:44,672
Scott: So yeah, Facebook is on its own.

155
00:10:44,952 --> 00:10:48,795
Scott: It's, you know, it's still huge, but it's down, it's trending downwards.

156
00:10:48,855 --> 00:10:49,095
Scott: Right.

157
00:10:49,155 --> 00:10:57,882
Scott: So they got this other sideshow and I guess you can see the synergy there, which is like, okay, we made this sort of social network of the beginning of the information age.

158
00:10:58,342 --> 00:10:58,502
Scott: Right.

159
00:10:58,522 --> 00:11:05,147
Scott: We were the champs in terms of looking at screens and typing text, you know, let's take to survive in the future.

160
00:11:05,348 --> 00:11:05,588
Scott: Right.

161
00:11:05,628 --> 00:11:08,430
Scott: We got, we got to put out multiple game plans.

162
00:11:08,910 --> 00:11:09,150
Scott: Right.

163
00:11:09,311 --> 00:11:16,736
Scott: If we can't save Facebook, that our game plan will be, you know, even if it's not for quite a while, cause they got a long runway.

164
00:11:16,836 --> 00:11:19,158
Scott: Cause how long will it take for Facebook to die die?

165
00:11:19,398 --> 00:11:19,638
Scott: Right.

166
00:11:19,738 --> 00:11:20,239
Scott: A long time.

167
00:11:20,559 --> 00:11:21,460
Scott: Even if they do nothing.

168
00:11:21,560 --> 00:11:23,521
Scott: So they got this long runway.

169
00:11:24,001 --> 00:11:32,508
Scott: that even though I still say that, you know, the current VR tech is not going to achieve any sort of mass thing.

170
00:11:32,568 --> 00:11:35,230
Scott: for, you know, maybe we'll be seniors by the time.

171
00:11:35,250 --> 00:11:35,610
Scott: Right.

172
00:11:35,890 --> 00:11:37,352
Rym: It's a lot sooner than that.

173
00:11:37,552 --> 00:11:40,795
Rym: You're weirdly pessimistic about this hardware that you've literally never used.

174
00:11:41,696 --> 00:11:46,360
Scott: Anyway, the point is you're not going to see that thing in people's homes being used frequently.

175
00:11:46,740 --> 00:11:47,741
Scott: Right.

176
00:11:48,061 --> 00:11:48,682
Scott: Anytime soon.

177
00:11:48,802 --> 00:11:51,524
Scott: Anyway, the point is that is a future.

178
00:11:51,845 --> 00:11:52,045
Scott: Right.

179
00:11:52,085 --> 00:11:57,370
Scott: It's like, ah, the future social network will be the one we imagine in cyberpunk world in Snow Crash.

180
00:11:57,410 --> 00:11:57,550
Scott: Right.

181
00:11:57,570 --> 00:12:00,492
Rym: But that already gets away from what a social network has always been.

182
00:12:00,552 --> 00:12:14,904
Rym: Because if a social network is about sharing information, then fire and forget content or fire and forget respond to something like that kind of interaction is the primary way people can share and disseminate information.

183
00:12:15,184 --> 00:12:18,286
Rym: You actually descale if it shrinks back to.

184
00:12:18,787 --> 00:12:22,790
Rym: I'm having a real physical conversation with someone in real time.

185
00:12:23,611 --> 00:12:35,919
Scott: Well, I think the way it lines up is if you think of a social regardless of how you interact in the space, which is obviously drastically different, it's still a space that is not a real world space that people come together in.

186
00:12:36,119 --> 00:12:36,379
Scott: Right.

187
00:12:36,499 --> 00:12:40,782
Scott: But I guess the difference is a real Facebook page is a place people come together in.

188
00:12:40,902 --> 00:12:45,225
Scott: a, you know, a chat room is a place people come from all around the world come together.

189
00:12:45,305 --> 00:12:51,770
Scott: So a virtual roar, you know, room like VR chat is a virtual place that where people come together in.

190
00:12:52,110 --> 00:12:52,270
Rym: Yep.

191
00:12:52,350 --> 00:12:58,577
Rym: I guess this is where we need to differentiate, because social media is almost too broad of a term now, what these spaces are.

192
00:12:58,617 --> 00:13:12,010
Rym: There are spaces where strangers come together and interact via video or via small chat or via throwing 100 page Tumblr posts at each other or via VR or via inside of a video game.

193
00:13:12,110 --> 00:13:23,738
Rym: All these things have very different affordances, very different user experiences, very different externalities that are intrinsic or possibly not necessarily intrinsic, but are made intrinsic by capitalism.

194
00:13:24,178 --> 00:13:31,383
Rym: It's there's so much going on here that it's very almost naive to talk about all of this as just social media at this point.

195
00:13:31,404 --> 00:13:31,904
Rym: Right.

196
00:13:32,144 --> 00:13:38,649
Scott: So the short term news is that a lot of the oculus stuff is no longer going to need a Facebook account.

197
00:13:38,709 --> 00:13:40,490
Scott: I don't know if that's all of it, but at least some of it.

198
00:13:40,770 --> 00:13:40,950
Scott: Yep.

199
00:13:41,731 --> 00:13:43,952
Scott: I know the quest they said is which people.

200
00:13:44,353 --> 00:13:54,140
Rym: people resisted what I posited way back when Facebook said they were getting rid of the oculus brand and requiring everyone who uses oculus, including dev kits to have a Facebook account.

201
00:13:54,580 --> 00:13:57,142
Rym: I remember saying the gaming industry won't stand for this.

202
00:13:57,342 --> 00:14:00,724
Rym: And so far it looks like the gaming industry didn't stand for this.

203
00:14:00,744 --> 00:14:03,246
Rym: People truly did not make Facebook accounts.

204
00:14:03,546 --> 00:14:05,348
Rym: They gave up on the platform instead.

205
00:14:06,268 --> 00:14:08,390
Scott: So they gave up on that, which I guess is a positive.

206
00:14:09,611 --> 00:14:13,717
Scott: The negative, I guess, is that it's still the same fucking Zuck dude running this.

207
00:14:13,737 --> 00:14:15,540
Rym: The problem is not that Facebook exists.

208
00:14:15,560 --> 00:14:22,130
Rym: The problem is that Facebook as an institution makes reliably harmful decisions in its space.

209
00:14:23,150 --> 00:14:42,590
Scott: And as we've seen from all the recent, you know, revealings due to court drama and all these documents that got released about, you know, mostly Facebook, but also others is that, yeah, you know, it's not that they Zuck doesn't seem to have a malicious evil motive only other than just the capitalist motive.

210
00:14:42,710 --> 00:14:42,990
Scott: Right.

211
00:14:43,111 --> 00:14:46,615
Scott: All their decisions seem to the thing that they all have in common.

212
00:14:46,675 --> 00:14:54,304
Scott: It's not like they're always deciding in favor of white supremacy or always deciding in favor of, you know, a good point.

213
00:14:54,584 --> 00:14:55,846
Scott: But here's always just.

214
00:14:55,946 --> 00:14:59,370
Scott: they're always deciding in favor of profits for Facebook.

215
00:14:59,470 --> 00:15:00,051
Scott: That is us.

216
00:15:00,171 --> 00:15:01,974
Rym: Every the externalities.

217
00:15:02,194 --> 00:15:03,116
Rym: How do they get profits?

218
00:15:03,376 --> 00:15:04,238
Rym: via engagement?

219
00:15:04,538 --> 00:15:07,883
Rym: What drives engagement, anger and conspiracy theories?

220
00:15:08,184 --> 00:15:11,990
Rym: Therefore, more anger, more conspiracy theories, more profits.

221
00:15:12,251 --> 00:15:19,630
Scott: But there are instances where they decided against anger and conspiracy theories where it either didn't harm or helped the bottom line.

222
00:15:20,050 --> 00:15:20,330
Rym: Yeah.

223
00:15:20,791 --> 00:15:24,857
Rym: But if it harms that bottom line, they reliably always make right.

224
00:15:25,077 --> 00:15:28,341
Scott: There's a decision between money and safety for the users.

225
00:15:28,381 --> 00:15:30,764
Scott: They choose the money option and don't lose.

226
00:15:31,325 --> 00:15:34,870
Scott: all the stories and anecdotes and all the documents are following that pattern.

227
00:15:35,030 --> 00:15:36,332
Rym: And don't lose and all this shuffle.

228
00:15:36,412 --> 00:15:44,964
Rym: A very important point that all the leaks from within Facebook are showing that there was at no point ignorance involved in this.

229
00:15:45,224 --> 00:15:49,670
Rym: People inside of Facebook at all levels were constantly raising the alarm.

230
00:15:50,250 --> 00:15:51,066
Rym: Like everyone there was smart.

231
00:15:52,350 --> 00:15:52,430
Rym: Yeah.

232
00:15:52,450 --> 00:15:53,273
Rym: They knew what they were doing.

233
00:15:53,293 --> 00:15:55,659
Rym: They're like, look, this is causing white supremacy.

234
00:15:55,719 --> 00:15:57,123
Rym: We need to do something about it.

235
00:15:57,624 --> 00:15:59,650
Rym: And they were just categorically ignored.

236
00:16:00,371 --> 00:16:01,572
Scott: Yep.

237
00:16:01,672 --> 00:16:13,286
Scott: So I guess just the last thing is simply what everyone else is saying is true is like you what you keep trying to recreate this cyberpunk stuff, you know, VR land from all these books.

238
00:16:13,446 --> 00:16:16,330
Scott: But didn't you miss the point that that was a dystopia, right?

239
00:16:16,770 --> 00:16:16,970
Scott: Yeah.

240
00:16:17,271 --> 00:16:18,453
Scott: In that world, not a good thing.

241
00:16:18,754 --> 00:16:19,475
Rym: People went in.

242
00:16:19,516 --> 00:16:20,638
Scott: Why are you trying to make this?

243
00:16:21,179 --> 00:16:24,165
Scott: It's like reading Dante's Inferno and like using it as your playbook.

244
00:16:24,205 --> 00:16:26,189
Scott: It's like, no, that's the wrong one.

245
00:16:29,011 --> 00:16:29,231
Rym: Yep.

246
00:16:29,271 --> 00:16:29,752
Rym: Shadowrun.

247
00:16:29,772 --> 00:16:37,905
Rym: We need big mega corpse and like NFTs and cash cards and like, no, those are all like you read Jurassic Park and you're like, oh, great idea.

248
00:16:37,925 --> 00:16:41,170
Scott: I mean, let me try to make some T-Rexes and velociraptors.

249
00:16:42,533 --> 00:16:43,489
Rym: What book did you read?

250
00:16:44,050 --> 00:16:50,402
Rym: Are the nerds whose reaction to Jurassic Park was, ah, that park would have been great if Nedry hadn't fucked it all up.

251
00:16:50,482 --> 00:16:54,910
Rym: Like how to imagine missing the point of that movie so badly.

252
00:16:55,091 --> 00:16:58,130
Scott: But Zuck is Nedry, the in charge guy.

253
00:17:02,191 --> 00:17:03,313
Rym: So what do you think is going to happen?

254
00:17:03,613 --> 00:17:06,998
Rym: I think like my guess, my pure guess is the one thing that's going to happen.

255
00:17:07,638 --> 00:17:15,550
Rym: Facebook, the platform, like the social media platform is going to see fewer and fewer updates, less engagement and just decline into nothing over time.

256
00:17:17,191 --> 00:17:18,111
Scott: I think a lot.

257
00:17:18,852 --> 00:17:26,540
Scott: I can't predict what's going to happen, but I can say that it depends on what action governments take.

258
00:17:26,579 --> 00:17:27,641
Scott: But I can't predict that.

259
00:17:27,800 --> 00:17:28,422
Scott: So I don't.

260
00:17:28,502 --> 00:17:28,742
Scott: Right.

261
00:17:29,003 --> 00:17:37,892
Scott: Because if if there are antitrust actions that actually come into play, which is right now, I'd say 50/50.

262
00:17:37,892 --> 00:17:39,850
Rym: Vote for Democrats if you want more of that, guys.

263
00:17:40,730 --> 00:17:41,832
Scott: Yeah, which I do.

264
00:17:41,992 --> 00:17:42,152
Scott: Right.

265
00:17:42,192 --> 00:17:43,835
Scott: So let's say let's say I get my way.

266
00:17:44,095 --> 00:17:44,296
Scott: Right.

267
00:17:44,336 --> 00:17:53,569
Scott: So if the best possible thing happens, the government breaks up Facebook and all the other companies, all the big tech companies into their component products.

268
00:17:54,050 --> 00:17:54,190
Scott: Right.

269
00:17:54,250 --> 00:17:58,416
Scott: So Amazon, the store is now separate from Oz, the computers.

270
00:17:58,696 --> 00:17:59,017
Scott: Right.

271
00:17:59,417 --> 00:18:00,859
Scott: It's a big AT&T breakup.

272
00:18:01,120 --> 00:18:01,921
Scott: And right.

273
00:18:01,941 --> 00:18:03,603
Scott: Because we're saying this is Scott's favorite.

274
00:18:03,684 --> 00:18:04,505
Scott: Right.

275
00:18:04,585 --> 00:18:07,749
Scott: We don't make the mistake of letting them join together again, like we did with AT&T.

276
00:18:08,310 --> 00:18:08,751
Scott: Whatever.

277
00:18:08,951 --> 00:18:09,512
Rym: Oh, my God.

278
00:18:09,532 --> 00:18:20,550
Rym: Scott, I know you don't like Star Trek, but so the new Lower Decks show, they address this directly in that in old Star Trek, there was an episode where there's a planet that was destroying itself and everyone was stupid.

279
00:18:21,070 --> 00:18:22,213
Rym: And they worshiped a god.

280
00:18:22,233 --> 00:18:22,715
Scott: Sounds like Earth.

281
00:18:22,835 --> 00:18:23,096
Scott: OK.

282
00:18:23,176 --> 00:18:26,345
Rym: And that God was actually just a leftover computer A.I.

283
00:18:26,405 --> 00:18:28,330
Rym: that was telling them to do bad things for its own purposes.

284
00:18:28,851 --> 00:18:38,610
Rym: So in Lower Decks, there's an episode where the plot is Starfleet, like 100 years later, goes back to this planet because they fucking started worshiping that computer again.

285
00:18:42,051 --> 00:18:43,675
Rym: That is literally the plot of the episode.

286
00:18:43,715 --> 00:18:46,222
Rym: Like, guys, what did we fucking tell you?

287
00:18:46,342 --> 00:18:46,703
Rym: It's it's.

288
00:18:46,903 --> 00:18:49,310
Rym: it's actually really funny how it plays out.

289
00:18:50,851 --> 00:18:53,776
Scott: I'm just imagining them worshiping the computer in the Twilight Zone again.

290
00:18:54,137 --> 00:18:55,239
Rym: That's the same one.

291
00:18:55,279 --> 00:18:56,602
Rym: Like, don't eat the food.

292
00:18:56,662 --> 00:18:57,604
Scott: It's radioactive.

293
00:18:57,644 --> 00:18:58,406
Rym: Fuck you, Dad.

294
00:18:58,426 --> 00:18:59,267
Rym: I do what I want.

295
00:18:59,328 --> 00:18:59,628
Rym: Exactly.

296
00:19:01,990 --> 00:19:06,619
Rym: I hate I hate how relevant Twilight Zone episodes are at every stage of my life.

297
00:19:07,200 --> 00:19:07,340
Scott: Right.

298
00:19:07,420 --> 00:19:11,208
Scott: So if that all if that all happens, I could actually see it.

299
00:19:13,211 --> 00:19:15,294
Scott: I guess it then depends who runs it.

300
00:19:15,414 --> 00:19:16,516
Rym: Two things have to happen.

301
00:19:16,756 --> 00:19:21,103
Rym: The breakup has to be such that no one of these companies is too powerful to.

302
00:19:21,744 --> 00:19:26,050
Rym: Zuckerberg himself cannot be in charge of any of these companies.

303
00:19:26,731 --> 00:19:28,434
Scott: Well, or more than one, at least.

304
00:19:28,535 --> 00:19:28,875
Scott: Yeah.

305
00:19:29,136 --> 00:19:35,530
Rym: But it probably go for the VR one, knowing the problem is the VR one is the one that I think has the most long term real potential.

306
00:19:35,991 --> 00:19:39,956
Rym: But it's also I think that I think will work.

307
00:19:40,197 --> 00:19:43,802
Scott: So the two things that they you know, there's a lot of things they acquired.

308
00:19:43,902 --> 00:19:49,450
Scott: But Facebook, Instagram and WhatsApp are both right now really meh.

309
00:19:49,790 --> 00:19:49,991
Scott: Right.

310
00:19:50,031 --> 00:19:51,594
Scott: Instagram got turned into Sky Mall.

311
00:19:52,155 --> 00:19:53,919
Scott: And WhatsApp is who knows.

312
00:19:53,939 --> 00:19:57,305
Rym: WhatsApp is how I communicate with old people.

313
00:19:57,406 --> 00:19:59,350
Rym: I know I don't have it.

314
00:19:59,911 --> 00:20:01,433
Rym: I have because of some people I know.

315
00:20:01,794 --> 00:20:10,970
Scott: While both of those are really meh right now, I actually believe that if though like if you made me in charge of Instagram or WhatsApp right now, they could be saved.

316
00:20:11,350 --> 00:20:15,619
Scott: Those are things that are not beyond saving Facebook.

317
00:20:15,999 --> 00:20:21,070
Scott: The only reason I think Facebook itself, Facebook Marketplace could be its own thing that could be saved.

318
00:20:21,671 --> 00:20:24,537
Scott: It's starting to have some scam problems and falling a bit.

319
00:20:25,679 --> 00:20:30,610
Scott: But Facebook, the social network, you know, events, groups, that sort of thing.

320
00:20:31,530 --> 00:20:42,090
Scott: I think the old any measure that would save it would actually kill it because because capital is just going to you're just going to scare people away and they'll go to some other thing.

321
00:20:42,432 --> 00:20:45,509
Scott: And there's no one who would use even a saved.

322
00:20:46,130 --> 00:20:47,752
Rym: Well, here's a very important point.

323
00:20:47,772 --> 00:20:49,334
Rym: Look what's happening on all social media.

324
00:20:49,874 --> 00:21:04,410
Rym: If you actually ban bad actors like the horse paced people, white supremacists, Republicans, et cetera, when you actually ban those people from platforms, then they migrate and mass to whatever platform will let them do their crap and they keep on going.

325
00:21:05,510 --> 00:21:09,155
Rym: But they are segregated from the better platform at that point.

326
00:21:09,715 --> 00:21:22,270
Rym: But without those people, these platforms can't make money because the money is driven by all these toxic engagements because the only way any of these things make money is selling your data and or selling ads to you via that data.

327
00:21:23,090 --> 00:21:29,860
Scott: There's also the side effect, right, which I think we've talked about in the past of the people who are more likely to be.

328
00:21:29,900 --> 00:21:37,370
Scott: that kind of horrible person who believes in, say, a conspiracy theory is also a more gullible person who is more vulnerable to ads.

329
00:21:37,991 --> 00:21:38,211
Scott: Right.

330
00:21:38,251 --> 00:21:43,436
Scott: You can write, you know, you look at the alignment of scams, you know, fake medicine scams.

331
00:21:43,537 --> 00:21:43,997
Scott: All right.

332
00:21:44,377 --> 00:21:46,199
Scott: And milking those people for money.

333
00:21:46,219 --> 00:21:51,746
Scott: And it's like you make more money off having that kind of horrible person as your customer.

334
00:21:51,966 --> 00:21:55,790
Scott: If you have me as your customer, I block all your ads and I don't buy a damn thing.

335
00:21:55,951 --> 00:21:56,213
Rym: Yep.

336
00:21:56,253 --> 00:21:57,461
Rym: You give me a free to play game.

337
00:21:57,602 --> 00:21:58,649
Rym: I play it for free.

338
00:21:59,690 --> 00:22:00,013
Scott: That's right.

339
00:22:00,093 --> 00:22:02,130
Scott: I don't ever pay for single microtransactions.

340
00:22:02,810 --> 00:22:05,092
Rym: So here's why government has to step in.

341
00:22:05,433 --> 00:22:17,604
Rym: The problem is the ad revenue will follow the worst content for all the reasons we described, unless there are laws and regulations that ban those ads and or that content.

342
00:22:17,944 --> 00:22:24,130
Rym: Because if you remove that, you remove the moral hazard from a company to even go after that business in the first place.

343
00:22:24,471 --> 00:22:29,150
Rym: If the white supremacists aren't making you money, even the evil company will kick them off their platform.

344
00:22:30,336 --> 00:22:30,450
Scott: Yep.

345
00:22:30,850 --> 00:22:38,470
Rym: And the only platform that will keep them is the the actively pro white supremacist platform as opposed to the pro money at all cost platform.

346
00:22:40,214 --> 00:22:40,516
Scott: All right.

347
00:22:40,536 --> 00:22:41,928
Scott: Well, so that's, you know.

348
00:22:42,458 --> 00:22:42,586
Rym: Yep.

349
00:22:42,810 --> 00:22:46,870
Scott: He basically told everyone his plan with the typical evil villain presentation.

350
00:22:48,097 --> 00:22:49,290
Rym: So I can say one thing.

351
00:22:49,531 --> 00:22:52,482
Scott: You can't complain that the evil villain didn't tell us what they were up to.

352
00:22:52,522 --> 00:22:54,590
Scott: We just don't have a Superman to go punch him in the face.

353
00:22:55,371 --> 00:22:55,472
Rym: Yep.

354
00:22:55,734 --> 00:22:57,788
Scott: So I think to see what we can do.

355
00:22:58,290 --> 00:23:11,729
Rym: But in this space, what we're going to see, too, is I think the platform is not going to succeed with a lot of developers because so far I follow and talk to a lot of VR developers just because that's the thing I'm very interested in.

356
00:23:12,750 --> 00:23:20,050
Rym: Categorically, they have all said things over the last week to the effect of you can't fool me, Facebook, meta is just Facebook.

357
00:23:20,530 --> 00:23:21,664
Rym: I'm waiting this one out.

358
00:23:24,032 --> 00:23:25,785
Scott: So even if they have the best hardware, that's not.

359
00:23:25,866 --> 00:23:26,390
Scott: it's not enough.

360
00:23:26,630 --> 00:23:26,759
Rym: Right.

361
00:23:26,781 --> 00:23:26,845
Rym: Yep.

362
00:23:27,451 --> 00:23:28,221
Scott: Betamax was better.

363
00:23:28,322 --> 00:23:28,869
Scott: It wasn't enough.

364
00:23:29,191 --> 00:23:29,452
Rym: Yep.

365
00:23:29,714 --> 00:23:32,330
Rym: The best product is not how you make money in a capitalist society.

366
00:23:32,832 --> 00:23:33,742
Rym: And some other minor news.

367
00:23:33,782 --> 00:23:34,490
Rym: We'll just link to this.

368
00:23:34,650 --> 00:23:37,030
Rym: But this is not as scary as it seems.

369
00:23:37,270 --> 00:23:39,310
Rym: It's only theoretical, but it's worth talking about briefly.

370
00:23:40,551 --> 00:23:55,970
Rym: This article is making the rounds like yesterday and today of vulnerability in compilers, meaning malicious code could be presented in a way that appears nonmalicious until it's compiled and then it becomes malicious.

371
00:23:56,530 --> 00:24:06,670
Rym: And the vulnerability has to do with, of all things, Unicode encoding of text in regard to left to right versus right to left text specifically.

372
00:24:06,831 --> 00:24:10,710
Scott: This is one of those, you know, old tricks, right, where someone sends you a link.

373
00:24:10,870 --> 00:24:12,650
Scott: It looks like Chase Bank dot com.

374
00:24:12,830 --> 00:24:18,630
Rym: But actually, the A is Cyrillic character and the E is like some Estonian Cyrillic adjacent character.

375
00:24:19,371 --> 00:24:19,612
Scott: Yep.

376
00:24:19,692 --> 00:24:24,809
Scott: Because they're using Unicode characters, your eyeballs look at your screen and your font renders it.

377
00:24:25,131 --> 00:24:27,570
Scott: And it looks like the word you think it is, but it's a different word.

378
00:24:27,710 --> 00:24:41,488
Scott: So you can mess with source code in such a way using Unicode right to left characters and whatnot, so that when a human being reviews the code and the pull request with their eyes, that what they see looks like correct code.

379
00:24:41,528 --> 00:24:43,030
Scott: that's going to do what you said it does.

380
00:24:43,472 --> 00:24:47,549
Scott: And they run it through their compiler to compile it and then test it.

381
00:24:48,271 --> 00:24:49,974
Scott: And now it's right.

382
00:24:50,094 --> 00:24:59,710
Scott: if you somehow have, you know, affected the compiler in such a way you have, you know, got some sort of security flaw on their computer of the person testing the code, at least.

383
00:25:00,191 --> 00:25:07,970
Scott: And if that code actually gets deployed, well, that you know, because it you know, it'd be really hard to get the code to also pass the unit tests if anyone tried to test the functionality.

384
00:25:08,654 --> 00:25:09,785
Scott: But if you could do that, whoa.

385
00:25:10,735 --> 00:25:12,029
Scott: You get that code deployed everywhere.

386
00:25:12,650 --> 00:25:22,570
Rym: The net result is actually exploiting this particular vulnerability seems to be about as difficult as exploiting when hash collisions are discovered in a lot of algorithms.

387
00:25:23,132 --> 00:25:25,710
Scott: It's pretty difficult to actually pull this off.

388
00:25:25,810 --> 00:25:35,510
Scott: It's just an interesting theoretical possibility that the old Unicode trick of fooling people's eyes could apply to this sort of situation and not just a normal old phishing situation.

389
00:25:35,550 --> 00:25:46,370
Rym: But the good news is the real story in this article is that researchers identified the possibility before there appear to have ever been actual practical exploits using this.

390
00:25:46,770 --> 00:25:52,890
Rym: And because it was theoretically understood, it is now being patched broadly to prevent this particular attack.

391
00:25:53,230 --> 00:26:04,470
Rym: So it's a success of security research as primary academic research, as opposed to the more common method of find vulnerabilities in the wild and then go patch them.

392
00:26:04,550 --> 00:26:09,221
Scott: Yeah, it shouldn't be too hard for a compiler to prevent this from doing anything bad, right?

393
00:26:09,241 --> 00:26:12,749
Scott: Just detect the characters that flip from right to left and then, you know.

394
00:26:13,675 --> 00:26:14,589
Rym: The old bite eyes.

395
00:26:15,590 --> 00:26:15,683
Scott: Yeah.

396
00:26:17,191 --> 00:26:18,523
Scott: OK, so one more news.

397
00:26:20,510 --> 00:26:21,110
Scott: Yeah, just quickly.

398
00:26:21,730 --> 00:26:28,550
Scott: So we could probably talk a whole lot about Roblox itself, which is a whole thing if you're not aware about the Roblox phenomenon.

399
00:26:28,610 --> 00:26:32,059
Rym: Which I'm curious, let us know, do you know what Roblox is or not?

400
00:26:32,119 --> 00:26:35,829
Rym: Because I've found that people younger than us know what it is.

401
00:26:37,133 --> 00:26:42,910
Rym: People who are older than us who don't have kids have never heard of it or think it's a game and literally don't know the rest.

402
00:26:43,050 --> 00:26:43,890
Scott: It is a game, kind of.

403
00:26:43,951 --> 00:26:44,509
Scott: I mean, yeah, it is.

404
00:26:44,810 --> 00:26:53,170
Scott: It's a strange, it's a really unique thing that is simultaneously amazing and also garbage and child exploitation all at once.

405
00:26:54,871 --> 00:27:01,770
Scott: So, but regardless, they had this enormous outage for something that has so many users and is such a big system.

406
00:27:02,291 --> 00:27:07,466
Scott: It was down for like more than 24 hours, like a very large number of hours.

407
00:27:07,546 --> 00:27:09,030
Scott: It was out and it's like out.

408
00:27:09,330 --> 00:27:18,950
Rym: And the funniest thing is a lot of people would have no idea this happened because none of this news would even except every child on earth who has wealthy enough to have a computer or an iPad or something.

409
00:27:19,291 --> 00:27:30,690
Rym: Oh my god, I found a Twitter thread where someone compiled, like it was a bot finding all these people who looked like parents asking what the fuck Roblox is and why their kids are screaming and crying and flipping out.

410
00:27:31,691 --> 00:27:31,871
Scott: Yep.

411
00:27:32,733 --> 00:27:39,750
Scott: And also, the thing is that the children who are using Roblox, right, are not on Twitter.

412
00:27:40,393 --> 00:27:41,889
Rym: Yeah, Twitter's for old people, guys.

413
00:27:42,731 --> 00:27:50,850
Scott: I'm just saying, any social broadcasting thing, it's like, you know, I guess not until you're more teens are you even using that, right?

414
00:27:51,830 --> 00:27:57,270
Scott: You know, because even if you're an eight year old and even if your parents let you use Twitter, you're not tweeting.

415
00:27:58,092 --> 00:28:00,290
Scott: They let you use Facebook or Instagram or whatever.

416
00:28:01,031 --> 00:28:08,390
Scott: Maybe you'd have fun with filters and photos and Instagram, but, you know, I don't think an eight year old is going to be like, you know, posting on Instagram.

417
00:28:08,491 --> 00:28:11,526
Scott: Why is Roblox down and searching on Instagram for Roblox?

418
00:28:11,586 --> 00:28:12,270
Scott: Why is it down?

419
00:28:12,550 --> 00:28:17,190
Rym: I feel like when I was maybe not when I was eight, but I was like talking to their friends on Instagram.

420
00:28:17,830 --> 00:28:19,658
Rym: Ten to twelve is when I would be doing that kind of stuff.

421
00:28:19,718 --> 00:28:22,390
Rym: Had that even existed or been a possibility at the time.

422
00:28:22,830 --> 00:28:23,171
Scott: Right.

423
00:28:23,232 --> 00:28:28,150
Scott: But, you know, I don't think that, you know, broadcast information, you know, like kids are probably aren't just reading the news.

424
00:28:28,250 --> 00:28:30,098
Scott: So why would you be interested in, you know, news?

425
00:28:30,359 --> 00:28:30,620
Scott: Right.

426
00:28:30,741 --> 00:28:32,890
Scott: It's like, I don't know.

427
00:28:33,110 --> 00:28:35,906
Scott: There is a eight year old going on forums somewhere.

428
00:28:35,987 --> 00:28:36,530
Scott: There's a forum.

429
00:28:36,590 --> 00:28:37,553
Rym: You know what they are doing?

430
00:28:37,613 --> 00:28:43,010
Rym: So they are streaming the Roblox crap on Twitch and YouTube, usually with accounts, probably a lot.

431
00:28:43,210 --> 00:28:48,110
Scott: Yes, but not in any of the places where like this information broadcasting going on.

432
00:28:48,210 --> 00:28:48,350
Scott: Right.

433
00:28:48,390 --> 00:28:51,315
Scott: The only news story that gets broadcast is Roblox is down.

434
00:28:51,395 --> 00:28:59,970
Scott: But you can't see the actual terror and, you know, you know, pain that that outage caused.

435
00:28:59,970 --> 00:29:02,618
Rym: These kids were losing money to the Internet.

436
00:29:02,739 --> 00:29:06,190
Rym: These kids are paying for ads for the games they make.

437
00:29:06,690 --> 00:29:06,951
Rym: They have.

438
00:29:06,971 --> 00:29:12,830
Rym: there's a whole like real money ecosystem around Roblox that a lot of parents don't think even realizes there.

439
00:29:13,411 --> 00:29:15,870
Scott: There's a lot when they check their credit card statement.

440
00:29:16,090 --> 00:29:16,251
Rym: Yeah.

441
00:29:16,411 --> 00:29:21,488
Rym: Or they will now because little Johnny was flipping the fuck out that Roblox was down for more than 24 hours.

442
00:29:22,730 --> 00:29:26,282
Scott: Also, if you have to get a gift for some kid, you know, you buy you can.

443
00:29:26,362 --> 00:29:28,850
Scott: I think you can buy like a Robux gift card at the drugstore.

444
00:29:28,870 --> 00:29:31,949
Rym: Pretty sure you can just buy Roblox bucks with cash.

445
00:29:33,090 --> 00:29:36,769
Scott: Almost any almost any kid's going to love some Robux as a gift this holiday season.

446
00:29:38,192 --> 00:29:39,616
Rym: Oh, this article is spot on.

447
00:29:40,841 --> 00:29:43,590
Rym: Roblox is valued at almost 30 billion pounds.

448
00:29:43,971 --> 00:29:48,370
Rym: Yet these child workers see only a fraction of that money as their labor drives its valuation up.

449
00:29:49,311 --> 00:29:57,452
Scott: If you make content for Roblox and then someone buys your content that you made, you split it with the Roblox company 3070.

450
00:29:57,452 --> 00:29:57,854
Rym: That's worse.

451
00:29:57,874 --> 00:30:02,431
Rym: They they get the 70.

452
00:30:02,431 --> 00:30:05,478
Scott: It's people are complaining about Apple getting the 30.

453
00:30:05,478 --> 00:30:10,790
Scott: Roblox gets the 70 70 and children made something.

454
00:30:10,850 --> 00:30:13,796
Scott: So it's a child labor producing a digital work.

455
00:30:14,257 --> 00:30:20,670
Scott: It sells the child gets 30 percent of the revenues from the sale and the company gets 70.

456
00:30:20,670 --> 00:30:20,951
Rym: Yep.

457
00:30:21,632 --> 00:30:22,393
Scott: That's all right.

458
00:30:22,713 --> 00:30:33,388
Rym: I don't think we saw yet what the cause of the outage was, but it's interesting because this I don't think Roblox has ever had a major outage before, at least not since it got really big.

459
00:30:33,629 --> 00:30:34,329
Rym: that I'm aware of.

460
00:30:35,210 --> 00:30:37,435
Scott: So I think it's also just unique in like.

461
00:30:37,976 --> 00:30:44,350
Scott: when in history have like, you know, it's not like Tickle Me Elmo has like an outage or a child's favorite toy.

462
00:30:44,471 --> 00:30:46,421
Scott: All our NES is didn't simultaneously have.

463
00:30:46,883 --> 00:30:48,170
Scott: I remember playing Nintendo.

464
00:30:48,711 --> 00:30:56,650
Rym: I remember when broadcast TV like like one of the networks went down in Detroit for like days.

465
00:30:56,971 --> 00:30:57,514
Rym: We just couldn't.

466
00:30:57,574 --> 00:30:58,920
Rym: One of the channels was just gone.

467
00:30:59,442 --> 00:31:00,205
Rym: That was an existential.

468
00:31:00,225 --> 00:31:01,270
Scott: You got other channels, though.

469
00:31:01,630 --> 00:31:02,774
Rym: Yeah, like six of them.

470
00:31:02,794 --> 00:31:07,188
Rym: It was it was the ladies like hurt that many channels back then.

471
00:31:08,371 --> 00:31:17,070
Scott: I'm just saying it's, you know, but there isn't a case for like every kid, you know, so many kids like everyone's same favorite toy all broke at the same time.

472
00:31:17,210 --> 00:31:18,152
Scott: Nobody could play.

473
00:31:18,533 --> 00:31:18,794
Rym: I do.

474
00:31:18,914 --> 00:31:25,489
Rym: All bicycles just stopped working when the BBS that I got my pirated games from when I was very young, dialing into disappeared.

475
00:31:26,252 --> 00:31:28,989
Rym: I guess I don't know if I got raided or whatever, but it got shut down.

476
00:31:29,832 --> 00:31:35,570
Rym: That was how I found all the other nerds in my school, because when I got into school, some people were talking about that.

477
00:31:35,711 --> 00:31:38,209
Rym: But most people had no idea what the fuck that was.

478
00:31:38,571 --> 00:31:45,390
Rym: And I actually made a bunch of friends by figuring out who else was using that anonymous, pirating BBS in my neighborhood.

479
00:31:46,510 --> 00:31:47,533
Rym: Anyway, one last news.

480
00:31:48,174 --> 00:32:04,330
Rym: And I talk about this on a Monday because something that technology people, especially computer types, people who do the kind of jobs that me and Scott do really need to internalize is that the main value of technology is not developing the next new technology.

481
00:32:04,751 --> 00:32:13,210
Rym: The main value of technology is taking existing technology and deploying it in more places, more fairly and more equitably.

482
00:32:13,897 --> 00:32:15,050
Scott: And more wisely.

483
00:32:15,570 --> 00:32:16,331
Rym: Yes, more wisely.

484
00:32:16,852 --> 00:32:20,016
Rym: That impacts people more than any new technology.

485
00:32:20,096 --> 00:32:31,010
Rym: Making Facebook better will not impact nearly as many people as making more trains or making more clean water or taking an old vaccine and getting it in more people's hands.

486
00:32:31,730 --> 00:32:33,609
Rym: So a story that just happened.

487
00:32:34,150 --> 00:32:34,252
Scott: Veins.

488
00:32:34,475 --> 00:32:34,820
Scott: Veins.

489
00:32:35,084 --> 00:32:35,429
Scott: Arteries.

490
00:32:35,771 --> 00:32:35,952
Rym: Yep.

491
00:32:36,475 --> 00:32:39,570
Rym: This is a huge story in New York City.

492
00:32:40,150 --> 00:33:00,470
Rym: The Long Island Railroad now has the ability for its trains to terminate, not just in Penn Station, which is out of the way and sucks shit, but also in Grand Central Terminal, one of the most used and most important train stations in the history of the goddamn world.

493
00:33:01,033 --> 00:33:04,550
Rym: Central to New York City, the best train station we got.

494
00:33:05,550 --> 00:33:19,770
Rym: It is the amount of economic loss from people taking Long Island Railroad trains to Penn Station only to then have to transit back to Grand Central to get to the place they were trying to get to, to connect to the rest of the transportation infrastructure more reliably.

495
00:33:20,551 --> 00:33:25,410
Rym: Just investing in what it took to make these trains go to one different place.

496
00:33:25,893 --> 00:33:28,589
Rym: This is a story that is decades in the making.

497
00:33:29,111 --> 00:33:38,970
Scott: When we graduated college, right, and I was working in, right, I would take the train to Grand Central every day, work day, right, to come to work.

498
00:33:39,671 --> 00:33:42,660
Scott: And they were like, yeah, we're going to do this project.

499
00:33:42,701 --> 00:33:45,510
Scott: So that was a fucking 6, 15 plus years ago.

500
00:33:46,090 --> 00:33:51,534
Scott: It's like this was proposed in 1963.

501
00:33:51,534 --> 00:33:53,050
Scott: When did they actually start digging, though?

502
00:33:53,332 --> 00:33:55,129
Rym: Oh, not so actually a long time.

503
00:33:55,270 --> 00:33:56,189
Scott: More than 10 years ago.

504
00:33:56,450 --> 00:33:57,669
Rym: Definitely more than 10 years ago.

505
00:33:58,090 --> 00:34:02,110
Rym: The story is so long that I'm struggling to scroll through this fast enough to actually find all the milestones.

506
00:34:03,431 --> 00:34:03,694
Scott: Right.

507
00:34:03,714 --> 00:34:05,269
Scott: But yeah, they ran a train.

508
00:34:06,030 --> 00:34:12,050
Scott: You know, it's not ready yet, but they ran a train with passengers from Long Island to Grand Central.

509
00:34:12,272 --> 00:34:12,737
Scott: It made it.

510
00:34:12,838 --> 00:34:14,130
Scott: They got off at Grand Central.

511
00:34:14,469 --> 00:34:20,790
Scott: Then they walked out to the street and it's going to be available to everybody next year at some point.

512
00:34:20,949 --> 00:34:21,914
Rym: OK, so they start.

513
00:34:21,934 --> 00:34:26,989
Rym: they started work and supposedly they started work in the 70s in 1975.

514
00:34:26,989 --> 00:34:31,043
Rym: They canceled the whole thing because New York City was out of money in the 90s, 1990s.

515
00:34:32,750 --> 00:34:48,809
Rym: So the late nineteen hundreds, a new set of studies showed that the majority of all Long Island railroad riders, which is one of the most used rail lines in the world, were trying to get somewhere closer to Grand Central than Defense Station.

516
00:34:50,851 --> 00:35:03,090
Scott: There's more places of employment near 42nd and Lex than there are on 34th and like, you know, you go behind the Madden Square Garden unless you're working at the post office.

517
00:35:03,211 --> 00:35:04,416
Scott: I don't know where you go.

518
00:35:04,537 --> 00:35:07,350
Scott: It's like there's no big, tall office buildings back there.

519
00:35:07,750 --> 00:35:16,250
Rym: To build this new terminal under Grand Central Terminal was one of the larger engineering projects in New York City's history.

520
00:35:16,851 --> 00:35:19,235
Rym: And the scale is enormous.

521
00:35:19,295 --> 00:35:25,587
Rym: The scale and the work involved in the 11 billion dollars is this was using mostly 1970s technology.

522
00:35:28,710 --> 00:35:31,290
Scott: Let me dig a tunnel, play a train track, put a signal.

523
00:35:32,130 --> 00:35:35,310
Rym: The technology to lay tunnels has been largely perfected.

524
00:35:36,030 --> 00:35:42,370
Rym: The boring company has not really done anything novel in this regard because that is not the problem.

525
00:35:42,511 --> 00:35:47,090
Rym: Just like how tech bros like to say, oh, I made a machine that can 3D print houses faster.

526
00:35:47,590 --> 00:35:47,711
Rym: Yeah.

527
00:35:47,811 --> 00:35:51,470
Rym: Building houses physically is not the bottleneck on housing people.

528
00:35:52,890 --> 00:35:57,946
Rym: You don't say we could build houses for everyone in the world pretty much instantly if we wanted to.

529
00:35:58,006 --> 00:35:59,210
Rym: That is far from the problem.

530
00:35:59,771 --> 00:36:03,164
Scott: So let's let's let's just end this news section with a piece of shit.

531
00:36:03,184 --> 00:36:04,750
Scott: news I saw today about piece of shit.

532
00:36:04,850 --> 00:36:05,872
Scott: Ellen Musk.

533
00:36:06,634 --> 00:36:09,801
Scott: The headline I saw said U.N.

534
00:36:10,302 --> 00:36:14,030
Scott: says they could feed all the hungry people if they just had like eight billion.

535
00:36:14,490 --> 00:36:14,992
Scott: Right.

536
00:36:15,233 --> 00:36:16,236
Scott: And piece of shit.

537
00:36:16,296 --> 00:36:20,250
Scott: Ellen Musk, you know, he could have said, here's the eight billion.

538
00:36:20,651 --> 00:36:20,872
Scott: Right.

539
00:36:21,113 --> 00:36:22,077
Scott: I'm just going to give it to you.

540
00:36:22,257 --> 00:36:25,190
Rym: He wouldn't even notice having that losing that eight bill.

541
00:36:25,791 --> 00:36:26,353
Scott: Of course not.

542
00:36:26,373 --> 00:36:27,155
Scott: But you know what he said?

543
00:36:27,175 --> 00:36:31,670
Scott: He said, prove it to me and I'll sell Tesla stock and give you eight billion.

544
00:36:32,531 --> 00:36:35,650
Scott: It's like, yeah, prove it to me means you're not going to fucking do it.

545
00:36:35,931 --> 00:36:39,930
Scott: What is going to be one of those things where, like, yeah, there is no proof, right, that he would accept.

546
00:36:40,351 --> 00:36:41,294
Scott: He's just being an asshole.

547
00:36:41,335 --> 00:36:45,250
Rym: Well, you know, if they proved it to him, he just called them pedophiles and not give them the money anyway.

548
00:36:45,950 --> 00:36:46,151
Scott: Right.

549
00:36:46,191 --> 00:36:46,532
Scott: Exactly.

550
00:36:46,592 --> 00:36:53,730
Scott: And also, I'd like to point out none of the other billionaires are, you know, giving eight billion either so they can all go fuck themselves as well.

551
00:36:54,270 --> 00:36:59,669
Scott: If I had eight billion, even if eight billion was literally all the dollars I had, I'd be like, here you go.

552
00:37:00,492 --> 00:37:00,653
Rym: Yep.

553
00:37:00,915 --> 00:37:03,248
Scott: I have zero dollars now, but there's no hungry people on earth.

554
00:37:03,288 --> 00:37:03,610
Scott: So cool.

555
00:37:03,850 --> 00:37:04,192
Rym: Eight billion.

556
00:37:04,433 --> 00:37:04,855
Rym: The U.S.

557
00:37:04,875 --> 00:37:08,070
Rym: Congress could just add that to the budget and not notice.

558
00:37:09,112 --> 00:37:09,293
Scott: Yep.

559
00:37:10,421 --> 00:37:11,025
Scott: And they don't either.

560
00:37:11,085 --> 00:37:11,649
Scott: So fuck them, too.

561
00:37:12,010 --> 00:37:12,150
Rym: Yeah.

562
00:37:12,591 --> 00:37:13,193
Rym: Well, fuck.

563
00:37:13,253 --> 00:37:19,188
Rym: in particular, the forty one Republican senators that themselves represent 20 percent of Americans.

564
00:37:20,230 --> 00:37:23,545
Scott: I think even if like, oh, yeah, they're dead.

565
00:37:23,585 --> 00:37:24,570
Rym: They're definitely.

566
00:37:27,273 --> 00:37:28,656
Scott: If every single U.S.

567
00:37:28,676 --> 00:37:34,490
Scott: senator was a clone of Chuck Schumer, I don't think you would get the eight billion for the starving people either.

568
00:37:34,850 --> 00:37:35,193
Rym: I don't know.

569
00:37:35,596 --> 00:37:37,150
Rym: I bet you could get the eight billion for the starving people.

570
00:37:37,150 --> 00:37:42,550
Scott: You would need a hundred AOCs in the Senate or sixty something, whatever the number is.

571
00:37:49,741 --> 00:37:52,107
Rym: But anyway, things of the day.

572
00:37:52,208 --> 00:37:55,276
Rym: So I think this is old, but I found out about it recently.

573
00:37:55,738 --> 00:37:56,600
Rym: It's called Orbis.

574
00:37:57,161 --> 00:37:59,126
Rym: It is a free online Web site thing.

575
00:37:59,808 --> 00:38:04,500
Rym: It's basically Google Maps directions for ancient Rome.

576
00:38:05,220 --> 00:38:13,579
Rym: You choose the season, the modes of transportation, what you're prioritizing, like speed versus economy versus security, et cetera.

577
00:38:14,340 --> 00:38:15,249
Scott: Avoiding barbarians.

578
00:38:15,270 --> 00:38:16,260
Scott: Yeah, I was going to say security.

579
00:38:16,741 --> 00:38:19,007
Rym: It'll outline like how much will it cost?

580
00:38:19,228 --> 00:38:20,371
Rym: How long will it take you?

581
00:38:20,391 --> 00:38:23,700
Rym: It's it's surprisingly thorough.

582
00:38:24,222 --> 00:38:28,640
Rym: This application, this is I've been playing with this for a couple of days now.

583
00:38:28,920 --> 00:38:31,250
Rym: It is really, really fucking neat.

584
00:38:31,752 --> 00:38:33,460
Scott: And also needs to make a game on that.

585
00:38:33,841 --> 00:38:34,122
Rym: Oh, yeah.

586
00:38:34,162 --> 00:38:34,604
Rym: You could build it.

587
00:38:34,625 --> 00:38:37,800
Rym: You could build a game just on top of this data, like straight up.

588
00:38:37,880 --> 00:38:39,124
Rym: And it would probably be great.

589
00:38:39,806 --> 00:38:44,220
Rym: In fact, I'm not going to say anything because I know I'm not going to do it.

590
00:38:44,300 --> 00:38:44,682
Rym: Never mind.

591
00:38:45,505 --> 00:38:46,489
Rym: OK, so what do you got?

592
00:38:46,610 --> 00:38:49,080
Scott: So here's a really cool Web site called Famicom Party.

593
00:38:49,281 --> 00:38:56,700
Scott: And someone's writing a book basically on how to make an NES and NES game in scratch from assembly in assembly.

594
00:38:57,560 --> 00:39:02,580
Scott: So there's a lot of stuff out there about making games for NES and lots of old hardware.

595
00:39:03,541 --> 00:39:06,733
Scott: And since the hardware is much simpler, doing it in assembly is feasible.

596
00:39:06,793 --> 00:39:08,479
Scott: In fact, that's what they did it in back in the day.

597
00:39:09,862 --> 00:39:12,700
Scott: But a lot of times, you know, you're going to use other tools, right?

598
00:39:12,821 --> 00:39:16,700
Scott: I know there's an NES maker and a Game Boy maker tools out there that are quite good.

599
00:39:16,780 --> 00:39:28,220
Scott: That will let you make a lot of games and actually output ROMs that will work on old hardware without having to learn assembly language, clearly, and not even having to learn any difficult programming at all.

600
00:39:29,201 --> 00:39:31,005
Scott: So most people are not doing that.

601
00:39:31,065 --> 00:39:38,240
Scott: And, you know, there are a lot of YouTube channels that are like teaching you specific things like retro game mechanics explained and whatnot.

602
00:39:38,320 --> 00:39:40,486
Scott: But I haven't seen too many.

603
00:39:40,526 --> 00:39:45,260
Scott: like ground up right here is literally everything, you know.

604
00:39:45,440 --> 00:39:46,742
Scott: So this is really cool.

605
00:39:46,762 --> 00:40:01,800
Scott: And I haven't actually started going through this yet, but it looks structurally like, yeah, you could come to this knowing, you know, I guess an amount about computers in general, but and then be able to make software that would run on an NES.

606
00:40:02,160 --> 00:40:14,300
Rym: Not only that, but a lot of those videos that explain really deep glitches, really interesting speedrun stuff, just having read a little bit of this already, it would definitely make understanding those explanations very straightforward.

607
00:40:15,381 --> 00:40:15,561
Scott: Right.

608
00:40:15,681 --> 00:40:19,127
Scott: This could also be very useful to you, even if you don't develop an entire game.

609
00:40:19,628 --> 00:40:26,660
Scott: If you want to like figure out some game genie code for a game or make a ROM hack, this would be very useful to go through.

610
00:40:26,981 --> 00:40:27,201
Scott: Right.

611
00:40:27,482 --> 00:40:34,060
Scott: Because then when you went to go get a ROM and read it and, you know, try to, you know, mess with it, you would understand what the hell was going on.

612
00:40:34,380 --> 00:40:34,541
Rym: Yep.

613
00:40:35,865 --> 00:40:39,880
Rym: In the better moment, the GeekNights Book Club book, Tale of Genji, I paused it to read a shounen manga.

614
00:40:40,320 --> 00:40:44,500
Rym: Going to be going straight back to Genji after that, because that shounen manga is shounen manga.

615
00:40:44,560 --> 00:40:47,709
Scott: I'm reading Genji because I got the new Kindle Paperwhite.

616
00:40:48,331 --> 00:40:48,993
Scott: It's pretty nice.

617
00:40:49,334 --> 00:40:50,738
Scott: I'm reading Genji on it.

618
00:40:50,798 --> 00:40:51,440
Scott: So there you go.

619
00:40:51,620 --> 00:40:59,100
Rym: I also got a bunch of vacation time I got to burn, so I'm going to have a lot of time off doing like local travel for skiing and nothing.

620
00:40:59,400 --> 00:41:00,700
Scott: Your October prediction is wrong.

621
00:41:00,940 --> 00:41:02,191
Rym: My October prediction is wrong.

622
00:41:02,655 --> 00:41:03,120
Rym: That was fair.

623
00:41:03,280 --> 00:41:03,520
Scott: I was right.

624
00:41:03,980 --> 00:41:04,647
Rym: You were right.

625
00:41:04,809 --> 00:41:05,840
Rym: I think end of year is very feasible.

626
00:41:06,881 --> 00:41:15,260
Scott: I am not working the week of Thanksgiving in the United States, which is, you know, one, two, three weeks from now.

627
00:41:15,280 --> 00:41:19,600
Rym: I'm taking like three days off that week and I'm taking the whole week before the Christmas week off.

628
00:41:19,921 --> 00:41:23,331
Scott: And I'm taking like after the week after Thanksgiving.

629
00:41:23,391 --> 00:41:25,377
Scott: So Black Friday, obviously not working.

630
00:41:25,437 --> 00:41:26,280
Scott: Weekend not working.

631
00:41:26,781 --> 00:41:29,048
Scott: That Monday, Tuesday, Wednesday, I work.

632
00:41:29,369 --> 00:41:32,098
Scott: That Wednesday after Thanksgiving is December 1st.

633
00:41:32,940 --> 00:41:35,367
Scott: That is the last day I am working in the year 2021.

634
00:41:35,367 --> 00:41:40,641
Scott: Not working again until January 3rd, 2022.

635
00:41:40,641 --> 00:41:43,860
Rym: Man, I got at some point I got to get out of an industry that never closes.

636
00:41:44,902 --> 00:41:48,862
Scott: And I still have 10 vacation days rolled over to 2022.

637
00:41:48,862 --> 00:41:52,580
Rym: Never worked in my life in a place that could like shut down or close.

638
00:41:53,180 --> 00:41:57,180
Rym: It's either been factories or fabs or hospitals or capital markets.

639
00:41:57,220 --> 00:42:01,400
Scott: My previous job and current job, the company just closes Christmas to New Year's.

640
00:42:03,365 --> 00:42:08,900
Rym: If I ran a game studio, we would just close for that holiday season and we'd pick one like to like a month in the summer.

641
00:42:09,481 --> 00:42:10,525
Scott: You know how much I would close?

642
00:42:10,585 --> 00:42:14,620
Scott: I'd be closing on Jewish holidays, Muslim holidays, Chinese New Year.

643
00:42:14,720 --> 00:42:17,168
Rym: I would definitely close the month of July.

644
00:42:17,249 --> 00:42:18,332
Rym: The best summer times.

645
00:42:18,413 --> 00:42:20,540
Rym: Why should anyone be working during the month of July?

646
00:42:20,540 --> 00:42:25,920
Scott: I'd be closing on if there's a bank holiday in any country in which we operate, closed whole company.

647
00:42:26,220 --> 00:42:26,863
Scott: Not right today.

648
00:42:27,064 --> 00:42:28,731
Scott: It was like All Saints Day.

649
00:42:28,811 --> 00:42:29,012
Scott: Right.

650
00:42:29,032 --> 00:42:30,780
Scott: So people in France, I think, are not working.

651
00:42:31,100 --> 00:42:35,458
Scott: If I had a French office and those people got off, I'd say whole world is off because it's All Saints Day.

652
00:42:35,538 --> 00:42:35,920
Scott: Deal with it.

653
00:42:36,120 --> 00:42:42,940
Rym: So I guess I actually have an anecdote around that because, you know, I used to work in a company where we had a subsidiary office in India, in Hyderabad.

654
00:42:43,564 --> 00:42:44,591
Rym: And we worked with a lot.

655
00:42:44,611 --> 00:42:45,960
Scott: I wonder what kind of cool holidays they got.

656
00:42:46,240 --> 00:42:53,600
Rym: So you basically register what your religion is and then you get that set of holidays for yourself.

657
00:42:55,563 --> 00:42:57,800
Scott: I'm letting everybody off every religious holiday.

658
00:42:58,181 --> 00:43:03,120
Rym: So I do know for a fact, if you did that, your office would basically never open.

659
00:43:04,201 --> 00:43:04,442
Scott: Good.

660
00:43:05,284 --> 00:43:05,505
Rym: Yeah.

661
00:43:05,806 --> 00:43:10,520
Rym: But that leads to other externalities if our whole society decided to stop working.

662
00:43:10,660 --> 00:43:16,780
Scott: But are there that many holidays that there's literally a serious holiday every day for nearly every day?

663
00:43:17,240 --> 00:43:18,645
Rym: Like kind of for real.

664
00:43:18,705 --> 00:43:21,013
Scott: It would be a problem if you would think there would be.

665
00:43:21,133 --> 00:43:23,160
Scott: there's got to be days where there's no holiday.

666
00:43:23,720 --> 00:43:25,043
Scott: Not many.

667
00:43:25,083 --> 00:43:32,980
Rym: If you earnestly engage with every major faith group and also all of the secular groups that have holidays in the world.

668
00:43:35,400 --> 00:43:35,742
Scott: I don't know.

669
00:43:36,144 --> 00:43:37,289
Scott: You got to draw a line somewhere.

670
00:43:37,309 --> 00:43:37,731
Rym: But anyway.

671
00:43:37,751 --> 00:43:37,911
Rym: Yeah.

672
00:43:37,932 --> 00:43:39,820
Rym: Well, the line I draw is much more simple.

673
00:43:40,161 --> 00:43:42,366
Scott: The only ice cream day doesn't get a day off.

674
00:43:42,406 --> 00:43:48,760
Rym: The only reason we pay people to do things is because otherwise they won't do those things.

675
00:43:49,440 --> 00:43:52,672
Rym: So if people aren't doing the things we have to pay them more.

676
00:43:53,114 --> 00:43:54,499
Rym: Somebody like my dad was a fireman.

677
00:43:54,559 --> 00:43:54,700
Rym: Right.

678
00:43:55,320 --> 00:44:00,060
Rym: Somebody's got to be a firefighter on like Christmas Day because a fire might happen.

679
00:44:00,481 --> 00:44:04,020
Rym: You know, you do if you can't find people willing to work on those days.

680
00:44:04,420 --> 00:44:06,691
Rym: You pay them a shit ton to work on those days.

681
00:44:07,033 --> 00:44:08,460
Rym: And that's how you solve that problem.

682
00:44:08,881 --> 00:44:13,696
Rym: Every other solution to that problem is unfair and capitalist.

683
00:44:14,017 --> 00:44:15,080
Scott: Let's move on to the main bit.

684
00:44:15,340 --> 00:44:15,741
Scott: Main bit.

685
00:44:15,802 --> 00:44:17,127
Rym: Documentation.

686
00:44:17,829 --> 00:44:18,231
Scott: Yeah.

687
00:44:18,291 --> 00:44:18,773
Scott: Some listen.

688
00:44:18,813 --> 00:44:20,700
Scott: The listener sent this one in on our forum.

689
00:44:21,140 --> 00:44:27,620
Scott: So we've talked about documentation of us systems before, but never talked about documentation in general.

690
00:44:27,941 --> 00:44:28,203
Scott: Right.

691
00:44:28,767 --> 00:44:30,880
Scott: So the first thing you got to know, what is documentation?

692
00:44:31,020 --> 00:44:32,002
Scott: Documentation?

693
00:44:32,303 --> 00:44:41,780
Scott: is you have some technology of some kind and there are going to be people who need to interact with that technology from some purpose.

694
00:44:42,720 --> 00:45:01,247
Scott: And they there's no way, no matter how well designed your technology is, that the person is going to be able to just know everything they need to know to get the full use out of that technology and use all the features and everything without instructions.

695
00:45:01,408 --> 00:45:17,120
Scott: You need to write in a human readable language or explain in a human spoken language or both for accessibility reasons, instructions on all the various possible ways that the technology works.

696
00:45:17,560 --> 00:45:29,273
Rym: Now, we will specifically exclude simplistic and toy examples of things that have a 100 percent intrinsically self-evident user experience, because those things tend to be not useful examples.

697
00:45:29,654 --> 00:45:31,340
Rym: Most things need some documentation.

698
00:45:31,980 --> 00:45:32,863
Scott: Well, consider this.

699
00:45:32,964 --> 00:45:33,205
Scott: Right.

700
00:45:33,566 --> 00:45:36,578
Scott: Think about a really simple Apple product like an iPod.

701
00:45:36,839 --> 00:45:37,040
Scott: Right.

702
00:45:38,040 --> 00:45:39,607
Scott: It's still an iPod.

703
00:45:39,627 --> 00:45:42,720
Scott: I don't know if they still make any iPod things, but the iPod came.

704
00:45:43,261 --> 00:45:46,158
Scott: You know, it doesn't need much of a manual because it's so straightforward.

705
00:45:46,199 --> 00:45:46,380
Scott: Right.

706
00:45:46,800 --> 00:45:57,147
Scott: But it comes with a really tiny manual that tells you there's still some things that you're not going to be able to figure out, even from like the best possible design.

707
00:45:57,168 --> 00:46:01,340
Rym: I guess I'm saying I've played some games that literally have zero documentation.

708
00:46:02,840 --> 00:46:02,981
Scott: Yeah.

709
00:46:03,001 --> 00:46:09,098
Scott: Like even Mario, it's like you just need to be like, hey, forward goes, push the arrows direction you want to go, hold B, run faster.

710
00:46:09,920 --> 00:46:10,626
Scott: You need to know that.

711
00:46:10,706 --> 00:46:10,848
Scott: Right.

712
00:46:10,888 --> 00:46:12,077
Scott: Because you're never going to figure that one out.

713
00:46:13,140 --> 00:46:14,408
Scott: I think I did figure it out.

714
00:46:14,428 --> 00:46:16,260
Scott: I don't think I understood that from a manual.

715
00:46:17,780 --> 00:46:22,820
Scott: You could figure it out, but I guess the other point is not necessarily immediately obvious.

716
00:46:22,880 --> 00:46:33,480
Rym: Well, you headed me off because my second part of that is a lot of things that appear to not have documentation have just embedded their documentation in a clever way that you don't recognize as documentation.

717
00:46:34,000 --> 00:46:38,080
Rym: A tutorial pop ups that like guide you when you try to use a new thing.

718
00:46:38,320 --> 00:46:39,426
Scott: I hate the guided pop ups.

719
00:46:39,466 --> 00:46:41,578
Scott: I just want I always just ignore them all.

720
00:46:41,598 --> 00:46:42,040
Scott: I don't know.

721
00:46:42,280 --> 00:46:44,488
Scott: Like I even saw one recently that really pissed me off.

722
00:46:44,589 --> 00:46:47,900
Scott: It was like the first is one of those little pop up tutorials.

723
00:46:48,863 --> 00:46:55,520
Scott: And the first pop up said, all right, we know it was something along the lines of like, let's get this over with.

724
00:46:55,681 --> 00:46:59,360
Scott: And I'm just like, if you know this is fucking bullshit, get this out of my fucking face.

725
00:46:59,620 --> 00:47:00,221
Rym: Let me skip it.

726
00:47:01,002 --> 00:47:01,382
Scott: Yeah.

727
00:47:01,643 --> 00:47:03,125
Scott: But let me have a skip all button.

728
00:47:03,805 --> 00:47:04,346
Scott: They didn't have it.

729
00:47:15,261 --> 00:47:22,220
Rym: For many purposes, even though it probably doesn't work as well as people think it does, and it's probably not complete.

730
00:47:22,840 --> 00:47:22,980
Rym: Yep.

731
00:47:23,462 --> 00:47:28,580
Rym: I think complete documentation is increasingly rare across all technology domains.

732
00:47:28,600 --> 00:47:29,423
Rym: All right.

733
00:47:29,443 --> 00:47:30,085
Scott: Well, it depends.

734
00:47:30,165 --> 00:47:30,326
Scott: Right.

735
00:47:30,366 --> 00:47:34,600
Scott: So the first with the documentation we mostly been talking about here is user documentation.

736
00:47:34,922 --> 00:47:35,102
Scott: Right.

737
00:47:35,183 --> 00:47:38,760
Scott: Someone who is going to use the technology needs instructions.

738
00:47:39,121 --> 00:47:47,500
Scott: And those instructions should tell the person every possible way to and also warnings on how not to operate the technology.

739
00:47:47,620 --> 00:47:48,765
Scott: What button does what?

740
00:47:49,268 --> 00:47:49,429
Scott: Right.

741
00:47:49,469 --> 00:47:50,333
Scott: You drive in the car.

742
00:47:50,373 --> 00:47:51,720
Scott: Here's what the steering wheel does.

743
00:47:51,880 --> 00:47:54,940
Scott: Here's what the pedals do is how to use the red buttons on the radio.

744
00:47:54,960 --> 00:48:00,920
Rym: Cars are a good example that still come with what I would consider absolutely complete and thorough documentation.

745
00:48:01,561 --> 00:48:01,781
Scott: Yep.

746
00:48:01,841 --> 00:48:09,520
Scott: The user manual that comes in the glove box, you know, the driver's guide or whatever, has complete user documentation for the car.

747
00:48:09,620 --> 00:48:09,820
Rym: Yep.

748
00:48:09,961 --> 00:48:21,260
Rym: Not it does not have complete service documentation, but it goes way deeper into service than people, I think, realize or expect because most consumers.

749
00:48:21,280 --> 00:48:27,240
Scott: It's all the user accessible service things, how to change tires, how to fill the fluids, how to check the oil.

750
00:48:28,120 --> 00:48:30,446
Rym: All the what all these doable.

751
00:48:30,967 --> 00:48:31,208
Rym: Yep.

752
00:48:31,649 --> 00:48:35,840
Scott: It doesn't tell you like it doesn't give you a map of what where the check balls are in the transmission.

753
00:48:36,541 --> 00:48:36,761
Scott: Yeah.

754
00:48:36,861 --> 00:48:37,603
Scott: It doesn't tell you that.

755
00:48:37,883 --> 00:48:46,660
Rym: But I think a lot of people forget the fact that the only reason that documentation is so thorough is due to regulations required by law.

756
00:48:47,160 --> 00:48:47,381
Rym: Yep.

757
00:48:47,781 --> 00:48:50,024
Rym: Things that don't require that don't have that anymore.

758
00:48:50,085 --> 00:48:51,787
Rym: So case in point, computers.

759
00:48:51,907 --> 00:49:00,800
Rym: Before you could build your own computer, unless you were a turbo nerd, computers came with a giant manual, just like a car that went to about the same level of depth.

760
00:49:01,700 --> 00:49:06,780
Rym: And no computer comes with anything even remotely like that anymore, nor do any computer components.

761
00:49:07,641 --> 00:49:16,120
Scott: So when I was a kid, I had the stereo system and it was like, you know, it was all together unit, these two tall speakers, right, with several, you know, tweeters and woofers in them.

762
00:49:16,521 --> 00:49:21,259
Scott: And then a main unit and the main unit on the bottom just had a storage area where you could put your vinyls.

763
00:49:21,440 --> 00:49:21,620
Scott: Right.

764
00:49:21,921 --> 00:49:30,020
Scott: And then above that was the system which had two cassette decks and a FM radio at the turntable at the top and then equalizer in the middle there.

765
00:49:30,360 --> 00:49:30,561
Scott: Right.

766
00:49:30,961 --> 00:49:37,431
Scott: And it came with a complete circuit diagram of the insides of itself.

767
00:49:38,192 --> 00:49:38,372
Scott: Right.

768
00:49:38,512 --> 00:49:41,717
Scott: On paper, like where every resistor, every everything.

769
00:49:42,258 --> 00:49:43,179
Scott: You don't see that anymore.

770
00:49:43,420 --> 00:49:43,680
Rym: Never.

771
00:49:45,000 --> 00:49:56,740
Rym: And I really like there are consequences of this to this day, even now, like Biosis will not Biosis, but the modern equivalent of Biosis are so poorly documented that Uefi.

772
00:49:57,240 --> 00:50:01,930
Rym: Yeah, the Uefi that there are options that I do not know what they do.

773
00:50:02,491 --> 00:50:05,757
Rym: And if I look at a different Uefi, there is a different option.

774
00:50:05,777 --> 00:50:07,060
Rym: that looks like it's the same option.

775
00:50:07,380 --> 00:50:10,906
Rym: And if you read the documentation that does exist, it's basically meaningless.

776
00:50:11,266 --> 00:50:20,820
Rym: And if you go to the Internet or like ask people or like look for consensus and you end up trusting some guy who may or may not have figured out the exact correct behavior.

777
00:50:21,600 --> 00:50:22,922
Scott: A lot of the problem there is.

778
00:50:22,982 --> 00:50:29,613
Scott: a lot of the people who make that software or the hardware for the Uefis are not English as a first language.

779
00:50:29,833 --> 00:50:34,220
Scott: So the language that's written in that software is not complete.

780
00:50:35,401 --> 00:50:41,400
Rym: Coupled with the fact that companies are very unwilling to hire formal, traditional, trained technical writers.

781
00:50:41,480 --> 00:50:42,079
Scott: It's not going to hurt sales.

782
00:50:42,460 --> 00:50:50,390
Rym: Nor are they willing to hire technical localizers and like the people who would translate documentation.

783
00:50:50,530 --> 00:50:50,930
Rym: Exactly.

784
00:50:51,311 --> 00:50:56,818
Rym: No one doesn't buy a motherboard because it didn't come with a 40 page manual that was written well.

785
00:50:56,858 --> 00:50:58,260
Rym: They'll just figure it out.

786
00:50:59,080 --> 00:50:59,241
Scott: Yep.

787
00:50:59,641 --> 00:50:59,941
Scott: So, yeah.

788
00:50:59,961 --> 00:51:01,403
Scott: So the user documentation.

789
00:51:01,443 --> 00:51:03,325
Scott: now we've been talking about service documentation.

790
00:51:03,385 --> 00:51:09,232
Scott: So service documentation is someone who's a user and or someone who's a fixer, right?

791
00:51:09,272 --> 00:51:11,194
Scott: They're not, you know, they're going to.

792
00:51:11,214 --> 00:51:16,020
Scott: their job is to fix the thing, you know, make it work, possibly even modify it.

793
00:51:17,040 --> 00:51:21,084
Scott: But they have the things delivered to them, but they have to open it up and do something in the inside.

794
00:51:21,104 --> 00:51:29,931
Scott: So now the documentation is sort of has this second purpose where it's not explaining the outer abstraction layer and how to interact with it.

795
00:51:30,392 --> 00:51:33,314
Scott: It's explaining what is beneath the abstraction.

796
00:51:33,374 --> 00:51:34,535
Scott: How does the thing work?

797
00:51:34,615 --> 00:51:35,336
Scott: What does it do?

798
00:51:35,416 --> 00:51:36,216
Scott: What are these parts?

799
00:51:36,577 --> 00:51:40,380
Scott: Whereas the user documentation wouldn't even tell you what the parts work, right?

800
00:51:40,520 --> 00:51:41,782
Scott: It's like you need to know what the parts were.

801
00:51:41,822 --> 00:51:44,685
Scott: You just need to know how these buttons and switches work on the outside.

802
00:51:46,347 --> 00:51:56,680
Rym: There's a big, big overlap in that space with a thing as a service platforms like software as a service platform as a service.

803
00:51:57,160 --> 00:52:09,250
Rym: All a lot of the way modern companies interact with their customers where you have a product that you sell, but the product you sell is basically a Web site that you go to to do stuff or some APIs you interface with.

804
00:52:09,810 --> 00:52:15,275
Rym: And there you have a service team that supports the people using your product.

805
00:52:15,735 --> 00:52:17,637
Rym: They need documentation that explains the things.

806
00:52:17,657 --> 00:52:21,700
Rym: you don't necessarily tell the people actually using your product specifically.

807
00:52:23,140 --> 00:52:23,721
Rym: That's my world.

808
00:52:23,761 --> 00:52:27,023
Rym: That's everything I've done for the last 15 years has been something as a service.

809
00:52:27,784 --> 00:52:33,348
Scott: And then the final level is close to the final level, at least, is there.

810
00:52:33,788 --> 00:52:35,689
Scott: You know, you're making something, right?

811
00:52:35,950 --> 00:52:37,751
Scott: And you're making it with other people.

812
00:52:37,771 --> 00:52:38,672
Scott: You didn't make it by yourself.

813
00:52:39,932 --> 00:52:43,155
Scott: And you need to you know, all you're actually making this thing.

814
00:52:43,215 --> 00:52:50,140
Scott: You need to have an even better level of understanding of the thing than people who have to fix the thing when it breaks.

815
00:52:50,500 --> 00:52:52,902
Rym: So case in point, like I'll use an example from my company.

816
00:52:52,922 --> 00:52:54,063
Rym: I just won't say any proper nouns.

817
00:52:54,444 --> 00:52:57,746
Rym: We have a feature that's in a Web page that people use to do a thing.

818
00:52:58,207 --> 00:53:02,830
Rym: So in that same Web page, we have an extensive user guide, like a fully written.

819
00:53:03,271 --> 00:53:05,052
Rym: a team of tech writers wrote this thing.

820
00:53:05,353 --> 00:53:07,114
Rym: It explains how the thing works.

821
00:53:07,374 --> 00:53:08,335
Rym: Here's a table of shit.

822
00:53:08,455 --> 00:53:08,875
Rym: Guess what?

823
00:53:09,116 --> 00:53:14,240
Rym: We're actually going to tell you what each one of these fields means like full documentation, how to use the thing.

824
00:53:14,941 --> 00:53:18,404
Rym: We have internally what we call a service run book or a service guide.

825
00:53:18,484 --> 00:53:19,685
Rym: Companies call these different things.

826
00:53:20,185 --> 00:53:27,052
Rym: That is the documentation that someone supporting a client or troubleshooting a problem would look at to understand.

827
00:53:27,212 --> 00:53:27,993
Rym: Is this a problem?

828
00:53:28,253 --> 00:53:29,234
Rym: How do I help the client?

829
00:53:29,594 --> 00:53:31,316
Rym: Are there any outages I should know about?

830
00:53:31,696 --> 00:53:35,920
Rym: How do I deal with situation X and I got locked or something weird like that?

831
00:53:37,200 --> 00:53:42,724
Rym: But then what Scott described, this last one, the developers who made these things work on many different teams.

832
00:53:43,225 --> 00:53:44,526
Rym: They move around between teams.

833
00:53:44,546 --> 00:53:45,787
Rym: They move around between companies.

834
00:53:46,827 --> 00:53:57,816
Rym: There are so many human beings that touched any feature that I'm describing that the developers have to have documentation that explains things like here's how it was architected.

835
00:53:58,216 --> 00:54:00,638
Rym: Here is why we architected it this way.

836
00:54:01,178 --> 00:54:02,599
Rym: This thing works weirdly.

837
00:54:02,639 --> 00:54:03,580
Rym: We know it's weird.

838
00:54:03,960 --> 00:54:07,086
Rym: Here's the engineering discussion around that.

839
00:54:07,447 --> 00:54:09,591
Rym: And here's the link to the ticket where we all agreed.

840
00:54:09,631 --> 00:54:12,296
Rym: someday we're going to re-architect this, but it's not worth it to do it yet.

841
00:54:13,097 --> 00:54:14,320
Rym: All of those things need to exist.

842
00:54:15,480 --> 00:54:15,740
Scott: Yeah.

843
00:54:15,820 --> 00:54:18,743
Scott: If you had something like, I don't know, a tunnel, right?

844
00:54:18,763 --> 00:54:19,904
Scott: We talked about tunnels today.

845
00:54:20,644 --> 00:54:22,866
Scott: What's the user guide for the tunnel walkthrough?

846
00:54:23,126 --> 00:54:30,552
Rym: User guide for the tunnel is literally the signs outside the tunnel telling you like, yeah, no propane tanks, no commercial vehicles.

847
00:54:30,832 --> 00:54:32,273
Scott: Here's how to turn on your head.

848
00:54:32,313 --> 00:54:33,734
Scott: Turn on your headlights just in case.

849
00:54:33,814 --> 00:54:34,074
Scott: Yeah.

850
00:54:34,114 --> 00:54:35,395
Scott: No, that kind of thing.

851
00:54:35,415 --> 00:54:35,616
Scott: All right.

852
00:54:35,856 --> 00:54:36,336
Scott: Say, all right.

853
00:54:36,376 --> 00:54:37,877
Scott: The maintenance guide for the tunnel.

854
00:54:37,997 --> 00:54:40,699
Scott: Wash the inside of the tunnel this way.

855
00:54:41,080 --> 00:54:41,340
Scott: Right.

856
00:54:42,141 --> 00:54:43,862
Rym: Every 10 years, get this kind of inspection.

857
00:54:43,902 --> 00:54:45,744
Rym: Every 20 years, get this kind of inspection.

858
00:54:45,824 --> 00:54:48,147
Scott: Every day, clean these vents in this way.

859
00:54:48,207 --> 00:54:51,730
Scott: Here, change the filters in this way so people don't suffocate down there.

860
00:54:51,830 --> 00:54:52,391
Scott: Right.

861
00:54:52,751 --> 00:54:54,193
Scott: Here's how to change the light bulbs.

862
00:54:54,233 --> 00:55:00,339
Rym: Here's the basic run book of like typical problems and like what is our process to deal with them or who to call.

863
00:55:00,819 --> 00:55:01,600
Rym: Usually it's who to call.

864
00:55:01,920 --> 00:55:04,443
Scott: If the tunnel is flooding, stop letting cars in.

865
00:55:04,503 --> 00:55:06,085
Scott: Here's how to stop letting cars in.

866
00:55:06,265 --> 00:55:06,385
Scott: Right.

867
00:55:06,746 --> 00:55:06,986
Scott: Okay.

868
00:55:07,186 --> 00:55:12,552
Scott: But then the other one is, okay, we dug this tunnel and you see this thing here.

869
00:55:12,612 --> 00:55:13,453
Scott: that looks weird.

870
00:55:13,493 --> 00:55:17,418
Scott: We put that there because there happens to be a rock there underground or something.

871
00:55:17,498 --> 00:55:19,220
Scott: You know, I don't know anything about tunnels.

872
00:55:19,300 --> 00:55:27,966
Rym: The lane is four inches narrower for these hundred feet because of and here's pages and pages and pages of architecture, diagrams and explanations.

873
00:55:28,106 --> 00:55:33,109
Scott: So if you come and you have to deal with this tunnel long after I'm dead because the tunnel will outlive me.

874
00:55:33,770 --> 00:55:33,990
Scott: Right.

875
00:55:34,090 --> 00:55:34,490
Scott: Here is.

876
00:55:34,790 --> 00:55:39,033
Scott: here is why we made this tunnel in this way where you come and you're an engineer and you know your stuff.

877
00:55:39,053 --> 00:55:42,796
Scott: You literally do know your stuff and you look at the tunnel and something will look wrong to you.

878
00:55:43,196 --> 00:55:44,657
Scott: This is why it looks wrong to you.

879
00:55:44,737 --> 00:55:45,498
Scott: There was a reason.

880
00:55:45,578 --> 00:55:48,419
Scott: Now it makes sense to you because you know your stuff because no one's reading this.

881
00:55:48,439 --> 00:55:49,220
Scott: Who doesn't know their stuff?

882
00:55:49,220 --> 00:55:54,805
Rym: So imagine the people who work the tunnel on a day to day basis need that second documentation like the run book on how to run it.

883
00:55:55,305 --> 00:55:59,469
Rym: That will include a lot of scenarios.

884
00:55:59,709 --> 00:56:04,393
Rym: and what is the standard operating procedure, which like, oh, there's a traffic jam.

885
00:56:04,413 --> 00:56:05,454
Rym: Do you do anything or not?

886
00:56:05,774 --> 00:56:06,855
Rym: I think it's flooding.

887
00:56:07,296 --> 00:56:12,100
Rym: Here's the phone number to call to trigger like the emergency response, like that kind of detail.

888
00:56:12,641 --> 00:56:26,040
Rym: But if there's a big problem, sometimes that run book will say, call these people and people are going to come in who have to decide what to do for a situation where there is no run book, like a crack appeared.

889
00:56:27,180 --> 00:56:27,481
Rym: All right.

890
00:56:27,521 --> 00:56:28,562
Rym: There's a giant crack.

891
00:56:28,842 --> 00:56:29,523
Rym: What do we do?

892
00:56:29,964 --> 00:56:32,447
Rym: There's no run book to cover every possible crack.

893
00:56:32,728 --> 00:56:41,820
Rym: So now you need experts to read the the deep documentation that Scott described and then use their expertise to decide what to do.

894
00:56:42,220 --> 00:56:45,924
Rym: Meaning the more information they have access to, the better.

895
00:56:45,944 --> 00:56:46,905
Rym: Right.

896
00:56:47,005 --> 00:56:59,739
Scott: If they if you just hire a tunnel expert to come and look at your tunnel crack and there's no instructions about that particular tunnel, you're going to be looking at a lot more cost, a lot more time, a lot more danger, a lot more everything that's bad and not a lot extra.

897
00:56:59,759 --> 00:57:00,140
Scott: That's good.

898
00:57:00,340 --> 00:57:00,640
Scott: Yeah.

899
00:57:00,660 --> 00:57:04,423
Scott: Something will do anything for the person who made the tunnel.

900
00:57:04,823 --> 00:57:08,486
Scott: That second person who comes along 100 years later is going to be helped out a lot.

901
00:57:08,746 --> 00:57:21,276
Rym: So if you're making a documentation of any kind, especially get back into the software technology stuff most of the listeners know about, then it really comes down to who is the audience of your documentation.

902
00:57:21,376 --> 00:57:25,739
Rym: But you can still break those audiences down usually to those three groups we just described.

903
00:57:26,199 --> 00:57:27,320
Rym: have user.

904
00:57:27,340 --> 00:57:29,503
Scott: There are other groups, but those are the three main ones.

905
00:57:29,563 --> 00:57:29,803
Scott: Yeah.

906
00:57:30,084 --> 00:57:34,850
Rym: But if you most companies, in my experience, don't even break it down to those three groups.

907
00:57:34,950 --> 00:57:41,519
Rym: So most likely you'll be the hero in your company if you even get them to the point of having those three groups.

908
00:57:42,340 --> 00:57:42,500
Scott: Yep.

909
00:57:43,021 --> 00:57:43,301
Scott: All right.

910
00:57:43,621 --> 00:57:57,376
Scott: So some other more specific things, right, is the question of, all right, you recognize the documentation is a good thing to have because you've engineered a technology of some kind, but it's not like it's free to make the documentation.

911
00:57:58,077 --> 00:58:01,320
Scott: It takes time, effort, writing skills.

912
00:58:01,480 --> 00:58:05,123
Rym: As a technologist, I also learned a lot about writing.

913
00:58:05,163 --> 00:58:06,404
Rym: I'm a trained technical writer.

914
00:58:07,005 --> 00:58:12,250
Rym: And the problem this presented in my younger career was I would document everything I did myself.

915
00:58:13,290 --> 00:58:13,651
Rym: Always.

916
00:58:14,652 --> 00:58:16,293
Rym: It took a huge amount of time.

917
00:58:16,834 --> 00:58:24,160
Rym: I would spend about an hour writing documentation for every two to four hours of primary work I did.

918
00:58:24,761 --> 00:58:25,902
Rym: That was just that was.

919
00:58:26,263 --> 00:58:28,165
Rym: I assumed how everyone operated.

920
00:58:29,326 --> 00:58:33,231
Rym: And then I got to a company where there wasn't any documentation of any kind because no one bothered.

921
00:58:33,712 --> 00:58:37,497
Rym: And if I spent time writing documentation, I was admonished for wasting my time.

922
00:58:37,757 --> 00:58:38,558
Rym: That's not my job.

923
00:58:38,598 --> 00:58:39,980
Rym: That's the documentation team's job.

924
00:58:42,921 --> 00:59:00,540
Scott: And the problem is that it's a fundamental problem in that a person who is most knowledgeable about the technology, right, is the person who could who has the skills to be building more technology, doing more engineering, and they may or may not have writing skills.

925
00:59:00,720 --> 00:59:07,933
Rym: But even if they do have writing skills, the company does not want to pay a developer developer money to write documentation.

926
00:59:08,194 --> 00:59:11,640
Rym: They want to pay documentation money, which usually is farmed out.

927
00:59:12,120 --> 00:59:21,572
Scott: So even if you get an expert, someone who's a writer, as that person going to be, even if they're expert at writing, are they expert at this technology someone else made?

928
00:59:21,592 --> 00:59:23,535
Scott: You're gonna have to have those people sit together and chat.

929
00:59:24,035 --> 00:59:25,777
Scott: You know, it's like it's.

930
00:59:26,578 --> 00:59:27,800
Scott: it's just a cost center.

931
00:59:27,860 --> 00:59:29,161
Scott: And it's not.

932
00:59:29,221 --> 00:59:44,253
Scott: it ends up not being worth it in capitalism unless it's a required by log, in which case, you know, you got to have it or be your technology is so big or so important that you're just you need to have the documentation.

933
00:59:44,353 --> 00:59:50,198
Scott: Just practically speaking, it ends up being worth it to you money wise to have it because not having it would be disastrous.

934
00:59:50,498 --> 00:59:52,320
Rym: That's more the world I live in today.

935
00:59:53,600 --> 01:00:02,334
Scott: But so many places are building important stuff that a lot of things rely upon and documentation isn't written.

936
01:00:02,514 --> 01:00:06,280
Scott: It isn't written well or it's not available or it's not available to the people.

937
01:00:07,040 --> 01:00:14,991
Rym: We don't know the full story, but that card game with unique decks had a problem where no one seemed to know how their algorithm worked so they couldn't run it again.

938
01:00:15,011 --> 01:00:16,173
Scott: Oh, yeah.

939
01:00:16,193 --> 01:00:16,754
Scott: Key Forge.

940
01:00:16,974 --> 01:00:17,255
Rym: Yeah.

941
01:00:18,016 --> 01:00:18,176
Scott: Yeah.

942
01:00:18,196 --> 01:00:19,097
Scott: We did an episode of that.

943
01:00:19,117 --> 01:00:20,199
Rym: We talked about that on a Tuesday.

944
01:00:20,239 --> 01:00:21,200
Rym: Go find the story.

945
01:00:21,320 --> 01:00:28,453
Scott: The story seems to be that they had, you know, a system that had an algorithm to, you know, generate Key Forge decks and then run them through the printer.

946
01:00:29,295 --> 01:00:32,240
Scott: And the people the rumor is they got ransomware.

947
01:00:33,100 --> 01:00:34,382
Scott: So they lost all their software.

948
01:00:34,402 --> 01:00:35,864
Scott: I guess they were really bad at software.

949
01:00:35,884 --> 01:00:37,606
Scott: They didn't have it backed up anywhere or anything.

950
01:00:38,708 --> 01:00:44,636
Scott: And now I guess with documentation, they could have at least had a new developer rewrite software.

951
01:00:44,656 --> 01:00:45,437
Scott: that was equivalent.

952
01:00:46,038 --> 01:00:47,560
Scott: But I guess they've just lost everything.

953
01:00:47,680 --> 01:00:48,301
Scott: Some I don't know.

954
01:00:48,641 --> 01:00:51,265
Rym: My advice to you out there is it really depends on the company.

955
01:00:51,365 --> 01:00:56,191
Scott: But if you documentation is sort of a backup, if you think about it, I go one step further.

956
01:00:56,391 --> 01:01:03,240
Rym: I treat documentation as a capital investment and an asset like having good documentation.

957
01:01:03,680 --> 01:01:04,962
Rym: I consider it at least.

958
01:01:05,322 --> 01:01:10,987
Rym: when I was in a C level position, which I am not now, I actually you know, I I went to a bigger company.

959
01:01:11,047 --> 01:01:13,089
Rym: So I'm a smaller fish in a bigger company.

960
01:01:13,449 --> 01:01:24,960
Rym: But when I was closer to like board of directors, executive work in a smaller company, I very much treated documentation as an asset that we would assign value to and high and treat as a priority.

961
01:01:25,300 --> 01:01:29,063
Rym: That saved our asses so many times that it it.

962
01:01:29,744 --> 01:01:32,486
Rym: I could say for a fact that it in the end made us money.

963
01:01:32,586 --> 01:01:34,747
Rym: We profited by writing good documentation.

964
01:01:34,767 --> 01:01:36,068
Rym: All right.

965
01:01:36,088 --> 01:01:39,971
Scott: Let's talk about just end up here with some specific, real narrow things.

966
01:01:39,991 --> 01:01:41,633
Scott: Something that always bothers me.

967
01:01:42,093 --> 01:01:44,315
Scott: I read a lot of software developer documentation.

968
01:01:44,355 --> 01:01:44,975
Scott: That's my job.

969
01:01:45,115 --> 01:01:45,335
Scott: Right.

970
01:01:45,936 --> 01:01:51,500
Scott: One thing that bothers me a lot is when the documentation is a not up to date.

971
01:01:51,560 --> 01:01:56,367
Scott: You've changed the software since you wrote your documentation and you didn't update your documentation.

972
01:01:57,910 --> 01:02:01,415
Rym: I look at the documentation and list five fields to put in the JSON.

973
01:02:01,695 --> 01:02:02,837
Rym: I look in the example code.

974
01:02:03,218 --> 01:02:04,460
Rym: There's six fields in there.

975
01:02:05,781 --> 01:02:08,326
Rym: I copy paste that six field into the document.

976
01:02:08,366 --> 01:02:09,849
Rym: It does not show up even once.

977
01:02:10,971 --> 01:02:11,192
Scott: Yep.

978
01:02:11,352 --> 01:02:14,959
Scott: It's a broken documentation is actually more frustrating than none, I think.

979
01:02:15,119 --> 01:02:17,282
Rym: Oh, I. This is just me.

980
01:02:17,783 --> 01:02:23,710
Rym: I treated software documentation like software issues and documentation is used as bugs.

981
01:02:23,830 --> 01:02:31,760
Rym: If someone found a flaw in the documentation, there was a bug ticket, just like if there is a bug in the software and we treated it with the same level of severity.

982
01:02:32,520 --> 01:02:38,487
Scott: Something else I really, really don't like is someone will write some software documentation and they'll give you an example.

983
01:02:38,607 --> 01:02:39,888
Scott: First of all, you got to have examples.

984
01:02:39,948 --> 01:02:41,510
Scott: I hate the ones where there's no example.

985
01:02:41,871 --> 01:02:42,051
Scott: Right.

986
01:02:42,091 --> 01:02:46,876
Scott: Don't just tell me what like, you know, oh, there's a function called this and describing what it does.

987
01:02:47,036 --> 01:02:50,360
Scott: It's like show me an actual example of it in use.

988
01:02:50,720 --> 01:02:50,920
Scott: Yeah.

989
01:02:51,020 --> 01:02:54,843
Rym: So that's the first thing, because what I'm going to do, I'm going to look at the example first thoughts with it.

990
01:02:54,863 --> 01:02:56,584
Rym: Then I'm gonna go back and read the rest of the documentation.

991
01:02:57,205 --> 01:02:57,665
Scott: Exactly.

992
01:02:57,705 --> 01:02:58,926
Scott: So you need to have examples.

993
01:02:59,046 --> 01:03:03,449
Scott: But something that bothers me above that is incomplete examples.

994
01:03:03,529 --> 01:03:07,672
Scott: For example, someone might have an example of how to use a function.

995
01:03:07,692 --> 01:03:08,832
Scott: Right.

996
01:03:08,973 --> 01:03:09,793
Scott: And they'll have.

997
01:03:09,813 --> 01:03:11,134
Scott: they'll be calling the function.

998
01:03:11,374 --> 01:03:13,936
Scott: So function parentheses, parameter, parameter.

999
01:03:14,596 --> 01:03:17,398
Scott: And they'll say, yeah, this will return X. Right.

1000
01:03:17,458 --> 01:03:19,219
Scott: With these inputs, it's like, OK, I see it.

1001
01:03:19,780 --> 01:03:19,920
Scott: But.

1002
01:03:20,540 --> 01:03:23,402
Scott: You didn't include where to import the function from.

1003
01:03:23,962 --> 01:03:25,984
Scott: It could be like from library import function.

1004
01:03:26,004 --> 01:03:28,766
Scott: You need to put that import statement in the example.

1005
01:03:29,106 --> 01:03:30,887
Scott: Otherwise, I'm like, OK, I see the function.

1006
01:03:31,187 --> 01:03:32,208
Scott: where the fuck do I import.

1007
01:03:32,228 --> 01:03:32,728
Rym: Oh, my God.

1008
01:03:32,768 --> 01:03:36,631
Rym: So fixed protocol documentation, like a specification for a fixed API.

1009
01:03:37,111 --> 01:03:37,612
Rym: Same thing.

1010
01:03:37,872 --> 01:03:44,476
Rym: They will give you the most excruciating examples possible of the payloads, like full interactions.

1011
01:03:45,037 --> 01:03:45,437
Rym: So cool.

1012
01:03:45,457 --> 01:03:46,137
Rym: You've got all that.

1013
01:03:46,598 --> 01:03:50,100
Rym: They'll often leave out the headers and footers of those messages.

1014
01:03:50,500 --> 01:03:52,301
Rym: Meaning you're looking at a partial message.

1015
01:03:52,562 --> 01:03:53,943
Rym: Now, I'm a I'm a fixed expert.

1016
01:03:54,043 --> 01:03:54,583
Rym: I look at this.

1017
01:03:55,123 --> 01:03:56,764
Rym: I can infer what the headers should look like.

1018
01:03:56,824 --> 01:03:57,645
Rym: Doesn't bother me at all.

1019
01:03:58,185 --> 01:04:05,090
Rym: Ninety nine percent of people who read that documentation are going to send that raw message without the header because the example didn't have it.

1020
01:04:05,490 --> 01:04:11,995
Rym: It's going to fail in ways they don't understand because the fixed protocol breaks down badly without those message, without those headers.

1021
01:04:12,355 --> 01:04:13,876
Rym: And they're not going to understand what happened.

1022
01:04:14,616 --> 01:04:16,137
Scott: So you should whatever you make put it.

1023
01:04:16,157 --> 01:04:17,879
Scott: you should put an example on everything.

1024
01:04:17,959 --> 01:04:19,880
Rym: And also, if you example seems trivial.

1025
01:04:20,200 --> 01:04:27,426
Scott: To you and all of your examples should be one hundred percent complete examples showing you everything is happening.

1026
01:04:27,566 --> 01:04:30,028
Rym: Don't know if you're a fixed message.

1027
01:04:30,108 --> 01:04:30,328
Rym: Right.

1028
01:04:30,648 --> 01:04:46,120
Scott: So now, even though in this section of the documentation, only one part of that complete example is like the relevant part to what you're discussing, include all the parts and then just put the relevant part in bold so that they can see that's the part that's being discussed here.

1029
01:04:46,440 --> 01:04:51,886
Scott: But I can see it in the full context of the full interaction that is happening.

1030
01:04:52,347 --> 01:04:54,789
Scott: And now when I go to use that, I will be successful.

1031
01:04:55,670 --> 01:05:01,036
Scott: If you just give me only that bold part and you leave out everything else, it is not even there that I'm going to try.

1032
01:05:01,056 --> 01:05:01,837
Scott: It's not going to work.

1033
01:05:01,897 --> 01:05:03,879
Scott: And I had to go and figure out everything else.

1034
01:05:03,979 --> 01:05:04,780
Scott: So that's annoying.

1035
01:05:06,500 --> 01:05:12,945
Rym: In terms of user documentation, like not just developer API documentation, I think it bothers me the most.

1036
01:05:13,005 --> 01:05:19,189
Rym: The two things that bother me the most are one, when instead of having a written document, they have a YouTube video like fuck that.

1037
01:05:19,550 --> 01:05:21,051
Rym: That is the least like.

1038
01:05:21,091 --> 01:05:22,872
Rym: videos are good accompaniments.

1039
01:05:23,132 --> 01:05:25,574
Rym: They're good accessories to documentation.

1040
01:05:25,614 --> 01:05:28,656
Rym: They are fantastic ways to augment documentation.

1041
01:05:28,956 --> 01:05:30,798
Rym: They do not replace documentation.

1042
01:05:30,858 --> 01:05:34,300
Rym: Video is a very information sparse medium.

1043
01:05:34,900 --> 01:05:37,883
Rym: That is very difficult to search and scan through.

1044
01:05:38,283 --> 01:05:40,024
Rym: It is very difficult to take things from it.

1045
01:05:40,305 --> 01:05:44,108
Rym: I can't copy paste code out of YouTube video and put it in my editor while I'm.

1046
01:05:44,148 --> 01:05:58,760
Rym: videos are great when you need to teach someone a physical thing because you can show the thing happening, but they still should not replace written documentation that provides more depth, more context and other information.

1047
01:05:58,880 --> 01:06:03,724
Scott: Well, I mean, if you were like how for something like how to assemble an Ikea furniture, right?

1048
01:06:03,804 --> 01:06:12,351
Scott: A video could end up being better than the because the diagram might be confusing, but the video would be like unambiguous to see the pieces going to get.

1049
01:06:12,371 --> 01:06:14,833
Rym: But I don't want by you without the document and vice versa.

1050
01:06:15,233 --> 01:06:24,240
Scott: In that case, I mean, I definitely still want the document, but I'm just saying in some scenarios, as long as the video is accessible to you, video could be the preferable thing.

1051
01:06:24,360 --> 01:06:31,745
Scott: I like if I had the video and the paper, I'd go to the video first, even though it's slower, because for that kind of thing, it's a better.

1052
01:06:32,085 --> 01:06:33,406
Scott: you know, it's better.

1053
01:06:33,626 --> 01:06:37,649
Rym: Though they get to the first for most things, video is not better.

1054
01:06:37,989 --> 01:06:49,757
Scott: Well, even any information thing that's not a physical thing, video is not better or anything that requires is not as good or anything that requires a physical learned skill, like for like, for example, skiing.

1055
01:06:50,037 --> 01:06:54,000
Rym: There's documentation on skiing, like the right way to do specific kinds of turns.

1056
01:06:54,501 --> 01:06:58,680
Rym: That text documentation is very helpful to understand the mechanics involved.

1057
01:06:59,460 --> 01:07:03,080
Rym: But a video is also very valuable because it shows it in action.

1058
01:07:03,300 --> 01:07:07,772
Rym: You see what the result of those motions should be, but you also need.

1059
01:07:08,053 --> 01:07:10,460
Scott: you can also see the person that you're going to be trying to mimic.

1060
01:07:10,600 --> 01:07:20,840
Rym: Right now, it's hard to mimic a drawing of a person, but just trying to mimic the person without the explanation of the mechanics involved is a great way to hurt yourself badly.

1061
01:07:23,481 --> 01:07:37,079
Rym: The other thing that really bothers me is when user documentation goes overboard and documents all the things like it goes, it's dense and documents things that that are honestly 100 percent self-evident.

1062
01:07:38,300 --> 01:07:44,760
Rym: I've seen so many user guides, especially in more commercial software that explain this is a table.

1063
01:07:45,160 --> 01:07:47,920
Rym: A table is a way to see information from our system.

1064
01:07:48,361 --> 01:07:58,540
Rym: You can sort this table by clicking on the top with these error and it'll spend paragraphs explaining how to use a table every time a table appears in the documentation.

1065
01:07:59,060 --> 01:08:00,619
Scott: You don't do it every time a table appears.

1066
01:08:00,761 --> 01:08:02,319
Scott: You do it once in one place.

1067
01:08:03,382 --> 01:08:07,340
Scott: And as long as you organize the documentation, like it's not bad to have those things.

1068
01:08:07,540 --> 01:08:12,840
Scott: Yeah, it's just as long as the documentation is organized to put those things in their own area.

1069
01:08:12,960 --> 01:08:19,319
Scott: So it's like, you know, oh, yes, in this, you know, you go to look up, maybe you're going the index and you're like, all right, how do I do X?

1070
01:08:19,600 --> 01:08:21,660
Scott: You find the section about X. It involves a table.

1071
01:08:22,241 --> 01:08:27,540
Scott: And if you don't understand the table, there'll be a reference like see appendix X, how to use table like you have a section like that is okay.

1072
01:08:27,901 --> 01:08:29,880
Rym: That's like how we use tables.

1073
01:08:30,180 --> 01:08:36,960
Rym: So in all my things, whatever it is I'm selling to you, here is the documentation of just in case you needed it, how tables work.

1074
01:08:37,401 --> 01:08:46,700
Rym: I find the main reason a lot of user guides do this is, one, they hire poorly trained technical writers who are trying to fill space.

1075
01:08:47,581 --> 01:08:48,198
Rym: I see that a lot.

1076
01:08:48,740 --> 01:08:52,067
Rym: And two, you have people where they're documenting it.

1077
01:08:52,147 --> 01:08:58,300
Rym: in every place tables appear because the behavior of the thing is inconsistent, which is a more fundamental problem.

1078
01:08:58,600 --> 01:09:05,880
Rym: If the thing behave more consistently, you could make your documentation way simpler and put all the table documentation in one spot.

1079
01:09:06,341 --> 01:09:10,200
Scott: You also got to consider, even if you get someone to write documentation, are you hiring editors?

1080
01:09:10,640 --> 01:09:11,420
Scott: Are you hiring review?

1081
01:09:11,760 --> 01:09:12,939
Scott: People review the documentation.

1082
01:09:13,340 --> 01:09:19,578
Rym: It's like, you know, I have someone in engineering read the documentation that came out to make sure it's not wrong now.

1083
01:09:20,720 --> 01:09:20,819
Scott: Yeah.

1084
01:09:21,062 --> 01:09:22,138
Scott: So much stuff is going on.

1085
01:09:22,520 --> 01:09:24,459
Rym: But here's how I handle that.

1086
01:09:24,862 --> 01:09:26,620
Rym: We literally like we have a software release.

1087
01:09:26,845 --> 01:09:27,160
Rym: All right.

1088
01:09:27,340 --> 01:09:30,551
Rym: We have tickets and all the stuff to track that all the way out to go to market.

1089
01:09:30,854 --> 01:09:32,520
Rym: QA, UAT, go live.

1090
01:09:32,761 --> 01:09:36,691
Rym: The user guide goes through QAT, UAT and go live.

1091
01:09:36,971 --> 01:09:39,960
Rym: the service run book, QA, UAT, go live.

1092
01:09:41,264 --> 01:09:43,100
Rym: We don't do that with the engineering documentation.

1093
01:09:43,720 --> 01:09:50,660
Rym: I trust the engineers to document their own stuff because if they don't document their own stuff, well, that's their problem when it's undocumented.

1094
01:09:51,901 --> 01:09:58,060
Scott: Well, the thing is, right, is that's often a problem in that you don't as an individual, right?

1095
01:09:58,200 --> 01:10:00,400
Scott: It's not your problem because you understand what you did.

1096
01:10:00,480 --> 01:10:02,260
Scott: It's only you just only cause problems.

1097
01:10:02,500 --> 01:10:03,615
Rym: I guess I'm not an engineer anymore.

1098
01:10:04,202 --> 01:10:06,180
Rym: So I'm speaking from like a product perspective.

1099
01:10:06,320 --> 01:10:10,380
Scott: If an engineer doesn't document for the other engineers, they're only causing other people's problems.

1100
01:10:10,440 --> 01:10:11,560
Scott: It never caused them a problem.

1101
01:10:12,041 --> 01:10:15,680
Scott: Of course, someone else not writing documentation for them causes them a problem.

1102
01:10:16,082 --> 01:10:17,020
Rym: But I'll give you an example.

1103
01:10:17,345 --> 01:10:18,320
Rym: There is a pipeline.

1104
01:10:18,460 --> 01:10:19,199
Rym: This is my current job.

1105
01:10:19,300 --> 01:10:26,360
Rym: There is a pipeline that pulls metrics out of some runtime production systems and via multiple engineering teams.

1106
01:10:26,380 --> 01:10:29,796
Rym: This code makes its way into an analytics platform that then does stuff.

1107
01:10:31,941 --> 01:10:35,580
Rym: Nobody works at the company who designed that pipeline originally.

1108
01:10:36,041 --> 01:10:39,940
Rym: So I wanted to build a thing that used the data at the end of the pipeline.

1109
01:10:40,300 --> 01:10:43,780
Rym: So I have a very clear specification on how I want this thing to work.

1110
01:10:45,241 --> 01:10:49,300
Rym: No engineering team would take ownership of it because the pipeline crossed so many teams.

1111
01:10:50,321 --> 01:10:55,459
Rym: So they assumed things worked the way it worked and they made a thing and it didn't do what they expected at all.

1112
01:10:56,680 --> 01:11:00,340
Rym: Nobody, every engineering team one by one said, oh, well, we didn't write that part.

1113
01:11:00,741 --> 01:11:09,920
Rym: And they passed the buck to the next engineering team down the line until eventually they discovered that at no point had anyone documented how that thing worked.

1114
01:11:10,621 --> 01:11:10,821
Rym: Ever.

1115
01:11:11,223 --> 01:11:16,560
Rym: It was never documented by anyone because everyone in this chain thought this is obvious.

1116
01:11:17,340 --> 01:11:26,160
Rym: Everyone I work with knows how it works and I won't even be here anymore 10 years from now when some jerk like Rym tries to change something about this pipeline.

1117
01:11:26,560 --> 01:11:34,080
Rym: So one engineer who didn't write documentation like seven years ago fucked over like 20 other engineers and me.

1118
01:11:35,261 --> 01:11:35,421
Scott: Yep.

1119
01:11:36,704 --> 01:11:42,999
Scott: So I guess that the most relevant thing, I guess, just to consumers is that, you know, this all ties in.

1120
01:11:43,381 --> 01:11:47,540
Scott: You know, we've talked about it mostly from like you're at work, you're an engineer or stuff like that.

1121
01:11:47,640 --> 01:11:53,240
Scott: But for consumers, the big deal is like all right to repair, you know, kind of stuff.

1122
01:11:53,643 --> 01:11:55,800
Scott: It's like, you know, things not being documented.

1123
01:11:56,162 --> 01:11:59,680
Scott: You buy a product and you can't make it do what you want, even though you own it.

1124
01:11:59,840 --> 01:12:02,860
Rym: That RTMP streaming box I bought, that just didn't work at all.

1125
01:12:03,521 --> 01:12:07,560
Scott: You buy a smart TV, it's spying on you, but they didn't document how you can put your own.

1126
01:12:08,340 --> 01:12:12,600
Scott: It's technically possible to completely replace the software on that smart TV with some other.

1127
01:12:12,660 --> 01:12:13,450
Scott: It's running Android.

1128
01:12:13,612 --> 01:12:14,220
Scott: So a lot of them.

1129
01:12:14,380 --> 01:12:14,480
Scott: Right.

1130
01:12:15,163 --> 01:12:20,480
Scott: There's nothing stopping you from installing some other software on there other than it's not documented how to interface with it.

1131
01:12:20,600 --> 01:12:20,781
Scott: Right.

1132
01:12:20,801 --> 01:12:25,080
Scott: If there was full documentation, you could open that shit up, flash it, go to town.

1133
01:12:25,681 --> 01:12:32,800
Scott: So, you know, but we only get that we're only lucky in some cases, like the famous, you know, Linksys WRT router.

1134
01:12:32,901 --> 01:12:33,202
Scott: Right.

1135
01:12:33,222 --> 01:12:36,380
Scott: You could put your own, you know, router software on there.

1136
01:12:36,400 --> 01:12:36,662
Scott: Right.

1137
01:12:37,104 --> 01:12:39,580
Scott: That's the GPL forced them to reveal or whatnot.

1138
01:12:39,680 --> 01:12:43,059
Scott: So that's, you know, nerds out there.

1139
01:12:43,320 --> 01:12:43,481
Scott: Right.

1140
01:12:43,561 --> 01:12:43,882
Scott: Lack.

1141
01:12:43,982 --> 01:12:59,660
Rym: If we could force documentation upon all consumer, you know, especially electronic, but all, you know, but you pick a line and above that line, you require like there's a bunch of tiers of above these lines and set these lines based on common sense and smartness.

1142
01:12:59,740 --> 01:13:02,819
Scott: The whole John Deere tractor right to repair business going on.

1143
01:13:03,080 --> 01:13:03,180
Scott: Right.

1144
01:13:03,281 --> 01:13:09,700
Scott: If they were required to include with all the tractors, a complete, you know, service manual that showed everything in the tractor and how it works.

1145
01:13:09,840 --> 01:13:10,643
Scott: Now it's put together.

1146
01:13:10,723 --> 01:13:14,840
Scott: It's like, well, then you couldn't really prevent farmers from fixing their own tractor, could you?

1147
01:13:14,980 --> 01:13:16,458
Scott: Because they see it right fucking there.

1148
01:13:18,405 --> 01:13:18,586
Rym: Yep.

1149
01:13:18,667 --> 01:13:20,500
Rym: And I could and I think we've gone on long enough.

1150
01:13:20,640 --> 01:13:26,660
Rym: Maybe we'll do a separate episode on technical writing in the future because we didn't even touch on what good documentation looks like in detail.

1151
01:13:26,760 --> 01:13:27,649
Rym: But what I'll link, we did.

1152
01:13:27,689 --> 01:13:28,740
Scott: It looks like good examples.

1153
01:13:29,002 --> 01:13:29,870
Scott: You cover everything.

1154
01:13:29,890 --> 01:13:30,879
Scott: You don't leave anything out.

1155
01:13:31,102 --> 01:13:32,100
Rym: I guess I could go a lot deeper.

1156
01:13:32,420 --> 01:13:34,620
Scott: You know, whatever language it is, you explain it clearly.

1157
01:13:34,981 --> 01:13:38,120
Rym: I guess as a technical writer, I could go a lot deeper into a lot of specifics.

1158
01:13:38,300 --> 01:13:49,340
Rym: But what I'm going to link to is a panel, a lecture that me and Scott gave years ago called Designing Game Rules, where we talked about game board game rules as documentation.

1159
01:13:50,121 --> 01:13:52,600
Scott: And obviously rules are just documentation for a game.

1160
01:13:53,040 --> 01:13:58,020
Rym: And we covered in extensive detail what makes good documentation in that panel.

1161
01:13:58,321 --> 01:14:01,660
Rym: You could take that panel and apply it to your software engineering job.

1162
01:14:07,504 --> 01:14:09,640
Rym: This has been GeekNights with Rym and Scott.

1163
01:14:09,780 --> 01:14:14,840
Rym: Special thanks to DJ Pretzel for the opening music, Kat Lee for web design and Brando K for the logos.

1164
01:14:15,140 --> 01:14:20,180
Scott: Be sure to visit our website at FrontRowCrew.com for show notes, discussion news and more.

1165
01:14:20,500 --> 01:14:23,120
Rym: Remember, GeekNights is not one, but four different shows.

1166
01:14:23,380 --> 01:14:27,860
Rym: Sci-Tech Mondays, Gaming Tuesdays, Anime Comic Wednesdays and Indiscriminate Thursdays.

1167
01:14:28,240 --> 01:14:31,376
Scott: GeekNights is distributed under a Creative Commons Attribution 3.0 license.

1168
01:14:32,680 --> 01:14:35,660
Scott: GeekNights is recorded live with no studio and no audience.

1169
01:14:35,920 --> 01:14:38,800
Scott: But unlike those other late shows, it's actually recorded at night.

1170
01:14:39,322 --> 01:15:04,140
Rym: And the Patreon patrons for this episode of GeekNights are Heidi McNicholallen, Joyce Linkeji, Dread Lily, Tanner Bryant, a bunch of people who don't want me to say their names, Chris Rahmer, Clinton Walton, Dex Finn, JustLikeADudeGuy, Shai Aye 85, Rebecca Dunn, ReviewMadBull34, Cowards, Ryan Perrin, Sam Erickson, Shervin Von Hurl, Taylor Brown, The Iron Front, You Hold the Key to My Heart and a whole collection of individuals who do not want me to say their names.

1171
01:15:04,961 --> 01:15:06,159
Rym: Uh, yeah, show went a little long.

1172
01:15:06,581 --> 01:15:11,040
Rym: Uh, Scott and I sometimes just get going because it's been a while since we, uh, hung out.

1173
01:15:11,320 --> 01:15:14,800
Rym: So, uh, GeekNights, uh, we found the episodes are getting longer.

1174
01:15:14,800 --> 01:15:19,040
Rym: We're actually having to cut ourselves off, even though we don't have great ideas for Monday and Thursday shows lately.

1175
01:15:19,942 --> 01:15:22,780
Rym: Uh, but anyway, for right now, I'm too hungry to do anything else.

1176
01:15:22,861 --> 01:15:24,619
Rym: So, uh, I just simply leave you with...

1177
01:15:24,619 --> 01:15:30,801
Scott: ♪ Have yourself a merry little Christmas ♪ ♪.

1178
01:15:30,801 --> 01:15:35,060
Scott: Let your heart be light ♪ ♪.

1179
01:15:35,060 --> 01:15:44,339
Scott: From now on, our troubles will be out of sight.

1180
01:15:44,339 --> 01:15:50,379
Scott: ♪ ♪ Have yourself a merry little Christmas.

1181
01:15:50,379 --> 01:15:50,901
Scott: ♪ ♪.

1182
01:15:50,901 --> 01:15:54,718
Rym: Make the yuletide gay.

1183
01:15:54,718 --> 01:16:00,095
Scott: ♪ ♪ From now on, our troubles will be miles away.

1184
01:16:00,095 --> 01:16:04,757
Scott: ♪ ♪ Miles away.

1185
01:16:04,757 --> 01:16:05,541
Scott: ♪ ♪.

1186
01:16:05,541 --> 01:16:09,579
Rym: Here we arise in olden days.

1187
01:16:09,579 --> 01:16:14,918
Rym: ♪ ♪ Happy golden days of yore.

1188
01:16:14,918 --> 01:16:19,599
Rym: ♪ ♪ Faithful friends who are dear to us.

1189
01:16:19,599 --> 01:16:20,000
Scott: ♪ ♪.

1190
01:16:20,000 --> 01:16:25,018
Rym: Gather near to us once more.

1191
01:16:25,018 --> 01:16:25,660
Scott: ♪ ♪.

1192
01:16:25,660 --> 01:16:30,576
Scott: Through the years we all will be together.

1193
01:16:30,576 --> 01:16:35,178
Scott: ♪ ♪ If it's allowed ♪.

