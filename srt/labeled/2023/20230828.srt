1
00:00:08,380 --> 00:00:09,987
Rym: It's Monday, August 28th, 2023.

2
00:00:09,987 --> 00:00:10,167
Rym: I'm Rym.

3
00:00:13,846 --> 00:00:14,280
Scott: I'm Scott.

4
00:00:14,520 --> 00:00:15,665
Rym: And this is GeekNights.

5
00:00:15,685 --> 00:00:19,720
Rym: Tonight we're talking about blocking on things like platforms and social media.

6
00:00:20,760 --> 00:00:21,757
Scott: Let's do this.

7
00:00:22,860 --> 00:00:35,560
Rym: So this weekend, because of a combination of wildfires, getting a sinus infection, having to travel for other stuff, Emily and I had not actually been to Sandy Hook Beach at any point, even though we usually go like two or three times a year.

8
00:00:36,544 --> 00:00:40,260
Scott: I went one time last Monday by myself.

9
00:00:41,304 --> 00:00:43,260
Rym: Yep, Monday, with your special Mondays.

10
00:00:44,523 --> 00:00:45,289
Scott: It's not my fault.

11
00:00:45,309 --> 00:00:46,256
Scott: Negotiate harder.

12
00:00:47,600 --> 00:00:48,343
Rym: I'm working on that.

13
00:00:48,926 --> 00:00:50,994
Rym: So we went to Sandy Hook, had a great time.

14
00:00:51,015 --> 00:00:52,240
Rym: It was a perfect beach day.

15
00:00:52,720 --> 00:00:57,420
Rym: The water was at its absolute peak temperature for the year, which is always...

16
00:00:57,440 --> 00:00:59,759
Scott: The water when I was there was very nice.

17
00:01:01,102 --> 00:01:05,900
Rym: And of course, it was the last weekend because next weekend is Labor Day weekend.

18
00:01:06,300 --> 00:01:12,080
Rym: And even though with climate change, the beach is still pretty warm and the water is still nice.

19
00:01:12,881 --> 00:01:16,478
Rym: Well into toward the end of September and even into October around New York.

20
00:01:17,521 --> 00:01:27,934
Scott: But the problem is, is that, you know, in places where it's always warm, there are people who are just professional lifeguards, professional beach employees, professional resort employees, right?

21
00:01:27,974 --> 00:01:29,160
Scott: They do that all year.

22
00:01:29,321 --> 00:01:30,751
Rym: Those kids got to go back to school.

23
00:01:30,933 --> 00:01:31,900
Rym: So the beach is closed.

24
00:01:32,641 --> 00:01:37,920
Scott: Right, in New York, in northern places that have seasons, that's a seasonal job, right?

25
00:01:38,100 --> 00:01:40,452
Scott: And schools start Labor Day.

26
00:01:40,532 --> 00:01:42,120
Scott: And a lot of those people are younger.

27
00:01:42,360 --> 00:01:45,220
Scott: College people, high school people even sometimes, right?

28
00:01:45,981 --> 00:01:47,991
Scott: Because that's, you know, a seasonal summer job.

29
00:01:48,031 --> 00:01:51,871
Scott: That's the kind of person that would, you know, or even if it's an adult, it'll be a teacher, right?

30
00:01:52,192 --> 00:01:53,680
Scott: Who's going to work only in the summer?

31
00:01:54,080 --> 00:01:55,730
Scott: Someone who works, not the summer.

32
00:01:55,750 --> 00:01:56,273
Scott: Who is that?

33
00:01:56,414 --> 00:01:57,420
Scott: Someone in academia.

34
00:01:57,802 --> 00:02:02,100
Scott: And as soon as summer is over, they have to go back to the other, their more lucrative job.

35
00:02:02,761 --> 00:02:11,100
Scott: And no matter, even if it remains 90 degrees, it's like we have nobody up here to work because it's not a full-time year-round job here.

36
00:02:11,581 --> 00:02:22,171
Scott: And I think even if, you know, the summer extends to September, October, it's like we still can't quite make it a full-time job because it's like in February, nobody's going to, right?

37
00:02:22,232 --> 00:02:24,160
Scott: It's like the person's not going to work, right?

38
00:02:24,501 --> 00:02:27,499
Rym: It's not worth it to deal with like a couple more months.

39
00:02:28,200 --> 00:02:33,014
Scott: Yeah, you can't have it be a full-time year-round job unless it's really tropical.

40
00:02:33,375 --> 00:02:37,360
Scott: every single month, you know, or at least 11 out of 12 months or something like that.

41
00:02:37,560 --> 00:02:45,960
Scott: So we're in this situation where we need pools and beaches open because it's still warm for, you know, everybody.

42
00:02:46,621 --> 00:02:51,559
Scott: But we got nobody to work there, so we had to close them and it's still hot out.

43
00:02:52,141 --> 00:03:01,020
Rym: Yup, because, you know, climate change is going to radically disturb every aspect of human society in ways that people are not even thinking about.

44
00:03:01,180 --> 00:03:04,980
Rym: Like this tiny thing is going to get worse and worse and worse.

45
00:03:05,340 --> 00:03:12,020
Rym: Ten years from now, it's probably going to be like 90 degrees in November and none of the pools are going to be open in New York City and people are going to die.

46
00:03:14,740 --> 00:03:19,520
Rym: So at least hanging out at the beach, perfect beach day, a few observations.

47
00:03:19,920 --> 00:03:24,160
Rym: So Sandy Hook has been getting more and more popular as we know, like more and more people hang out at that beach.

48
00:03:24,500 --> 00:03:25,959
Rym: That ferry is like really bumping.

49
00:03:26,820 --> 00:03:39,720
Rym: And when we used to go to Sandy Hook, the only food options, unless you biked like all the way over to Highlands, like over that bridge where there's a bunch of good seafood, were basically three food trucks of varying levels of sadness.

50
00:03:40,720 --> 00:03:48,040
Rym: Now, not only are there more food trucks, but there are two full-on, normal restaurants on Sandy Hook.

51
00:03:48,540 --> 00:03:49,560
Rym: That is a new development.

52
00:03:50,841 --> 00:03:54,057
Scott: I only saw the one that was there last year, which is the like, you know...

53
00:03:54,802 --> 00:03:57,200
Rym: I already forget the names, there's the one near the lighthouse.

54
00:03:57,300 --> 00:03:58,740
Rym: Yeah, the one near the lighthouse is kind of small.

55
00:03:58,840 --> 00:04:01,260
Rym: There's another one right next to the ferry dock.

56
00:04:02,780 --> 00:04:03,479
Scott: Oh, okay, I didn't see it.

57
00:04:03,620 --> 00:04:09,620
Rym: It's huge and we thought, like we ate dinner somewhere else because we wanted the good seafood over at Highland, like we biked over there.

58
00:04:09,701 --> 00:04:11,679
Rym: But we went to check this place out.

59
00:04:12,081 --> 00:04:16,480
Rym: There were easily like a hundred plus people in the main dining area of this.

60
00:04:16,540 --> 00:04:17,418
Scott: So you were there on a weekend.

61
00:04:18,082 --> 00:04:20,779
Rym: Yeah, but it was rocking, it was completely full.

62
00:04:20,880 --> 00:04:21,980
Rym: There was like a line out the door.

63
00:04:22,040 --> 00:04:22,968
Scott: Maybe that's why I didn't see it.

64
00:04:23,009 --> 00:04:24,260
Scott: Maybe it wasn't open on a weekday.

65
00:04:24,660 --> 00:04:26,859
Rym: Yeah, I imagine it's only open on weekends.

66
00:04:27,380 --> 00:04:28,759
Rym: I didn't see any hours or anything.

67
00:04:29,201 --> 00:04:35,740
Rym: But also, some minor updates, more of those houses are available for rentals.

68
00:04:36,500 --> 00:04:40,157
Scott: I saw one that had a sign that said "for rent" with some kind of URL.

69
00:04:40,217 --> 00:04:40,820
Scott: I didn't look at.

70
00:04:40,920 --> 00:04:44,739
Rym: Yep, I went to that URL and I saw there's a bunch you can rent and there's also some on Airbnb.

71
00:04:46,360 --> 00:04:51,480
Rym: Also, the campsite that used to, as best I can tell, was always for group camping.

72
00:04:51,640 --> 00:04:55,160
Rym: You had to organize like in advance and it wasn't like a straightforward process.

73
00:04:55,561 --> 00:05:03,900
Rym: Now it just has a bunch of individual tent camping sites you can just reserve on a website just like a hotel for a nominal fee.

74
00:05:04,340 --> 00:05:10,560
Rym: And they even have a process, which was the thing that always kept me away from trying to rent one of the places on this island.

75
00:05:10,960 --> 00:05:16,260
Rym: In the past, if you wanted to go there with your friends and you wanted to use that ferry, the ferry is very strict.

76
00:05:16,540 --> 00:05:23,080
Rym: You can only book one day round trip tickets or like you'll get tackled like that crazy lady that one time.

77
00:05:24,540 --> 00:05:27,700
Rym: So now, there's a thing on the Seastreak website.

78
00:05:28,541 --> 00:05:43,520
Rym: If you are staying on the island or on the peninsula for multiple days because you're camping and you use the express ferry, you can call them and arrange a special multi-day trip where you can come on one day and leave on another day and not get tackled by the park service.

79
00:05:45,420 --> 00:05:51,540
Rym: So we're thinking about camping on Sandy Hook in October and checking it out and seeing what that's like.

80
00:05:53,644 --> 00:05:54,388
Rym: You can always come.

81
00:05:54,509 --> 00:05:55,816
Rym: You just gotta get your own tent.

82
00:05:55,836 --> 00:05:56,480
Rym: I only have one tent.

83
00:05:57,220 --> 00:05:58,499
Scott: I have a tent, but it seems cold.

84
00:05:59,120 --> 00:05:59,341
Rym: Cold?

85
00:05:59,361 --> 00:05:59,884
Rym: Are you kidding?

86
00:05:59,904 --> 00:06:01,291
Rym: In October?

87
00:06:01,311 --> 00:06:03,120
Rym: It's gonna be perfectly comfortable to camp.

88
00:06:03,680 --> 00:06:09,200
Rym: And in fact, camping in a tent is nicer in like late September or October because you got the nice warm sleeping bag.

89
00:06:09,660 --> 00:06:15,478
Rym: It's not that comfortable usually to camp in a place like that in the dead of summer when it doesn't get under like 75 at night.

90
00:06:18,421 --> 00:06:20,207
Rym: Anyway, Sandy Hook adventures.

91
00:06:20,328 --> 00:06:22,395
Rym: Lots of tech news, not a tech news roundup.

92
00:06:22,576 --> 00:06:23,640
Rym: We're saving that for the future.

93
00:06:24,220 --> 00:06:25,938
Rym: But I'm sure you've seen.

94
00:06:27,522 --> 00:06:30,533
Scott: If you go long enough, you can refill your quota.

95
00:06:30,834 --> 00:06:32,560
Scott: You could do two tech news roundups in a row.

96
00:06:32,880 --> 00:06:33,242
Scott: I could.

97
00:06:33,665 --> 00:06:36,000
Rym: The listener is always asking for the tech news roundup.

98
00:06:37,220 --> 00:06:41,580
Scott: There's like 10,000 podcasts and websites that are nothing but tech news roundups.

99
00:06:41,740 --> 00:06:43,800
Rym: Yeah, and I get the impression either they're all bad.

100
00:06:44,422 --> 00:06:45,867
Scott: Shouldn't we do something different?

101
00:06:46,107 --> 00:06:49,940
Scott: If you want tech news roundup, why don't you just go to one of the people who do it every single day?

102
00:06:51,801 --> 00:06:56,237
Rym: There's a thousand Spidermans all over the place, but why are we talking a lot about Spider-Verse?

103
00:06:56,298 --> 00:06:56,940
Rym: That's the good one.

104
00:06:57,862 --> 00:06:58,420
Scott: I'm just saying.

105
00:06:59,760 --> 00:07:09,320
Rym: So in some news, and this is a technology news because this is an area where technology was employed and had problems and needs to be employed better.

106
00:07:09,340 --> 00:07:10,802
Rym: And it fits into a common theme of GeekNights.

107
00:07:11,443 --> 00:07:24,380
Rym: One aspect of the extreme wildfires and the devastation in Hawaii and Maui during the wildfires not too long ago was that there are warning sirens on the island.

108
00:07:24,580 --> 00:07:25,580
Scott: We talked about this already.

109
00:07:25,760 --> 00:07:26,745
Scott: Yes.

110
00:07:26,986 --> 00:07:29,560
Rym: The warning sirens were not used.

111
00:07:30,462 --> 00:07:33,979
Scott: Yes, because they thought people would hear them and run up away from the water.

112
00:07:35,862 --> 00:07:47,240
Rym: So the technology problem that is now in the news being talked about is how do you inform people in a place like Maui about different kinds of disasters?

113
00:07:47,880 --> 00:07:48,001
Scott: Right.

114
00:07:48,021 --> 00:07:50,714
Scott: We've been relying on our text message alerts, but guess what?

115
00:07:51,035 --> 00:07:51,920
Scott: That shit was down.

116
00:07:52,060 --> 00:07:53,666
Scott: Yep.

117
00:07:53,706 --> 00:07:54,409
Rym: Put a tweet out.

118
00:07:54,449 --> 00:07:57,340
Rym: Well, Twitter doesn't even work anymore, let alone people don't have internet.

119
00:07:57,620 --> 00:07:57,720
Scott: Right.

120
00:07:57,740 --> 00:08:00,086
Scott: The cell towers were on fire, right?

121
00:08:00,187 --> 00:08:02,834
Scott: It's like, yeah, the radio, you know, you could have a radio tower.

122
00:08:02,874 --> 00:08:05,240
Scott: that, you know, but people don't turn on radios.

123
00:08:05,560 --> 00:08:08,240
Rym: Nor do most people even have radios anymore.

124
00:08:08,883 --> 00:08:10,120
Scott: Or broadcast television.

125
00:08:10,260 --> 00:08:16,397
Rym: The only radio in our apartment, I was thinking about this, the only one is gone.

126
00:08:17,900 --> 00:08:24,753
Rym: Because the last radio we had was the same alarm clock radio that I had since middle school.

127
00:08:25,154 --> 00:08:28,100
Rym: that could theoretically get AM and FM if I wanted it to.

128
00:08:28,480 --> 00:08:29,458
Rym: And we got rid of that thing.

129
00:08:30,500 --> 00:08:30,622
Scott: Yeah.

130
00:08:30,642 --> 00:08:32,260
Scott: Well, I mean, I have radios.

131
00:08:32,820 --> 00:08:32,880
Rym: Yep.

132
00:08:32,900 --> 00:08:35,339
Rym: I don't have any because what would I ever use one for?

133
00:08:36,384 --> 00:08:40,480
Scott: I mean, I have an emergency radio and I also have a little Sony radio.

134
00:08:41,360 --> 00:08:46,780
Rym: But this gets into an even bigger problem because even if, like, how do we solve this problem?

135
00:08:47,281 --> 00:08:55,260
Rym: Does the government need to start giving people emergency radios coupled with instructions on when and how to use them?

136
00:08:56,001 --> 00:08:56,102
Scott: No.

137
00:08:56,122 --> 00:09:02,035
Scott: I think by law, they should, you know, put AM/FM radios in all smartphones.

138
00:09:02,196 --> 00:09:03,579
Scott: Otherwise, you can't sell them in the US.

139
00:09:03,599 --> 00:09:03,960
Scott: Tough shit.

140
00:09:04,901 --> 00:09:09,720
Rym: That would actually require some more expensive chips and I don't think people would use them anyway.

141
00:09:09,840 --> 00:09:11,466
Scott: There have been cell phones in the past.

142
00:09:11,546 --> 00:09:15,200
Scott: In Japan, flip phones could pick up broadcast television, right?

143
00:09:15,420 --> 00:09:15,761
Scott: Yes.

144
00:09:15,821 --> 00:09:17,385
Rym: My old cell phone could do that.

145
00:09:17,445 --> 00:09:17,967
Rym: Guess what?

146
00:09:18,368 --> 00:09:23,020
Rym: It required physical headphones plugged into it to act as the antenna.

147
00:09:23,480 --> 00:09:24,307
Rym: You can't have an antenna.

148
00:09:24,327 --> 00:09:25,880
Rym: You need a bigger antenna or that doesn't work.

149
00:09:26,440 --> 00:09:29,294
Rym: All those phones required wired headphones plugged in.

150
00:09:29,314 --> 00:09:30,339
Rym: Guess what iPhones don't have?

151
00:09:32,002 --> 00:09:32,980
Scott: A point I'm pretty sure.

152
00:09:33,000 --> 00:09:36,680
Rym: You need to be through an adapter because you need a direct connection for that type of antenna.

153
00:09:38,260 --> 00:09:40,018
Scott: I think there'd be a way to accomplish this.

154
00:09:40,445 --> 00:09:41,059
Scott: I don't know.

155
00:09:41,320 --> 00:09:42,099
Scott: This doesn't seem impossible to me.

156
00:09:42,240 --> 00:09:47,240
Rym: Yeah, put the headphone jack back on or give people an antenna that has to be plugged into their device.

157
00:09:48,840 --> 00:09:50,899
Scott: I think that, you know, this is a solvable problem.

158
00:09:51,160 --> 00:09:57,340
Rym: But also, even if you did that, one, most people are not going to have an up-to-date cell phone.

159
00:09:57,520 --> 00:10:00,000
Rym: Like, most people either don't have a smartphone or have an old one.

160
00:10:01,621 --> 00:10:09,960
Rym: And two, even if you do this, I don't think people would even think or know to activate that feature or even be aware that it existed.

161
00:10:10,520 --> 00:10:19,040
Scott: That's okay because you can have the emergency broadcast system broadcast a signal and that signal would then automatically activate the radio in the phone.

162
00:10:19,580 --> 00:10:20,819
Scott: You wouldn't have to, like, go through it on purpose.

163
00:10:20,860 --> 00:10:25,280
Rym: That is more infeasible because they're not always listening.

164
00:10:26,800 --> 00:10:29,860
Rym: And making them always listen would drain the batteries.

165
00:10:31,188 --> 00:10:31,700
Scott: I'm just saying.

166
00:10:32,060 --> 00:10:34,380
Rym: I'm saying there are significant technical challenges to that.

167
00:10:34,380 --> 00:10:35,220
Scott: Broadcasting drains the batteries.

168
00:10:36,240 --> 00:10:36,533
Scott: Receiving...

169
00:10:37,141 --> 00:10:45,200
Rym: So you should look up the difference between AM and FM and why you can have unpowered radios of certain kinds, but not unpowered radios of other kinds.

170
00:10:45,860 --> 00:10:50,680
Scott: Well, we're not using this spectrum for, you know, people aren't listening to actual radio anymore, so we use the unpowered kind.

171
00:10:51,763 --> 00:10:53,659
Rym: Except we haven't shut all that existing stuff down yet.

172
00:10:53,960 --> 00:10:54,670
Scott: Shut that shit off.

173
00:10:54,711 --> 00:10:55,279
Scott: We ain't using it.

174
00:10:55,600 --> 00:10:56,602
Rym: Yep.

175
00:10:56,782 --> 00:11:08,020
Rym: I guess the technology problem here is pretty interesting because in New York City, the way, like, all commercial buildings work is there's one kind of sound that means fire GTFO.

176
00:11:08,762 --> 00:11:09,240
Rym: And there's another...

177
00:11:09,240 --> 00:11:14,080
Scott: Well, I mean, a lot of modern buildings, the alarm systems actually say words.

178
00:11:14,302 --> 00:11:15,259
Rym: Well, that's what I was about to say.

179
00:11:15,760 --> 00:11:16,691
Rym: They still require...

180
00:11:17,522 --> 00:11:18,519
Scott: Or carbon monoxide.

181
00:11:19,263 --> 00:11:20,259
Rym: Yes, that's type two.

182
00:11:20,920 --> 00:11:21,415
Rym: Terrorist.

183
00:11:21,901 --> 00:11:23,628
Rym: Is a different tone.

184
00:11:23,950 --> 00:11:26,520
Rym: that, as far as I can tell, by law is a different tone.

185
00:11:26,980 --> 00:11:30,200
Rym: And that tone means listen for further instructions.

186
00:11:30,801 --> 00:11:34,680
Rym: And those are the only two tones because we have more than two tones.

187
00:11:35,361 --> 00:11:45,500
Rym: Who the hell... What human, average human of average intelligence and average knowledge will know the difference between three or four or five different tones, especially when different states are going to do it differently.

188
00:11:45,802 --> 00:11:47,100
Rym: So New York has got two tones.

189
00:11:47,500 --> 00:11:48,540
Rym: One of them is fire.

190
00:11:48,820 --> 00:11:49,578
Rym: Get the fuck out.

191
00:11:49,862 --> 00:11:51,880
Rym: And the other one is listen for instructions.

192
00:11:52,240 --> 00:11:53,000
Rym: Don't do anything.

193
00:11:53,440 --> 00:11:54,340
Rym: Listen for instructions.

194
00:11:54,421 --> 00:11:55,719
Rym: We'll tell you what to do with words.

195
00:11:56,980 --> 00:12:03,800
Rym: And I feel like that type of system of there are no more than two different kinds of signals.

196
00:12:04,264 --> 00:12:11,280
Rym: And one of them should be the... If you hear this signal, do the specific thing that we have been teaching you your entire lives to do.

197
00:12:11,701 --> 00:12:16,380
Rym: Like in Hawaii, the thing you are told if that siren goes off is head up mountain.

198
00:12:16,646 --> 00:12:17,139
Rym: Just get that.

199
00:12:17,300 --> 00:12:17,899
Rym: There's tsunami coming.

200
00:12:18,040 --> 00:12:18,439
Rym: Head up mountain.

201
00:12:18,841 --> 00:12:26,860
Rym: So the second tone should be activate whatever emergency device the government gave you or turn on your cell phone and hit the emergency button or whatever.

202
00:12:27,200 --> 00:12:28,599
Rym: Like wait for instructions.

203
00:12:29,420 --> 00:12:34,460
Scott: I also feel like these low population areas with specific disaster concerns...

204
00:12:35,200 --> 00:12:39,580
Rym: You can do what Costa Rica does and what a lot of countries do and this is super effective.

205
00:12:40,322 --> 00:12:49,060
Rym: A truck with a megaphone and people on bikes with megaphones just fan out from the emergency center telling people what to do actively.

206
00:12:49,440 --> 00:12:53,080
Scott: We definitely do not employ that method enough in the United States anywhere.

207
00:12:53,440 --> 00:12:54,226
Scott: It's like in Japan.

208
00:12:54,266 --> 00:12:56,140
Scott: you see them doing it for like political campaigning.

209
00:12:56,721 --> 00:12:58,279
Scott: And remember the great northeast power outage?

210
00:12:59,240 --> 00:13:04,540
Scott: I'm not saying we should use it for political campaigning or advertising but it's like that method is not used enough here.

211
00:13:04,980 --> 00:13:08,060
Scott: It is effective and good in high population areas.

212
00:13:08,141 --> 00:13:08,385
Scott: Yup.

213
00:13:08,609 --> 00:13:09,280
Rym: Case in point.

214
00:13:09,961 --> 00:13:17,980
Rym: If there's a riot because some live streamer caused a problem in Manhattan, a bunch of people immediately show up to handle the situation.

215
00:13:18,420 --> 00:13:25,120
Rym: You'd think disaster response would be a similar high value thing for society but capital is angered by this idea.

216
00:13:26,461 --> 00:13:27,480
Rym: Anyway, got any news?

217
00:13:29,104 --> 00:13:30,019
Scott: We do have a news.

218
00:13:32,101 --> 00:13:39,500
Scott: There's been a lot of hoo-ha around Dolby Vision, Dolby Atmos, Dolby everything lately.

219
00:13:40,081 --> 00:13:42,232
Rym: I don't even have them all straight in my head.

220
00:13:42,272 --> 00:13:43,880
Rym: I gotta look it up every time.

221
00:13:44,280 --> 00:13:45,877
Scott: I watched some YouTube videos so now I know.

222
00:13:46,921 --> 00:14:27,160
Scott: But basically Dolby, they make these technologies which are good/bad that allow basically creators of mostly movies but also television shows and other television productions to sort of distribute and master their audio and video in a certain way using Dolby technologies in order to try to guarantee to the extent feasible that when you watch, because they're mastering some movie doing color grading on like a monitor, a special studio monitor, that's like a reference thing that costs $40,000.

223
00:14:27,160 --> 00:14:35,000
Scott: So there's no way that you with your $800 TV from Costco are going to be seeing the same color that they see.

224
00:14:35,921 --> 00:14:40,045
Scott: So they want to try to guarantee that you see the color they see as much as you could.

225
00:14:40,886 --> 00:14:54,020
Scott: or you don't have the sound system that they have in their recording studio but they want to make sure that you hear as much as close to the fancy movie theater as you possibly can with what you have in your home.

226
00:14:54,020 --> 00:14:57,085
Rym: You want to know how movie theaters and stadiums actually set that up?

227
00:14:57,586 --> 00:15:05,860
Rym: They'll send tones of different frequencies out all the speakers and they put sensors and people all over the facility and they use that to autotune.

228
00:15:06,420 --> 00:15:08,243
Scott: The ones that care can set it up.

229
00:15:08,283 --> 00:15:17,440
Scott: but the thing is the vast majority of theaters and home theaters especially but also real theaters do not go through the effort of setting everything up properly.

230
00:15:18,281 --> 00:15:18,822
Scott: Imagine

231
00:15:18,842 --> 00:15:31,640
Rym: the average person who has a TV and some stuff and then you tell them yes get this extra $100 device and put it in the middle of your living room and then hit a button and it's going to screech for an hour and let it do its thing.

232
00:15:31,900 --> 00:15:41,493
Scott: There are those audiophile nerdy types but there are also those other types who aren't believing in audiophile nonsense but they just really want their home theater to be perfect.

233
00:15:41,773 --> 00:15:46,980
Scott: so they'll pay someone to come calibrate their TV and pay someone to calibrate their stereo.

234
00:15:48,791 --> 00:15:50,754
Scott: So Dolby has a thing called Atmos.

235
00:15:50,814 --> 00:15:56,080
Scott: you probably heard of it and what Atmos is is basically just even more surround sound.

236
00:15:56,380 --> 00:15:57,301
Scott: It's like you know.

237
00:15:57,481 --> 00:16:04,787
Scott: see if we had we're used to like you know 5.1 said whatever right it's like Atmos will go the even further.

238
00:16:05,208 --> 00:16:19,600
Scott: not just rear front center channels right but actually sounds going up and you know over your head right and things bouncing sounds off the ceiling and shit like that to make it sound like things are coming from anywhere.

239
00:16:19,843 --> 00:16:21,820
Rym: Is that 14.1?

240
00:16:21,820 --> 00:16:22,021
Scott: I have.

241
00:16:22,061 --> 00:16:23,463
Scott: no I know it it's.

242
00:16:23,743 --> 00:16:26,728
Scott: there's no set number for it because it depends what your equipment is.

243
00:16:27,248 --> 00:16:34,519
Scott: but you know generally you know you're going to have like some rear speakers with some like upward firing drivers right that and shit like that.

244
00:16:35,901 --> 00:16:40,806
Scott: And like your center channel would be like some soundbar with like who knows how many tiny drivers is.

245
00:16:40,866 --> 00:16:55,579
Rym: a true audio file will want a 3D printed fully anatomically correct set of human heads arranged in their TV so that any characters dialogue is recreated with actual biological vocal cords in real time.

246
00:16:57,740 --> 00:16:58,261
Scott: That'd be good.

247
00:16:59,181 --> 00:17:02,984
Scott: so the thing with Dolby Atmos is that you know it works.

248
00:17:03,324 --> 00:17:07,867
Scott: but you have to get like you know Dolby Atmos equipment and set it up specifically.

249
00:17:08,088 --> 00:17:12,391
Scott: position the speakers right and you know a lot of people have different rooms right.

250
00:17:12,411 --> 00:17:18,095
Scott: for example the room I have is not ideal because the you know it's not huge so the couch is up against the wall.

251
00:17:18,135 --> 00:17:21,718
Scott: you can't really put speakers behind you right so you can't read.

252
00:17:21,738 --> 00:17:24,099
Scott: the rear channels aren't very rear are they.

253
00:17:26,140 --> 00:17:30,064
Scott: Or you know things of that nature and you know you get a lot of people.

254
00:17:30,104 --> 00:17:33,227
Scott: you know not too many people have like wireless systems right.

255
00:17:33,267 --> 00:17:33,787
Scott: that's you know.

256
00:17:34,147 --> 00:17:37,230
Scott: there's also various companies for example Samsung.

257
00:17:37,270 --> 00:17:38,211
Scott: I forget what they call it.

258
00:17:38,231 --> 00:17:44,436
Scott: they have like a special Samsung only thing where you won't actually turn off the speakers in your television.

259
00:17:44,957 --> 00:17:48,560
Scott: it'll incorporate them in to whatever sound system you already have.

260
00:17:51,422 --> 00:17:52,023
Scott: Shit like that.

261
00:17:52,383 --> 00:17:56,329
Scott: so Dolby actually announced the thing today.

262
00:17:56,729 --> 00:18:00,535
Scott: it's called Dolby Atmos flex connect right.

263
00:18:01,115 --> 00:18:04,300
Scott: so hypothetically the way this would work is that.

264
00:18:05,341 --> 00:18:12,006
Scott: Just like Rym said oh with the professional calibration they put microphones and sensors all around and play sounds out of all the speakers.

265
00:18:12,086 --> 00:18:15,668
Scott: and then right it basically sort of does that in your home.

266
00:18:16,289 --> 00:18:20,852
Scott: so your TV would play sounds out of all its speakers.

267
00:18:20,912 --> 00:18:31,580
Scott: however many the fuck you've got with your sound bars and your wireless rear speakers or who knows what you got and then the you have microphones in the flex connect television.

268
00:18:32,081 --> 00:18:35,105
Scott: Right and then that would figure out what to do.

269
00:18:35,746 --> 00:18:36,307
Scott: and there you go.

270
00:18:36,347 --> 00:18:37,989
Scott: now you've got a Dolby app.

271
00:18:38,049 --> 00:18:42,135
Scott: you're going to get the as much at most as you can get with what you got.

272
00:18:42,696 --> 00:18:45,700
Scott: so this is actually strange because.

273
00:18:46,780 --> 00:18:51,568
Scott: Usually this Dolby shit is all about making money for TV manufacturers and for Dolby.

274
00:18:51,709 --> 00:18:53,612
Scott: right because it's like number one.

275
00:18:54,153 --> 00:18:58,540
Scott: if you want to have a TV with Dolby shit in it you have to pay a licensing fee to Dolby.

276
00:18:58,940 --> 00:19:13,780
Scott: So for example some TV manufacturers you know just have HDR something something which is like open right and open license protocol whatever and they don't have Dolby vision because they would have to pay Dolby to have Dolby vision certification on their TVs.

277
00:19:14,541 --> 00:19:17,744
Scott: And it's like alright you know is the HDR 10 whatever?

278
00:19:17,924 --> 00:19:20,006
Scott: just as good probably.

279
00:19:20,686 --> 00:19:35,200
Scott: but you know the thing is some people will only buy a TV if it has Dolby vision because they really want to make sure that if they get some booray that was Dolby vision that it's the colors are exactly right even though they probably couldn't tell if it was the HDR.

280
00:19:35,440 --> 00:19:39,005
Rym: I mean that's why you know even doing like color like design work.

281
00:19:39,626 --> 00:19:50,680
Rym: I have some Dell ultra sharps and they're pretty good on color but they're not like pro good and it's fine but they're definitely better than like random LG.

282
00:19:51,900 --> 00:19:52,120
Scott: Right.

283
00:19:52,341 --> 00:20:02,331
Scott: so there's a two levels of making money you pay the manufacturer pays Dolby for a license and then the manufacturer hopes to get increased sales because they can slap a Dolby logo on their product.

284
00:20:02,712 --> 00:20:10,320
Scott: this the Dolby flex connect seems to satisfy both those things but also maybe not because.

285
00:20:11,121 --> 00:20:25,180
Scott: Yes the you know the Dolby would make money from the licensing and the manufacturer of a television would make money from selling their flex connect television but they might actually lose money on selling sound systems.

286
00:20:25,781 --> 00:20:40,757
Scott: Because hypothetically with flex connect you could just connect whatever the fuck speakers you've got not some Dolby vision you know or Dolby at most certified sound bar system which is probably what people would buy anyway.

287
00:20:40,817 --> 00:20:42,940
Scott: but like you could theoretically make a TV.

288
00:20:43,940 --> 00:20:56,094
Scott: That just has Bluetooth in it and you connect as many Bluetooth speakers as you can find and you throw them all over your room and you don't care where that where they are or what direction they're facing or what kind they are.

289
00:20:56,154 --> 00:21:02,020
Scott: mix all the brands together like as many as you can pair right without Bluetooth failing.

290
00:21:03,461 --> 00:21:15,358
Scott: And this will play sounds out of all of them and do as much Dolby at most as it can do with the speakers that you provided that were you know cheap Bluetooth speakers you bought off of.

291
00:21:15,819 --> 00:21:16,400
Scott: you know discount.

292
00:21:16,480 --> 00:21:27,696
Rym: You know what is that that idea scratches is something that every nerd was obsessed with back before computers you know had the idea of things like more than one core or more than one processor.

293
00:21:28,176 --> 00:21:30,720
Rym: everybody wanted to make a Beowulf cluster of something.

294
00:21:31,421 --> 00:21:43,100
Scott: Yep so this could also theoretically obviate the need for like the Samsung thing I talked about where it uses the TV where it incorporates the TV speaker because a flex connect TV would obviously just.

295
00:21:43,781 --> 00:21:53,300
Scott: Play sound out of its speaker as part of the and always incorporate it right it would just every speaker it can find and make noise out of will be incorporated into the at most so.

296
00:21:55,081 --> 00:22:10,140
Scott: Yeah I think maybe this is like a good sign like hey you know when if you need a new TV wait for flex connect to actually come out and get a flex connect TV and then you know that'll be good because like you know forward in time.

297
00:22:11,940 --> 00:22:15,745
Scott: Whatever speakers you happen to own or whatever you know will always kind of work.

298
00:22:15,986 --> 00:22:17,868
Rym: right now that my my my conundrum is one.

299
00:22:17,908 --> 00:22:26,560
Rym: I'm looking at buying a TV now and I may wait because of this because the current TV has not died yet it's it's having some troubles but it has not died yet.

300
00:22:28,840 --> 00:22:34,334
Rym: But I am vacillating on the audio side between a kind of a different problem or a different question.

301
00:22:35,036 --> 00:22:36,680
Rym: do I want long term.

302
00:22:37,500 --> 00:22:47,100
Rym: Hyper accurate audio to what the media intended or do I want to go the opposite direction like I used to do like listening to music in high school and.

303
00:22:47,701 --> 00:22:53,807
Rym: Just fuck it all up and mix it to my own personal enjoyment regardless of what the creators intended.

304
00:22:54,187 --> 00:23:05,940
Rym: for example maybe I just start boosting the mid range vocals and put compressors in my chains to compress everything down to make it more convenient to listen to and watch movies in my actual real life.

305
00:23:06,901 --> 00:23:08,202
Scott: Yeah but I mean it depends.

306
00:23:08,263 --> 00:23:12,348
Scott: right because certain you know different movies are going to that's you know we're going to need that.

307
00:23:12,648 --> 00:23:15,191
Scott: some aren't right and also it's.

308
00:23:15,331 --> 00:23:22,600
Scott: it's not so much about the how the the sound right the equalization or whatever you're going to do in that department but just the positioning.

309
00:23:22,700 --> 00:23:24,184
Scott: Yeah right it's like you know.

310
00:23:24,204 --> 00:23:29,699
Scott: do you want to hear a star destroyer actually fly over your head or are you OK with just.

311
00:23:31,301 --> 00:23:33,263
Scott: Right because you're home and you're not at the movie theater?

312
00:23:33,283 --> 00:23:34,004
Scott: who cares what?

313
00:23:34,025 --> 00:23:35,266
Rym: it reminds me a total side thing.

314
00:23:35,306 --> 00:23:40,294
Rym: I saw an article and I got to find it again because I want to see how much more there is.

315
00:23:40,494 --> 00:23:44,340
Rym: an argument from a doctor that the current debate of.

316
00:23:45,421 --> 00:23:50,000
Rym: Movies are mixed wrong and no one can hear the audio anymore has a complication.

317
00:23:51,341 --> 00:24:08,260
Rym: People have damaged their hearing more it but we want the error we are in since when this complaint started to arise it happens to line up with a bunch of industry trends but the complaints are broad even in places where Hollywood has not penetrated in the same way.

318
00:24:09,081 --> 00:24:12,426
Rym: So this doctor's argument was that what's actually happening?

319
00:24:12,846 --> 00:24:22,040
Rym: this is the first generation that got old and lost their fucking hearing like everyone has for all of time and was online enough to complain about it.

320
00:24:23,260 --> 00:24:25,060
Rym: That and is what this doctor's arguing.

321
00:24:28,168 --> 00:24:28,574
Rym: And anyway.

322
00:24:31,041 --> 00:24:35,505
Rym: I think it's time for things of the day.

323
00:24:35,905 --> 00:24:48,718
Rym: so I'm back on my neutrino kick and cork kick and I'm increasingly watching ever increasingly mathematical videos about quantum physics and quantum theory.

324
00:24:49,038 --> 00:24:50,319
Rym: but the video I want to link to is.

325
00:24:52,082 --> 00:24:53,064
Rym: Just fantastic.

326
00:24:53,304 --> 00:25:01,580
Rym: it's not long it's like 15 minutes long and what it does is it explains as simply as possible.

327
00:25:02,581 --> 00:25:12,419
Rym: To the best of our current knowledge like 2023 what's the best we know about what the hell quantum theory means and what it is.

328
00:25:14,381 --> 00:25:15,442
Rym: And it's just really well done.

329
00:25:15,482 --> 00:25:27,479
Rym: it has this great diagram that kind of shows that everything we think of as a particle it's basically just like a field and each one of these fields is like one dimension of a wave in space and we're pretty sure that's what reality is.

330
00:25:29,721 --> 00:25:30,382
Rym: Really good video.

331
00:25:30,642 --> 00:25:42,740
Rym: it's not three blue one brown where it's gonna feel like you understand and then it shows an equation that you can't parse and then it's all down here from there and never gets to the point of showing you an equation that you will not understand.

332
00:25:45,460 --> 00:25:47,562
Scott: Okay so you ever go to restaurant.

333
00:25:48,623 --> 00:25:53,467
Scott: usually it's going to be like a Chinese restaurant jab you know East Asian restaurant but not always.

334
00:25:54,008 --> 00:26:04,497
Scott: and there is you know food that is not edible is plastic food that is on display to show you what the meal looks like but it is made of plastic.

335
00:26:04,777 --> 00:26:08,380
Scott: right but it looks like you know like that's what the food looks like.

336
00:26:09,020 --> 00:26:14,305
Scott: Or pretty close to it other than maybe like a hint of shininess that lets you know it's plastic and not edible.

337
00:26:14,646 --> 00:26:19,911
Scott: yeah I've seen those around quite a bit in my life and the question is where do those come from?

338
00:26:20,311 --> 00:26:24,976
Scott: is there just like you know did someone make the food and then like cast it in wax?

339
00:26:25,036 --> 00:26:25,736
Scott: did somebody?

340
00:26:26,017 --> 00:26:28,299
Scott: is there a catalog of like fake food you can buy?

341
00:26:28,319 --> 00:26:29,660
Scott: and right.

342
00:26:30,421 --> 00:26:38,649
Scott: And the answer is there's people like this guy in this video who have been making fake plastic food for like fifty years.

343
00:26:38,709 --> 00:26:43,613
Scott: he's like a craftsman an artisan and he makes fake food.

344
00:26:44,034 --> 00:26:48,538
Scott: and in this video he makes fake food and he just he just comes right out of the gate.

345
00:26:48,578 --> 00:26:50,099
Scott: he makes a lettuce like out of nothing.

346
00:26:50,180 --> 00:26:50,580
Scott: it's like what.

347
00:26:52,281 --> 00:26:54,163
Scott: It's like a wizard of making fake food.

348
00:26:54,623 --> 00:26:56,465
Scott: if only making real food was so easy.

349
00:26:56,485 --> 00:26:58,327
Scott: well I mean it's not easy.

350
00:26:58,367 --> 00:27:06,934
Scott: the guys you know a highly talented skilled you know legend of the craft but you know this is this is just fascinating.

351
00:27:07,054 --> 00:27:09,897
Scott: this video right it's like he just makes it with like this.

352
00:27:09,917 --> 00:27:13,680
Scott: he's got some sort of chemical some sort of plastic thing where you put it in water.

353
00:27:14,161 --> 00:27:15,723
Scott: And it starts to solidify.

354
00:27:15,783 --> 00:27:21,349
Scott: but he can sort of you know mix it up and reshape it and mix the colors of it before that happens.

355
00:27:22,411 --> 00:27:29,940
Scott: I wonder what that material is but it's pretty just you know even if I had the material I couldn't work with it like this guy right.

356
00:27:29,960 --> 00:27:31,983
Scott: Just gets it perfect immediately.

357
00:27:32,003 --> 00:27:35,607
Scott: right you can make any kind of food make you know ice creams or whatever.

358
00:27:35,627 --> 00:27:46,040
Rym: this feels like the kind of thing where this person has one or more apprentices and people learn it by learning from someone who is good at it and not from an institution.

359
00:27:48,841 --> 00:28:00,100
Rym: In the meta moment the GeekNights book club book the murderbot diaries I have read 1.4 of the murderbot diaries and I expect to have read a lot of them by the time we get back from PAX because I have two six hour flights.

360
00:28:00,320 --> 00:28:00,781
Scott: I've read.

361
00:28:00,801 --> 00:28:07,160
Scott: I've read like four murderbot diaries for I think four maybe five I'm not sure.

362
00:28:07,600 --> 00:28:10,560
Rym: I feel like around the first or second week of October.

363
00:28:10,740 --> 00:28:12,511
Scott: I only have two left and I'm gonna get other.

364
00:28:12,551 --> 00:28:13,960
Scott: I'm gonna get them from the library soon.

365
00:28:14,221 --> 00:28:18,300
Rym: Which implies we're probably gonna have read all the murderbot diaries by the time we do this.

366
00:28:18,380 --> 00:28:21,680
Scott: There's one that's coming out in November that so we're not if we haven't read all of them.

367
00:28:21,881 --> 00:28:26,660
Rym: All the murderbot diaries that exist as of August 28, 2023.

368
00:28:26,660 --> 00:28:29,767
Scott: You know what we could do since they're so easy to read and so fast.

369
00:28:29,827 --> 00:28:35,600
Scott: we could just wait till the one comes out in November right read it and then do the episode in November.

370
00:28:35,960 --> 00:28:36,749
Rym: We could do that.

371
00:28:37,093 --> 00:28:37,620
Rym: target November.

372
00:28:37,700 --> 00:28:42,480
Scott: Yeah and since it's so many books that gives people time because I think one of them is not a short one.

373
00:28:42,621 --> 00:28:44,000
Scott: I think one of them is like an actual novel.

374
00:28:44,180 --> 00:28:49,240
Rym: Well our friend Luke in the forum was complaining that starting with the fifth book they get really long.

375
00:28:50,081 --> 00:28:52,080
Scott: That must be the fifth one that I'm about to read.

376
00:28:52,600 --> 00:28:54,746
Scott: So let's do it.

377
00:28:54,846 --> 00:29:00,820
Scott: let's just go to November and then we can have all of them read including the brand new one and we'll have a relevant book club episode.

378
00:29:01,121 --> 00:29:03,789
Rym: Yeah so start reading the murderbot diaries.

379
00:29:03,870 --> 00:29:06,157
Rym: So far I have enjoyed them.

380
00:29:06,197 --> 00:29:07,100
Rym: There's a lot going on.

381
00:29:08,040 --> 00:29:14,240
Rym: They're not the best books I've ever read and they're not exactly going to be mind-blowing if you are well versed in science fiction.

382
00:29:15,000 --> 00:29:17,732
Scott: Spoiler it's one of those books where it's most.

383
00:29:17,792 --> 00:29:19,660
Scott: it's not entirely about what happens.

384
00:29:19,880 --> 00:29:26,080
Scott: It's mostly about what happens and it's it does have something to say but it's mostly what happens right.

385
00:29:26,803 --> 00:29:31,520
Scott: But it's fun and the characters are likable and that's why.

386
00:29:31,880 --> 00:29:32,941
Scott: I really like murderbot.

387
00:29:32,961 --> 00:29:48,136
Rym: I just imagine murderbot as being this this in its in its own mind this gremlin like a gremlin like entity whose sole goal is to fuck around not have to do work watch TV play video games and the world keeps intruding.

388
00:29:48,216 --> 00:29:49,397
Rym: and it's just like I guess.

389
00:29:49,697 --> 00:29:52,540
Rym: but it actually does kind of care a little but it's shy.

390
00:29:54,301 --> 00:29:56,206
Rym: Anyway I've read 1.4 of these books.

391
00:29:56,286 --> 00:29:56,868
Rym: we'll see if it.

392
00:29:57,550 --> 00:30:00,719
Rym: murderbot has increasing troubles as time goes on.

393
00:30:01,520 --> 00:30:03,059
Scott: Also yes it yes it does.

394
00:30:04,121 --> 00:30:11,220
Rym: We will not be doing a show on Thursday because we will be flying to Seattle for PAX West 2023.

395
00:30:11,220 --> 00:30:16,794
Rym: We're doing an all new panel games you can't play on Sunday at 3 30 p.m.

396
00:30:17,235 --> 00:30:19,420
Rym: in the blue morpho theater.

397
00:30:21,820 --> 00:30:34,840
Scott: Otherwise the GeekNights website is actually you're not gonna believe this it is like nearing completion not completion but like the point at which it does everything the current website does and it's better than the current website.

398
00:30:35,100 --> 00:30:45,440
Scott: Therefore we can launch it and they continue to work on it which will be easier to do than working on the old website because it's actually using modern technologies and not ancient versions of everything.

399
00:30:45,440 --> 00:30:47,745
Rym: I think the most important indicator that this is coming along.

400
00:30:47,826 --> 00:30:53,699
Rym: we're at the point where I have to actually start doing my short task list of things that only I can do or that I can do it.

401
00:30:54,320 --> 00:31:00,348
Scott: So what we're gonna do is we're gonna pick a day maybe in a couple weeks and we're gonna launch it on some server.

402
00:31:00,368 --> 00:31:08,560
Scott: you can't get to listener right and then we're gonna hack away at it until it's correct and then we'll move the DNS entry and then it'll be live.

403
00:31:10,301 --> 00:31:17,251
Rym: And so means I gotta do my full elevated adobe marker test to make sure that adobe didn't break anything.

404
00:31:17,552 --> 00:31:20,937
Scott: if it that really is for me that the markers don't work they don't work right.

405
00:31:20,957 --> 00:31:22,900
Scott: to work on that later it's not a necessary feature.

406
00:31:26,900 --> 00:31:30,543
Scott: Also you know once it goes live I'm gonna make the.

407
00:31:30,743 --> 00:31:33,305
Scott: there is a. you know the git repository open source.

408
00:31:33,826 --> 00:31:36,568
Scott: so if you want to then for once it's live.

409
00:31:37,048 --> 00:31:40,611
Scott: you can then help work on the website if you so desire.

410
00:31:40,631 --> 00:31:51,560
Scott: there's a list of things that are not done that could be done like for example it doesn't currently automatically like post a new episode to discord right that's a feature that pretty easy to add.

411
00:31:52,281 --> 00:31:55,189
Scott: It might take like a you know a couple hours of work but I haven't done it.

412
00:31:55,550 --> 00:31:57,695
Scott: so you could.

413
00:31:57,715 --> 00:31:59,480
Scott: you could do that so I don't have to if you want.

414
00:31:59,980 --> 00:32:02,779
Scott: Send a full request and I may or may not reject it.

415
00:32:03,200 --> 00:32:08,827
Rym: Not all help we need or would ask for or would be happy to receive is programming.

416
00:32:08,888 --> 00:32:18,180
Rym: for example a while ago we crowd sourced our terms of service and community guidelines and there is stuff like that that you could help us with on the website as well.

417
00:32:18,560 --> 00:32:21,724
Rym: So don't think that if you're not a programmer you can't help.

418
00:32:22,065 --> 00:32:34,660
Rym: not that the programming is hard for this kind of thing but there's a lot of like text and like categorization and helping us with labels and things that you could actually for real help with.

419
00:32:35,281 --> 00:32:36,123
Scott: Yeah we're going to start.

420
00:32:36,303 --> 00:32:43,280
Scott: also you know another feature that's planned is to help clear out the 404s and dead links on news is things of the day etc.

421
00:32:43,840 --> 00:32:52,156
Rym: Oh man I just randomly the other day I found an old episode of GeekNights and I saw the name of the thing of the day and I was like what the fuck is that?

422
00:32:52,176 --> 00:32:54,420
Rym: and of course it goes nowhere like it's dead.

423
00:32:57,704 --> 00:32:59,360
Scott: You could listen to the episode and find out.

424
00:32:59,560 --> 00:33:01,160
Rym: I could and we'll see.

425
00:33:01,501 --> 00:33:02,967
Scott: That's what the listener would do.

426
00:33:03,028 --> 00:33:05,600
Scott: is they would go and you know.

427
00:33:06,962 --> 00:33:10,609
Rym: Yeah anyway let's get into the main bit.

428
00:33:10,929 --> 00:33:16,460
Rym: so this was partly predicated by a news which we'll talk about as part of this but also.

429
00:33:16,740 --> 00:33:17,680
Scott: Let's talk about that news first.

430
00:33:18,041 --> 00:33:19,144
Rym: But this is a broader topic.

431
00:33:19,525 --> 00:33:24,860
Rym: so Twitter which was kind of one of the more important social networks in history for a lot of reasons.

432
00:33:28,940 --> 00:33:34,469
Rym: Notable and again this is a I'm not saying this is good I'm saying this is what happened situation.

433
00:33:34,810 --> 00:33:41,220
Rym: Twitter of course has shat the bed and somehow has continued to shit the bed in increasing ways.

434
00:33:41,721 --> 00:33:49,400
Rym: But this latest one isn't just annoying it is dangerous to a degree to the people still using Twitter.

435
00:33:50,540 --> 00:33:54,020
Rym: Twitter is removing the ability to block other users.

436
00:33:55,421 --> 00:33:58,949
Rym: Just full stop now there we could.

437
00:33:59,350 --> 00:34:03,640
Rym: we don't need to address why they're doing it which comes down to the right wing.

438
00:34:04,741 --> 00:34:09,679
Rym: People on Twitter who are angry at being blocked which is one of the main things driving Twitter.

439
00:34:10,360 --> 00:34:18,000
Rym: Also advertisers and influencers who are obsessed with having their opinions are supposed to be seen.

440
00:34:18,520 --> 00:34:26,719
Rym: A lot of bad people don't want you to be able to block people and blocking is a fundamental safety feature of any interactive platform in the world.

441
00:34:26,739 --> 00:34:27,199
Rym: full stop.

442
00:34:27,962 --> 00:34:30,649
Scott: So they are keeping muting right.

443
00:34:30,768 --> 00:34:35,080
Scott: so let's talk about how it's implemented specifically on Twitter right.

444
00:34:35,679 --> 00:34:42,820
Scott: And I'm not saying it's entirely right to get rid of blocking but it's not entirely wrong either because.

445
00:34:43,239 --> 00:34:48,100
Rym: I do disagree with what you're about to say pretty strongly because you didn't use Twitter the way most people use it.

446
00:34:48,801 --> 00:34:57,520
Scott: That's fine but blocking on Twitter right doesn't actually never even when it was there did not actually block anyone right.

447
00:34:57,720 --> 00:35:09,880
Scott: If your account was unprotected meaning that your default tweets were completely public or if you had a protected account blocking is meaningless because no one can interact with you unless you allow them right so that that doesn't account.

448
00:35:10,421 --> 00:35:15,154
Scott: So if you had an unprotected account someone who was blocked right they would not.

449
00:35:15,234 --> 00:35:17,360
Scott: if they tried they couldn't follow you right.

450
00:35:17,880 --> 00:35:21,980
Scott: And if they you know if you tweeted they wouldn't see your tweets.

451
00:35:22,360 --> 00:35:23,404
Rym: They also couldn't search for you.

452
00:35:23,504 --> 00:35:23,765
Rym: they could.

453
00:35:23,805 --> 00:35:26,435
Rym: basically as long as they were logged in they could not see.

454
00:35:26,455 --> 00:35:27,700
Rym: it was like you didn't exist anymore.

455
00:35:28,100 --> 00:35:30,594
Scott: But they could log out and then see you.

456
00:35:30,855 --> 00:35:31,680
Scott: so there's no point.

457
00:35:31,800 --> 00:35:35,227
Scott: There is no reason to hide something that is public from someone right.

458
00:35:42,280 --> 00:35:46,526
Scott: It's like yeah there's some Nazi right and it's like you know.

459
00:35:46,806 --> 00:35:49,129
Scott: if they're they're harassing me right.

460
00:35:49,229 --> 00:35:55,738
Scott: it's like okay if I want to prevent them from seeing my tweets but my tweets are still public and they can log out and see them.

461
00:35:55,778 --> 00:35:57,500
Scott: why prevent them from seeing them when they're logged in.

462
00:35:57,580 --> 00:36:11,580
Rym: Because as most people who were harassed especially minorities and targeted groups the main reason they use this is because yes it's not perfect but it introduced significant friction to harassers.

463
00:36:12,120 --> 00:36:14,725
Rym: In that someone who wants to harass has it.

464
00:36:14,986 --> 00:36:22,200
Rym: it's not as like an impulsive person a Nazi who just sees someone they don't like and wants to harass them and spout slurs at them or whatever.

465
00:36:22,561 --> 00:36:24,944
Rym: You block them now they don't see you anymore.

466
00:36:25,345 --> 00:36:28,070
Rym: they probably don't think about you much anymore.

467
00:36:28,150 --> 00:36:29,272
Rym: they don't see your content.

468
00:36:29,472 --> 00:36:34,240
Rym: you don't pop into their feeds especially because these communities were sharing block lists.

469
00:36:34,600 --> 00:36:46,657
Scott: But if they wanted to harass you right it's like sure they can't tweet at you but they could write a tweet that's like the letter A the letter T space Rym like hey my followers everyone tweet AT space RYM.

470
00:36:47,078 --> 00:36:48,680
Scott: he's a person we want to harass.

471
00:36:48,700 --> 00:36:49,987
Scott: It didn't actually protect you.

472
00:36:52,720 --> 00:36:57,000
Rym: It did to a meaningful degree that friction really cut down on the amount of harassment.

473
00:36:57,240 --> 00:37:05,460
Scott: What they should have done is implemented actual blocking right which is you know like there's no way it right.

474
00:37:06,300 --> 00:37:12,160
Rym: I do disagree because that's infeasible and the blocking feature was extremely effective for marginalized groups.

475
00:37:12,240 --> 00:37:20,173
Rym: You're really underestimating how powerful the blocking as it was was especially before muting.

476
00:37:20,494 --> 00:37:24,480
Scott: the muting that they still have right effectively accomplishes the same.

477
00:37:24,640 --> 00:37:25,695
Rym: No it absolutely does not.

478
00:37:26,700 --> 00:37:27,722
Scott: Not how is it not?

479
00:37:27,902 --> 00:37:37,200
Rym: because one the biggest preventing any tweet that that person makes you won't know because almost no one blocked people to not see the harassment coming at them.

480
00:37:37,280 --> 00:37:47,580
Rym: The main reason targeted groups use the blocking feature was also to make sure that their tweets generally didn't penetrate as far into those bad spaces because these groups were sharing block lists.

481
00:37:48,220 --> 00:38:03,480
Rym: And if someone's a harasser usually everyone who follows them was also on the same block list and that introduced a huge amount of very real and material friction to that community of shitheads even noticing that their targets were still active.

482
00:38:03,861 --> 00:38:12,796
Rym: It materially reduced the harassment that they received not because they didn't see the messages but because you couldn't even just retweet.

483
00:38:12,877 --> 00:38:14,800
Rym: if you want to retweet to direct hated someone.

484
00:38:15,200 --> 00:38:17,223
Rym: You had to log out make a burner account.

485
00:38:17,264 --> 00:38:19,487
Rym: you had to do all these extra steps that only you know.

486
00:38:19,507 --> 00:38:26,720
Scott: you could just tweet on your account and just don't put the at symbol in front of the person's name and then tell all your followers hey everyone you know.

487
00:38:28,283 --> 00:38:32,640
Rym: Most of those followers are usually also on the same block list because of the shared block list.

488
00:38:32,740 --> 00:38:35,119
Scott: You could have a mute list and now you don't see any of the harassment.

489
00:38:35,240 --> 00:38:43,980
Rym: No but the followers still see it and the harassers can still organize around doxing you pointing people at you so they come to your website and other things.

490
00:38:44,400 --> 00:38:45,960
Rym: The blocking being too way was very effective.

491
00:38:45,960 --> 00:38:47,640
Scott: They could do that even if they can't see your tweets.

492
00:38:48,020 --> 00:38:50,119
Scott: Yes they could but they didn't.

493
00:38:50,440 --> 00:38:52,520
Scott: It doesn't actually protect you from anything.

494
00:38:53,142 --> 00:38:56,713
Rym: Scott go talk to any of the communities who use these features.

495
00:38:56,753 --> 00:38:58,940
Rym: they will tell you they were very effective.

496
00:38:59,500 --> 00:39:08,240
Rym: So I do not agree even remotely that muting and blocking are comparable in any way in terms of how people actually use Twitter.

497
00:39:09,881 --> 00:39:11,344
Scott: I think the whole point right.

498
00:39:11,384 --> 00:39:19,560
Scott: the fundamental issue here is that this argument we're having right highlights the core problem not just Twitter right.

499
00:39:19,900 --> 00:39:32,720
Scott: But basically the whole internet the battle that we've been fighting on the internet one of the core battles of the internet since its inception or maybe even pre internet right which is that you are a person as a consumer of information right.

500
00:39:33,503 --> 00:39:36,020
Scott: Everyone everyone in the whole world wears both hats right.

501
00:39:36,140 --> 00:39:46,160
Scott: But as the consumer of information you only want to see what you want to see and you don't want to see anything that you don't want to see right.

502
00:39:46,940 --> 00:39:48,803
Scott: It's like here are the things that I want to see.

503
00:39:48,883 --> 00:39:50,046
Scott: I want to see tech news.

504
00:39:50,166 --> 00:39:51,388
Scott: I want to listen to GeekNights.

505
00:39:51,488 --> 00:39:56,437
Scott: I want to know how the Mets are doing and I don't want to know anything else that I didn't ask for.

506
00:39:56,457 --> 00:39:58,000
Scott: I don't want it right.

507
00:39:58,340 --> 00:40:00,780
Scott: Harassers I don't want to see anything harassers are saying.

508
00:40:01,161 --> 00:40:04,354
Scott: Ellen Musk don't want to see anything he's saying advertising some companies.

509
00:40:04,575 --> 00:40:05,940
Scott: I don't want to see that right.

510
00:40:06,780 --> 00:40:15,752
Scott: And then the other hat right which is I am a producer of information right or art or whatever right a journalist anyone.

511
00:40:15,852 --> 00:40:17,073
Scott: I've created information.

512
00:40:17,093 --> 00:40:19,016
Scott: I wrote something right I had.

513
00:40:19,056 --> 00:40:19,917
Scott: I just had an idea.

514
00:40:19,977 --> 00:40:21,199
Scott: randomly I farted.

515
00:40:21,279 --> 00:40:22,260
Scott: I wanted to share my fart.

516
00:40:22,340 --> 00:40:25,144
Rym: Now that person wants people to see on.

517
00:40:26,546 --> 00:40:31,093
Rym: ethically that person may want to force people to see exactly.

518
00:40:31,113 --> 00:40:33,998
Scott: you share the thing that you want to share with the world.

519
00:40:34,038 --> 00:40:35,580
Scott: you put it out there right.

520
00:40:35,960 --> 00:40:41,167
Scott: And the question is well there are people who are going to ask to see the thing that I shared.

521
00:40:41,227 --> 00:40:46,374
Scott: the listener of GeekNights right is like they are explicitly subscribing to GeekNights.

522
00:40:46,775 --> 00:40:50,460
Scott: they want GeekNights so if I put out a GeekNights they can see it.

523
00:40:51,040 --> 00:40:57,673
Scott: But should someone who is not subscribed to GeekNights should GeekNights ever show up on their screen right now?

524
00:40:57,733 --> 00:40:58,113
Scott: should there?

525
00:40:58,254 --> 00:41:01,159
Scott: should it even be possible for that to happen?

526
00:41:01,560 --> 00:41:01,760
Scott: right.

527
00:41:02,400 --> 00:41:10,451
Scott: And it's like well if it's not then how would anyone ever find GeekNights you if the only things that they would have to know about it already?

528
00:41:10,552 --> 00:41:16,179
Rym: now that zooms out to an even bigger problem discoverability of why is finding GeekNights.

529
00:41:18,281 --> 00:41:26,259
Rym: GeekNights is the example that we're not making an argument about us here the listener already found us but GeekNights.

530
00:41:27,680 --> 00:41:32,245
Rym: Why would GeekNights be so desperate to get people to see it?

531
00:41:32,726 --> 00:41:35,489
Rym: mostly because capitalism capitalism.

532
00:41:35,829 --> 00:41:45,820
Rym: most people who are making content and making things and having ideas and aggressively promoting on the internet are themselves hustling because they need people to see that or they will starve.

533
00:41:46,661 --> 00:41:54,546
Scott: Right there are some people who are doing it for the money some for the fame some for both right right and it's like people just want to be seen.

534
00:41:55,026 --> 00:41:55,307
Scott: right.

535
00:41:55,747 --> 00:42:06,014
Scott: and it's like if you're blocking ads but then you're like also trying to get someone to see even if it's not an ad for a product or something you'll make money from.

536
00:42:06,054 --> 00:42:10,537
Scott: but like you just really want your tweet to be seen by a lot of people.

537
00:42:10,577 --> 00:42:14,800
Scott: you told a funny joke and you want a lot of people to laugh people who aren't following you right.

538
00:42:15,861 --> 00:42:17,943
Scott: It's like well then you're that's.

539
00:42:18,123 --> 00:42:31,574
Rym: you're still pushing information on people who didn't ask for it which right like I think most billboards should be banned like I think non-consensual information sharing is should be strictly regulated.

540
00:42:31,655 --> 00:42:37,960
Scott: the ideal the ideal system is one in which you don't have blocking because everything is blocked.

541
00:42:38,220 --> 00:42:41,443
Scott: Absolutely everything by default is equivalently blocked.

542
00:42:41,503 --> 00:42:44,226
Scott: you only see what you ask to see.

543
00:42:44,286 --> 00:42:53,954
Scott: so if you tweet into the wind or whatever you do activity pub into the wind right and a bunch of harassers see it and they you know pass it all around.

544
00:42:53,994 --> 00:43:00,240
Scott: all the Nazis pass Scott's tweet around that says Nazis suck right and they're all sharing it amongst each other and hating on me.

545
00:43:00,840 --> 00:43:01,541
Scott: I won't see that.

546
00:43:01,641 --> 00:43:02,642
Scott: I won't even know what happened.

547
00:43:02,982 --> 00:43:09,147
Rym: right you can be dangerous and there are instances of this where I mean it's no different than like writing in your journalist.

548
00:43:09,167 --> 00:43:10,528
Scott: you write an article in the newspaper.

549
00:43:10,569 --> 00:43:13,291
Scott: you have no idea who reads it or who's discussing it in the.

550
00:43:13,391 --> 00:43:16,153
Scott: at the got it pinned up on the wall at the clan house.

551
00:43:16,513 --> 00:43:16,974
Scott: you don't know.

552
00:43:17,474 --> 00:43:17,775
Scott: it's like.

553
00:43:17,875 --> 00:43:18,875
Scott: it's no different than that.

554
00:43:18,976 --> 00:43:24,300
Scott: it's like you put information in the world and you do not know who is reading it what anyone's doing with it.

555
00:43:24,841 --> 00:43:28,929
Scott: At all right you just tossed it out there and you don't know how many clicks it got.

556
00:43:28,949 --> 00:43:29,851
Scott: you know how many views it got.

557
00:43:29,871 --> 00:43:31,354
Scott: you don't know how many how famous you are.

558
00:43:31,374 --> 00:43:32,496
Scott: you don't know how much money you made.

559
00:43:32,977 --> 00:43:33,618
Scott: you don't know nothing.

560
00:43:33,738 --> 00:43:34,620
Scott: you just putting it out.

561
00:43:34,780 --> 00:43:35,982
Rym: And I think this is there are two.

562
00:43:36,082 --> 00:43:44,334
Rym: I think the blocking to prevent someone else from interacting with your information is a separate but adjacent conversation.

563
00:43:44,374 --> 00:43:48,340
Rym: to blocking to not see someone's content because exactly they are both.

564
00:43:48,400 --> 00:43:48,961
Scott: The same word.

565
00:43:49,503 --> 00:43:52,831
Scott: the same word is used for both things but they are completely different.

566
00:43:52,951 --> 00:43:53,412
Scott: and around.

567
00:43:53,452 --> 00:43:56,380
Rym: back out of the Twitter thing our disagreement just now.

568
00:43:57,880 --> 00:44:07,371
Rym: Twitter achieved both with a moderate amount of success but some significant limitations and Twitter also was a very widely used platform.

569
00:44:08,011 --> 00:44:15,580
Rym: so now we're in a situation where both sides of that equation just got gutted on what was one of the biggest social networks in the world.

570
00:44:15,901 --> 00:44:17,926
Scott: No the only one side was gutted which is the.

571
00:44:18,246 --> 00:44:20,772
Scott: you try to make it harder for people to see your stuff.

572
00:44:20,812 --> 00:44:22,777
Scott: the you only see what you want to see.

573
00:44:22,877 --> 00:44:23,920
Scott: stuff is still the same.

574
00:44:24,200 --> 00:44:31,800
Rym: So according to this article mutes seem to not interface correct like you will still see things you didn't subscribe to.

575
00:44:33,181 --> 00:44:39,536
Scott: That is a separate problem because Twitter right and all these newer social networks.

576
00:44:39,616 --> 00:44:41,420
Rym: also there's a limit on how many accounts you can mute.

577
00:44:42,202 --> 00:44:43,847
Scott: Well that's also my block list.

578
00:44:43,907 --> 00:44:46,154
Rym: before Twitter shut down the API had more than 400,000 accounts on it.

579
00:44:48,180 --> 00:44:51,364
Scott: Yeah that's a. that's a problem for sure right it should be infinity in fact right.

580
00:44:51,544 --> 00:45:00,535
Scott: but anyway the all of these things have their sort of algorithmic feeds YouTube's recommendations Twitter's.

581
00:45:00,875 --> 00:45:04,860
Scott: you know the all any right all those sort of feeds you know.

582
00:45:06,370 --> 00:45:07,691
Scott: All that shit right.

583
00:45:08,111 --> 00:45:10,572
Scott: that is not just the reverse.

584
00:45:10,592 --> 00:45:24,239
Scott: chronological order list of things you follow is fundamentally you are seeing things that someone else wants you to see and not something you asked for and that is the core problem.

585
00:45:24,519 --> 00:45:26,340
Scott: anything like that should just get the fuck out.

586
00:45:26,740 --> 00:45:29,823
Rym: YouTube go to youtube.com.

587
00:45:29,904 --> 00:45:32,847
Scott: such a thing because Twitter has such a thing.

588
00:45:32,867 --> 00:45:35,409
Scott: that is why mute fails.

589
00:45:35,689 --> 00:45:36,210
Scott: right?

590
00:45:36,250 --> 00:45:41,315
Scott: if they didn't have that mute would be perfect because that were a secondary experience.

591
00:45:41,375 --> 00:45:45,880
Rym: if the default experience was here's what you subscribe to and like Twitter used to be.

592
00:45:46,460 --> 00:45:57,033
Scott: And if there is some other feed of other things that I'm not following I at least have to click on it which means I have asked to see the things that I don't follow.

593
00:45:57,093 --> 00:46:03,140
Scott: it should never be the default screen because then I am seeing things I do not follow without asking for it.

594
00:46:04,741 --> 00:46:12,954
Scott: You can have all those things as long as they're a click away or a command away or somewhere else other than a pay a place.

595
00:46:12,994 --> 00:46:15,659
Scott: you cannot avoid looking like the default homepage.

596
00:46:15,699 --> 00:46:16,440
Scott: that can't be changed.

597
00:46:17,302 --> 00:46:21,793
Scott: They're perfectly fine to exist but it should never be unavoidable.

598
00:46:21,974 --> 00:46:22,896
Scott: it should always be.

599
00:46:22,916 --> 00:46:24,320
Scott: I asked to see this.

600
00:46:24,860 --> 00:46:26,141
Rym: What do you propose?

601
00:46:26,181 --> 00:46:37,409
Rym: this angers capital because it does remember and I know we talk about this a lot but you really really have to understand that this is like the fundamental crisis of the entire Internet.

602
00:46:37,809 --> 00:46:40,331
Rym: the whole fucking thing is propped up on advertising.

603
00:46:40,651 --> 00:46:48,356
Rym: even if we ignore the fact that most of American society is propped up on advertising the Internet is like more propped up on advertising.

604
00:46:48,696 --> 00:46:49,517
Rym: no fucking webs.

605
00:46:50,077 --> 00:46:54,080
Rym: if there were no ads tomorrow the Internet would go back to what it was like.

606
00:46:54,440 --> 00:47:01,454
Rym: Before it was commercialized there's a few hundred websites and wealthy white people have made all of them with whatever they wanted.

607
00:47:01,775 --> 00:47:02,917
Rym: GeekNights would keep going.

608
00:47:03,218 --> 00:47:04,400
Rym: there wouldn't be any other podcast.

609
00:47:05,740 --> 00:47:13,239
Scott: Yep I mean it's like if you put up some e-commerce right on an Internet where people only saw what they asked to see.

610
00:47:15,101 --> 00:47:21,311
Scott: The only way anyone to find your e-commerce is if they already knew you somehow right.

611
00:47:21,551 --> 00:47:25,537
Scott: they found your business in the real world or something or you know.

612
00:47:25,898 --> 00:47:27,400
Scott: it's like how right it's.

613
00:47:28,201 --> 00:47:34,166
Rym: How do you and I as a case study want to find out about things we wouldn't otherwise know about?

614
00:47:34,326 --> 00:47:34,466
Rym: one?

615
00:47:35,046 --> 00:47:36,027
Rym: I read a bunch.

616
00:47:36,167 --> 00:47:41,512
Rym: I go to specific websites that aggregate and curate news and areas I care about.

617
00:47:41,812 --> 00:47:43,013
Rym: that's Paul I'm choosing.

618
00:47:43,533 --> 00:47:47,877
Rym: I read The Verge because I want to know about some of the kinds of things The Verge has.

619
00:47:47,937 --> 00:47:48,618
Rym: it's not perfect.

620
00:47:49,058 --> 00:47:51,460
Rym: I would like a more curated feed but it's not that bad.

621
00:47:52,141 --> 00:48:01,212
Rym: I used to follow a bunch of people on Twitter partly because they were the people who would tell me about things I wouldn't have thought to look for and I trust their opinion.

622
00:48:01,252 --> 00:48:02,193
Rym: but again I chose.

623
00:48:02,734 --> 00:48:07,240
Rym: I want to hear what Mike tool has to say because he'll tell me about an anime would have otherwise not found out about.

624
00:48:08,023 --> 00:48:11,380
Scott: I listen to somebody else already follow.

625
00:48:12,621 --> 00:48:21,277
Scott: For explicitly right some other source of information you do know and there is some path through that to the thing that you don't follow.

626
00:48:21,357 --> 00:48:22,560
Rym: and for products you know what I do.

627
00:48:23,680 --> 00:48:29,996
Rym: I don't look for products to buy unless I've decided I need to buy something to solve X problem.

628
00:48:30,256 --> 00:48:31,580
Rym: and then I do research.

629
00:48:32,781 --> 00:48:38,030
Scott: Yeah but the research is using a search engine and the search engine is you know.

630
00:48:38,330 --> 00:48:43,680
Scott: yes you're in some sense asking but in the other sense the SEO is determining what you see and what you don't see.

631
00:48:43,920 --> 00:48:47,208
Rym: Let's see I'm going to type something to YouTube right now because I'm extra annoyed about this.

632
00:48:47,228 --> 00:48:48,271
Rym: let's see I'm going to type.

633
00:48:48,612 --> 00:48:50,176
Rym: I don't know minotaur.

634
00:48:50,196 --> 00:48:51,840
Rym: I just picked a random word.

635
00:48:53,060 --> 00:48:54,240
Scott: Wikipedia page for minotaur.

636
00:48:54,500 --> 00:48:55,540
Rym: So what does YouTube return?

637
00:48:56,142 --> 00:48:57,520
Scott: D&D monster page for minotaur.

638
00:48:57,680 --> 00:49:08,320
Rym: So YouTube returns a random curated set of videos that include the word minotaur in the title and then after one two three four five six seven eight nine ten results.

639
00:49:09,180 --> 00:49:15,429
Rym: Now it says people also watched in the tiniest font and it if you scroll by it looks like it's more search results.

640
00:49:15,770 --> 00:49:16,651
Rym: but it's not.

641
00:49:17,052 --> 00:49:22,440
Rym: it's showing me what other people who watch some of the videos from the search.

642
00:49:23,460 --> 00:49:37,700
Rym: Themselves watched not things that matched that search and then it shows me a bunch of shorts and the more I scroll down it's just a chum bucket of garbage until eventually I hit for you and you know what that's showing me?

643
00:49:38,400 --> 00:49:39,944
Rym: Literally a bunch of videos I've already watched.

644
00:49:41,688 --> 00:49:42,350
Rym: Fantastic.

645
00:49:44,796 --> 00:49:46,419
Rym: Thank you Google for being a terrible search.

646
00:49:47,381 --> 00:49:47,922
Scott: So yeah there's.

647
00:49:48,342 --> 00:49:49,664
Scott: the war is again.

648
00:49:50,224 --> 00:49:51,206
Scott: you only want to see what.

649
00:49:51,246 --> 00:49:57,814
Scott: you want to see people what you also as a producer want people to see your shit even if they didn't ask for it.

650
00:49:57,914 --> 00:50:02,600
Scott: and then vice versa you don't want to see shit people trying to push on you and alright.

651
00:50:02,880 --> 00:50:08,799
Rym: So on YouTube why can't I block an account if I see an account and a video is recommended to me.

652
00:50:09,721 --> 00:50:10,161
Scott: And why?

653
00:50:10,241 --> 00:50:11,403
Scott: no that's not the question.

654
00:50:11,443 --> 00:50:16,469
Scott: the question is why did not every single account start blocked?

655
00:50:16,589 --> 00:50:24,998
Scott: everything should be blocked by default and instead you should be turning things on right not turning things off and by default.

656
00:50:25,039 --> 00:50:26,320
Scott: you see the world right.

657
00:50:27,001 --> 00:50:31,426
Scott: Twitter originally the original Twitter was effectively an IRC chat room.

658
00:50:31,626 --> 00:50:37,333
Scott: right effectively or you could only put short messages but it IRC chat room but everyone was.

659
00:50:37,493 --> 00:50:41,218
Scott: you go in the chat room and you see all the names but everyone is muted.

660
00:50:41,278 --> 00:50:41,779
Scott: by default.

661
00:50:41,799 --> 00:50:42,840
Scott: you don't see any chats.

662
00:50:42,960 --> 00:50:46,300
Rym: And you pick the set of people you want to see and everyone picks a different set.

663
00:50:46,360 --> 00:50:51,660
Scott: You unmute people right and then you see only the things they're saying and everyone else is shut the fuck up.

664
00:50:51,660 --> 00:50:53,214
Rym: That was the only good thing Twitter ever did.

665
00:50:53,315 --> 00:50:53,879
Rym: the first thing.

666
00:50:54,420 --> 00:50:57,828
Scott: Right that was the original Twitter and that's that is the model.

667
00:50:57,848 --> 00:50:58,830
Scott: that's the correct model.

668
00:50:58,870 --> 00:51:00,394
Scott: the whole internet should be like that.

669
00:51:00,735 --> 00:51:03,040
Scott: you only see what you want to see right.

670
00:51:03,200 --> 00:51:10,640
Scott: When you go to Google you start googling and it should be like you don't see anything and then you pick domains that you want to search right.

671
00:51:10,840 --> 00:51:10,980
Scott: Like.

672
00:51:11,081 --> 00:51:11,621
Scott: I only want to.

673
00:51:11,741 --> 00:51:12,002
Scott: you know.

674
00:51:12,162 --> 00:51:12,662
Scott: you know.

675
00:51:12,723 --> 00:51:26,860
Scott: right now you can do it with like the site command right like imagine if you use Google and you only had certain domains that you trusted and liked and newer bullshit and only search those domains and every other domain you never saw results from.

676
00:51:27,920 --> 00:51:28,902
Scott: It's like you block.

677
00:51:28,942 --> 00:51:36,698
Scott: you shouldn't be block having to block because block should be the default in terms of what you see now in terms of what you send out into the world.

678
00:51:36,719 --> 00:51:36,819
Scott: right.

679
00:51:37,960 --> 00:51:40,685
Scott: Me and Rym have a difference of opinion but I believe right.

680
00:51:40,946 --> 00:51:41,246
Scott: if you're.

681
00:51:41,727 --> 00:51:47,218
Scott: if you're choosing to send something to a private group or individual that's private messaging.

682
00:51:47,258 --> 00:51:48,000
Scott: that's already right.

683
00:51:48,781 --> 00:51:55,730
Scott: But if you are sending something out into the world publicly you have to just accept the fact that you have made that information public.

684
00:51:56,211 --> 00:52:02,620
Scott: and it is this trying to prevent some people in the world from seeing it but having most of the world see it.

685
00:52:02,880 --> 00:52:03,461
Rym: Well that's the thing.

686
00:52:03,621 --> 00:52:06,204
Rym: it doesn't actually prevent people from seeing it.

687
00:52:06,565 --> 00:52:08,748
Rym: it introduces friction within that platform.

688
00:52:08,788 --> 00:52:17,560
Rym: and that's the value that if there is a widely used platform then introducing friction to bad actors who would try to engage with you.

689
00:52:17,720 --> 00:52:19,939
Scott: I mean the bad actors shouldn't be there in the first place.

690
00:52:20,601 --> 00:52:22,720
Rym: Yes but they're there and the tool was effective.

691
00:52:24,161 --> 00:52:31,340
Scott: Secondly if the bad actors can't message you then you know because the other patch is correct.

692
00:52:31,340 --> 00:52:32,542
Rym: It's not just that they can't message you.

693
00:52:32,582 --> 00:52:33,403
Rym: I'll give you an example.

694
00:52:33,463 --> 00:52:44,120
Rym: there was that the series of studies showing that individual entities on a platform like Twitter or YouTube will always randomly be selected to be extremely popular.

695
00:52:44,461 --> 00:52:56,040
Rym: If you make a fake Twitter with a bunch of pseudo ML mechanisms that all randomly retweet things over time certain random messages and random accounts just become the most widely followed and widely used like that.

696
00:52:56,540 --> 00:53:01,520
Rym: That happens as a consequence of the ability to be able to share and reshare content just in general.

697
00:53:02,540 --> 00:53:04,107
Scott: So just don't do that.

698
00:53:04,409 --> 00:53:06,820
Scott: but if everyone's blocked by default will that happen?

699
00:53:07,522 --> 00:53:14,080
Rym: But if everyone's blocked by default then I can still subscribe to anyone and retweet to my people.

700
00:53:14,660 --> 00:53:15,579
Rym: Reshare to my people.

701
00:53:17,703 --> 00:53:20,773
Scott: Talking about retweet I think it's a design failure.

702
00:53:20,854 --> 00:53:22,700
Scott: it shouldn't be so simple to retweet.

703
00:53:23,460 --> 00:53:27,760
Rym: But at the same time that was the feature I used on Twitter the most.

704
00:53:28,561 --> 00:53:31,039
Scott: Regardless that's a separate topic but the point is.

705
00:53:31,200 --> 00:53:35,327
Rym: But I'm saying if you have a platform the friction of making it.

706
00:53:35,687 --> 00:53:43,180
Rym: if I block you on a platform then it introduces friction of you not just interacting with me.

707
00:53:43,900 --> 00:53:48,910
Rym: But also resharing and like interacting with my content within that platform.

708
00:53:49,190 --> 00:53:53,940
Rym: meaning if you are a bad actor who wants to take the extra step to harass beyond the block.

709
00:53:54,601 --> 00:54:05,280
Rym: Now you have to do things outside of what the platform directly supports which introduces the ability to have you to easily block or ban you or bring legal consequences to you or prove.

710
00:54:05,400 --> 00:54:08,586
Scott: I mean they could just log out see your tweet copy it paste.

711
00:54:08,606 --> 00:54:09,588
Rym: yes they can push.

712
00:54:09,628 --> 00:54:10,049
Scott: that's a.

713
00:54:10,109 --> 00:54:14,117
Rym: that's a far cry for most people to go through that much effort.

714
00:54:14,177 --> 00:54:15,880
Rym: that's why that feature was right effective.

715
00:54:16,121 --> 00:54:17,263
Scott: And I think that it's not.

716
00:54:17,383 --> 00:54:19,408
Scott: I don't think that the block is the right answer.

717
00:54:19,448 --> 00:54:24,600
Scott: I think the right answer is there shouldn't be such a low friction to retweet in the first place.

718
00:54:24,800 --> 00:54:25,000
Scott: It should.

719
00:54:25,141 --> 00:54:33,140
Scott: everyone who wants to retweet should have to explicitly when you're putting things out into the world right that the whole world is going to see.

720
00:54:33,601 --> 00:54:38,380
Rym: I want everyone who follows me to see everything I say if they want which includes retweets.

721
00:54:38,761 --> 00:54:40,826
Scott: If they want that's that's fine right.

722
00:54:41,106 --> 00:54:46,980
Scott: but the point is is that if you are going to publish or republish something right on any platform.

723
00:54:47,621 --> 00:54:51,468
Scott: That is you know and knowing that the whole world will see a public thing right.

724
00:54:52,129 --> 00:54:53,432
Scott: that should never be.

725
00:54:53,572 --> 00:54:57,400
Scott: it's a bad design to have that be a low friction action.

726
00:54:58,082 --> 00:55:00,108
Scott: It should because you're you're doing something serious.

727
00:55:00,168 --> 00:55:01,452
Scott: right you are publishing right.

728
00:55:01,512 --> 00:55:04,160
Scott: publishing should always be a big action like post.

729
00:55:04,960 --> 00:55:07,183
Scott: And therefore that shouldn't be so simple.

730
00:55:07,203 --> 00:55:17,898
Scott: with like one click to completely take a huge thing or someone else's post and completely repost it you should have to copy it paste it look at it see where I disagree.

731
00:55:17,938 --> 00:55:18,900
Rym: there is that.

732
00:55:19,940 --> 00:55:27,880
Rym: Society has shown that low friction is what people want and that is what built a lot of very positive spaces and positive communities as well.

733
00:55:28,400 --> 00:55:28,861
Scott: It can build.

734
00:55:28,961 --> 00:55:30,225
Scott: it can go both ways.

735
00:55:30,365 --> 00:55:35,418
Scott: right you know a fast road gets you where you're going faster and it also kills people right.

736
00:55:35,478 --> 00:55:36,260
Rym: that's why I'm saying.

737
00:55:36,940 --> 00:55:38,443
Scott: I think we would all be better off.

738
00:55:38,623 --> 00:55:47,000
Scott: in general though with a slow road right you get where you're going still and less people die even though we don't have the fast trips.

739
00:55:47,361 --> 00:55:48,383
Rym: But that's where I'm saying.

740
00:55:48,403 --> 00:55:54,840
Rym: in a world where the reality is almost all people want the ability to have rapidly reshare and that's not going to go away.

741
00:55:55,520 --> 00:55:57,547
Scott: Do they want or do they not want?

742
00:55:57,607 --> 00:56:01,100
Scott: right it's like it's one of those things where it's like when people have this.

743
00:56:01,300 --> 00:56:04,306
Rym: I think they want it partly because Twitter and platforms like it.

744
00:56:04,767 --> 00:56:11,020
Rym: this was not a primary feature and retweets didn't even work that well and they rapidly became the most used thing without being pushed.

745
00:56:11,100 --> 00:56:14,007
Scott: They were they were very used but that was first of all.

746
00:56:14,427 --> 00:56:20,080
Scott: they want the people designing the system designed it to make people use that on purpose right.

747
00:56:21,000 --> 00:56:22,663
Scott: And it was so.

748
00:56:22,703 --> 00:56:26,411
Scott: it's like when it's there right it's like yes people ate it.

749
00:56:26,471 --> 00:56:30,880
Scott: it's like yes when I put the mouse in the box with the cheese the mouse ate the cheese.

750
00:56:31,040 --> 00:56:32,163
Scott: Take any group of nerds.

751
00:56:32,463 --> 00:56:40,400
Rym: put them in a room with a computer and nine times out of ten they all have five YouTube videos they each want to show to everyone else there.

752
00:56:40,900 --> 00:56:43,368
Rym: And there's the big fight about who puts on which video.

753
00:56:43,629 --> 00:56:46,980
Rym: like every nerd group always has this exact same dynamic.

754
00:56:47,240 --> 00:56:49,386
Scott: Yes people have a desire to share things.

755
00:56:49,426 --> 00:56:51,070
Scott: that is without a doubt right.

756
00:56:51,111 --> 00:56:52,274
Scott: Ivan I have that desire right.

757
00:56:52,294 --> 00:56:52,715
Scott: what are we doing?

758
00:56:52,735 --> 00:56:53,617
Scott: things of the day on here?

759
00:56:53,658 --> 00:56:54,520
Scott: for no reason right.

760
00:56:54,881 --> 00:56:56,603
Scott: Come on everyone has things.

761
00:56:56,623 --> 00:57:00,249
Scott: when they see a cool thing you want to tell your friends about the.

762
00:57:00,329 --> 00:57:02,353
Rym: I'm saying I don't think the friction is a problem.

763
00:57:02,393 --> 00:57:06,800
Rym: I think that there's other societal problem but I make the lack of friction on resharing.

764
00:57:07,060 --> 00:57:11,329
Scott: I think we would be better off if the re sharing action right.

765
00:57:11,389 --> 00:57:17,020
Scott: if you're you know everyone everyone has a lot of sees cool things all the time that they want to share with everyone right.

766
00:57:17,461 --> 00:57:25,791
Scott: If everyone just shared everything then it's like you know it's just wait it's too much it's too noisy and a lot of low quality stuff gets through.

767
00:57:25,951 --> 00:57:33,100
Scott: if we added a little friction to that process on all platforms right to where it's like oh you want to share that cool YouTube video with everyone.

768
00:57:36,301 --> 00:57:40,289
Scott: Then that would raise the bar a little bit raise the quality a little.

769
00:57:40,330 --> 00:57:43,095
Rym: I have an alternative but complimentary argument.

770
00:57:43,456 --> 00:57:45,340
Rym: that the only reason.

771
00:57:46,961 --> 00:57:57,995
Rym: The bar is so low and what you call qualitatively low quality content is indeed qualitatively yes I am also similarly ice.

772
00:57:58,176 --> 00:57:59,678
Rym: I have the same quality judgment.

773
00:57:59,718 --> 00:58:00,158
Rym: is you like?

774
00:58:00,198 --> 00:58:01,400
Rym: don't think that I'm okay.

775
00:58:01,580 --> 00:58:03,283
Scott: Okay I'm just saying I'm just.

776
00:58:03,343 --> 00:58:10,014
Rym: I'm noting that there's someone out there who earnestly likes that bottom tier content like there's.

777
00:58:10,054 --> 00:58:13,380
Scott: yeah I mean it wouldn't be you know but that person is going to be following people.

778
00:58:14,000 --> 00:58:21,073
Scott: Right who are more like them and with the higher bar are going to see more of that stuff we think is bottom tier that they love a little bit.

779
00:58:21,173 --> 00:58:22,315
Scott: I'm saying the only reason.

780
00:58:25,701 --> 00:58:33,819
Rym: Almost any of that low tier content exists in the first place is because of the extreme pressures of capitalism in the at all.

781
00:58:34,682 --> 00:58:37,720
Scott: Could be depends on depends on which content exactly you're talking about.

782
00:58:38,160 --> 00:58:39,964
Rym: All of it there are exceptions.

783
00:58:40,225 --> 00:58:42,891
Rym: one exception I can think of is fascist indoctrination.

784
00:58:43,172 --> 00:58:46,280
Rym: that is not directly profit motive that is evil motive.

785
00:58:47,101 --> 00:58:58,356
Scott: It's true yes without the profit motive, a lot of people out there who are making content, you know, a lot of variety, the people who say like and subscribe would not be making it right unlike the GeekNights.

786
00:58:58,416 --> 00:59:01,740
Scott: that makes it even if there's one listener doesn't put ads right.

787
00:59:02,301 --> 00:59:16,160
Rym: I'm saying on a given week, instead of 400,000 Minecraft videos that I have a high production value and let's just say qualitatively to low quality content, there would be an order of magnitude fewer.

788
00:59:16,880 --> 00:59:25,780
Rym: And if you look at the old internet before anyone even realized the internet could be commercialized every website was just kind of great and just had the content you wanted.

789
00:59:26,962 --> 00:59:39,300
Scott: That is the thing is I think that without the ability to make people see your thing and to chase view counts or anything I think that is a motivator for a lot of people to post and create in the first place.

790
00:59:39,860 --> 00:59:41,114
Scott: I think the primary motivator.

791
00:59:44,045 --> 00:59:46,300
Scott: It is the primary motivator for that kind of person.

792
00:59:46,940 --> 00:59:53,535
Rym: But I think that is only the primary motivator for so many people because that is capitalism.

793
00:59:53,595 --> 00:59:55,379
Rym: like everyone's got their hustle.

794
00:59:56,300 --> 01:00:00,940
Scott: Capitalism is a part of it but there are some people who just want to be famous regardless of the money.

795
01:00:04,083 --> 01:00:08,700
Scott: If we took that away a lot of people would simply stop creating, stop sharing.

796
01:00:08,840 --> 01:00:14,860
Scott: The only people who would create and share were the people who are doing it like we are because for other reasons.

797
01:00:17,102 --> 01:00:22,240
Scott: And I think that would be a better internet but it would be a quieter internet but it would be a safer internet I think.

798
01:00:22,500 --> 01:00:38,260
Rym: It absolutely would and we have to solve this real quick as a society and culture because large language models are going to generate a literal infinite sea of garbage content.

799
01:00:38,760 --> 01:00:42,700
Rym: And that is why you will never be able to find anything good again in that sea.

800
01:00:43,080 --> 01:00:46,800
Rym: It is going to be like the cork foam that I just learned about from one of those Arvin Ash videos.

801
01:00:47,741 --> 01:00:52,760
Scott: So we agree that blocking what's coming in, you should only see what you want to see.

802
01:00:53,261 --> 01:00:55,220
Scott: And we disagree what's going out.

803
01:00:55,420 --> 01:01:03,120
Scott: I think if you're willing to send something out that there should be a little bit of friction ideally because it's not a small action that you're taking.

804
01:01:03,280 --> 01:01:05,960
Scott: It's a serious action, you should think about it for at least a second.

805
01:01:06,520 --> 01:01:13,020
Scott: And also that you have to accept the fact that you're putting it out into the whole world, Nazis are going to see it.

806
01:01:13,261 --> 01:01:19,160
Scott: Even though if we at least get the first part right you won't ever hear the Nazis coming back to you and you disagree.

807
01:01:20,401 --> 01:01:22,000
Rym: Here's an idea there, a specific one.

808
01:01:22,260 --> 01:01:29,980
Rym: Let's say we solve the depredations of capitalism problem so now it's more Nazis versus literally everyone else in terms of posting.

809
01:01:31,821 --> 01:01:34,519
Rym: Which wouldn't be that far off from that when we get to that point.

810
01:01:35,961 --> 01:01:44,740
Rym: So say we're in that environment, then arguably blocking features within platforms for the publishing if the barrier to resharing is low.

811
01:01:45,280 --> 01:01:54,460
Rym: And the barrier to resharing being low would likely plausibly be a benefit to society because we've removed all this low tier content that was being generated by capitalism.

812
01:01:55,620 --> 01:02:00,080
Rym: Then, now already I realize I have so many caveats that this is such a narrow point.

813
01:02:00,983 --> 01:02:06,100
Rym: Then the blocking features are a very specific ratchet style tool.

814
01:02:06,920 --> 01:02:18,960
Rym: They, in aggregate, decrease the friction of people interacting with my content by default, but increase the friction of people I don't want to interact with my content.

815
01:02:19,400 --> 01:02:23,680
Rym: But it's not necessarily blocking more, it's almost like limiting, it's not muting either.

816
01:02:24,141 --> 01:02:33,560
Rym: It basically means everyone can reshare my content, but specific motherfuckers who have crossed me in some way have more friction to do the same.

817
01:02:34,060 --> 01:02:43,760
Rym: And in a large long term system, that would lead to, over time, what I see as bad or what society sees as bad actors being more limited.

818
01:02:45,560 --> 01:02:50,800
Rym: But, to your point, that isn't really blocking as it is used today by most people.

819
01:02:51,120 --> 01:03:09,440
Scott: If we get the first part right, where you only see what you want to see, then it's like, no matter how much Nazis reshare amongst themselves my anti-Nazi screed, I'll never hear from them, you'll never hear from them, we'll never know that that's going on, and they will be cut off from society because no one will see their Nazi conversation other than themselves.

820
01:03:09,660 --> 01:03:12,780
Scott: They'll be in their own little bubble, which is effectively what they are anyway.

821
01:03:12,940 --> 01:03:17,780
Rym: So do we just have another episode of GeekNights where the moral of how to solve a problem is we have to destroy capitalism?

822
01:03:18,562 --> 01:03:32,578
Scott: I mean, we already know that, but the point is, we disagree on the "block what you post" part, we agree on the "block what you're reading" part, and I'm, you know, working on building exactly something, right?

823
01:03:33,880 --> 01:03:47,560
Scott: I'm basically being an activity pub server that follows the philosophy that I've just espoused, right, where when you post something, it's out to the world to deal with it, but the only things you ever see are the things you ask to see and nothing else, the end.

824
01:03:49,104 --> 01:03:50,599
Scott: And we'll see if that actually works or not.

825
01:03:51,901 --> 01:03:57,078
Rym: And in the interim, like, if you're using Twitter and these block features go away...

826
01:03:58,066 --> 01:03:58,900
Scott: Twitter is done, I think.

827
01:03:59,000 --> 01:04:15,140
Rym: But if you're still using it, be ready for the fact that if blocking goes away, because that platform is designed the way it is, it could become specifically more dangerous to you, especially if you are a group, like, typically targeted.

828
01:04:15,481 --> 01:04:20,220
Scott: Well, I think because the information I didn't know of the mute being limited, right?

829
01:04:20,660 --> 01:04:33,820
Scott: You could eventually, you could basically run into a situation where, you know, you've muted all the bad people and then there's more mad people and you can't mute them, and now the bad people can tweet at you and you're gonna see it, you're gonna see something you didn't ask to see, and now it's unsafe.

830
01:04:33,840 --> 01:04:36,200
Rym: So funnily enough, before I got rid of my Twitter account...

831
01:04:36,262 --> 01:04:36,579
Scott: It's unusable.

832
01:04:36,761 --> 01:04:38,048
Rym: You know what terms I had muted?

833
01:04:38,068 --> 01:04:39,415
Rym: Patreon.

834
01:04:42,263 --> 01:04:43,700
Rym: That's it, that's the only term I had muted.

835
01:04:48,042 --> 01:04:50,180
Rym: This has been GeekNights with Rym and Scott.

836
01:04:50,380 --> 01:04:55,320
Rym: Special thanks to DJ Pretzel for the opening music, Kat Lee for web design, and Brando K for the logos.

837
01:04:55,700 --> 01:05:00,720
Scott: Be sure to visit our website at FrontRowCrew.com for show notes, discussion news, and more.

838
01:05:01,040 --> 01:05:03,660
Rym: Remember, GeekNights is not one, but four different shows.

839
01:05:03,920 --> 01:05:08,140
Rym: Sci-Tech Mondays, Gaming Tuesdays, Anime Comic Wednesdays, and Indiscriminate Thursdays.

840
01:05:08,763 --> 01:05:11,937
Scott: GeekNights is distributed under a Creative Commons Attribution 3.0 license.

841
01:05:13,280 --> 01:05:16,240
Scott: GeekNights is recorded live with no studio and no audience.

842
01:05:16,460 --> 01:05:19,360
Scott: But unlike those other late shows, it's actually recorded at night.

843
01:05:19,921 --> 01:05:42,320
Rym: And the GeekNights Patreon patrons for this episode are... I assume to get access to that sweet Patreon-exclusive RSS feed.

844
01:05:42,460 --> 01:05:45,400
Rym: That is the same as our feed, but it works within Patreon.

845
01:05:46,482 --> 01:05:46,865
Rym: Uh, yeah.

846
01:05:47,854 --> 01:05:48,339
Rym: See you at PAX.

847
01:05:49,401 --> 01:05:51,030
Rym: Definitely not do another show this week.

848
01:05:51,050 --> 01:05:52,960
Rym: We'll probably do one show next week.

849
01:05:53,361 --> 01:05:55,138
Rym: And I leave you tonight only with...

850
01:05:55,341 --> 01:05:55,999
Media: The Soviet Union.

851
01:05:56,620 --> 01:05:57,517
Media: I thought you guys broke up.

852
01:05:58,221 --> 01:06:00,419
Media: Yes, that's what we wanted you to think.

853
01:06:00,703 --> 01:06:01,008
Media: [Laughing].

854
01:06:05,521 --> 01:06:24,100
Media: [Singing] Must crush capitalism!

855
01:06:24,800 --> 01:06:25,180
Media: [Growling].

