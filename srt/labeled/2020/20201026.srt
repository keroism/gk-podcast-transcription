1
00:00:09,580 --> 00:00:11,486
Rym: It's Monday October 26 2020.

2
00:00:11,486 --> 00:00:13,312
Rym: I'm Rym.

3
00:00:14,034 --> 00:00:15,979
Rym: I'm Scott and this is GeekNights.

4
00:00:15,999 --> 00:00:19,399
Rym: tonight We are talking about facial recognition technology.

5
00:00:20,881 --> 00:00:21,916
Scott: Let's do this.

6
00:00:23,461 --> 00:00:23,963
Rym: Tried to vote.

7
00:00:24,364 --> 00:00:26,551
Rym: I do you know voting's big this year.

8
00:00:26,591 --> 00:00:30,204
Rym: like a lot of people are voting who have never voted before a lot Of people are trying to vote early.

9
00:00:30,225 --> 00:00:37,952
Rym: a lot of people who were gonna mail a ballot aren't mailing a ballot because the post office I hope these people vote You know next year and the year after.

10
00:00:37,972 --> 00:00:39,560
Scott: yeah, well you're after that.

11
00:00:39,701 --> 00:00:48,660
Rym: It's tricky though because some of them have never voted before but a lot of them are also voting early and avoiding You know post office problems, but I figured New York City the first day of early voting.

12
00:00:48,741 --> 00:00:51,558
Rym: I wasn't going anywhere near that because I got a whole week where I can vote.

13
00:00:51,699 --> 00:00:54,318
Scott: well election is the thing about the early voting right is I?

14
00:00:55,120 --> 00:01:07,386
Scott: Finally, this is the first time during I think a major election that New York City State has had early voting because we passed it Thanks to our previous elections that where we didn't early vote we regular voted And we voted for people who may vote

15
00:01:07,427 --> 00:01:10,057
Rym: in election years that aren't leap years guys like come on.

16
00:01:10,258 --> 00:01:11,924
Scott: Yeah We voted that.

17
00:01:11,945 --> 00:01:15,800
Scott: those years we were able to get you know the early voting to happen in the first place.

18
00:01:15,860 --> 00:01:18,280
Scott: So normally the election day is a Tuesday, which is really stupid.

19
00:01:19,721 --> 00:01:21,436
Scott: That's what they wrote in the freaking Constitution.

20
00:01:21,456 --> 00:01:21,779
Scott: I don't know.

21
00:01:23,501 --> 00:01:29,220
Scott: So then right people are fucking working on Tuesday, so as soon as early voting now you can vote on Saturday and Sunday.

22
00:01:29,401 --> 00:01:30,871
Scott: That's how people can turn out.

23
00:01:30,912 --> 00:01:31,939
Scott: they don't to go to fucking work.

24
00:01:32,282 --> 00:01:33,155
Scott: Yeah, I can vote right.

25
00:01:33,175 --> 00:01:36,266
Rym: especially Silver link to that talked about.

26
00:01:36,567 --> 00:01:38,574
Rym: what are the specific reasons Americans don't vote?

27
00:01:38,634 --> 00:01:44,474
Rym: and the number one reason across all Demographics was the wait in line to vote was more than an hour.

28
00:01:45,237 --> 00:01:52,100
Scott: Yeah, also People you know there is technically a law that your boss is like let you go vote on Tuesday.

29
00:01:52,241 --> 00:01:53,855
Scott: I don't do that work.

30
00:01:54,298 --> 00:01:58,393
Scott: well You know people don't have the balls to tell their boss that and then fight.

31
00:01:58,614 --> 00:01:59,236
Scott: and you're right.

32
00:01:59,256 --> 00:02:00,260
Scott: whatever they just go to work.

33
00:02:00,532 --> 00:02:02,267
Scott: Yeah More important than going to vote for them.

34
00:02:02,347 --> 00:02:09,493
Scott: so but I figured I wouldn't go on the first day because I figured that's usually the day When people I knew Saturday and Sunday were gonna be a complete trash fire.

35
00:02:09,553 --> 00:02:14,908
Scott: because you know for early voting Not only is this the only time you can vote on the weekend.

36
00:02:15,029 --> 00:02:21,216
Scott: Yeah, right the early voting in New York has fewer locations than actual election day.

37
00:02:21,256 --> 00:02:31,480
Scott: election day There's like tons of locations open because all these people who don't work on election day go to become poll workers Yeah, and that that way that enables them to open up more locations during the early voting.

38
00:02:31,901 --> 00:02:36,834
Scott: It's only the locations that the BOE has staff for that can work all those days.

39
00:02:37,155 --> 00:02:38,919
Scott: You know the old retired people and such.

40
00:02:40,242 --> 00:02:43,013
Scott: And so there's a lot less locations with a lot less hours.

41
00:02:43,576 --> 00:02:47,149
Scott: and because it's weekend This is the only time on the weekend less locations.

42
00:02:47,169 --> 00:02:48,574
Scott: Yeah, it's gonna be a long line.

43
00:02:48,835 --> 00:02:51,063
Rym: Yep, so Saturday We got there.

44
00:02:51,083 --> 00:02:56,707
Rym: All right, right when it opened and the line we see a line like, okay, it doesn't look so bad It's socially distanced line.

45
00:02:56,888 --> 00:02:58,918
Scott: people really really really want to vote right now.

46
00:02:59,320 --> 00:03:04,139
Rym: So we walk down the line walk down the line keep walking down the line and then oh, there's the end of it.

47
00:03:04,603 --> 00:03:06,080
Rym: Nope, it's like a PAX line.

48
00:03:06,140 --> 00:03:14,963
Rym: It's around the corner and then around another corner and then and I then we realized it was like a four or five hour line And we're gonna vote a different day Mm-hmm.

49
00:03:15,003 --> 00:03:17,712
Scott: So I what I did is I say I'm gonna vote early and often.

50
00:03:17,792 --> 00:03:23,800
Scott: I sent in the mail-in ballot long ago But oh, I'm gonna go a New York, right?

51
00:03:24,000 --> 00:03:42,559
Scott: So there were other people from other states who are my friends who were saying Oh New York is so dumb they don't open the absentee ballots till after and They talked about how someone showed up to vote in person who had received an absentee ballot in the mail At least according to the records, but they had not brought it with them to prove that they had not used it.

52
00:03:43,242 --> 00:03:54,806
Scott: Therefore they had to fill out a provisional, you know affidavit Ballot because you know as soon as that state receives ballots in the mail from voters They open them right away.

53
00:03:55,308 --> 00:04:01,111
Rym: New York doesn't open them till after the election Although no states open them in advance, which is a big problem.

54
00:04:01,673 --> 00:04:03,660
Scott: Well, some states do they're including my friends.

55
00:04:03,700 --> 00:04:05,540
Rym: Yeah, those states don't right.

56
00:04:05,640 --> 00:04:09,493
Scott: So not voting them till after is actually kind of good because it.

57
00:04:09,974 --> 00:04:18,197
Scott: the advantage is that I can now Vote by mail and then if I feel like voting in person, maybe I just changed my fucking mind.

58
00:04:18,216 --> 00:04:19,160
Scott: I don't know, right?

59
00:04:19,360 --> 00:04:20,747
Scott: Maybe I just want to make sure.

60
00:04:20,928 --> 00:04:25,509
Scott: maybe I not sure if I'll be able to vote in person So I send one in in case I can't.

61
00:04:25,890 --> 00:04:28,300
Scott: but then if I can I go and do that anyway.

62
00:04:28,842 --> 00:04:36,807
Scott: and what happens is when they go on the day after the election or the night or whatever they start opening the absentee ballots once The polls close and they see wait a minute.

63
00:04:36,827 --> 00:04:37,529
Scott: This is from Scott.

64
00:04:37,790 --> 00:04:40,980
Scott: Scott voted in person near his town near his house.

65
00:04:41,421 --> 00:04:42,886
Scott: We'll just throw this one in the trash.

66
00:04:42,987 --> 00:04:44,773
Rym: Yeah, but some states can't even do that.

67
00:04:45,515 --> 00:04:59,560
Scott: And maybe I'll get lucky and They won't throw it in the trash and I'll get to vote twice Once they crime I. They can't prove it because once they open that second envelope they because what they do is there's the there's the outside envelope.

68
00:04:59,600 --> 00:05:01,699
Rym: They got an admission right here live on GeekNights.

69
00:05:02,621 --> 00:05:10,492
Scott: Yeah, they open that first day open the first envelope right and now now they're sitting at the second envelope Which is my name on it, right and those envelopes they've.

70
00:05:10,512 --> 00:05:12,520
Scott: don't open them, but they verify each one.

71
00:05:12,601 --> 00:05:17,736
Scott: So this is the part where they would say Oh this envelope says Scott on it and he voted at the school or whatever.

72
00:05:17,856 --> 00:05:20,619
Scott: or the old folks home Throw this out and they throw out the whole thing.

73
00:05:20,860 --> 00:05:25,395
Scott: Right if they open if they mess that up and they open that envelope and they throw up.

74
00:05:25,616 --> 00:05:26,760
Scott: then they throw out the envelope.

75
00:05:26,780 --> 00:05:27,664
Scott: This is Scott on it.

76
00:05:28,246 --> 00:05:29,170
Scott: Right now.

77
00:05:29,210 --> 00:05:30,696
Scott: They're left with an anonymous ballot.

78
00:05:30,736 --> 00:05:31,418
Scott: They gotta count it.

79
00:05:32,343 --> 00:05:33,652
Scott: Yeah, right GG.

80
00:05:33,712 --> 00:05:34,578
Scott: I got to vote twice.

81
00:05:34,658 --> 00:05:41,217
Scott: maybe If they fuck up but legally I am allowed to both mail it in and then vote in person.

82
00:05:41,257 --> 00:05:42,180
Rym: so check your state laws.

83
00:05:42,221 --> 00:05:42,695
Rym: I'll just go.

84
00:05:43,903 --> 00:05:45,080
Rym: What check your state laws?

85
00:05:46,422 --> 00:05:48,250
Rym: Different cuz America is a really stupid country.

86
00:05:48,912 --> 00:05:50,840
Scott: Yeah, they explicitly allowed that in New York.

87
00:05:50,940 --> 00:05:57,965
Scott: So if I see that there's an opportunity to go vote in person and it's not crowded or anything and there's no line I'll go over and do it.

88
00:05:58,125 --> 00:06:01,240
Scott: And if no such opportunity presents itself, I already voted.

89
00:06:01,922 --> 00:06:13,460
Rym: The importance of this mode is not so much in New York cuz New York's gonna go blue no matter what but Kind of elections that got us early voting in the first place.

90
00:06:13,500 --> 00:06:19,240
Rym: Oh, but we have a sitting president who won't commit to the peaceful transfer of power and the Supreme Court has just been destroyed.

91
00:06:19,683 --> 00:06:36,323
Rym: so we're in a situation where if election night and the day after aren't a clear Biden victory then court cases and nonsense could actually overturn the election and cause a lot of Drama, the more votes get counted the day of the election the better Mmm, like.

92
00:06:36,363 --> 00:06:39,754
Rym: that's a really important thing, especially in certain states like Pennsylvania.

93
00:06:39,814 --> 00:06:42,543
Rym: that could determine the entire election Mm-hmm.

94
00:06:43,386 --> 00:06:52,185
Rym: But yeah, so we're gonna go either like in the middle of a work day Like tomorrow like one day this week or they alternate the days like some days It opens at like 7 a.m.

95
00:06:52,225 --> 00:06:54,875
Rym: And closes at 4 and some days that opens is like 11 a.m.

96
00:06:55,156 --> 00:06:55,858
Rym: And closes like 8 p.m.

97
00:06:57,240 --> 00:07:04,896
Scott: Is that the poll workers can't work from 7 to 8 But they want to give some people who can go late an opportunity and some people can go early.

98
00:07:04,916 --> 00:07:10,476
Rym: and oh from what I heard The people have been stuck at the polling places every night for like four or five extra hours.

99
00:07:10,517 --> 00:07:12,797
Rym: because of how many people get in Line, they can't turn away.

100
00:07:13,442 --> 00:07:18,601
Scott: But if you went from 7 to 8 they'd be there from 7 to midnight instead of 10 to midnight or 7.

101
00:07:18,601 --> 00:07:20,780
Rym: You know that was always my strategy when I was a kid.

102
00:07:20,860 --> 00:07:24,941
Rym: We'd go to Cedar Point the roller coaster park and the park would close at 11.

103
00:07:24,941 --> 00:07:30,960
Rym: But all that meant was all the restaurants closed and all the lines don't let anyone else get in line.

104
00:07:31,080 --> 00:07:40,266
Scott: So what we would always do that was that mean that was that's you know, you were taking advantage of their policy But what they should what they should do is have the packs policy Which is it's six o'clock.

105
00:07:40,327 --> 00:07:42,858
Scott: a big wall of enforces just pushes everyone out immediately.

106
00:07:42,898 --> 00:07:46,852
Rym: the end Yeah, you gotta let people vote and if they're too slow to process voting.

107
00:07:46,872 --> 00:07:47,474
Scott: Yeah voting.

108
00:07:47,514 --> 00:07:48,960
Scott: Yes, but amusement park?

109
00:07:49,341 --> 00:07:53,811
Scott: Yeah, no, but if I ran the amusement park, I'd push you out But if I ran the voting I would not.

110
00:07:53,892 --> 00:08:04,734
Rym: it was so great though like me and all my friends would literally like get into a multi-hour line at 1059 with a pile of like chicken fingers and Mountain Dew and we would be the lat.

111
00:08:04,754 --> 00:08:11,035
Rym: we would try to be the last people in That line on purpose so we would be the last people walking out of the park at like whatever.

112
00:08:11,055 --> 00:08:11,938
Scott: just let everyone cut you.

113
00:08:13,222 --> 00:08:14,614
Rym: We would love anyone who came in after us.

114
00:08:14,635 --> 00:08:15,240
Rym: We'd always like cut.

115
00:08:15,320 --> 00:08:17,715
Rym: We were the last people in line having a chicken finger party.

116
00:08:17,775 --> 00:08:18,540
Rym: That was like a thing.

117
00:08:20,302 --> 00:08:21,667
Scott: I go for some chicken fingers right now.

118
00:08:21,888 --> 00:08:22,551
Rym: I actually could too.

119
00:08:22,571 --> 00:08:23,133
Rym: I'm pretty hungry.

120
00:08:23,474 --> 00:08:25,040
Rym: So there is actually some big news.

121
00:08:25,402 --> 00:08:28,660
Rym: It's not as big a news as some of you nerds are thinking but it is really big news.

122
00:08:28,981 --> 00:08:32,452
Rym: They have confirmed that there is water on the moon.

123
00:08:33,034 --> 00:08:34,820
Rym: We've suspected it for a long time.

124
00:08:35,842 --> 00:08:42,340
Rym: there's a lot of evidence of it, but they basically have Absolutely confirmed that there is significant amounts of water on the moon.

125
00:08:43,082 --> 00:08:46,195
Scott: If you collected all the water on the moon in a cup how big would the cup be?

126
00:08:46,295 --> 00:08:47,580
Rym: it'd be bigger than a cup now.

127
00:08:47,741 --> 00:08:49,128
Scott: It's like a swimming pool.

128
00:08:49,791 --> 00:08:51,540
Rym: Well, you can read the article to see all the details.

129
00:08:51,580 --> 00:08:55,092
Rym: But basically they found water in places.

130
00:08:55,132 --> 00:08:57,700
Rym: They didn't expect to find water and it seems to be protected.

131
00:08:57,782 --> 00:09:08,080
Rym: It's not a lot of water I think they said in those parts like on the sunny side of the moon like not on the poles There's the equivalent of a 12 ounce bottle of water per cubic meter of soil.

132
00:09:09,222 --> 00:09:10,351
Scott: not a ton big meter.

133
00:09:10,351 --> 00:09:13,526
Rym: 12 a Cubic yard is close enough.

134
00:09:13,566 --> 00:09:14,088
Rym: you can think of it.

135
00:09:14,128 --> 00:09:18,919
Scott: that and that's if you that's if you collect literally all the water which Is really hard to do even on earth right yeah?

136
00:09:19,040 --> 00:09:29,480
Scott: The water is basically trapped in like either dust particles or maybe like if I if I pull a plant out of the ground or Something that's got water in it right, but like can I extract a hundred percent of the water from that plant?

137
00:09:29,780 --> 00:09:30,565
Scott: It's pretty difficult.

138
00:09:30,585 --> 00:09:31,269
Scott: Well.

139
00:09:31,289 --> 00:09:32,335
Scott: Yeah, you can get pretty close.

140
00:09:32,596 --> 00:09:33,200
Scott: I can get a lot.

141
00:09:33,523 --> 00:09:35,120
Scott: I can get a lot, but you can't get all of it.

142
00:09:35,120 --> 00:09:48,254
Rym: You're not gonna get the full 12 ounces, but basically they found water in a lot of places around the moon and it implies that there might be a larger source of water near the poles and It's just cool that they actually like this was.

143
00:09:48,636 --> 00:09:59,234
Rym: this was saw I don't know decades and decades coming like the Soviets detected what they thought was water there in the late 70s But no one could ever prove it definitively until now.

144
00:09:59,635 --> 00:10:00,800
Scott: so it's hard to prove something.

145
00:10:00,840 --> 00:10:03,490
Scott: That's small and clear and you know yeah, also.

146
00:10:03,510 --> 00:10:06,380
Rym: It's not like we've sent anyone back to the moon to do more science.

147
00:10:07,561 --> 00:10:10,812
Rym: Yeah, we can only science it from with our more with our fancier technology.

148
00:10:10,852 --> 00:10:11,414
Scott: right the only.

149
00:10:11,454 --> 00:10:14,303
Scott: we've only explored the moon with you know 70s technology.

150
00:10:14,403 --> 00:10:20,840
Rym: yeah, basically and now we're scanning and analyzing it with 2000s technology, maybe some 2010s technology.

151
00:10:22,002 --> 00:10:25,277
Rym: Yep, so yeah, you can read the story like I'm not gonna like.

152
00:10:25,317 --> 00:10:25,960
Rym: that's the news.

153
00:10:26,241 --> 00:10:28,186
Rym: There's literally for real 100%.

154
00:10:28,186 --> 00:10:33,659
Rym: there is significant amounts of water on the moon, and that's actually pretty cool.

155
00:10:34,863 --> 00:10:36,233
Scott: Partly doesn't live up there that easily.

156
00:10:37,401 --> 00:10:45,615
Rym: There's a lot of things about space like things about black holes things about other Galaxies that are like quasars and things that we just think of.

157
00:10:45,676 --> 00:11:02,460
Rym: it's like common knowledge like oh, yeah We know that but a lot of things that are commonly understood and obvious about space We're only actually discovered in the last 30 or 40 years Like textbooks I had in elementary school did not have this information Mmm.

158
00:11:02,982 --> 00:11:03,083
Scott: Well.

159
00:11:03,103 --> 00:11:04,368
Scott: There's also just a lot of things.

160
00:11:04,408 --> 00:11:16,680
Scott: It's like you know we mostly know We're really really sure and then there'll be a news That's like it's a hundred percent or at least as not a hundred percent But ninety nine point nine percent confirmed like us confirmed as can be now.

161
00:11:16,800 --> 00:11:23,896
Scott: It's like aha, and it's like you know it's sort of a news But it sort of lacks its impact because you sort of already kind of knew.

162
00:11:23,916 --> 00:11:28,875
Rym: you know yeah But there's also a hindsight bias where you feel like you always knew it's like it didn't.

163
00:11:28,895 --> 00:11:33,379
Rym: our brains are real like And saying yeah, I always knew that.

164
00:11:34,183 --> 00:11:40,027
Scott: But if you asked me yesterday all right, let's take bets if you Is there water on the moon?

165
00:11:40,087 --> 00:11:41,091
Scott: I'd say water on the moon.

166
00:11:41,212 --> 00:11:41,453
Scott: Yes.

167
00:11:41,553 --> 00:11:41,774
Scott: Yes.

168
00:11:41,855 --> 00:11:43,887
Scott: No you got a bet on yes, or no You got no choice.

169
00:11:44,089 --> 00:11:49,479
Scott: I would have bet on yes I would have bet on yes, cuz I'd be like how many molecules counts one molecule of water?

170
00:11:49,519 --> 00:11:59,651
Scott: yes Yeah, Neil Armstrong like you know like a drop of water from his sweat got out or so if you ask me Say a decade ago are there white holes alongside black holes.

171
00:11:59,691 --> 00:12:02,940
Rym: I probably would have bet on yes, but we're increasingly leaning toward no.

172
00:12:03,822 --> 00:12:05,050
Scott: Yeah, all right.

173
00:12:05,594 --> 00:12:08,048
Scott: so a News I got here.

174
00:12:08,310 --> 00:12:15,595
Scott: That's pretty big going around the tech peoples But is largely understood sometimes blown out or under proportion right.

175
00:12:15,695 --> 00:12:18,683
Scott: so there is a tool called YouTube DL.

176
00:12:18,944 --> 00:12:26,050
Scott: it lets you download videos from YouTube a feature that is not an official YouTube feature, but According to whispers.

177
00:12:26,171 --> 00:12:29,439
Scott: I have heard from unnamed Unverified sources.

178
00:12:30,767 --> 00:12:38,460
Scott: It is I think Likely in my opinion that there are developers working at YouTube who intentionally?

179
00:12:39,080 --> 00:12:48,593
Scott: Design YouTube in such a way that it is not obvious That you can download things from YouTube because obviously they would never allow that.

180
00:12:48,853 --> 00:12:58,790
Scott: right, but it is always Possible if you are technologically sophisticated enough, and that is why a tool like YouTube DL Yeah, it is possible to create.

181
00:12:58,831 --> 00:13:00,440
Scott: it'll always be possible to create.

182
00:13:00,540 --> 00:13:04,296
Rym: I love always if I can see it I can records it right.

183
00:13:04,316 --> 00:13:05,160
Scott: There's always a hole.

184
00:13:05,320 --> 00:13:07,671
Rym: I'm gonna use OBS right now to record my screen.

185
00:13:07,711 --> 00:13:09,560
Rym: I could just record a YouTube video with OBS.

186
00:13:09,601 --> 00:13:10,219
Scott: I mean there's even.

187
00:13:10,882 --> 00:13:19,720
Scott: There's even just a hole just in the fact that you know while the video has to come to your computer and get decoded into Frames you could always grab it there because you're the administrator of your own computer.

188
00:13:19,800 --> 00:13:26,017
Rym: Yeah, also because it can't even rely on like private encryption keys and browsers because YouTube works on multiple browsers.

189
00:13:26,098 --> 00:13:32,415
Scott: right so it always be Possible, but it's slightly easier than it could be because of those developers that I have heard.

190
00:13:32,475 --> 00:13:33,939
Scott: rumors of that are unverified.

191
00:13:33,979 --> 00:13:36,651
Scott: so This tool YouTube DL exists.

192
00:13:36,852 --> 00:13:43,595
Scott: it is used by many people for Various reasons some legitimate some not legitimate some piracy.

193
00:13:43,655 --> 00:13:47,466
Scott: Yeah all of which I'm okay with personally, but the law.

194
00:13:47,686 --> 00:13:49,511
Scott: the law is not okay with some of them.

195
00:13:49,631 --> 00:13:50,994
Rym: Well the law is complicated.

196
00:13:51,035 --> 00:13:54,877
Rym: the RIAA is Against this.

197
00:13:56,281 --> 00:13:59,589
Scott: Understand this issue sufficiently right, but I'm saying it's some of the.

198
00:13:59,730 --> 00:14:03,178
Scott: some of these uses are illegal under some laws and some are not.

199
00:14:03,660 --> 00:14:11,079
Scott: so Yeah What happened is the source code of this tool YouTube DL is available on github because this is an open source project.

200
00:14:11,763 --> 00:14:20,539
Scott: github received a DMCA takedown request From the RAS you know and they were saying hey take down this YouTube DL.

201
00:14:21,062 --> 00:14:24,680
Rym: There are even was quote that the code is inherently illegal.

202
00:14:25,563 --> 00:14:25,763
Scott: Right.

203
00:14:25,804 --> 00:14:28,773
Scott: so this is interesting because a right.

204
00:14:28,933 --> 00:14:32,043
Scott: it would not be under the normal DMCA.

205
00:14:32,083 --> 00:14:32,926
Scott: takedown notice.

206
00:14:33,006 --> 00:14:37,620
Scott: because YouTube DL the source code itself is not a copyright infringement.

207
00:14:37,761 --> 00:14:38,162
Scott: It's not like.

208
00:14:38,182 --> 00:14:42,438
Scott: there's some other tool that YouTube DL is a pirated copy of.

209
00:14:42,518 --> 00:14:43,422
Scott: yeah, right It's not.

210
00:14:43,582 --> 00:14:43,964
Scott: it's not like.

211
00:14:44,004 --> 00:14:46,053
Scott: it's a pirated Photoshop or something.

212
00:14:46,415 --> 00:14:51,947
Scott: It's a. it's a. it's a bread Unique you know on its own Freely licensed piece of software.

213
00:14:51,967 --> 00:14:54,416
Scott: so the code itself is not illegal.

214
00:14:55,078 --> 00:15:00,071
Scott: the argument The RA was making was that this is a tool for circumvention.

215
00:15:00,512 --> 00:15:08,866
Scott: right a copyright circumvention tool, but The DMCA is like hey you can't have DRM Circumventing tools.

216
00:15:08,906 --> 00:15:12,139
Scott: well YouTube DL isn't really circumventing a DRM.

217
00:15:12,480 --> 00:15:15,913
Scott: There isn't like a DRM on YouTube the way that like CSS is.

218
00:15:16,013 --> 00:15:17,879
Rym: I was about to bring up CSS DCSS.

219
00:15:18,181 --> 00:15:20,614
Rym: They had a better case on but that wasn't the RIAA.

220
00:15:20,634 --> 00:15:21,399
Rym: that was the MPAA.

221
00:15:22,194 --> 00:15:26,243
Scott: right You know YouTube DL is Sort of.

222
00:15:26,263 --> 00:15:31,260
Scott: you know YouTube isn't implementing a DRM to keep you from downloading videos.

223
00:15:31,381 --> 00:15:33,090
Scott: It's just not providing that as a feature.

224
00:15:33,111 --> 00:15:41,619
Scott: Yeah, so you're sort of you're saying I believe the lack of a download button a You know and you sort of adding one.

225
00:15:41,981 --> 00:15:47,627
Rym: I do believe that YouTube has language to the effect of we do not allow Downloads.

226
00:15:47,950 --> 00:15:48,940
Scott: that is something like that.

227
00:15:49,000 --> 00:15:54,838
Scott: But that would be a fight that would be a violation of between you and Google as a breach of contract.

228
00:15:54,898 --> 00:15:59,530
Rym: another lawyer That's between you and your god on your YouTube.

229
00:15:59,750 --> 00:16:03,038
Scott: You know user agreement right out, whatever.

230
00:16:03,179 --> 00:16:08,676
Scott: so So this takedown notice itself is questionable right on its on its.

231
00:16:08,796 --> 00:16:14,870
Rym: oh, I'm pretty confident not being a lawyer That however this would not hold up.

232
00:16:14,931 --> 00:16:17,158
Rym: a real lawyer actually wanted to wow this.

233
00:16:17,178 --> 00:16:20,049
Scott: well So here's here's some problems right.

234
00:16:20,149 --> 00:16:22,800
Scott: so so it's a positive and a negative problem.

235
00:16:23,081 --> 00:16:30,526
Scott: So the negative problem YouTube DL made a big boo-boo and that in their documentation They specifically cited examples of like.

236
00:16:30,546 --> 00:16:31,529
Scott: hey like.

237
00:16:31,589 --> 00:16:37,184
Scott: literally the examples in the documentation were like if you wanted to download some Taylor Swift Or some you know whatever.

238
00:16:37,204 --> 00:16:38,969
Scott: yeah, right like they.

239
00:16:39,390 --> 00:16:49,860
Scott: they used copyright infringement as an example in their Documentation of how to use YouTube DL basically admitting that they were you know a tool for illegal uses.

240
00:16:49,980 --> 00:16:50,563
Scott: They weren't like.

241
00:16:50,603 --> 00:17:04,859
Scott: hey if you want to download some Creative Commons licensed videos from YouTube But you just can't download them because you know YouTube doesn't have a download button like say some GeekNights videos Yeah, which are all Creative Commons attribution only licensed.

242
00:17:06,342 --> 00:17:07,547
Scott: You know that wasn't their example.

243
00:17:07,567 --> 00:17:09,876
Scott: their example was use this for piracy right?

244
00:17:09,915 --> 00:17:10,859
Scott: Yeah, so that's a negative.

245
00:17:11,021 --> 00:17:16,679
Scott: So I think a non technologically sophisticated judge would see that as very bad.

246
00:17:16,940 --> 00:17:21,839
Rym: Yeah, even though they sell this is yeah, this feels more akin to lock picking tools.

247
00:17:22,162 --> 00:17:25,020
Rym: It is perfectly legal for me to own and carry lock picking tools.

248
00:17:25,320 --> 00:17:28,590
Rym: What is legal is to use them on someone else's property.

249
00:17:29,172 --> 00:17:32,020
Scott: right as long as you only pick locks you own you're all good.

250
00:17:32,080 --> 00:17:33,915
Scott: Yeah, anyway, thank you.

251
00:17:33,936 --> 00:17:38,065
Scott: lock picking law Yes So then the.

252
00:17:38,206 --> 00:17:44,151
Scott: the good part though is apparently this is really interesting There's apparently a bug in github right.

253
00:17:44,171 --> 00:17:44,814
Scott: so in github.

254
00:17:45,255 --> 00:17:46,420
Scott: You know you see a repository.

255
00:17:46,621 --> 00:17:47,464
Scott: What do you do you make?

256
00:17:47,485 --> 00:17:48,549
Scott: you want to contribute to it.

257
00:17:48,569 --> 00:17:49,674
Scott: you make a fork right.

258
00:17:49,714 --> 00:17:52,625
Scott: so it starts out as like Scott slash front row crew.

259
00:17:52,866 --> 00:17:55,094
Scott: Rym makes a fork Rym slash front row crew.

260
00:17:55,154 --> 00:17:56,980
Scott: he makes his own version of the source code.

261
00:17:57,503 --> 00:18:01,000
Scott: Then he submits a pull request to me and says hey, I made some changes.

262
00:18:01,140 --> 00:18:06,154
Scott: Here's the changes, please merge Rym front row crew slash changes into Scott front row crew.

263
00:18:06,495 --> 00:18:08,180
Scott: you know main branch slash changes.

264
00:18:08,240 --> 00:18:11,993
Scott: Yeah, whatever slash main branch, and I can say yes or no.

265
00:18:12,515 --> 00:18:32,894
Scott: apparently it is a bug in github Where if you it's arguable whether it's a bug or who knows, but if you make a pull request It'll actually sort of it'll actually make a copy of that code onto the Sort of the the this the receiving repos You know area right?

266
00:18:34,420 --> 00:18:40,871
Scott: So like for example you might make a pull request to me and then delete your repo I'll still have the pull request you sent to me right?

267
00:18:40,891 --> 00:18:43,620
Scott: so it's sort of like a necessary thing in case you delete yourself.

268
00:18:43,786 --> 00:18:47,089
Scott: Yeah In case I wanted to keep that or something.

269
00:18:47,612 --> 00:18:56,600
Scott: so somebody made a pull request To the github because github has a repo that consists of every DMC a takedown notice that has been sent to github.

270
00:18:57,263 --> 00:19:05,211
Scott: So they sent a pull request to that DMC a github that wasn't merged But it contained the source code of youtube DL.

271
00:19:05,251 --> 00:19:13,700
Scott: Yes, so you can see you can go to github.com Slash DMC a or slash github slash DMC a you know to find this repo.

272
00:19:14,382 --> 00:19:17,540
Scott: And then if you you it won't be linked easily anywhere.

273
00:19:17,640 --> 00:19:20,012
Scott: It'll be hard to find but people are sharing the link.

274
00:19:20,555 --> 00:19:21,480
Scott: so you can go.

275
00:19:21,640 --> 00:19:32,010
Scott: It's like you go to github.com such github such DMC a to the repository of DMC a takedown notices the github has received and Poof there's the youtube DL source code.

276
00:19:32,070 --> 00:19:40,420
Rym: now even if it wasn't the like DCSS despite the fact that that one long integer was technically illegal.

277
00:19:41,301 --> 00:19:43,972
Rym: Somehow it was very easy to find that integer online.

278
00:19:44,334 --> 00:19:46,139
Rym: this code is going to be like that All right.

279
00:19:46,541 --> 00:19:49,329
Scott: Also the fact that the entire world has switched to.

280
00:19:49,509 --> 00:19:56,693
Scott: effectively the entire world has switched from SVN to get I don't know if people Realize that would distributed source code control software as opposed.

281
00:19:56,713 --> 00:19:58,600
Scott: We've talked about this in the past actually on GeekNights.

282
00:19:58,702 --> 00:19:59,740
Scott: Go find those episodes.

283
00:20:00,362 --> 00:20:04,835
Scott: Every single clone of that repo has the entire history of the repo.

284
00:20:04,875 --> 00:20:11,600
Scott: if you get clone the Linux kernel You will have every version of the Linux kernel going back to the first version like on your computer.

285
00:20:11,600 --> 00:20:13,080
Scott: It takes forever to download the friggin thing.

286
00:20:13,080 --> 00:20:21,106
Scott: Yeah, so if you if you have ever cloned YouTube DL on to your local computer You have the code.

287
00:20:21,126 --> 00:20:22,050
Scott: no right.

288
00:20:22,110 --> 00:20:25,543
Scott: and so all these YouTube DL developers have all the code You can't really?

289
00:20:25,945 --> 00:20:28,740
Scott: you know taking it down off github.com doesn't really stop anything.

290
00:20:29,384 --> 00:20:31,738
Scott: And they can also file a counterclaim to get it put back up.

291
00:20:31,819 --> 00:20:44,124
Scott: so Nothing has changed on the YouTube side, so there's really no danger of us losing the YouTube DL functionality Yeah, which I rely on heavily All that you know.

292
00:20:44,185 --> 00:20:55,765
Scott: and even so there are other Git posting places including host it yourself, so it's like as long as the YouTube DL developers carry on their work Hosting their repo somewhere else

293
00:20:56,026 --> 00:21:02,999
Rym: as long as there's a discord somewhere server somewhere where people talk about and use a private repo This code will exist.

294
00:21:03,742 --> 00:21:10,560
Scott: So there's really nothing to get worried about here unless the YouTube GL developers decide to you know throw in the towel or something.

295
00:21:10,640 --> 00:21:11,866
Rym: Yeah, but even then what else?

296
00:21:11,886 --> 00:21:14,520
Scott: just someone else will just carry that or continue to work.

297
00:21:15,404 --> 00:21:23,700
Scott: Yes, as long as those rumored YouTube developers Don't make it much much more difficult to download things from YouTube, then we'll have some trouble.

298
00:21:23,820 --> 00:21:31,047
Rym: But on the other hand I can't see them being able to make it impossible because the frame It won't be impossible, but they could.

299
00:21:31,187 --> 00:21:34,820
Scott: they could make it extremely much more difficult than it is they could.

300
00:21:35,001 --> 00:21:39,660
Rym: It's not very and the current way things they could make it to where it's easier to use the analog hole.

301
00:21:40,215 --> 00:21:42,790
Scott: Yes It's not nearly as difficult as it could be.

302
00:21:42,850 --> 00:22:05,040
Rym: I guess what I would say is with this kind of copyright takedown The best case scenario for the people who are going after this kind of tool the best they could possibly achieve is to make the Thing they're trying to protect more of a pain in the ass than using the analog hole Because the analog hole will always exist no matter what and you can always Copy any media at a real-time playback rate.

303
00:22:06,325 --> 00:22:06,912
Scott: Yep, pretty much.

304
00:22:07,801 --> 00:22:11,511
Rym: But uh the EFF did respond to this and they said the thing they always say.

305
00:22:11,872 --> 00:22:20,940
Rym: they called the RA's notice disappointing and counterproductive Pretty much a sentiment echoed by activists who work in the fields of civil rights human rights and hate speech.

306
00:22:21,663 --> 00:22:24,940
Scott: Yeah, like I said, you know, there are many legitimate uses for YouTube DL.

307
00:22:25,040 --> 00:22:29,215
Scott: They're not copyright infringement and that should have been what the examples also notice.

308
00:22:29,335 --> 00:22:32,000
Rym: It's not the movie industry It's not videos.

309
00:22:32,080 --> 00:22:32,200
Rym: The.

310
00:22:32,441 --> 00:22:38,056
Rym: the people who went after this code are the music industry because they are arguing.

311
00:22:38,076 --> 00:22:39,641
Rym: we talked about this on our last GeekNights Too.

312
00:22:40,023 --> 00:22:43,158
Rym: the RIA and the music industry is really thrashing right now.

313
00:22:43,982 --> 00:22:44,886
Scott: Generally, yeah, they're.

314
00:22:45,328 --> 00:22:47,799
Scott: they're really going after twitch as well, right?

315
00:22:48,200 --> 00:22:50,677
Scott: That's why twitch is all is bringing the hammer down a little bit.

316
00:22:51,461 --> 00:22:57,482
Rym: There's a reason why we've always hated the RIAA in particular because even though we do have to figure out a way to pay Musicians.

317
00:22:57,803 --> 00:23:04,124
Rym: the RIAA is basically never acted in good faith when it comes to copyright at any point in its existence Right.

318
00:23:04,245 --> 00:23:09,360
Scott: Well and at least in the twitch like YouTube does pay people In fact, it's sort of you know goes too far.

319
00:23:09,500 --> 00:23:21,826
Scott: Right, if I make a video and include a copyrighted song in my in my video then the YouTube policy is basically Okay, I use Rolling Stones right now and they come the Rolling Stones come and say hey used our song We're gonna put a claim on your video.

320
00:23:21,866 --> 00:23:25,660
Scott: your videos now showing ads and the Rolling Stones take all the money.

321
00:23:26,162 --> 00:23:28,010
Scott: It's like excuse me, right?

322
00:23:28,090 --> 00:23:30,400
Scott: You should get maybe a portion of the money from this video.

323
00:23:30,520 --> 00:23:32,774
Scott: But there's also the part that I made right.

324
00:23:32,794 --> 00:23:33,640
Scott: you're taking my money.

325
00:23:33,760 --> 00:23:36,330
Rym: My 20-minute video has one of minutes of your audio.

326
00:23:36,371 --> 00:23:38,720
Rym: you get two out of 20 of my revenue.

327
00:23:39,720 --> 00:23:41,045
Scott: Exactly, right some sort of.

328
00:23:41,306 --> 00:23:43,293
Scott: but no they just take everything which is bullshit right.

329
00:23:43,333 --> 00:23:44,678
Scott: and then on twitch.

330
00:23:44,979 --> 00:23:45,926
Scott: twitch It's you know.

331
00:23:45,986 --> 00:23:50,769
Scott: twitch is obviously, you know Don't think that because twitch is not completely capitulating.

332
00:23:50,789 --> 00:23:52,414
Scott: It's sort of covering for its streamers.

333
00:23:52,454 --> 00:23:54,520
Rym: now twitch is completely capitulating.

334
00:23:55,641 --> 00:23:56,163
Scott: No, it's not.

335
00:23:56,284 --> 00:23:59,557
Scott: It's it's sort of like it's sort of being evil both ways right.

336
00:23:59,577 --> 00:24:04,820
Scott: on the one hand They're like taking down people's videos just without even saying, you know, just like I'll take all this crap down.

337
00:24:04,960 --> 00:24:28,849
Scott: so, you know to get these people off our back, but on the other hand, it's like Twitch is has purchased music licenses, but it's only purchased Performance licenses which are the kind for playing music and like a restaurant, you know that kind of thing It's technically supposed to be part because you're synchronizing video and the music You're legally supposed to be purchasing sync licenses.

338
00:24:28,869 --> 00:24:32,899
Scott: I mean and then if it's a VOD mechanical licenses, right.

339
00:24:33,300 --> 00:24:37,483
Scott: so Twitch is not paying the Musicians, right?

340
00:24:37,503 --> 00:24:42,620
Scott: So YouTube steals all your money on the video creator and gives it to the musicians, right?

341
00:24:42,660 --> 00:24:43,987
Scott: It's almost too music friendly.

342
00:24:44,007 --> 00:24:44,670
Scott: Right?

343
00:24:45,012 --> 00:24:48,571
Scott: But meanwhile twitch is The opposite.

344
00:24:48,632 --> 00:24:49,964
Scott: it's like, okay They're they're.

345
00:24:49,984 --> 00:24:55,540
Scott: they're taking down streamers videos to make them upset Right and to sort of get the RA to go away a little bit.

346
00:24:55,640 --> 00:24:59,173
Scott: but they're also ripping off the music people not paying them.

347
00:24:59,273 --> 00:25:00,999
Rym: and this is at the intersection of.

348
00:25:01,880 --> 00:25:06,520
Rym: Someone buys a game but the game has music that is licensed within it.

349
00:25:06,882 --> 00:25:09,200
Rym: But do they have a right to stream that game or not?

350
00:25:09,601 --> 00:25:11,168
Rym: Like this is this whole area.

351
00:25:11,188 --> 00:25:14,040
Scott: the person who makes the game the person who makes the game doesn't care.

352
00:25:14,464 --> 00:25:21,384
Scott: Yeah, they're like, please stream Please stream because that is better marketing and gets me more sales than anything else I could spend marketing money on.

353
00:25:21,445 --> 00:25:24,215
Scott: in fact, I will give the streamer money to stream the game.

354
00:25:24,275 --> 00:25:38,980
Rym: I'm paying you to do this Yep, and you do see some more and more games are having completely original soundtracks to bypass this entire process Where the game itself like music came with the game and it's just part of that game.

355
00:25:39,101 --> 00:25:40,660
Rym: There's no separate music license.

356
00:25:41,781 --> 00:25:53,499
Scott: Anyway, the final story is if you didn't know that it's possible to download YouTube videos permanently I'll come to the party and you've got and you've got videos that might be taken down at some point or you're worried about not Being able to see them easily again.

357
00:25:53,640 --> 00:25:57,317
Scott: You should get the YouTube DL tool or a similar tool and download all your.

358
00:25:57,337 --> 00:26:01,954
Rym: be wary though If you get a similar tool from an untrusted source, and it's not source code.

359
00:26:02,516 --> 00:26:03,500
Rym: It's probably malware.

360
00:26:04,382 --> 00:26:05,909
Scott: Make sure you're getting some sort of legitimate.

361
00:26:06,150 --> 00:26:09,399
Rym: if you google for YouTube downloader You're gonna find a lot of malware.

362
00:26:10,845 --> 00:26:11,957
Scott: You are there's some out there.

363
00:26:11,978 --> 00:26:18,239
Scott: yet There's also some older un-maintained tools that don't work because YouTube changed yep since and they didn't maintain them.

364
00:26:18,279 --> 00:26:29,001
Rym: YouTube DL is actively main thing, but anyway things Of the day, so check this out.

365
00:26:29,042 --> 00:26:32,835
Rym: This is a two second video Looping in a tweet.

366
00:26:33,116 --> 00:26:46,130
Rym: That is my thing of the day, but what this video is is the surface of a comet Seen through a blizzard of dust ice and cosmic rays and a backdrop of stars.

367
00:26:46,391 --> 00:26:49,845
Rym: This is a fucking video of the surface of a comet.

368
00:26:50,126 --> 00:26:52,423
Scott: Holy shit Is it a comet?

369
00:26:52,443 --> 00:26:53,109
Scott: just a ball of ice?

370
00:26:53,590 --> 00:26:55,862
Rym: Yeah, and rocks it looks like wouldn't it wouldn't?

371
00:26:55,882 --> 00:26:57,330
Scott: it just look like a ice cube with rocks in it.

372
00:26:57,370 --> 00:27:01,850
Rym: It looks like a cliff face with rocks and a blizzard happening and snow.

373
00:27:03,332 --> 00:27:04,438
Rym: Okay, it's really cool.

374
00:27:04,458 --> 00:27:06,268
Rym: It's a goddamn comet.

375
00:27:07,491 --> 00:27:09,116
Rym: All right, I mean we've landed things on.

376
00:27:09,157 --> 00:27:10,782
Rym: comets like comets are neat.

377
00:27:11,183 --> 00:27:17,259
Rym: comets are probably where a lot of that water on the moon comes from - Yeah, anyway, that's all I got.

378
00:27:18,534 --> 00:27:24,626
Scott: Yeah, so I've been doing the bike to nowhere situation because it there's nowhere to go and the weather sucks now, right?

379
00:27:25,790 --> 00:27:27,054
Scott: So beat when you're doing the bike to nowhere.

380
00:27:27,094 --> 00:27:27,776
Scott: the bike to nowhere.

381
00:27:27,816 --> 00:27:28,879
Scott: software, right?

382
00:27:28,899 --> 00:27:32,850
Scott: You sort of can't avoid learning these new things like FTP.

383
00:27:32,871 --> 00:27:33,495
Scott: ever heard of FTP?

384
00:27:33,535 --> 00:27:35,548
Scott: not the file transfer protocol, but the other FTP.

385
00:27:35,588 --> 00:27:38,577
Scott: now It's functional threshold power.

386
00:27:38,657 --> 00:27:40,423
Scott: It's like the average wattage.

387
00:27:40,463 --> 00:27:42,590
Scott: You're capable of putting out in one hour.

388
00:27:42,690 --> 00:27:46,863
Rym: I've seen people talking about wattage hours stuff on blogs, but I don't care.

389
00:27:46,943 --> 00:27:49,310
Scott: So you bike as hard as you can for an hour.

390
00:27:49,491 --> 00:27:52,586
Scott: What's the average wattage you would put out over the hour?

391
00:27:52,647 --> 00:27:53,209
Scott: That's your FTP.

392
00:27:54,111 --> 00:27:55,375
Scott: Yeah, TSS.

393
00:27:55,495 --> 00:27:57,361
Scott: It's like this scoring system.

394
00:27:57,401 --> 00:27:58,986
Scott: They use it's not very complicated.

395
00:27:59,066 --> 00:27:59,287
Scott: Actually.

396
00:27:59,307 --> 00:28:02,517
Scott: It's a simple formula Which has to do with this has to.

397
00:28:02,739 --> 00:28:09,763
Scott: it's mostly based on wattage and length and time But it's basically a scoring system for how difficult a particular bike ride is.

398
00:28:09,944 --> 00:28:13,057
Scott: So it's like if it's a 200 TSS That's a really hard bike ride.

399
00:28:13,117 --> 00:28:15,229
Scott: But like a 50 is like alright you biked, you know.

400
00:28:15,992 --> 00:28:17,476
Scott: Anyway, so all this stuff.

401
00:28:17,496 --> 00:28:32,617
Scott: so I started going on YouTube to better understand what the hell this stuff meant and I found this channel this guy Dylan Johnson, so Dylan Johnson is a. I don't know if he's professional or not, but he is definitely a competitive Endurance mountain biker, right?

402
00:28:32,857 --> 00:28:35,765
Scott: So and he places highly so he's really good at it.

403
00:28:36,206 --> 00:28:39,670
Rym: endurance mountain biking is extremely difficult and painful.

404
00:28:40,951 --> 00:28:44,000
Scott: It actually looks to me like I would do that.

405
00:28:44,542 --> 00:28:48,338
Scott: then regular mountain biking cuz like regular mountain biking like, you know Downhill is like no.

406
00:28:48,418 --> 00:28:49,810
Scott: No, you're you mistake.

407
00:28:50,470 --> 00:28:53,460
Rym: Downhill is a separate subcategory of mountain biking.

408
00:28:53,501 --> 00:28:59,170
Rym: most people who say they're mountain bikers do not do downhill mountain biking Right, but it's like this looks way less scary.

409
00:28:59,271 --> 00:29:03,154
Scott: It just looks like hey you're biking a long way Which I do anyway.

410
00:29:03,455 --> 00:29:07,771
Scott: only it happens to be in the dirt and there might be some rocks and shit and you have a mountain bike Instead.

411
00:29:07,792 --> 00:29:08,916
Rym: that's most mountain biking.

412
00:29:08,936 --> 00:29:10,463
Rym: That's when I say I'm doing mountain biking.

413
00:29:10,503 --> 00:29:11,527
Rym: That's what I'm doing 90% of the time.

414
00:29:12,893 --> 00:29:13,945
Scott: That actually seems okay.

415
00:29:13,986 --> 00:29:19,822
Scott: But anyway So this guy does that very well and he is also I guess his profession is.

416
00:29:19,863 --> 00:29:25,460
Scott: he is a coach right athletic coach trainer person And he's got a YouTube channel where he talks about stuff.

417
00:29:25,600 --> 00:29:32,784
Scott: and normally when I search and try to find any Exercise health fitness wellness, you know, I even like the term wellness.

418
00:29:32,824 --> 00:29:35,396
Scott: if they say you they use the word wellness That's usually up flags.

419
00:29:35,537 --> 00:29:36,201
Rym: Nope right out of there.

420
00:29:36,221 --> 00:29:37,830
Rym: That's one step before homeopathy.

421
00:29:38,652 --> 00:29:39,167
Scott: That's right.

422
00:29:40,511 --> 00:29:44,210
Scott: Whenever you see that kind of YouTube channel, you're like this is gonna be a bunch of woo bullshit, right?

423
00:29:44,370 --> 00:29:44,673
Scott: I can't.

424
00:29:44,834 --> 00:29:45,298
Scott: how do I know?

425
00:29:45,318 --> 00:29:46,689
Scott: I can trust what this guy's gonna say?

426
00:29:47,510 --> 00:29:49,890
Scott: Dylan Johnson has done the best job of convincing me.

427
00:29:49,910 --> 00:30:03,750
Scott: He knows what he's talking about because all his videos right are all about him reading every single study about the topic right and Saying well this one says this this one says that this one says this this one says that and this one says this.

428
00:30:04,111 --> 00:30:09,550
Scott: So in the end, what can we say is true to the best of human knowledge as of today?

429
00:30:10,270 --> 00:30:26,753
Scott: We don't know or this or the opposite of you know What you thought and he answers a lot of questions that are very relevant to any cyclist Who is even slightly more than non serious, even if you're not considering racing Like.

430
00:30:26,774 --> 00:30:27,750
Scott: I have no interest in racing.

431
00:30:28,231 --> 00:30:32,926
Scott: But he answers a lot of questions like are the clipless pedals more efficient than just?

432
00:30:33,066 --> 00:30:39,589
Rym: that's the one I'm looking at And the one I'm gonna watch after the show are is is what's the right seat height?

433
00:30:40,152 --> 00:30:43,307
Scott: What you know is it is it better be low high in the middle, right?

434
00:30:43,347 --> 00:30:43,870
Scott: How do you figure?

435
00:30:45,230 --> 00:31:00,049
Rym: Biking specifically because the thing I found about biking that I've not found with all a lot of the other sports I do is that biking people tend to always say there is a one true way to do a specific thing and There's never seems to be evidence to back that up.

436
00:31:00,431 --> 00:31:07,730
Rym: But it's like this very specific dogma about there like here's the rule on how to size your seat exactly to you for your bike.

437
00:31:08,453 --> 00:31:09,660
Rym: Do not do a lot of kids.

438
00:31:09,962 --> 00:31:15,802
Scott: Yes, there is a lot of Conventional wisdom in the cycling community and also a lot of just common sense.

439
00:31:15,963 --> 00:31:18,570
Scott: Yeah, that's sort of two things that just make sense, right?

440
00:31:20,402 --> 00:31:27,090
Scott: and You know things you see you look at pro cyclists and you like Tour de France You see them doing something and you say well that must be the right way.

441
00:31:27,110 --> 00:31:32,370
Scott: Yeah, but now maybe not not always but maybe but maybe not right, you know, I saw video.

442
00:31:32,694 --> 00:31:33,969
Scott: Did I do that as a thing of the day?

443
00:31:34,190 --> 00:31:36,610
Scott: Like what's the best position to go to be in going down?

444
00:31:37,550 --> 00:31:44,590
Rym: Because we talked a lot when we did that show about Superman's the best position but don't do Superman right exactly so.

445
00:31:46,053 --> 00:31:49,453
Scott: but yeah, Dylan Johnson's channel is Incredible.

446
00:31:49,533 --> 00:31:53,170
Scott: I've learned a lot so far and I've only watched like a handful of the videos.

447
00:31:53,271 --> 00:31:57,030
Scott: I'm probably gonna watch all the ones relevant to myself and adjust accordingly.

448
00:31:58,371 --> 00:32:04,107
Scott: So yeah, if you if you bike at all and care about getting better at biking is a must watch channel.

449
00:32:04,648 --> 00:32:05,330
Scott: Good job, Dylan.

450
00:32:05,370 --> 00:32:12,955
Rym: I guess it's interesting that when I think about this like I run into that conventional wisdom and doctrine way more recycling than other sports I do specifically like.

451
00:32:13,015 --> 00:32:14,863
Rym: even skiing does not have this.

452
00:32:14,943 --> 00:32:21,426
Rym: like we ask a question of a ski instructor The answer is full of a lot of caveats and it depends and a lot of sort of like.

453
00:32:21,848 --> 00:32:23,273
Rym: this might work But it might not.

454
00:32:23,333 --> 00:32:24,156
Rym: let's try.

455
00:32:24,377 --> 00:32:27,810
Rym: but with cycling it's just always like put your seat at this height based on this formula.

456
00:32:29,854 --> 00:32:30,337
Scott: Well, there is.

457
00:32:30,377 --> 00:32:32,670
Scott: there is a formula which one's the right exactly.

458
00:32:33,531 --> 00:32:34,072
Scott: Dylan knows.

459
00:32:34,132 --> 00:32:36,701
Rym: he'll tell you so in the moment stuck at home.

460
00:32:37,082 --> 00:32:38,346
Rym: You can watch our panels on YouTube.

461
00:32:38,908 --> 00:32:40,297
Rym: join our discord I don't know.

462
00:32:40,317 --> 00:32:43,235
Rym: I Thought about fucking like vote.

463
00:32:43,275 --> 00:32:43,636
Rym: That's it.

464
00:32:43,676 --> 00:32:47,588
Rym: Just go fucking vote for Joe Biden or things are gonna get real bad in a hurry.

465
00:32:47,769 --> 00:32:55,112
Scott: or If you if you are eligible to vote in the United States of America and you do not vote for Joe Biden get the hell Out.

466
00:32:55,152 --> 00:33:02,010
Scott: Yep, and if you live in New York State You should vote for Joe Biden on the working families party line should to make to make the governor mad.

467
00:33:02,875 --> 00:33:03,479
Scott: It will can't?

468
00:33:03,519 --> 00:33:04,425
Scott: it will count the same.

469
00:33:04,506 --> 00:33:04,969
Scott: I promise.

470
00:33:04,989 --> 00:33:08,785
Rym: Yep It still counts for Joe Biden, but it pisses off Cuomo and all.

471
00:33:08,805 --> 00:33:09,668
Rym: good people hate him.

472
00:33:10,695 --> 00:33:12,510
Rym: Bad people hate him too, but so do good people.

473
00:33:13,912 --> 00:33:14,678
Scott: Same thing for the mayor.

474
00:33:14,758 --> 00:33:14,940
Scott: Yeah.

475
00:33:14,960 --> 00:33:19,543
Scott: Anyway, I Thought about reading a chapter of our book club.

476
00:33:19,664 --> 00:33:24,362
Scott: Oh so fancy of Genji, but instead I read a comic book.

477
00:33:24,563 --> 00:33:25,627
Rym: We're in a comic book.

478
00:33:25,667 --> 00:33:26,973
Rym: You know what I did I can't?

479
00:33:27,113 --> 00:33:30,930
Rym: I played a bunch of Star Wars and like made some food and went hiking.

480
00:33:31,991 --> 00:33:32,754
Scott: I made some food.

481
00:33:32,774 --> 00:33:34,759
Scott: I played some links of the past.

482
00:33:34,779 --> 00:33:36,344
Rym: problem is I like normally this.

483
00:33:36,384 --> 00:33:42,810
Rym: like this season when I'd go hiking I'd have a long train ride to and from the hiking that I would read books on.

484
00:33:43,191 --> 00:33:45,799
Rym: But now the only way to hike safely is to drive places.

485
00:33:46,160 --> 00:33:47,865
Rym: So I have to drive the whole time.

486
00:33:47,885 --> 00:33:49,149
Scott: I just hike to the hiking.

487
00:33:50,210 --> 00:33:55,405
Rym: That'd be like yeah, let me bike to Poughkeepsie to then bike to Albany.

488
00:33:55,685 --> 00:33:58,572
Rym: I Mean.

489
00:33:58,592 --> 00:33:59,315
Rym: I guess I could get.

490
00:33:59,395 --> 00:34:00,560
Rym: I could get the.

491
00:34:00,580 --> 00:34:07,848
Rym: probably I'd have to camp because to get all those mountains I would have to hike about 70 miles from Queens to get to those mountain trailheads.

492
00:34:11,570 --> 00:34:15,222
Rym: Three days two days if I'd like death marched it but really that's a three-day.

493
00:34:15,242 --> 00:34:17,449
Scott: I could bike 70 miles in like seven hours.

494
00:34:17,570 --> 00:34:18,213
Rym: Yeah, bike it.

495
00:34:18,253 --> 00:34:19,819
Rym: Let's see how far you can walk.

496
00:34:20,141 --> 00:34:21,446
Rym: Okay, how long they'll take you to walk.

497
00:34:21,446 --> 00:34:23,833
Rym: 70 miles Days.

498
00:34:24,137 --> 00:34:27,893
Rym: Yeah take about three days Three Days.

499
00:34:27,954 --> 00:34:31,155
Rym: if you're really fit and good at walking I'm good at walking.

500
00:34:31,496 --> 00:34:32,040
Rym: Are you really?

501
00:34:32,081 --> 00:34:32,724
Rym: we should test this?

502
00:34:32,745 --> 00:34:33,449
Rym: you want to go for a walk?

503
00:34:34,971 --> 00:34:38,040
Scott: My legs are long Therefore I'm good at walking.

504
00:34:38,322 --> 00:34:39,110
Rym: But yeah vote.

505
00:34:39,770 --> 00:34:42,603
Rym: Otherwise, like the next week is gonna be rough for a lot of people.

506
00:34:42,623 --> 00:34:49,487
Rym: So just be ready for that and We'll try to just keep doing GeekNights until then and maybe at some point We'll have some downtime and actually read books again.

507
00:34:50,771 --> 00:35:02,421
Scott: my major concern these days is that Hockey will resume and for some reason they will allow people to go to hockey Before it is because then we have to sell all those tickets.

508
00:35:02,441 --> 00:35:04,068
Rym: because I'm not going to have a to sell right.

509
00:35:04,490 --> 00:35:12,441
Scott: they will have to sell all these tickets because Even though I said I would go as soon as I could I'm not gonna go if it's not that was assuming they wouldn't let Me go until it was safe.

510
00:35:12,482 --> 00:35:12,886
Scott: Yeah, right.

511
00:35:12,967 --> 00:35:15,252
Scott: So That's my.

512
00:35:15,272 --> 00:35:18,524
Scott: that's you know and for that to be my concern I'm doing pretty well.

513
00:35:18,564 --> 00:35:24,002
Rym: honestly though the way the news is trending I'm pretty sure COVID is gonna be like a wave worse than anything.

514
00:35:24,042 --> 00:35:25,145
Rym: We've seen up to this point.

515
00:35:25,807 --> 00:35:27,395
Rym: over the next few weeks That's gonna happen.

516
00:35:27,415 --> 00:35:42,470
Rym: Like things are looking pretty bad in most of the country I'll say the only saving grace for us personally Luckily is if we live in New York City Which except for one neighborhood is actually trending very well like one specific neighbor a couple couple couple neighborhoods.

517
00:35:42,691 --> 00:35:44,140
Rym: Only one neighborhood is the red zone.

518
00:35:44,341 --> 00:35:45,629
Rym: There are three yellow zones.

519
00:35:46,577 --> 00:35:48,050
Scott: Yeah, then one of the other ones is pretty big.

520
00:35:48,150 --> 00:35:51,569
Rym: Yeah, but that one big yellow zone is around the red zone.

521
00:35:52,751 --> 00:35:54,777
Scott: No, no, no, there's another one out by Q Gardens.

522
00:35:55,580 --> 00:35:56,242
Rym: That one's pretty big.

523
00:35:56,302 --> 00:35:57,566
Scott: It's like a second one.

524
00:35:57,667 --> 00:36:00,750
Rym: Anyway, anyway So, uh, let's get right into it.

525
00:36:00,810 --> 00:36:04,063
Rym: We talked about facial recognition off and out over the years, but we never really did a whole.

526
00:36:04,083 --> 00:36:05,690
Scott: she had some AI episodes.

527
00:36:05,891 --> 00:36:07,500
Scott: You've had some privacy episodes.

528
00:36:07,540 --> 00:36:09,229
Scott: Yeah, you know things like that.

529
00:36:09,832 --> 00:36:12,990
Scott: But it's in the news so much and we don't have a lot of Monday ideas.

530
00:36:13,050 --> 00:36:14,755
Scott: So send your Monday ideas to us.

531
00:36:15,036 --> 00:36:15,237
Scott: cuz.

532
00:36:15,437 --> 00:36:21,778
Scott: Mondays for some reason are like slightly more popular than the other days even though They're the hardest to come up with ideas.

533
00:36:21,959 --> 00:36:23,669
Rym: Wednesdays are the least popular days.

534
00:36:23,990 --> 00:36:26,790
Rym: I think it's because we're the old men of anime at this point.

535
00:36:27,395 --> 00:36:33,977
Scott: Maybe it's because we just know more about Technology and gaming than we know about anime and that's why well We don't watch as much anime as we used to like.

536
00:36:34,017 --> 00:36:35,543
Rym: I basically only watch great shows.

537
00:36:35,603 --> 00:36:41,810
Rym: now though total aside Remember way back we're talking about how we should watch decadence because there's people keep talking about it.

538
00:36:42,494 --> 00:36:48,657
Rym: we watch the first two episodes, uh Yeah You're the whole first episode.

539
00:36:48,678 --> 00:36:49,804
Rym: You're like, alright, it's a show.

540
00:36:49,824 --> 00:36:50,890
Rym: Alright, I like it.

541
00:36:50,930 --> 00:36:53,177
Rym: Okay at the very end of the episode you like wait what.

542
00:36:53,899 --> 00:36:54,802
Rym: and then episode two.

543
00:36:55,424 --> 00:36:58,461
Rym: the show is not what it looks like Holy shit.

544
00:36:58,501 --> 00:36:59,490
Rym: It is not what it looks like.

545
00:37:00,971 --> 00:37:04,705
Rym: Okay, but I think it's specifically up your alley directly.

546
00:37:04,725 --> 00:37:07,598
Scott: you person Is there?

547
00:37:07,962 --> 00:37:08,870
Scott: is there a terrible secret?

548
00:37:09,512 --> 00:37:20,058
Scott: Oh is there and when you're there a train that is there a train that quietly goes out into the night and has a moral What a certain character looks like.

549
00:37:20,760 --> 00:37:22,405
Rym: you'll see what I mean, that's all I can say.

550
00:37:22,425 --> 00:37:24,010
Scott: a robot a cute robot.

551
00:37:24,875 --> 00:37:25,570
Rym: Okay, I can't.

552
00:37:26,531 --> 00:37:28,723
Rym: Everyone who's tried to get me to watch the show has said the same thing.

553
00:37:28,884 --> 00:37:29,850
Rym: I won't tell you anything about it.

554
00:37:29,890 --> 00:37:30,352
Rym: Just watch it.

555
00:37:31,115 --> 00:37:31,918
Rym: Do not read about it.

556
00:37:31,999 --> 00:37:32,360
Scott: Maybe I'll.

557
00:37:32,581 --> 00:37:33,725
Scott: where is it available?

558
00:37:33,786 --> 00:37:34,830
Rym: funimation and Hulu?

559
00:37:36,572 --> 00:37:37,416
Scott: I don't have either one of them.

560
00:37:37,436 --> 00:37:39,226
Rym: Yeah, we happen to have Hulu by accident.

561
00:37:39,246 --> 00:37:40,010
Rym: So we watch it on Hulu.

562
00:37:41,152 --> 00:37:42,259
Rym: No, I didn't know we had Hulu.

563
00:37:42,279 --> 00:37:43,064
Rym: Apparently we had Hulu.

564
00:37:43,990 --> 00:37:46,038
Scott: I Previously had Hulu before I had Netflix.

565
00:37:46,058 --> 00:37:47,163
Scott: I'm currently in Netflix mode.

566
00:37:47,243 --> 00:37:48,347
Scott: Once I get out of Netflix mode.

567
00:37:48,387 --> 00:37:49,231
Scott: I might go back to Hulu.

568
00:37:49,291 --> 00:37:52,710
Rym: yeah, it's hard though cuz Netflix has just got so much constant good stuff lately.

569
00:37:53,551 --> 00:37:54,013
Scott: Yeah, I did.

570
00:37:54,033 --> 00:37:55,622
Scott: I watched like that Michael Jordan documentary.

571
00:37:55,642 --> 00:37:56,004
Scott: That was good.

572
00:37:56,144 --> 00:37:57,089
Rym: Yeah, you can watch a keep.

573
00:37:57,149 --> 00:38:01,270
Rym: Oh Season 3 the third season is the last season anyway.

574
00:38:01,870 --> 00:38:09,190
Rym: facial recognition technology is a good topic because It is so illustrative of the tech transfer ethics concerns of technology.

575
00:38:10,171 --> 00:38:13,580
Rym: But unlike nuclear weapons, it's not like just killing people.

576
00:38:13,961 --> 00:38:15,144
Rym: There aren't that many.

577
00:38:15,284 --> 00:38:17,510
Rym: like peaceful uses for nuclear weapons.

578
00:38:18,393 --> 00:38:18,935
Rym: There were a few.

579
00:38:18,995 --> 00:38:21,686
Rym: there were terrible ideas, but there were a few.

580
00:38:22,107 --> 00:38:23,312
Rym: you can read about it You want.

581
00:38:23,633 --> 00:38:25,339
Rym: nuclear mining was a thing for a while.

582
00:38:25,399 --> 00:38:26,423
Rym: It was a terrible idea.

583
00:38:26,443 --> 00:38:27,808
Scott: That's a bad idea.

584
00:38:28,310 --> 00:38:29,855
Rym: Oh It was tested.

585
00:38:29,915 --> 00:38:35,994
Rym: It's a bad idea, but you don't say facial recognition It's one of those technologies.

586
00:38:36,275 --> 00:38:37,860
Rym: that one is unstoppable.

587
00:38:38,060 --> 00:38:38,421
Rym: We did.

588
00:38:38,642 --> 00:38:43,630
Rym: there is no way to get rid of this technology So you need cannot go back in the bottle.

589
00:38:43,670 --> 00:38:47,670
Scott: We know how to do it therefore and all you need to do it is a camera and a computer.

590
00:38:48,013 --> 00:38:49,506
Scott: You can buy those things off the shelf.

591
00:38:49,688 --> 00:38:51,689
Scott: Yep There is no putting the genie back in the bottle.

592
00:38:51,910 --> 00:38:53,515
Scott: It can be done and it will be done.

593
00:38:53,555 --> 00:39:01,627
Rym: if the world banned facial recognition technology the source code exists and just like YouTube DL people would use it on their own hardware and it would still happen.

594
00:39:02,069 --> 00:39:05,901
Scott: and Unlike, you know, if the world banned nuclear weapons, well, you could.

595
00:39:06,102 --> 00:39:10,630
Scott: there's only so much plutonium, you know, it can be regulated It can be detected with your counters.

596
00:39:10,771 --> 00:39:12,598
Scott: It could be well also do something about.

597
00:39:12,618 --> 00:39:17,341
Rym: almost no one on earth knows how to make a thermonuclear device Like that is there's.

598
00:39:17,461 --> 00:39:18,629
Scott: there are very easy.

599
00:39:19,091 --> 00:39:26,230
Scott: It is relatively easy ways to enforce that law and detect violators to stop people from using facial recognition.

600
00:39:26,330 --> 00:39:41,047
Scott: It's almost impossible because it's already in so many things And you have to ban like digital cameras which are being like there's mostly factories in the on earth Various places just like spewing out thousands of digital cameras a second.

601
00:39:41,087 --> 00:39:44,075
Scott: Like it's unstoppable You can't do anything about it.

602
00:39:44,657 --> 00:39:49,070
Rym: I just think of that old Bloom County strip randomly where they're making that illegal drug.

603
00:39:49,210 --> 00:40:01,029
Rym: It's a legal drug like opus and the crew are making it and the government just declares it illegal and they see the news and they Just yell like stop pouring the stuff Oliver like stop cut it off.

604
00:40:01,934 --> 00:40:09,871
Scott: But like they're literally there must be like a factory somewhere where they're just like, you know Like little tiny cell phone cameras like just coming out and like a flood like there's tons of them anyway,

605
00:40:10,072 --> 00:40:16,556
Rym: but also facial recognition has a huge number of Extremely beneficial uses

606
00:40:17,218 --> 00:40:17,940
Scott: and a huge

607
00:40:18,000 --> 00:40:20,467
Rym: number of extremely dangerous uses,

608
00:40:21,169 --> 00:40:21,330
Scott: right?

609
00:40:22,411 --> 00:40:26,845
Scott: Yeah, it bears mentioning that facial recognition is really just is not actually the technology?

610
00:40:26,905 --> 00:40:29,492
Scott: the technology is simply image Recognition.

611
00:40:29,553 --> 00:40:33,905
Scott: right is where you use machine learning to train a computer.

612
00:40:34,246 --> 00:40:39,104
Scott: you give it lots of data So images and you tell it hey, this is a cat.

613
00:40:39,264 --> 00:40:39,967
Scott: This is a cat.

614
00:40:40,027 --> 00:40:40,710
Scott: This is a cat.

615
00:40:41,131 --> 00:40:41,893
Scott: Here's a new image.

616
00:40:41,913 --> 00:40:42,916
Scott: You've never seen before.

617
00:40:43,157 --> 00:40:43,919
Scott: Is there a cat?

618
00:40:43,999 --> 00:40:45,965
Scott: and if so, where is the cat?

619
00:40:46,326 --> 00:40:47,750
Scott: and this is a software.

620
00:40:47,911 --> 00:40:48,634
Scott: You can this.

621
00:40:48,734 --> 00:40:52,690
Scott: instructions online like tutorials how to write that exact software yourself.

622
00:40:53,293 --> 00:40:56,850
Scott: You can write it if you want to make one to the text something right?

623
00:40:57,310 --> 00:40:59,984
Scott: All you need is the database of whatever it is.

624
00:41:00,024 --> 00:41:02,275
Scott: You want to detect so Human face.

625
00:41:02,396 --> 00:41:05,189
Scott: is simply that you're like detect human face, right?

626
00:41:06,110 --> 00:41:11,307
Scott: And then you go to the next step and you say okay you found human face right in this picture.

627
00:41:11,368 --> 00:41:12,110
Scott: You've counted them.

628
00:41:13,511 --> 00:41:18,264
Scott: Now here's a database of human faces which have names and phone numbers attached.

629
00:41:18,645 --> 00:41:21,607
Scott: find the phone numbers of all these faces Right, that's the step two.

630
00:41:21,898 --> 00:41:26,726
Rym: Yep Now even worse think about I could find the phone numbers of all the cats, but they don't have phones.

631
00:41:26,826 --> 00:41:37,387
Rym: humans are uniquely suited like we can identify other people very quickly and Unconsciously just by seeing their face like some people can.

632
00:41:37,568 --> 00:41:44,970
Scott: well, yeah Have a Disability like face blindness, which is a great reason for a positive use of facial recognition.

633
00:41:45,111 --> 00:41:52,269
Rym: Imagine Penn Jillette could wear a Google Glass and whenever someone walked up to him It showed them if he knows this person and what their name was.

634
00:41:52,952 --> 00:41:59,190
Scott: Right a face blind person with ARG that identified faces of that the person already knew and told them their names.

635
00:41:59,591 --> 00:42:03,624
Scott: Like that would even be useful for people who weren't face blind if used appropriately.

636
00:42:03,644 --> 00:42:05,430
Scott: Yeah, I don't remember any remember?

637
00:42:06,272 --> 00:42:08,550
Rym: Great that would be if people's names just appeared over there.

638
00:42:08,992 --> 00:42:11,244
Rym: I was in a panel at a PAX taking questions, right?

639
00:42:11,545 --> 00:42:21,184
Rym: or someone comes up to me And I they act like they know me and I have no idea who they are right, it's like if people who already did know me and had seen my face and knew my name.

640
00:42:21,245 --> 00:42:26,400
Scott: if only they could see my Face and instantly recall my name with a memory aid.

641
00:42:26,700 --> 00:42:29,769
Scott: Maybe they're maybe they aren't face blind, but their memory is just normal.

642
00:42:29,869 --> 00:42:37,843
Scott: like You didn't say bad you just said normal Yeah, or you know not not perfect as no one's is right or hardly anyone's is.

643
00:42:38,244 --> 00:42:41,475
Scott: that would be a great and good use of Technology, right?

644
00:42:41,495 --> 00:42:42,239
Scott: Yeah, people would know.

645
00:42:42,682 --> 00:42:45,495
Scott: it would help people connect with each other What Facebook says they want to do.

646
00:42:45,595 --> 00:43:06,170
Rym: but it also makes this technology uniquely suited to identifying individual humans because the human brain like we are so we sort of evolved to where Specific cues in our faces can be rapidly parsed by our brains to remember who someone is meaning It doesn't take that much facial data for a computer to do the same thing.

647
00:43:06,210 --> 00:43:10,114
Rym: You only need a little bit of data from someone's face Right.

648
00:43:10,174 --> 00:43:12,002
Scott: a face is easy to find.

649
00:43:12,082 --> 00:43:17,543
Rym: It's got you know, mostly usually Humans are good at finding faces that don't even exist, right?

650
00:43:17,924 --> 00:43:20,876
Scott: It's a roughly circular Oval type shape.

651
00:43:21,097 --> 00:43:28,522
Scott: Yeah, there's a limited number of shapes and it has distinct features Right that are easy for this kind of computer software to find.

652
00:43:29,184 --> 00:43:34,296
Scott: and then it's also so Even though it's able to say it's easy to say that's a face.

653
00:43:34,797 --> 00:43:45,504
Scott: But then once you have the face cut out Faces are so unique and varied and detailed especially with high-resolution cameras It's easy to tell faces apart and say well, which face is it?

654
00:43:45,945 --> 00:43:47,150
Scott: It's like two different questions.

655
00:43:47,271 --> 00:43:49,306
Scott: It's actually two technologies at work, right one.

656
00:43:49,931 --> 00:43:51,129
Scott: So here's another one for step two.

657
00:43:51,290 --> 00:43:57,931
Rym: Here's a an example of how the exact same app even that use facial recognition could be used for great harm or great good Cuz.

658
00:43:57,951 --> 00:43:58,514
Rym: this is an app.

659
00:43:58,534 --> 00:43:59,177
Rym: I've always wanted.

660
00:43:59,217 --> 00:44:04,217
Rym: I even wrote like a document and RIT Describing this app is one of my classes.

661
00:44:04,257 --> 00:44:16,149
Rym: So I remember like I did a lot of research on facial recognition back in 2003 for my tech transfer class and The app I put together was basically I called it that guy.

662
00:44:17,072 --> 00:44:17,995
Rym: But what the app was?

663
00:44:18,296 --> 00:44:28,930
Rym: so you and your group of friends like our group of friends or like the GeekNights listeners as a whole We all like friend each other in this app and say one of us of our group of friends

664
00:44:29,331 --> 00:44:29,752
Scott: encounter

665
00:44:29,792 --> 00:44:51,643
Rym: someone who is an abuser or a piece of shit like someone who is an annoying that guy at conventions or someone who is like just being misogynist and racist and terrible at conventions if I flag that person to say That person like like that person was racist to me at this con and that at another con Scott Meet someone and his Google s just pops up and says hey Scott.

666
00:44:51,664 --> 00:44:53,550
Rym: So, you know Rym said this guy was a racist.

667
00:44:54,353 --> 00:44:54,514
Scott: Right.

668
00:44:54,554 --> 00:44:58,270
Scott: Now the only reason this is working is because me and Rym already agreed.

669
00:44:58,532 --> 00:45:04,902
Scott: You know the fact that I friended Rym on this service Yeah already means I trust his opinion and I'm only seeing the opinions of people.

670
00:45:04,962 --> 00:45:07,610
Scott: I trust I'm not just seeing data from randos exactly.

671
00:45:08,592 --> 00:45:12,068
Rym: So even in that context evil use exact same app.

672
00:45:12,089 --> 00:45:32,722
Rym: an Evil person who would say a stalker or a sexual abuser flags the faces of people who are easy marks or who have been abused successfully so that Friends in their shitty pickup artist Network could get a notification of hey this person you're talking to in a bar This is a person that this other pickup artist already fucked with.

673
00:45:33,023 --> 00:45:34,909
Rym: and here's the cheat sheet on how to pick them up.

674
00:45:35,631 --> 00:45:36,735
Rym: That's far right.

675
00:45:37,296 --> 00:45:45,730
Scott: same or exact same at or a way to detect like, you know People who are like, you know good at detecting them, right?

676
00:45:45,890 --> 00:45:50,230
Scott: So it's like, you know, maybe you're a criminal and you got all the cops faces, right?

677
00:45:50,550 --> 00:45:58,996
Scott: Maybe you're a protester and you got all the cops or maybe you're a cop and you got all the protesters faces or The criminals faces.

678
00:45:59,137 --> 00:46:00,846
Scott: Yeah, and this is be good.

679
00:46:00,906 --> 00:46:01,590
Scott: It could be bad.

680
00:46:02,112 --> 00:46:05,890
Rym: This is why there's so many serial killer on the loose.

681
00:46:05,950 --> 00:46:09,310
Scott: We have a video of the serial killer and now we're gonna use facial.

682
00:46:09,411 --> 00:46:12,630
Scott: It's an actual serial killer actual crime not bullshit, right?

683
00:46:12,970 --> 00:46:25,810
Scott: and now we're gonna use the facial recognition technology on all the security cameras and an alarm will go off if this if the serial killer is spotted anywhere in range of a camera and then we can go get Them to stop them from serial killing again, right?

684
00:46:25,990 --> 00:46:37,790
Rym: Oh, so I was actually looking something up because I remember seeing something about how the BCEC we're PAX East is every year Had that system Remember when they put in that system that could figure out the number of unique people in the building based on like low-key facial recognition.

685
00:46:38,532 --> 00:46:47,288
Rym: the city of Boston has actually recently banned the use of facial recognition technology and I wonder what that will mean for the fire code counts at the BCEC.

686
00:46:48,332 --> 00:46:50,650
Scott: Yeah, I wonder I don't know about that system specifically.

687
00:46:50,710 --> 00:47:01,020
Scott: I know I heard rumors that it could count people but I don't know if it could like look up people but in China They absolutely have ones that can identify Individuals in a crowd basically cheat sheet.

688
00:47:01,060 --> 00:47:01,723
Scott: Where's Waldo?

689
00:47:01,783 --> 00:47:03,250
Scott: Yeah, that's literally what it is.

690
00:47:03,370 --> 00:47:04,293
Scott: No, they can take.

691
00:47:04,494 --> 00:47:05,878
Rym: how good could that technology be?

692
00:47:05,939 --> 00:47:07,985
Rym: a kid get ridiculously good.

693
00:47:08,006 --> 00:47:09,330
Rym: Yeah, I could get lost.

694
00:47:09,430 --> 00:47:12,359
Rym: I know I'm saying how good in terms of boons to society.

695
00:47:12,660 --> 00:47:26,456
Rym: a kid gets lost in a city or a giant convention center and Cameras are media like the kid is here highlight him give him give coordinates and follow him until someone can go find the kid and save them or The bank is robbed.

696
00:47:26,657 --> 00:47:27,881
Scott: we arrested this person.

697
00:47:27,901 --> 00:47:30,730
Scott: Oh, but then we checked the camera footage and we exonerated them.

698
00:47:30,810 --> 00:47:33,588
Scott: They were actually at this other location at the time of the bank robbery.

699
00:47:33,608 --> 00:47:49,350
Rym: Yep The problem the main problem is that generally when a technology is powerful like this The people who have more real-world power can leverage this technology more effectively Against people who wield less real-world power.

700
00:47:49,872 --> 00:47:53,690
Rym: What that means is that governments can use it more effectively than private citizens.

701
00:47:53,972 --> 00:47:57,030
Rym: Police can use it more effectively than private citizens.

702
00:47:58,516 --> 00:48:04,610
Rym: Generally Disadvantaged communities can use it less effectively than more privileged communities, right?

703
00:48:04,931 --> 00:48:07,310
Rym: So we'll exacerbate existing divides in society.

704
00:48:08,292 --> 00:48:10,159
Scott: We do have access to this technology.

705
00:48:10,219 --> 00:48:12,990
Scott: You can get it and just use it yourself for your own purposes.

706
00:48:13,130 --> 00:48:15,179
Scott: the problem is your data.

707
00:48:15,420 --> 00:48:20,760
Scott: will that your database of faces and Information about those faces will be severely limited?

708
00:48:21,101 --> 00:48:23,570
Scott: and in order to build up that database, right?

709
00:48:23,916 --> 00:48:29,470
Scott: It will require You know, you're not going to be able to build as good of one as the government who can put cameras all over the city.

710
00:48:29,531 --> 00:48:32,458
Scott: Yeah right and use use tax money to buy giant comp.

711
00:48:32,538 --> 00:48:38,618
Rym: or you could even see hackers like a lot of facial recognition software that is Made by like smaller companies or private individuals.

712
00:48:38,940 --> 00:48:42,352
Rym: They all train it using the same like generic data sets You can buy.

713
00:48:42,753 --> 00:48:51,910
Rym: meaning if you understand the biases in that data set you could possibly exploit Someone's implementation of facial recognition to paint a crime on someone else.

714
00:48:52,531 --> 00:48:54,035
Scott: That's actually a huge problem right?

715
00:48:54,096 --> 00:49:04,980
Scott: is that even people who do have you know, lots of data right advanced systems Those systems are often racist like you have a huge database But the database is all white people.

716
00:49:05,583 --> 00:49:06,990
Scott: or you know, let's say China.

717
00:49:07,131 --> 00:49:10,030
Scott: The Chinese database is almost entirely Chinese people, right?

718
00:49:10,270 --> 00:49:13,710
Scott: You know, so if I go over to China that system might you know?

719
00:49:13,750 --> 00:49:17,110
Scott: I imagine it would just be like unknown not Chinese person, right?

720
00:49:17,671 --> 00:49:22,729
Scott: or maybe they would take my photos when I Come to China and then they would put me in the database and that way they could find me.

721
00:49:24,071 --> 00:49:28,286
Scott: But it might have a hard time because it's heavily trained on Chinese people, right?

722
00:49:28,426 --> 00:49:29,510
Scott: So different facial structure.

723
00:49:29,671 --> 00:49:36,172
Rym: So some of the things that second do can day are things like from a data set find one person or find like.

724
00:49:36,193 --> 00:49:47,864
Rym: the people are most likely to be one particular person or like they're especially powerful when you focus them on a very Specific community like that's right now where the tech is the most powerful.

725
00:49:48,145 --> 00:49:51,500
Rym: the committee could be just you like Your face unlocks your phone.

726
00:49:51,561 --> 00:49:53,189
Rym: That's a community of one person.

727
00:49:55,171 --> 00:49:58,527
Rym: Or you and your like small group of friends like you use it as a like.

728
00:49:58,547 --> 00:49:58,808
Rym: I've already.

729
00:49:58,828 --> 00:50:06,090
Rym: you can buy Door locks that are electronic and some of them have the ability to like unlock your house based on just looking at your face.

730
00:50:06,539 --> 00:50:06,969
Rym: That's cool.

731
00:50:08,072 --> 00:50:10,623
Scott: One really another if you're talking about small uses, right?

732
00:50:10,684 --> 00:50:15,484
Scott: So your camera it Using the first part of the technology just find human faces.

733
00:50:15,504 --> 00:50:16,890
Scott: I don't care who they are, right?

734
00:50:16,971 --> 00:50:26,270
Scott: So you take a camera it finds faces and therefore Autofocus is really well because most of the time when you take a photo and the face in it You want to focus on the face because who wants photo of the tree, right?

735
00:50:26,390 --> 00:50:30,378
Scott: No, you take if you're taking a photo of the tree It wouldn't be a person in the photo right looking at the camera.

736
00:50:30,398 --> 00:50:32,925
Scott: Yeah, and then step two, right?

737
00:50:33,006 --> 00:50:39,644
Scott: This is also a really, you know completely Mundane but useful use of the technology.

738
00:50:40,045 --> 00:50:40,909
Scott: whose face is it?

739
00:50:41,710 --> 00:50:48,199
Scott: Automatically organize my photo collection based on who's in the photo now Forever my fucking old gx-1.

740
00:50:48,279 --> 00:50:52,879
Rym: I programmed in the names of a bunch of our friends and It'll tag the photos.

741
00:50:52,919 --> 00:50:54,309
Rym: I take with that thing with their names.

742
00:50:54,470 --> 00:50:57,881
Scott: Yeah, Lightroom Lightroom does it pretty much every photo app these days.

743
00:50:57,922 --> 00:50:58,503
Scott: does that right?

744
00:50:58,523 --> 00:50:59,206
Scott: It's like basic.

745
00:50:59,286 --> 00:51:00,530
Scott: It's like a standard feature.

746
00:51:00,611 --> 00:51:02,406
Scott: It's not even an advanced new feature.

747
00:51:02,467 --> 00:51:07,065
Scott: It's like Expected that you have this where it's like, okay find me photos.

748
00:51:07,125 --> 00:51:08,190
Scott: I've taken of Scott.

749
00:51:08,411 --> 00:51:10,908
Scott: Oh, here's all the photos in my library with my face in them.

750
00:51:11,069 --> 00:51:12,013
Scott: Yep I didn't have to.

751
00:51:12,234 --> 00:51:17,537
Scott: I didn't have to do any, you know, like tagging by hand, you know Like I used to have to do in the old days.

752
00:51:17,597 --> 00:51:20,410
Rym: Yeah, I don't even like I. increasingly I take a lot of photos.

753
00:51:20,430 --> 00:51:21,308
Rym: They generate a lot of video.

754
00:51:21,795 --> 00:51:29,790
Rym: I've increasingly stopped Bothering to fully and like add the metadata necessarily to find specific things in the future because it's not worth the effort.

755
00:51:30,131 --> 00:51:34,750
Rym: I'm sort of waiting and relying on technology like this to do that for me in the future.

756
00:51:35,651 --> 00:51:39,530
Scott: Yeah, I really wish people would apply because there's no reason technologically speaking.

757
00:51:39,590 --> 00:51:46,550
Scott: This couldn't be applied to audio, you know, you should be able to say that wave that mp3 is a GeekNights episode, right?

758
00:51:46,891 --> 00:51:50,073
Scott: Yep, without having to put id3 tags on it It should just know it.

759
00:51:50,977 --> 00:51:52,724
Scott: might I know which episode or the topic?

760
00:51:53,266 --> 00:52:00,069
Rym: but it should be able to Commute and then Okay, so that doesn't narrow it down at all.

761
00:52:00,971 --> 00:52:11,790
Scott: No, it doesn't right, but you should be able to have one that's like oh, here's a song It's a just automatically tag the genre and possibly even the artist right if it doesn't and not base.

762
00:52:11,850 --> 00:52:13,662
Scott: You know the way most music things work is.

763
00:52:13,682 --> 00:52:14,870
Scott: they're looking at like, you know.

764
00:52:14,890 --> 00:52:17,397
Scott: They just have a database of the exact songs right like.

765
00:52:17,758 --> 00:52:22,030
Scott: oh, here's the M is exactly, you know, the song, you know a Beatles song.

766
00:52:22,372 --> 00:52:23,841
Scott: Oh, this is that exact song.

767
00:52:23,982 --> 00:52:29,810
Scott: It's it's my guitar gently weeps I know this song right, but what if it just didn't have a database of songs?

768
00:52:29,931 --> 00:52:37,481
Scott: it just had a database of you know singers and Musical styles and was saying oh that's a rock song and who do we hear?

769
00:52:37,541 --> 00:52:41,654
Scott: singing sounds like the Beatles and automatically tagged the music Library that way.

770
00:52:41,754 --> 00:52:42,437
Scott: Yep.

771
00:52:42,477 --> 00:52:45,290
Scott: There's no reason that couldn't exist right now if the database is large enough.

772
00:52:45,310 --> 00:52:51,242
Rym: Yep No actually getting to the database because one of the listeners Sam is actually posting a lot of good info in the stream right now Because he works in this space.

773
00:52:52,051 --> 00:52:55,549
Scott: But the data says if you're doing evil shit quit the job.

774
00:52:56,554 --> 00:53:00,170
Rym: And he seems like he's not doing evil shit because he's talking a lot about ethical concerns.

775
00:53:00,938 --> 00:53:01,545
Scott: Good and leak.

776
00:53:01,585 --> 00:53:04,758
Rym: that shit You know But evil think it's of what you just said.

777
00:53:04,879 --> 00:53:11,169
Rym: a lot of the more advanced uses of facial recognition Require machine learning of some kind meaning training data sets.

778
00:53:12,432 --> 00:53:19,948
Rym: The data sets encode the bias of society at the time The data set was collected and the biases of the people doing the collecting.

779
00:53:21,711 --> 00:53:33,810
Rym: We've told we've talked about that a lot on GeekNights and it doubly applies here like The facial recognition software built into like my smartphone just fucking doesn't work as well on non-white faces.

780
00:53:35,351 --> 00:53:37,519
Rym: No, of course not like straight up because that's what.

781
00:53:37,579 --> 00:53:38,382
Rym: what do they train it on?

782
00:53:38,623 --> 00:53:45,650
Scott: they trained it on data sets that are mostly white Yeah, or they you know the people working in the office where they made the software, right?

783
00:53:45,750 --> 00:53:46,132
Scott: I think that's.

784
00:53:46,212 --> 00:53:47,617
Scott: that's an old story that they liked.

785
00:53:47,778 --> 00:53:50,810
Scott: it's true story, but they tell it a lot where it's not even facial recognition.

786
00:53:50,914 --> 00:53:57,429
Scott: it was like It was like a paper towel dispenser or soap dispenser where you put your hand in front of it And then the soap just comes out without you having to touch it.

787
00:53:57,571 --> 00:54:08,770
Scott: Yeah And all the people who worked in the in the engineering team that designed the hand Detector were white and then black people put their hand under it and the soap didn't come out and the paper towel didn't move.

788
00:54:09,011 --> 00:54:11,021
Scott: Yeah, right and it's like oops.

789
00:54:11,142 --> 00:54:23,389
Rym: Maybe you should have had some for you know employees but the racist the weird danger of facial recognition is that a lot of the most powerful things we could do with it for the benefit of society are also the most dangerous.

790
00:54:23,409 --> 00:54:36,284
Rym: and If we make the data sets more equitable and we make the core technology better, which is going to happen We actually enable those larger broader uses more readily.

791
00:54:36,304 --> 00:54:39,698
Scott: It's like yeah, let's put you know We wanted this to be less racist.

792
00:54:39,838 --> 00:54:42,651
Scott: Okay, add more black faces to the database All right now.

793
00:54:42,772 --> 00:54:46,138
Scott: equally good on the races and all the black people.

794
00:54:46,238 --> 00:54:47,872
Scott: Yeah, it's like Aha.

795
00:54:48,973 --> 00:54:49,536
Scott: So great.

796
00:54:49,596 --> 00:54:52,088
Scott: now the cops have an even better idea of who to go after.

797
00:54:52,148 --> 00:55:09,150
Rym: Thanks I don't know how like society is going to deal with the like the next generation of facial tech like 10 15 20 years from now when the some of the Examples we've talked about become like not only widespread but easy to implement.

798
00:55:10,051 --> 00:55:16,972
Scott: Yeah, I think this technology is massively disruptive at least in countries where it's well and heavily Regulated.

799
00:55:17,313 --> 00:55:23,130
Scott: right the wrong large the corporations and government won't be using it for nefarious purposes.

800
00:55:23,293 --> 00:55:29,110
Rym: We live in America But I'm not even worried about the government using it so much as I'm worried about private companies using right reg.

801
00:55:29,271 --> 00:55:31,590
Scott: I don't regulate a well-regulated country, right?

802
00:55:31,790 --> 00:55:33,234
Scott: It'll be those Pete.

803
00:55:33,274 --> 00:55:44,808
Scott: the corporations and government won't be using it as much or in in ways that aren't you know Well controlled but there's nothing stopping the general public from using it and who knows what way.

804
00:55:44,828 --> 00:55:52,682
Scott: yeah As long as they you know, if they're technologically sophisticated So there will be you know, some sort of YouTube DL.

805
00:55:52,863 --> 00:56:00,480
Scott: ask right if you're in the know And you can set up your own fancy tech and you get this database from some Pirate Bay.

806
00:56:01,411 --> 00:56:07,437
Scott: then you're gonna have evil facial recognition technology and use it for evil and But also maybe use it for good.

807
00:56:07,899 --> 00:56:22,338
Rym: Yep, but I don't know like there is Really kick-ass to constrain the power of this technology except through government regulation and transparency Or Adversarial use of it.

808
00:56:22,379 --> 00:56:34,230
Rym: there have been a number of articles recently talking about cyberpunk and like you want to know what cyberpunk really is because basically The police and law enforcement America are already heavily using and abusing facial recognition.

809
00:56:34,350 --> 00:56:36,599
Rym: There's a whole like not to get into specifics.

810
00:56:36,920 --> 00:56:38,065
Rym: They're definitely using it.

811
00:56:38,105 --> 00:56:39,330
Rym: They're definitely abusing it.

812
00:56:39,591 --> 00:56:42,179
Rym: They're definitely targeting protesters with it.

813
00:56:42,841 --> 00:56:43,985
Scott: Yeah, you were at a protest.

814
00:56:44,025 --> 00:56:45,710
Scott: All right, we took photos of everyone at the protest.

815
00:56:45,791 --> 00:56:46,639
Scott: We didn't do anything.

816
00:56:46,760 --> 00:56:47,830
Scott: and then we walk around town.

817
00:56:47,930 --> 00:56:59,469
Scott: People are just going to get groceries and then with facial recognition technology says oh that person in the grocery checkout aisle They they were at the protest last night and they were anti cop and then they go out to put the groceries in the car And then we get them and they're alone.

818
00:56:59,932 --> 00:57:03,487
Scott: All right, then we know it's them because we photo their face at the.

819
00:57:03,728 --> 00:57:07,630
Scott: you know Yeah, we captured everyone's face at the protest with our facial recognition technology.

820
00:57:07,971 --> 00:57:12,130
Rym: Yeah, but then that opened up the door to let's say we have good regulations and controls.

821
00:57:12,191 --> 00:57:22,030
Rym: So, all right the Baltimore Convention Center has their facial recognition thing that that keeps track of The fire code count and they use it if a kid gets lost to reunite them with their parents.

822
00:57:22,112 --> 00:57:22,688
Rym: That's all good.

823
00:57:23,072 --> 00:57:30,109
Rym: And let's say they even they even like don't use it on ethically Directly like the company just uses it for its purpose and that's all fine.

824
00:57:31,330 --> 00:57:35,423
Rym: One low paid employee who has access to that data could abuse it.

825
00:57:35,443 --> 00:57:35,564
Rym: Mm-hmm.

826
00:57:36,326 --> 00:57:37,229
Scott: That's right or leak it.

827
00:57:37,550 --> 00:57:39,069
Rym: Yep, leak it or abuse it.

828
00:57:39,391 --> 00:57:45,590
Rym: How many times does some cop get caught looking up an ex-girlfriend in a database to then go commit some crime?

829
00:57:46,750 --> 00:57:47,814
Scott: Yeah, something like that.

830
00:57:48,015 --> 00:57:59,962
Scott: Yep, but or you know, maybe there's somebody who's like you know like Trying to hide and that person Who controls the thing is like the evil person is trying to find them.

831
00:58:00,122 --> 00:58:02,610
Scott: or maybe you know, someone just breaks in right?

832
00:58:02,730 --> 00:58:12,370
Scott: It's like, you know, you know that the person you're you're a stalker and the person you're stalking You know is that is that a convention in the building and you break into the office and you use it and you find where?

833
00:58:12,410 --> 00:58:13,588
Scott: They are in the building, right?

834
00:58:14,110 --> 00:58:26,849
Rym: Otherwise you your chance of finding them are so small or you just call someone who works there and socially engineer them similar to how people's Sims get stolen all the time with cell phones Mm-hmm because a lot of people in the chain are not paid enough to care.

835
00:58:27,611 --> 00:58:43,407
Scott: Alright, so the last thing we should talk about which is pretty obvious and well-spoken on the internet But is that yeah, this technology is at least for the foreseeable future Somewhat actually easy to foil because it's not so advanced to the point where you can see through things.

836
00:58:43,427 --> 00:58:43,728
Scott: Yep.

837
00:58:43,788 --> 00:58:44,370
Rym: Wear a mask.

838
00:58:45,253 --> 00:58:46,296
Scott: You can use masks.

839
00:58:46,557 --> 00:58:48,102
Scott: You can just shield your face.

840
00:58:48,303 --> 00:58:50,410
Scott: You can use various kinds of makeup.

841
00:58:50,530 --> 00:58:54,730
Rym: No, so I have read numerous studies showing that that dazzling makeup has zero effects.

842
00:58:54,850 --> 00:59:00,548
Scott: That is not that maybe that specific but there are other kinds you can use though that makeup basically doesn't do anything.

843
00:59:00,869 --> 00:59:02,889
Rym: only cover and concealment does.

844
00:59:03,652 --> 00:59:07,063
Scott: Obviously that helps the most right but there there you can do.

845
00:59:07,083 --> 00:59:10,870
Scott: I'm not like not talking about like makeup like You know somewhat tame makeup.

846
00:59:10,975 --> 00:59:18,275
Rym: No No the extreme makeup seemed to have no effect either because some of the more on your face like some extra eyeballs that are like Realistic and shit.

847
00:59:18,376 --> 00:59:21,830
Rym: I saw a lot of papers talking about how that stuff's all trivially foiled.

848
00:59:22,771 --> 00:59:26,269
Scott: Maybe we'll say but I'm pretty sure a mask is a mask.

849
00:59:27,106 --> 00:59:29,170
Scott: Yeah Cameras can't see through things.

850
00:59:29,230 --> 00:59:35,450
Scott: I guess you can infrared cameras, but that's still not gonna give you the resolution that you need to really identify a face.

851
00:59:35,555 --> 00:59:50,398
Rym: Yeah I was reading right with earlier today because they get written ready for the show an article about using basically LIDAR and other technology from cameras to generate pseudo 3d models of faces as well as 2d and how that Drastically improves the quality.

852
00:59:51,080 --> 00:59:52,948
Scott: the new Pro iPhones have that at least.

853
00:59:53,008 --> 01:00:02,668
Scott: yeah I'm very surprised the new Pro iPhones are adding that and using it for autofocus When like a Canon DSLR doesn't have it and maybe it should.

854
01:00:02,889 --> 01:00:03,712
Rym: no Maybe it should.

855
01:00:04,153 --> 01:00:20,729
Scott: I have seen people selling systems third-party systems that you can basically attach to any manual lens Gears and it will use LIDAR to slowly and shittily Focus a manual focus lens automatically not too bad.

856
01:00:21,312 --> 01:00:25,949
Scott: There might be someone who needs that like you really need autofocus no matter how shitty it is.

857
01:00:26,330 --> 01:00:30,950
Rym: Yeah, you as and you care about like some ancient specialized manual only lens.

858
01:00:31,434 --> 01:00:39,344
Scott: Yeah, you care about it focusing accurately But you don't care and you care about focusing automatically and you don't care about money And you don't care about how much equipment you carry.

859
01:00:39,364 --> 01:00:44,341
Scott: Yeah But you don't care how slowly it autofocus is either.

860
01:00:44,382 --> 01:00:45,124
Scott: you're okay with that.

861
01:00:45,565 --> 01:00:50,984
Scott: then this is a good choice for you But that could develop into something much better as time goes on.

862
01:00:51,104 --> 01:00:55,228
Rym: now one direction this could go is You know that whole cyberpunk thing I was talking about.

863
01:00:56,253 --> 01:01:05,801
Rym: One way to control this kind of technology if it gets out of control is for organized Activists to aggressively use it against the entities that are oppressing them.

864
01:01:06,282 --> 01:01:16,990
Rym: case in point the recent groups of protesters Who have been cataloging police violence from videos and then using facial recognition to identify and document the specific?

865
01:01:17,232 --> 01:01:18,729
Rym: officers involved in the abuse.

866
01:01:19,491 --> 01:01:19,612
Scott: Right.

867
01:01:19,632 --> 01:01:23,110
Scott: So you're hanging out and there's a bunch of cops coming and you're like, alright, those are all good cops.

868
01:01:23,190 --> 01:01:23,854
Scott: They have like this.

869
01:01:23,874 --> 01:01:27,050
Scott: many of us looks up their faces and looks up in the database and says here's how many?

870
01:01:27,310 --> 01:01:28,334
Scott: Violations of those cops have?

871
01:01:28,395 --> 01:01:30,484
Scott: how many times they've gotten in trouble for beating someone up?

872
01:01:30,885 --> 01:01:32,010
Scott: Oh zero zero zero zero.

873
01:01:32,091 --> 01:01:33,369
Scott: These are the four good cops in town.

874
01:01:33,452 --> 01:01:35,095
Scott: Okay You know the next one right.

875
01:01:35,356 --> 01:01:39,333
Scott: and then you come across another cop and it's like 20 and it's like whoop taking another street getting Away from that.

876
01:01:39,373 --> 01:01:41,689
Rym: Yeah, or even just as simple as all right.

877
01:01:42,330 --> 01:01:43,798
Rym: Some violence in the street.

878
01:01:44,119 --> 01:01:46,410
Rym: you hit the you have some video of it and you approve.

879
01:01:46,811 --> 01:01:49,439
Rym: Oh, that's the same cop who attacked this other person two days ago.

880
01:01:49,459 --> 01:01:51,305
Rym: attack this other person three days ago.

881
01:01:51,325 --> 01:01:54,516
Scott: or a bunch of undercover Cops ain't so undercover anymore.

882
01:01:54,677 --> 01:01:55,560
Scott: Yeah their face.

883
01:01:55,821 --> 01:01:58,230
Scott: It's like oh, there's a bunch of people coming to join our protest.

884
01:01:58,330 --> 01:01:58,732
Scott: Wait a minute.

885
01:01:59,213 --> 01:02:01,180
Scott: Those are cops and get them out of here.

886
01:02:01,341 --> 01:02:02,324
Rym: getting back to YouTube.

887
01:02:02,365 --> 01:02:03,830
Rym: GL kind of bringing this all together.

888
01:02:05,130 --> 01:02:14,570
Rym: that is the kind of tech activism that will be necessary if Governments don't step in and properly regulate these things in an equitable manner.

889
01:02:14,992 --> 01:02:16,018
Rym: That is the only way to.

890
01:02:16,440 --> 01:02:23,369
Rym: the only way to protect yourself from technology That's out of the genie bottle is to use the technology against the people who are using it against you.

891
01:02:24,333 --> 01:02:30,683
Scott: The last the last thing I think is one possible route that I hasn't I haven't seen explored much.

892
01:02:31,125 --> 01:02:33,795
Scott: is a Database poisoning right?

893
01:02:33,875 --> 01:02:39,150
Scott: It's like if they're collecting faces and failing and that's learning more faces, right?

894
01:02:40,631 --> 01:02:50,075
Scott: You know just somehow feed into the cameras lots of wrong or messed up or otherwise, you know faces Theoretically possible.

895
01:02:50,155 --> 01:02:59,850
Rym: I just don't know if it's practical but it is a thing I've thought about so I Have been doing a database poisoning experiment for most of my life since late middle school.

896
01:03:00,736 --> 01:03:07,104
Rym: uh-huh, I Put slightly wrong birthdays into everything I ever put my birthday into.

897
01:03:07,385 --> 01:03:27,467
Rym: that is not an official government record And what I found as time goes on Websites that I do not have accounts with or that I make a new account with like things that I interact with will sometimes Have my birthday somewhere or will send me a birthday thing Even though I didn't tell them my birthday and based on what birthday they

898
01:03:27,668 --> 01:03:28,070
Scott: say

899
01:03:28,613 --> 01:03:32,190
Rym: I can trace back to what database they got that data from

900
01:03:33,832 --> 01:03:34,034
Scott: Mm-hmm.

901
01:03:35,002 --> 01:03:35,970
Rym: I haven't done much with it.

902
01:03:35,990 --> 01:03:53,143
Rym: It's just something I noticed over the years, but I was thinking of it because a couple weeks ago I remembered that my birthday and steam is from the year 1978 because that's the year I picked for that particular platform and Sither to the 1978 birth year has never shown up anywhere else.

903
01:03:53,203 --> 01:03:54,046
Rym: It's only in Steve.

904
01:03:55,330 --> 01:03:58,529
Rym: I Was just thinking about that the other day, but it's relevant to the whole database poisoning thing.

905
01:03:59,152 --> 01:03:59,835
Scott: Yeah, all right.

906
01:03:59,915 --> 01:04:10,596
Scott: So facial recognition is gonna be with us for the rest of our lives Cannot make it go as long as you have a face and a computer and a camera and the Cameras are connected to the computers.

907
01:04:11,158 --> 01:04:14,950
Scott: You're gonna have to learn to live with it somehow, right?

908
01:04:15,290 --> 01:04:16,274
Scott: Yeah, I recommend it.

909
01:04:16,394 --> 01:04:20,390
Scott: a good start extreme government regulation, which is happening already.

910
01:04:20,450 --> 01:04:21,053
Scott: So that's a good sign.

911
01:04:21,254 --> 01:04:25,270
Rym: Yep, extreme government regulation coupled with cyberpunk activism.

912
01:04:31,265 --> 01:04:33,800
Rym: This has been GeekNights with Rym and Scott.

913
01:04:33,860 --> 01:04:38,599
Rym: Special thanks to DJ pretzel for the opening music cat leave for web design and Brando K for the logos.

914
01:04:38,921 --> 01:04:43,940
Scott: Be sure to visit our website at front row crew comm for show notes discussion news and more.

915
01:04:44,220 --> 01:04:51,240
Rym: Remember GeekNights is not one but four different shows sci-tech Mondays gaming Tuesdays anime comic Wednesdays and indiscriminate Thursdays.

916
01:04:51,980 --> 01:04:55,156
Scott: GeekNights is distributed under a Creative Commons attribution 3.0 license.

917
01:04:56,402 --> 01:04:59,480
Scott: GeekNights is recorded live with no studio and no audience.

918
01:04:59,682 --> 01:05:09,690
Rym: But unlike those other late shows It's actually recorded at night and the patreon patrons for this episode of GeekNights are Alan Joyce had McNichol Mardi Gras Nia Graham Finch.

919
01:05:09,751 --> 01:05:11,199
Rym: you hold the key to my heart.

920
01:05:11,722 --> 01:05:14,536
Rym: The license plate said fresh and it had dice in the mirror.

921
01:05:14,636 --> 01:05:18,449
Rym: Clinton Walton J Bats friend who's been from New Zealand Ryan parent Chris mint.

922
01:05:18,469 --> 01:05:20,857
Rym: give dread lily tenebrae just like a dude guy.

923
01:05:21,198 --> 01:05:27,019
Rym: Chris Reimer Finn chirping von Horrell and a bunch of people who do not want me to say their names.

924
01:05:28,141 --> 01:05:33,180
Rym: We'll see if Scott actually watches decadence yet, but uh, yeah you saw that bit in the stream.

925
01:05:33,662 --> 01:05:35,933
Rym: You should go check out that show and for right now.

926
01:05:35,953 --> 01:05:37,019
Rym: I leave you with.

927
01:05:43,263 --> 01:05:49,319
Scott: I'm such a loser My guts my guts.

