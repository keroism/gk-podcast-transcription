1
00:00:09,420 --> 00:00:11,186
Rym: It's Thursday, June 4th.

2
00:00:11,487 --> 00:00:11,868
Rym: I'm Rym.

3
00:00:11,888 --> 00:00:12,450
Rym: I'm Scott.

4
00:00:12,510 --> 00:00:13,655
Rym: And this is GeekNights.

5
00:00:13,695 --> 00:00:15,160
Rym: Tonight, levels of discourse.

6
00:00:25,950 --> 00:00:26,908
Scott: Let's do this.

7
00:00:31,242 --> 00:00:33,444
Scott: Today is Thursday, what's the day?

8
00:00:33,544 --> 00:00:34,747
Scott: January 4th.

9
00:00:34,787 --> 00:00:35,529
Scott: January 4th.

10
00:00:35,830 --> 00:00:36,912
Rym: As I just said a second ago.

11
00:00:36,933 --> 00:00:38,236
Scott: Wait, it's not January 4th.

12
00:00:38,296 --> 00:00:38,857
Rym: June 4th.

13
00:00:39,118 --> 00:00:39,720
Scott: June 4th.

14
00:00:40,563 --> 00:00:41,551
Rym: It's one of the J months.

15
00:00:41,592 --> 00:00:42,459
Scott: A few months off.

16
00:00:44,162 --> 00:00:53,600
Scott: And on June 6th and 7th 2009 is the Museum of Comic and Cartoon Art Arts Festival.

17
00:00:55,341 --> 00:00:56,405
Scott: In a new place.

18
00:00:56,545 --> 00:00:59,575
Scott: It's not in the Puck building where it has previously been.

19
00:00:59,595 --> 00:01:06,192
Rym: It is at the 69th Regiment Armory at 68 Lexington Avenue between 25th and 26th.

20
00:01:06,693 --> 00:01:07,977
Scott: Ooh, in an armory.

21
00:01:08,017 --> 00:01:09,140
Scott: I hope there's arms there.

22
00:01:09,320 --> 00:01:09,702
Rym: I don't know.

23
00:01:09,722 --> 00:01:14,040
Rym: As cool as arms might be, I'm really gonna miss that vintage elevator in the Puck building.

24
00:01:14,100 --> 00:01:15,780
Scott: There might be a vintage elevator in the armory.

25
00:01:15,921 --> 00:01:18,999
Scott: It might actually be a really big elevator meant to transport arms.

26
00:01:20,201 --> 00:01:21,245
Rym: They might not let me ride it.

27
00:01:21,325 --> 00:01:28,216
Scott: No, actually a lot of the armory places are like just buildings that used to be armories But now are not armories in any way shape or form.

28
00:01:28,277 --> 00:01:31,469
Scott: other than that They are big buildings that were previously armories.

29
00:01:31,590 --> 00:01:37,226
Rym: But suffice it to say if you listen to GeekNights You will probably enjoy the mocha.

30
00:01:37,286 --> 00:01:42,400
Scott: If you're a comic person, even if you just like reading the Sunday comics in the newspaper.

31
00:01:43,362 --> 00:01:45,899
Scott: The mocha is a place to go and it is cheap.

32
00:01:46,322 --> 00:01:48,696
Scott: It is like ten bucks to go there.

33
00:01:48,736 --> 00:01:49,320
Rym: It's ten bucks.

34
00:01:49,560 --> 00:01:52,233
Scott: And basically all you do is you don't even have to go there for that long.

35
00:01:52,273 --> 00:02:07,139
Scott: You just show up, you pay your ten bucks You walk around, you look at every single table, and you talk to everybody and you hang out a little bit And then you go home and with a wallet empty and a sack full of comics that were probably not available many other places in the world.

36
00:02:08,202 --> 00:02:11,900
Rym: You also pretty much get to meet the artists of any indie comic that you're reading.

37
00:02:12,001 --> 00:02:20,440
Scott: It's like you go to a comic book convention, like a typical one And all the comic creators, some of them might be in the artist alley, but most of them, the high level ones anyway.

38
00:02:20,781 --> 00:02:25,340
Scott: It's like you gotta pay for an autograph or maybe you gotta wait in line or they're on a panel.

39
00:02:25,781 --> 00:02:42,940
Scott: At the mocha, you'll have some indie guy who printed his comic at Kinko sitting at one table And the table immediately next to him is a super famous guy And every table, the person sitting there is pretty much 90% of the time the person who made the comic and not someone else.

40
00:02:43,301 --> 00:02:48,016
Scott: So the mocha is the awesome, and the win is ten bucks.

41
00:02:48,417 --> 00:02:49,160
Scott: It's in New York City.

42
00:02:50,303 --> 00:02:52,600
Scott: You can go Saturday or Sunday or both.

43
00:02:53,242 --> 00:02:55,309
Rym: Are there any after parties that we should go to?

44
00:02:55,389 --> 00:02:58,860
Rym: Because we missed everything last year, but the year before we went to that after party.

45
00:02:59,061 --> 00:03:01,111
Scott: Oh yeah, I don't know about any after parties this year.

46
00:03:01,131 --> 00:03:02,720
Scott: I did not investigate that situation.

47
00:03:02,800 --> 00:03:07,900
Rym: We should go after party though, because kind of at the last minute half the crew is coming out to go to this thing with us.

48
00:03:07,940 --> 00:03:12,780
Scott: Yeah, it being up in the 20 something-ish area, I think we should go to the conveyor belt sushi restaurant.

49
00:03:12,860 --> 00:03:16,412
Rym: I think we will get some Kaiten sushi and then everyone but Scott will do karaoke.

50
00:03:16,453 --> 00:03:18,500
Rym: that is also in the Kaiten sushi place.

51
00:03:18,983 --> 00:03:20,820
Scott: Is karaoke in the Kaiten sushi place?

52
00:03:21,060 --> 00:03:22,639
Scott: Yeah, upstairs I did not know this.

53
00:03:22,743 --> 00:03:25,168
Scott: Yeah But I will not do any karaoke.

54
00:03:25,188 --> 00:03:28,019
Scott: There's a lot more than ten dollars and it's stupid.

55
00:03:29,646 --> 00:03:31,113
Rym: I don't know how you cannot like karaoke.

56
00:03:31,173 --> 00:03:32,660
Rym: No human cannot like karaoke.

57
00:03:33,923 --> 00:03:35,259
Scott: Most humans don't like karaoke.

58
00:03:35,724 --> 00:03:37,240
Rym: I would argue that humans like karaoke.

59
00:03:37,300 --> 00:03:40,140
Scott: Karaoke isn't the same thing as disco only I like disco.

60
00:03:40,222 --> 00:03:45,160
Scott: I like disco too But I don't like karaoke and most people dislike disco and karaoke.

61
00:03:45,221 --> 00:03:47,180
Rym: See the thing is there are two kinds of karaoke.

62
00:03:47,301 --> 00:03:56,120
Rym: There's the lame American, you know It's a bar and there are drunk women at the front singing the same song over and over again And then there's rent a private room and hang out with friends singing.

63
00:03:56,882 --> 00:03:58,640
Scott: Both kinds suck for the same reason.

64
00:03:58,661 --> 00:03:59,238
Scott: Oh, you suck.

65
00:03:59,723 --> 00:04:01,876
Scott: Anyway, so news time.

66
00:04:02,521 --> 00:04:03,670
Rym: Yeah, I guess we don't have to do news.

67
00:04:03,710 --> 00:04:04,275
Rym: It's Thursday.

68
00:04:04,315 --> 00:04:05,285
Rym: It's the lounge Whatever.

69
00:04:05,326 --> 00:04:07,239
Scott: I got something I want to talk about Something you want to talk about.

70
00:04:07,501 --> 00:04:11,840
Scott: So there was an article in Newsweek, which is I guess which is real news, right?

71
00:04:12,040 --> 00:04:13,519
Scott: Serious news, not internet news.

72
00:04:13,823 --> 00:04:22,219
Scott: All right, one could say that The article was about Oprah and it called her out on all her snake oil bullshit hardcore Really?

73
00:04:22,381 --> 00:04:23,872
Scott: So I was like, really?

74
00:04:24,113 --> 00:04:24,979
Scott: In the real news?

75
00:04:25,362 --> 00:04:31,260
Scott: And it was a big long article that got everything right And it talked about how there are these two good doctors who are on Oprah.

76
00:04:31,401 --> 00:04:35,600
Scott: But there's all these other bullshit people and Oprah defends anyone who comes on her show.

77
00:04:35,700 --> 00:04:41,960
Scott: And it really like picked apart Oprah's psychology And like, you know, how she why she's all fucked up in the head.

78
00:04:42,041 --> 00:04:43,700
Rym: Oprah has already responded.

79
00:04:44,581 --> 00:04:50,340
Scott: Oh, she responded because there was a. there was something about like she wouldn't come.

80
00:04:50,542 --> 00:04:55,360
Scott: It said in the article that she wouldn't comment But there was like an official like two sentence statement or something.

81
00:04:55,360 --> 00:04:55,521
Scott: Yes,

82
00:04:55,561 --> 00:04:59,846
Rym: the statement is, quote, for 23 years, my show has presented thousands of That's

83
00:04:59,886 --> 00:05:00,921
Scott: the statement, yes Yes,

84
00:05:00,941 --> 00:05:10,780
Rym: that reflect the human experience, including doctor's medical advice and personal health stories that have prompted conversations between our audience and members of their health care providers, audience members and their health care providers.

85
00:05:11,581 --> 00:05:17,299
Rym: I trust the viewers and I know that they are smart and discerning enough to seek out medical opinions to determine what may be best for them.

86
00:05:17,564 --> 00:05:22,620
Scott: So she said nothing Right, and the thing is, right, she she says I trust the viewers, right?

87
00:05:22,660 --> 00:05:35,160
Scott: But at the same time, right, one time she had someone on promoting some like Randy, you know, shit, and someone then like wrote her a letter that was like, yeah, because you I'm not getting chemo, I'm going to do the Randy shit instead for my cancer.

88
00:05:35,501 --> 00:05:41,160
Scott: And then Oprah had to tell the person, you know, actually, you should probably go get your chemo and your radiation.

89
00:05:41,722 --> 00:05:47,218
Scott: So you trust the viewers, but then you there you realize that you told them wrong and you have to correct them.

90
00:05:47,641 --> 00:06:01,340
Rym: You see, the thing is, while people argue that Oprah has done a lot for communities in general, I still cannot forgive her for the fact that she constantly and blatantly just kowtows to idiocy and Randy bullshit.

91
00:06:01,461 --> 00:06:06,959
Scott: Well, basically anything that's on her show is something she's promoting and endorsing and defending, right?

92
00:06:07,100 --> 00:06:09,278
Rym: And she endorses and promotes way too much BS.

93
00:06:09,460 --> 00:06:30,760
Scott: She'll just endorse and promote whatever, you know, and she's so, you know, she's not I mean, what really are Oprah's credentials other than I have a lot of money and I've been on TV for a long time and I know how to speak in a way that, you know, is makes my, you know, she's just a really good salesperson to a very specific audience.

94
00:06:30,861 --> 00:06:34,220
Rym: That's that's our only came out of the woodwork already.

95
00:06:34,501 --> 00:06:39,940
Rym: All the news I can find all the opinion pieces are people lambasting this article.

96
00:06:40,302 --> 00:06:42,820
Rym: How dare they attack Oprah, a pillar of the community?

97
00:06:43,143 --> 00:06:48,180
Rym: They're just attacking her because they're racist Racist, okay Or sexist or sexist?

98
00:06:48,281 --> 00:06:50,880
Rym: It seems like it's equal parts race, equal parts sex Right.

99
00:06:51,403 --> 00:06:54,840
Scott: Read the Newsweek article and know that's spelled wrong too.

100
00:06:54,860 --> 00:06:55,260
Scott: That's great.

101
00:06:55,301 --> 00:06:56,340
Scott: Read the Newsweek article.

102
00:06:56,420 --> 00:07:01,098
Scott: The Newsweek article is 100% correct and anything that disagrees with it is wrong.

103
00:07:03,264 --> 00:07:07,224
Scott: And if you disagree with it, you're stupid Stupid.

104
00:07:08,443 --> 00:07:09,550
Scott: So Oprah's a bitch.

105
00:07:10,305 --> 00:07:11,098
Scott: She has too much money.

106
00:07:11,421 --> 00:07:37,720
Rym: So in some personal news, since we want to get right to the main bit, I think it's an interesting topic, but I'm sure many of you in the forums have seen all the rumblings and people who follow my tweet, tweet, Twitter, tweeter that I don't update that often because I hate Twitter, but I use it occasionally and I've been in the market for a house and I found a house and things are going well and it looks like very soon I'm going to be writing a very, very, very large check and becoming a member of the landowning gentry.

107
00:07:37,902 --> 00:07:39,780
Rym: Finally, I will be able to vote.

108
00:07:40,285 --> 00:07:41,680
Rym: I will be able to speak before the Senate.

109
00:07:41,700 --> 00:07:44,820
Rym: I will get all the privileges of the landowning upper class.

110
00:07:45,241 --> 00:07:50,866
Scott: That's, that, it's, it's 19, it's, actually no, it's 2009, not 1709.

111
00:07:50,866 --> 00:07:52,040
Scott: So that When did this happen?

112
00:07:52,381 --> 00:07:56,980
Rym: Yeah So you're saying that people who don't even own land have the right to vote?

113
00:07:57,320 --> 00:07:57,738
Scott: I've voted.

114
00:07:58,686 --> 00:07:59,640
Scott: You don't own any land.

115
00:07:59,660 --> 00:08:02,138
Rym: I know That, that's a travesty.

116
00:08:02,300 --> 00:08:08,460
Rym: Well How can, without the noblesse obligé, how can one possibly make complex decisions?

117
00:08:08,581 --> 00:08:15,180
Scott: Well, in fact, the people who own land get fucked more because you have to pay the land tax that we, uh, we voted in, us non-landowners.

118
00:08:15,361 --> 00:08:17,960
Rym: I thought taxes only applied to poor people and immigrants.

119
00:08:18,221 --> 00:08:21,760
Scott: No, the taxes, in fact, apply more to the people with the land.

120
00:08:21,941 --> 00:08:24,639
Rym: Well, luckily I have land so I can do something about it.

121
00:08:25,343 --> 00:08:28,160
Scott: Uh, you prepared that well in advance.

122
00:08:28,961 --> 00:08:32,940
Rym: Actually, no, I was going to make a different set of jokes But I can't tell you why, it's too stupid.

123
00:08:33,783 --> 00:08:35,198
Rym: You still won't tell me what that is.

124
00:08:35,421 --> 00:08:37,259
Scott: I wonder if anyone listening knows what that's for.

125
00:08:38,140 --> 00:08:41,258
Rym: It's, uh, it's weird because I feel like I know what that's from, but I don't.

126
00:08:41,359 --> 00:08:42,620
Scott: actually You don't, there's no way you know.

127
00:08:42,620 --> 00:08:44,459
Rym: No, I know I don't, it's just too stupid.

128
00:08:46,321 --> 00:08:54,780
Rym: But no, it's almost like I have an unreferenced pointer, I have this pointer and I see the pointer there and I say, all right, that pointer means I know what this is.

129
00:08:54,800 --> 00:08:57,900
Rym: So I go in my brain to the pointer and it's not pointing anything It's a null pointer.

130
00:08:58,001 --> 00:09:00,279
Rym: It's a null pointer, but I keep trying to reference it.

131
00:09:00,501 --> 00:09:02,839
Scott: I will, uh, I will de-nullify your pointer soon enough.

132
00:09:03,552 --> 00:09:05,760
Rym: Uh, okay You gonna wait for the crew to come out?

133
00:09:05,920 --> 00:09:08,520
Rym: Because we have to show them a story from North America first.

134
00:09:08,944 --> 00:09:11,560
Scott: No, no, it's not, it's not a video It's not a video?

135
00:09:11,780 --> 00:09:14,640
Scott: No All right It's not, it's not something that can be gotten quickly.

136
00:09:21,273 --> 00:09:22,809
Rym: But anyway, things of the day.

137
00:09:23,272 --> 00:09:26,930
Rym: So you ever wonder what happens to all those hats on the ice after a hat trick?

138
00:09:27,711 --> 00:09:29,970
Scott: You don't get them back, I know that much.

139
00:09:30,172 --> 00:09:34,090
Scott: I don't wonder what happens If you're throwing a hat, just, this is a note for people, right?

140
00:09:34,190 --> 00:09:47,047
Scott: I was at the New York Giants Super Bowl victory parade Uh, wow, already two years ago And, uh, a kid in front of me, like, took his friend's, you know, Super Bowl victory hat And threw it to get it autographed Asshole.

141
00:09:47,851 --> 00:09:52,370
Scott: The hat does not come back in, you know, it just doesn't happen.

142
00:09:52,571 --> 00:09:59,570
Scott: So if you're getting ready to throw a hat on the ice, not an expensive hat Do not throw your fancy hat.

143
00:09:59,610 --> 00:10:10,510
Rym: Well apparently the majority of hats that are thrown are either old, worn hats Like one that someone's been wearing forever Or they're just a throwaway hat that someone brought in a bag to throw in case there was a hat trick.

144
00:10:10,531 --> 00:10:17,069
Rym: Exactly I used to, whenever I went to a hockey game, I always carried with me I had this really dumb hat that I hated.

145
00:10:17,693 --> 00:10:20,650
Rym: It was just like, it had this, like, metal mesh on the brim.

146
00:10:21,210 --> 00:10:23,850
Scott: Yeah, so you had a hat in one bag and an octopus in the other?

147
00:10:24,531 --> 00:10:25,550
Rym: I didn't carry the octopus.

148
00:10:25,671 --> 00:10:29,050
Rym: Octopi are too smart for me to feel happy throwing one on the ice.

149
00:10:29,334 --> 00:10:30,128
Scott: They like it on the ice.

150
00:10:30,718 --> 00:10:31,450
Rym: Nah, they're already dead.

151
00:10:31,491 --> 00:10:32,489
Scott: They live in cold waters.

152
00:10:34,874 --> 00:10:41,950
Rym: But I've seen octopuses thrown on the ice because I know it's a hockey tradition But it's much more prevalent in the midwest than it is everywhere else.

153
00:10:42,030 --> 00:10:56,569
Rym: I mean, when I went to the Red Wing Stanley Cup playoffs back in the day, like '96, '97 They had a giant octopus thing called Stanley that would come down from the ceiling over the ice Called Stanley?

154
00:10:56,850 --> 00:10:58,728
Rym: It was called Stanley, Stanley the Octopus.

155
00:11:00,074 --> 00:11:01,189
Scott: That's not the thing to name it.

156
00:11:01,331 --> 00:11:13,710
Rym: Little known fact, all you non-hockey fans You throw an octopus on the ice because there used to be eight games in the series Now it's seven, but they still throw octopuses because there are no seven-legged animals.

157
00:11:13,851 --> 00:11:23,530
Rym: Yep But apparently, well, not apparently I found this article that explains what happens to the hats and it's kind of interesting.

158
00:11:23,997 --> 00:11:24,769
Scott: What happens to the hats?

159
00:11:25,191 --> 00:11:27,090
Rym: Oh, should I tell anyone or should I read the article?

160
00:11:27,170 --> 00:11:29,310
Scott: Well, is it really that complex that you can't tell it quickly?

161
00:11:29,531 --> 00:11:39,970
Rym: One, the players keep them, usually they take all the hats that aren't disgusting And they leave them in the dressing room of the player who scored the hat trick And he can do with them whatever he wants.

162
00:11:39,990 --> 00:11:40,426
Scott: That's nice.

163
00:11:41,372 --> 00:11:45,929
Scott: They throw away the scary hats The nasty hats the guy doesn't want to keep.

164
00:11:46,674 --> 00:11:48,950
Scott: I would want all the hats, every single one.

165
00:11:49,332 --> 00:11:50,240
Rym: Some teams actually.

166
00:11:50,280 --> 00:11:55,250
Rym: what they do is they take all the hats They send them to a company just to get them steam cleaned really quick And then they donate them to charity.

167
00:11:55,515 --> 00:11:56,026
Scott: That's good too.

168
00:11:56,431 --> 00:11:59,090
Scott: You know, that's what happens to the, because you know the Super Bowl, right?

169
00:11:59,170 --> 00:12:11,610
Scott: When the team wins, suddenly there's all these hats and t-shirts that say, you know New York Giants, Super Bowl 42 champions And all the hats and t-shirts that say New England Patriots, Super Bowl 42 champions.

170
00:12:12,012 --> 00:12:16,810
Scott: They send those to Africa and places where, you know, no one in America will ever see them.

171
00:12:17,231 --> 00:12:21,229
Rym: There was one time I did not, I had the hat, I did not throw it at the hat trick.

172
00:12:21,990 --> 00:12:22,094
Rym: Whoa?

173
00:12:22,530 --> 00:12:28,870
Rym: Because Sergei Fedorov scored two goals and he accidentally scored one against the Red Wings.

174
00:12:29,793 --> 00:12:31,590
Rym: So it was technically a hat trick.

175
00:12:31,610 --> 00:12:32,346
Scott: No, it's not.

176
00:12:34,573 --> 00:12:36,210
Rym: The commentators counted it as one of the least.

177
00:12:36,210 --> 00:12:37,187
Scott: It's not a hat trick.

178
00:12:37,896 --> 00:12:38,828
Rym: Well, they lost the game too.

179
00:12:39,072 --> 00:12:47,608
Rym: That's another kind of trick Of course, my brother, if you think I was into hockey, my brother, I remember he was Like the noise that came out of him was like a wookie dying.

180
00:12:51,571 --> 00:12:55,010
Rym: There's also a picture here of a case, apparently the Columbus Blue Jackets.

181
00:12:55,931 --> 00:13:11,750
Rym: Every time there's a hat trick, they put all the hats from the ice in this bin And they keep the bin on display And they've put every hat from every hat trick they've ever gotten since their first hat trick Which was in 2001 and there are not that many hats in there.

182
00:13:11,951 --> 00:13:14,430
Scott: Well, it's not, it's a relatively new team and they're not that good.

183
00:13:14,653 --> 00:13:16,987
Scott: Yeah, there aren't that many hats You know, they're not terrible, but they're not that good.

184
00:13:17,861 --> 00:13:18,748
Rym: Okay That's all I got.

185
00:13:19,192 --> 00:13:22,630
Scott: So I'm pretty sure this is not a duplicate thing of the day.

186
00:13:22,691 --> 00:13:24,390
Scott: If it is, shoot me, right?

187
00:13:25,234 --> 00:13:28,469
Scott: I checked the thing of the day feed and it was not in there.

188
00:13:29,113 --> 00:13:33,230
Scott: And also I think I posted it in a forum maybe Just because I couldn't wait to post it somewhere.

189
00:13:33,331 --> 00:13:35,188
Scott: But I'm pretty sure it was not a thing of the day.

190
00:13:35,793 --> 00:13:41,910
Scott: Basically what this is, is a game called Wayfarer And what it is, it's a roguelike game.

191
00:13:42,132 --> 00:13:50,470
Scott: If you've never played a roguelike game I think we've discussed them on the show previously It's pretty much a game just like NetHack or like Rogue, the original roguelike.

192
00:13:51,333 --> 00:13:52,790
Scott: It's basically a dungeon crawl.

193
00:13:52,971 --> 00:13:55,730
Scott: You walk around, you kill bad guys, you get treasure.

194
00:13:55,831 --> 00:14:00,450
Scott: You know, you explore the dungeon, you know You see more dungeon as you explore.

195
00:14:00,551 --> 00:14:10,050
Scott: The dungeon is randomly created You know, it's pretty much, you know, a straight up kind of RPG But not RPG in the good way, RPG in the dean.

196
00:14:11,074 --> 00:14:12,430
Scott: It's like hero quest, one player.

197
00:14:12,716 --> 00:14:14,228
Scott: That's what it is All right Right.

198
00:14:14,572 --> 00:14:21,390
Scott: So Wayfarer is a roguelike Because most of them are sort of difficult to play and or annoying.

199
00:14:22,111 --> 00:14:46,590
Scott: This is a web-based one that is Java powered, I think It's got some 3D action, but not really And it actually has a really good user interface And it makes it like a lot more pleasant to play A lot more accessible And actually sort of maybe a little bit fun And definitely a million times more fun than other roguelikes As far as I'm concerned Even though it's maybe less complex than other roguelikes.

200
00:14:46,630 --> 00:14:49,509
Scott: But I mean, it's still alpha and it's already made it that far.

201
00:14:49,932 --> 00:15:00,728
Scott: So I think there is actually a significant potential in this game And if you are bored and you got nothing better to do And you're on a computer with the web browser And you know, all the other games aren't really exciting.

202
00:15:00,769 --> 00:15:02,568
Scott: you Why not?

203
00:15:02,730 --> 00:15:04,789
Scott: It's free and it's an alpha, what the hell?

204
00:15:06,150 --> 00:15:07,149
Rym: So onto the topic.

205
00:15:07,312 --> 00:15:08,250
Rym: And we were inspired.

206
00:15:08,432 --> 00:15:12,190
Rym: There was an article linked on Slashshot The perils of pop philosophy.

207
00:15:13,115 --> 00:15:14,190
Rym: You should all read the article.

208
00:15:14,230 --> 00:15:17,761
Rym: We're not really going to talk about the article in depth But it's a fantastic article Pretty

209
00:15:17,782 --> 00:15:17,908
Scott: good

210
00:15:18,393 --> 00:15:37,575
Rym: And it got us to talking a lot about the topic And then from there to this kind of broader concern That it's one of those things where the more I think about it The more I realize just how much it controls Or at least influences the interactions I have every day With every information source or destination in my entire life Including

211
00:15:37,636 --> 00:15:38,044
Scott: this show.

212
00:15:38,105 --> 00:15:40,247
Scott: even Definitely This show is a victim, right?

213
00:15:40,831 --> 00:15:43,050
Scott: So here is the basic problem here, right?

214
00:15:43,250 --> 00:15:43,534
Scott: Is?

215
00:15:43,574 --> 00:15:51,470
Scott: the guy talks about The article references another article And the other article is discussing some philosophical topic, right?

216
00:15:52,152 --> 00:15:59,210
Scott: And the guy who's writing this article Says basically Yeah, that other article is a load of shit, right?

217
00:15:59,890 --> 00:16:04,290
Scott: But you wouldn't really know unless you were, you know, like a philosophy expert.

218
00:16:04,330 --> 00:16:13,830
Scott: And he says here is my counter argument to that other article And it's a whole bunch of big fancy philosophy words That nobody who doesn't have a philosophy degree will be able to understand.

219
00:16:13,931 --> 00:16:15,209
Scott: I didn't understand what he was saying at all.

220
00:16:15,512 --> 00:16:25,370
Rym: What he basically, the gist of what he points out Is that if someone, it's very easy to make a stupid claim Or a fallacious argument It is very easy to refute that argument.

221
00:16:25,715 --> 00:16:36,310
Rym: If you know about the topic It is almost impossible to refute that argument In a way that people who aren't familiar with the field Will see or understand.

222
00:16:36,350 --> 00:16:44,190
Scott: Yeah, I mean by using all his big philosophy words And all his philosophy knowledge He was able to easily and trivially refute this other argument.

223
00:16:44,290 --> 00:16:59,230
Scott: However, the only people who could understand and comprehend the refutation Were other philosophy experts And for him to make that refutation accessible to the mass populace He'd basically have to write an entire book Worth of normal non-philosophy talk, right?

224
00:16:59,730 --> 00:17:01,670
Rym: And it goes further than this when you really think about it.

225
00:17:01,670 --> 00:17:11,710
Rym: Because say someone makes a fallacious claim And even you're not trying to convince anyone else You don't have to explain the refutation to anyone else Just you're trying to argue with the person who made the fallacious claim.

226
00:17:12,851 --> 00:17:16,530
Rym: Alright, you have ten different ways to refute them.

227
00:17:16,957 --> 00:17:21,198
Rym: So you use one And they don't understand it Or you use two and they don't understand it Or you can't-.

228
00:17:21,930 --> 00:17:26,690
Rym: Basically it comes down to the fact that you can't engage them On the level where the claim is fallacious.

229
00:17:27,194 --> 00:17:28,686
Rym: If they're not able to engage you back.

230
00:17:29,253 --> 00:17:30,362
Rym: They're not able to reciprocate Right?

231
00:17:30,613 --> 00:17:37,250
Rym: So if I engage- If I make a claim at level one And someone else refutes it at level one Basically they're equal.

232
00:17:37,331 --> 00:17:40,350
Rym: There's no real way to determine which one is right.

233
00:17:40,370 --> 00:17:42,470
Scott: It happens with science a lot, right?

234
00:17:42,510 --> 00:17:51,590
Scott: You get like some person who comes around And they're not an expert in science They don't know anything about, you know They know the world is made of atoms and molecules And that's about it, right?

235
00:17:51,910 --> 00:17:57,549
Scott: So they come and say some bullshit about evolution or something And they're completely wrong.

236
00:17:58,215 --> 00:18:01,830
Scott: But you go to explain why they're wrong And you're a biologist.

237
00:18:02,192 --> 00:18:05,490
Scott: So the only people who understand what you're saying are biologists.

238
00:18:05,671 --> 00:18:13,168
Scott: And for you to get this non-biologist person to understand why they're wrong You basically have to give them a university biology education.

239
00:18:13,228 --> 00:18:13,509
Scott: first.

240
00:18:13,972 --> 00:18:27,290
Rym: It comes down to the fact that the refutation of some kinds of fallacies Is in a higher order than the fallacy itself And it's not- So it's one order to make the fallacy But it is impossible to refute the fallacy without making a higher order argument.

241
00:18:27,452 --> 00:18:31,850
Scott: And it's not just in arguing either It's just in general comprehension, right?

242
00:18:31,990 --> 00:18:41,489
Scott: I mean, you know, some guy writes a newspaper article that speaks very colloquially And is completely wrong because it, you know, summarizes and generalizes.

243
00:18:41,792 --> 00:18:46,670
Scott: But people understand it And it sort of makes sense on the level at which people are thinking.

244
00:18:46,791 --> 00:18:56,030
Scott: And these people have never thought about the topic on a higher level And don't have the education or expertise or whatever they need To understand the higher levels of the particular topic.

245
00:18:56,713 --> 00:19:00,030
Scott: And as it stands in that state, it makes perfect sense.

246
00:19:00,151 --> 00:19:01,589
Scott: And they go on believing this thing.

247
00:19:02,552 --> 00:19:11,248
Scott: And that's that, you know People think in their minds about things, you know People- some guy who's, say, I don't know, an engineer, right?

248
00:19:11,890 --> 00:19:23,430
Scott: Will think about, say, you know, medicine in some simple way Because he's not an engineer But he's thinking about medicine in the highest order that he can think about medicine And he'll come up with something.

249
00:19:24,132 --> 00:19:28,667
Scott: And thus he now, you know, believes something about medicine.

250
00:19:28,707 --> 00:19:35,470
Scott: that's probably wrong Because, you know, he doesn't have the knowledge in that higher order in that department.

251
00:19:36,631 --> 00:19:38,450
Rym: But what I really want to talk about?

252
00:19:38,511 --> 00:19:56,289
Rym: We could go on and on about this specific topic But there's not a lot to say But I think the more general interesting topic is the interactions between people on the internet Or in real life where one person wants to engage on one level Another person can't or won't engage on that level.

253
00:19:57,373 --> 00:20:04,930
Rym: Or the situation where you have a topic Where the only way you can have a meaningful conversation is to engage at a higher level.

254
00:20:05,211 --> 00:20:08,950
Scott: Right, because all of the low-level things are sort of already figured out.

255
00:20:09,050 --> 00:20:16,310
Scott: I mean, when you try to talk philosophy with your friends You might think you're all smart and stuff, but really It's all just shadows on a wall.

256
00:20:16,435 --> 00:20:23,510
Scott: Yeah, right The thing is, right, you know, real philosophers, you know People who really know this shit and write books.

257
00:20:23,913 --> 00:20:26,090
Scott: And, well, not everyone, some people write bullshit books.

258
00:20:26,191 --> 00:20:28,130
Scott: But, you know, real philosophers, right?

259
00:20:28,752 --> 00:20:31,166
Scott: Wait, wait, real Real We're getting some Scotsman in the house.

260
00:20:31,531 --> 00:20:33,669
Scott: I understand that's a Faujo Andrew Scotsman.

261
00:20:33,951 --> 00:20:40,568
Rym: But, oh, someone made a website of a graphic for every logical fallacy And the Andrew Scotsman was just an angry willy.

262
00:20:40,853 --> 00:20:41,228
Scott: That's good.

263
00:20:41,552 --> 00:20:48,830
Scott: But they, you know, they figured out everything you were saying And you're basically treading over well-tread ground.

264
00:20:48,991 --> 00:20:52,230
Scott: You're rebuilding already built wheels, you know.

265
00:20:52,712 --> 00:21:05,470
Scott: So, in order to sort of get into new areas of thought You really have to sort of learn all the, you know, things that have come before And crawl up to the, you know, to the higher level.

266
00:21:05,530 --> 00:21:10,910
Scott: Imagine if, say, we're all, all of humanity together is building a ladder, right?

267
00:21:10,990 --> 00:21:13,849
Scott: And the ladder is 10 steps tall and we need the 11th step.

268
00:21:14,252 --> 00:21:17,330
Scott: But only people on the 10th step can build the 11th step.

269
00:21:17,434 --> 00:21:17,809
Scott: You know what?

270
00:21:17,870 --> 00:21:23,269
Scott: You're down on the third step You don't know the fourth step exists and you think you're all smart Figuring out the fourth step.

271
00:21:23,411 --> 00:21:24,588
Rym: You know, you know what you just said?

272
00:21:25,030 --> 00:21:27,770
Rym: It's almost word for word from the fourth way.

273
00:21:28,119 --> 00:21:30,609
Scott: I know Stupid fourth way.

274
00:21:31,034 --> 00:21:40,750
Scott: Oh, so close, but still crazy Right, you know, and it's sort of like, hey, if you don't, you know, see all the steps that are already there You're just, you know, what are you doing?

275
00:21:40,810 --> 00:21:41,910
Rym: I don't think we need more analogies.

276
00:21:41,910 --> 00:21:43,429
Scott: I think it's I love analogies.

277
00:21:43,531 --> 00:21:44,570
Scott: I'm the analogy master.

278
00:21:44,771 --> 00:21:47,630
Rym: It's a real world thing where I have this problem personally.

279
00:21:48,092 --> 00:21:51,790
Rym: My interest in the topic is that many times I'll be in.

280
00:21:52,413 --> 00:21:54,384
Rym: I guess I'm in low level mode.

281
00:21:54,404 --> 00:22:00,970
Rym: when I'm walking around in the street I don't expect anyone to a stranger to out of the blue while I'm like walking and eating my baguette.

282
00:22:01,393 --> 00:22:04,050
Rym: to engage me suddenly on a high level.

283
00:22:04,070 --> 00:22:08,330
Rym: There's usually kind of like, we all go through this When you talk to someone, you don't know where there's the probe.

284
00:22:08,391 --> 00:22:09,170
Rym: You probe each other.

285
00:22:09,170 --> 00:22:16,790
Rym: It's like a protocol, a handshake Where you both feel out what the level of discourse is going to be for the remainder of this new conversation This new encounter.

286
00:22:17,113 --> 00:22:18,990
Rym: You know, you make the comment about the weather.

287
00:22:19,615 --> 00:22:21,250
Rym: They say something back about the weather.

288
00:22:21,411 --> 00:22:22,910
Rym: You've established that baseline level.

289
00:22:23,534 --> 00:22:25,670
Rym: You mention, you make an offering about politics.

290
00:22:26,234 --> 00:22:29,330
Rym: You see if they make a high or low level statement And then you respond accordingly.

291
00:22:29,451 --> 00:22:31,850
Rym: And then the discourse is set and you have your discussion.

292
00:22:31,971 --> 00:22:35,810
Rym: But much like in Burning Wheel, the blossoms are falling setting.

293
00:22:37,878 --> 00:22:41,330
Rym: I was thinking about this a lot In that setting, it's based in like old Japan.

294
00:22:42,212 --> 00:22:52,044
Rym: So there are different levels of formality of the Japanese language And the rules in the game are that you test against another player to see what you as a group set the level of discourse.

295
00:22:52,285 --> 00:23:01,050
Rym: as for your discussion And depending on the level of discourse Some topics are or are not allowed to be broached without a serious breach of etiquette.

296
00:23:02,500 --> 00:23:04,030
Rym: And the same thing happens in real life.

297
00:23:04,111 --> 00:23:09,829
Rym: I mean, say I'm sitting on the train and guy next to me says something about politics Like blah, blah, Obama.

298
00:23:10,535 --> 00:23:13,870
Rym: Now I have a choice to engage them on their level Higher level, lower level.

299
00:23:13,971 --> 00:23:15,309
Rym: I don't know really what their level is at.

300
00:23:16,034 --> 00:23:46,390
Rym: But if they won't engage on the higher level Like if someone is just a Democrat or a Republican And the only argument they have for being a Democrat or a Republican is like the talking point of their pundit of choice on either side There is no possible way I can have a conversation that'll be meaningful with this person Unless I either force them to engage on a higher level Or I don't know, not talk to them and not have the... I guess it might be meaningful for them But how is it meaningful for me if they only have talking points?

301
00:23:46,754 --> 00:23:48,050
Rym: I've already heard every talking point.

302
00:23:48,333 --> 00:23:50,070
Rym: I already have a reputation for every talking point.

303
00:23:50,131 --> 00:23:51,348
Scott: They can't comprehend any of them.

304
00:23:51,713 --> 00:23:53,330
Rym: So what's the point of even discoursing?

305
00:23:53,490 --> 00:23:55,149
Rym: What's the point of even engaging at that point?

306
00:23:55,450 --> 00:24:00,170
Scott: Well, I mean, you know, to give you, you know In that example, I can't think of a reason to engage.

307
00:24:00,311 --> 00:24:04,490
Scott: But for example, on our show We will often discuss things related to game theory, right?

308
00:24:04,610 --> 00:24:20,370
Scott: But we will not engage the game theory topics on the highest level You know, and the point is that even though the audience Some of the audience, I'm sure, would understand it But most of the audience, we assume, does not And we try to, you know, say things in a way that they will comprehend them.

309
00:24:20,430 --> 00:24:22,629
Rym: You know, we won't say "Oh, that's...".

310
00:24:22,891 --> 00:24:30,370
Scott: You know, because I mean, we could end the show in like a second Like we're discussing a game, we'll be like "Yeah, that's just, you know, zero sum perfect information game".

311
00:24:30,571 --> 00:24:31,129
Scott: "Oh, okay".

312
00:24:31,830 --> 00:24:33,650
Rym: Yeah, well, how many states does it have?

313
00:24:33,650 --> 00:24:34,669
Rym: 10 to the sixth?

314
00:24:35,070 --> 00:24:35,745
Scott: Yeah, all right.

315
00:24:36,591 --> 00:24:56,250
Scott: So, all right, but, you know, instead, you know When we're discussing on the show, sometimes we either A) We take the route of giving all the full We engage on the high level, but we break the words down And go on longer so that they get the full idea Or we simplify to get just given the gist, right?

316
00:24:56,410 --> 00:25:00,290
Scott: And hopefully we can educate them over time and bring them up to the higher level.

317
00:25:00,614 --> 00:25:02,609
Rym: How noble of you I know, right?

318
00:25:03,210 --> 00:25:06,370
Scott: But, you know, there are many, I'm sure, you know That's on the topics that we're familiar with.

319
00:25:06,611 --> 00:25:09,630
Scott: There are many topics for which we cannot engage on the high level.

320
00:25:09,670 --> 00:25:11,990
Rym: For example, we'll say something about, we talk about viruses.

321
00:25:11,990 --> 00:25:14,289
Scott: How many times do we say something stupid on the show?

322
00:25:14,690 --> 00:25:17,890
Scott: Every day, we've probably already said 20 stupid things on the show.

323
00:25:18,051 --> 00:25:19,810
Rym: How many times do we say something about viruses?

324
00:25:20,370 --> 00:25:32,329
Rym: And then, you know, the next morning I get an email from Scott Johnson and Pete and Lisa Yeah, right Viruses do not work that way You know, or we say stupid things about like economics or who knows what else.

325
00:25:32,732 --> 00:25:44,970
Rym: I mean, that other article really points it out is that The long form debate almost never happens in modern society Because no one has the patience and no one's going to pay attention.

326
00:25:45,351 --> 00:25:53,730
Rym: And generally the people who are up for a long time debate or a long form debate Are the ones who are already trying to engage at a higher level in the first place.

327
00:25:53,870 --> 00:25:59,049
Scott: Exactly, I mean, you know, and this goes back to that Neil Postman book that you disagreed with, right?

328
00:25:59,430 --> 00:26:02,510
Scott: Where he was talking about how, you know, the medium is the message.

329
00:26:02,590 --> 00:26:08,890
Scott: He talked about how Lincoln Douglas would, you know, debate for reals And people would sit there for hours and they would debate at a very high level.

330
00:26:09,392 --> 00:26:13,330
Scott: And if you look at the old newspapers, you know, it was much higher level.

331
00:26:13,390 --> 00:26:17,389
Rym: I guess I disagree with a lot of his conclusions Because a lot of what he predicted did not come to pass.

332
00:26:18,892 --> 00:26:31,230
Scott: I don't know, that book was from the 80s, I think Yeah Right, so, I mean, you know, the major point of the book, though, was that, you know, The medium in which you are communicating, right, you know, modifies the message.

333
00:26:31,431 --> 00:26:39,170
Scott: On TV, you can't have these long, boring things Because when you do, you get, like, that boring PBS news show that nobody watches.

334
00:26:39,170 --> 00:26:40,589
Rym: But, Scott, I love things like that.

335
00:26:40,771 --> 00:26:42,610
Scott: You do, but most people don't, right?

336
00:26:42,651 --> 00:26:43,390
Rym: Yes, but I don't think it's.

337
00:26:43,390 --> 00:26:49,069
Scott: And he talks about how, you know, this medium is, you know, The mediums of the olden days are better for the long-form, higher level.

338
00:26:49,512 --> 00:26:52,110
Scott: And you look at the internets, right, the internet is good for Twitter.

339
00:26:52,634 --> 00:26:54,730
Scott: They just shorten everything, the shorter the better.

340
00:26:54,790 --> 00:26:57,310
Rym: Scott, I disagree that the medium forces the message.

341
00:26:57,330 --> 00:27:00,410
Scott: It doesn't force, but it has optimized a particular message.

342
00:27:00,510 --> 00:27:06,549
Scott: And even though you could put any sort of message in any sort of medium, It won't, no one will go for it.

343
00:27:06,650 --> 00:27:09,870
Rym: No, see, Scott, I also disagree that it's even optimized for a particular message.

344
00:27:10,071 --> 00:27:17,665
Rym: All it is, is that society itself, people generally are lazy And would rather not engage on a high level.

345
00:27:17,685 --> 00:27:26,808
Rym: in most cases And even back then, I would wager that not that many people in the US Understood what was going on in Lincoln vs.

346
00:27:26,828 --> 00:27:27,130
Rym: Douglas.

347
00:27:27,170 --> 00:27:32,910
Rym: I don't know, do you How many people were all for the Civil War and the South?

348
00:27:34,110 --> 00:27:35,009
Rym: They clearly couldn't win.

349
00:27:35,595 --> 00:27:37,389
Rym: Any high level debate would have pointed that out.

350
00:27:37,450 --> 00:27:44,490
Scott: Well, that was just because in those days, right, they didn't have the, you know, The amount of information that we have today.

351
00:27:44,954 --> 00:27:46,650
Scott: Everyone knows everything about everything everywhere.

352
00:27:46,670 --> 00:27:53,810
Scott: I don't want to get into Neil Postman because I disagree with a great majority But it's the same thing that you're saying now, talking about the high level and the low level.

353
00:27:54,092 --> 00:27:56,149
Rym: But I don't think it has anything to do with the medium, it's just people.

354
00:27:57,297 --> 00:27:57,948
Scott: I don't know about that.

355
00:27:58,252 --> 00:28:03,350
Rym: People generally avoid the high level discourse Partly because high level discourse takes a long time.

356
00:28:03,531 --> 00:28:06,210
Scott: The high level discourse was commonplace in the olden days.

357
00:28:06,390 --> 00:28:06,870
Rym: Yeah, it was.

358
00:28:06,952 --> 00:28:07,687
Rym: I don't think it was.

359
00:28:07,830 --> 00:28:21,210
Rym: You look at the, you know, the "reading level" of, you know, as you go back in time Scott, I point out as you go back in time, you're looking at the reading level of a smaller And smaller subset of the literate population.

360
00:28:22,257 --> 00:28:22,809
Scott: Is this true?

361
00:28:23,210 --> 00:28:25,990
Rym: I mean, the further back you go, who is literate?

362
00:28:26,271 --> 00:28:31,529
Rym: The wealthy aristocrats and the philosophers and the people like that The people with schooling, learning and knowledge.

363
00:28:32,633 --> 00:28:35,070
Rym: You had a smaller, more literate set.

364
00:28:35,293 --> 00:28:36,070
Scott: So what are you saying?

365
00:28:36,190 --> 00:28:37,690
Scott: So you're saying that now, right?

366
00:28:38,411 --> 00:28:44,770
Scott: You're basically saying it's no different now That even though the people are literate, they're still not as smart as the, you know.

367
00:28:44,870 --> 00:28:54,110
Scott: So really, still, even though everyone can read the words technically Only the people who are actually educated and wealthy and whatnot are really literate.

368
00:28:54,233 --> 00:28:54,909
Scott: Is that what you're saying?

369
00:28:55,415 --> 00:28:56,750
Rym: I think there's a strong correlation.

370
00:28:57,576 --> 00:29:06,710
Rym: Sadly Alrighty then You said that like you're going to use this in some sort of argument against me No, I just wanted to put that on the table.

371
00:29:07,002 --> 00:29:08,110
Scott: Alright It's out there.

372
00:29:08,150 --> 00:29:08,190
Scott: I

373
00:29:08,230 --> 00:29:28,489
Rym: think it's more that the general, as we democratize access to distribution of ideas And consumption of ideas, that does not necessarily precipitate the full dissemination of those ideas Because every person, regardless of their abilities, is exposed to them But not everyone can get the same thing out of them.

374
00:29:29,432 --> 00:29:39,350
Rym: I mean, an idea is a meme And a meme can spread And some people can take on and then retransmit larger memes than other people.

375
00:29:40,590 --> 00:29:48,509
Rym: So maybe the same percentage of people throughout history just have the innate ability to handle large memes And some people can be trained to.

376
00:29:48,876 --> 00:29:50,444
Rym: Some people can't Some people refuse to.

377
00:29:50,991 --> 00:30:00,610
Rym: But the result is that if you add more people to the water where the meme virus is spreading That does not necessarily mean that that meme virus will spread to all those people.

378
00:30:01,953 --> 00:30:04,070
Rym: And I think the problem with this pop philosophy idea?

379
00:30:04,435 --> 00:30:05,450
Rym: Well not the problem with the idea.

380
00:30:05,551 --> 00:30:12,050
Rym: The problem it portends Is that memes spread if they're compact little concise things.

381
00:30:12,613 --> 00:30:16,110
Rym: That if more people can spread a meme, it's going to spread more rapidly.

382
00:30:16,696 --> 00:30:21,250
Scott: Because if only one percent It's like, you know, if you go to baseball at any stadium, right?

383
00:30:21,330 --> 00:30:26,744
Scott: The more people that you want to get to do something in unison The simpler it has to be, right?

384
00:30:27,470 --> 00:30:32,329
Scott: If you want to get, say, 10 people to like sing a song You could do that.

385
00:30:32,410 --> 00:30:34,749
Scott: You just give everyone the lyrics on a piece of paper, right?

386
00:30:35,230 --> 00:30:37,310
Scott: But try to get a hundred people to sing a song.

387
00:30:37,330 --> 00:30:42,870
Rym: There's one answer, soccer hooligans Ten thousand, they can be so drunk they can't see five feet in front of their faces.

388
00:30:43,194 --> 00:30:48,630
Scott: They can sing that song Right, but I mean, you know, they can't sing, you know, say a complicated song.

389
00:30:48,750 --> 00:30:55,890
Scott: And they have to, you know, getting them, they have to know that song in advance And they've trained and learned the song over a great period of time.

390
00:30:55,950 --> 00:31:08,690
Scott: If you just get a bunch of brand new people, you can do the wave And maybe you can clap in unison And maybe you can say like one or two words in unison But it's very difficult to get them to say, you know, do a complex thing.

391
00:31:08,750 --> 00:31:20,330
Rym: But if you let me finish my point and what I think was really happening I think what Postman was observing But now we can see it with hindsight more clearly Is that it's not the particular merits of any kind of media.

392
00:31:20,712 --> 00:31:24,789
Rym: It's simply that more media is more bi-directional and unidirectional.

393
00:31:25,453 --> 00:31:33,790
Rym: So now we kind of have a wider pool Where smaller pieces of information spread more rapidly and have more enduring power.

394
00:31:34,554 --> 00:31:47,830
Rym: So simply because we have more low-power transmitters Instead of a few high-power transmitters Smaller, more low-powered pieces of information Are the ones that are more fit to survive in the broad population.

395
00:31:48,952 --> 00:32:00,490
Rym: That's exactly what, you're not disagreeing with him at all No, because he's saying that the way the kind of media does it And he made all these arguments that television forces The transmission of the media is part of its kind.

396
00:32:00,594 --> 00:32:02,390
Scott: No, but Is an aspect of its kind.

397
00:32:03,073 --> 00:32:11,989
Rym: I'm making the much broader argument that it's the fact that it's transmitted at all Is the only factor Doesn't matter how it's transmitted All that matters is that it is transmitted in any form.

398
00:32:12,492 --> 00:32:19,010
Rym: And because more information can be transmitted more quickly in general We self-select toward the smaller pieces of information.

399
00:32:20,073 --> 00:32:23,010
Scott: That is one aspect of it, yes That's my whole argument.

400
00:32:23,890 --> 00:32:26,669
Scott: Alright, so I think you're on a lower level then?

401
00:32:27,631 --> 00:32:34,370
Rym: No, I really, I just, I don't, I think his book was kind of crap And I think he made a lot of good points But I think he made a lot of spurious conclusions.

402
00:32:34,695 --> 00:32:35,730
Scott: Yeah, anyway.

403
00:32:36,733 --> 00:32:41,570
Scott: So yeah, it's just, you know What is there, can we come up with any sort of solution for this problem, right?

404
00:32:41,610 --> 00:32:44,950
Scott: We want more PR, if we have this great thing, right?

405
00:32:45,010 --> 00:32:47,310
Scott: That we have basically the whole world almost, right?

406
00:32:47,330 --> 00:32:55,470
Scott: Is able to communicate with each other Without, you know, any significant hampering of time Or amount of information.

407
00:32:55,591 --> 00:32:59,310
Scott: Or, you know, we can basically get on webcams with everyone all at once, right?

408
00:33:00,171 --> 00:33:06,670
Scott: So we want people to sort of get new things Instead of just, you know, continuing to mull down low.

409
00:33:06,750 --> 00:33:17,050
Scott: We want, you know, the highest level, most useful, you know, conversations to be happening As opposed to people just, you know, basically bullshitting Thinking that they're on the high level.

410
00:33:17,131 --> 00:33:18,930
Scott: It might be impossible.

411
00:33:19,275 --> 00:33:22,550
Scott: It might be impossible Alright, so let's assume it's not impossible.

412
00:33:23,332 --> 00:33:27,110
Scott: In what scenario would we, any chance of it occurring?

413
00:33:27,270 --> 00:33:29,870
Rym: I think what it shows more is some of the, like.

414
00:33:30,071 --> 00:33:37,150
Rym: I think it is either the root or the symptom of the root Of a lot of the problems we have in the world today.

415
00:33:37,150 --> 00:33:39,470
Rym: I mean, look at the inherent problems of democracy.

416
00:33:39,610 --> 00:33:45,630
Rym: Look at the national dialogue about any popular topic in the United States.

417
00:33:45,711 --> 00:33:47,890
Scott: That is definitely, absolutely true.

418
00:33:48,931 --> 00:33:52,630
Rym: Almost all the discussion of any topic boils down to.

419
00:33:53,054 --> 00:33:54,410
Rym: I wouldn't even call them talking points.

420
00:33:54,450 --> 00:33:56,410
Rym: They're just, like, the abortion debate.

421
00:33:57,151 --> 00:34:03,409
Rym: A lot of the people who are anti-abortion don't have any argument or anything All they have.

422
00:34:03,651 --> 00:34:14,969
Scott: A lot of people who are pro-choice don't really have much of an argument either You know, they just boil everything down to the, you know, these incredibly simple things When the issue is ludicrously complex.

423
00:34:15,110 --> 00:34:24,550
Rym: Well, Scott, the thing is, with abortion in particular If you move to the higher levels, I think it's clear that one side has a Well, I'm not saying, I also agree that the pro-choice side is correct.

424
00:34:24,670 --> 00:34:40,965
Scott: I'm saying is that many of the people who argue, even though they're on the correct side Their argument is not on the highest level And that, you know, I could actually, you know, in some cases I could argue for the wrong side using a higher level argument And beat some of the people on the right side who have a

425
00:34:41,005 --> 00:34:41,690
Rym: lower level argument.

426
00:34:41,730 --> 00:35:02,970
Rym: No, you can't beat them because someone who makes a Remember, someone who makes, in one particular field We're not arguing about the intelligence of our human Just about the capability to transmit and relay a single meme In the abortion debate, someone who can only transmit these small, pro- or anti-meme Cannot be affected by the larger meme in any capacity.

427
00:35:03,712 --> 00:35:05,650
Rym: It cannot get to them unless you boil it down.

428
00:35:05,731 --> 00:35:10,930
Rym: And it is possible to take a large, complex meme Make it compact and still make it true.

429
00:35:11,112 --> 00:35:21,610
Rym: If you make a good argument at the high level And you boil the argument down to a very small, compact thing The end argument is still absolutely true And your little, compact thing is right.

430
00:35:22,092 --> 00:35:26,570
Rym: The problem is, it's very powerful, but it loses kind of the redundancy.

431
00:35:26,791 --> 00:35:29,810
Rym: It loses, like, its own self-referential metadata.

432
00:35:30,232 --> 00:35:33,550
Rym: So it's really easy to corrupt it and use it for the wrong purposes.

433
00:35:33,650 --> 00:35:45,710
Rym: Like, I make a boiled-down argument that is pro-choice, completely And while pro-choice, I think, is the absolutely inarguably correct philosophical And practical argument on all high level.

434
00:35:46,532 --> 00:35:52,290
Rym: I think most intelligent people agree on that point But I can make a boiled-down argument that is pro-choice.

435
00:35:52,896 --> 00:35:54,410
Rym: That is equally valid.

436
00:35:54,872 --> 00:36:09,969
Rym: However, because it's boiled down, it's so broad and tiny now Broad in scope, tiny in reference It is now a powerful philosophical hammer that people can use To back up very poor, unrelated ideas.

437
00:36:11,553 --> 00:36:16,270
Rym: It's the whole thing of libertarianism on the high level Is a great and fantastic field of debate.

438
00:36:16,752 --> 00:36:24,248
Rym: On the low level, it effectively turns into the rationale for I do what I want, I do what I want Right And that's bad.

439
00:36:24,532 --> 00:36:28,830
Scott: Well, I mean, you know, this makes me think of people Like, say, Ben Stein or Michael Moore, right?

440
00:36:28,950 --> 00:36:34,110
Scott: Two people who are basically completely wrong about a great, great many things To the majority of the time, right?

441
00:36:34,510 --> 00:36:45,690
Scott: And what they tend to do is they go and they make, you know, they make, you know, movies Or they get on TV and they talk And they're slightly above, you know, the lowest level, right?

442
00:36:45,770 --> 00:36:49,670
Scott: They get lots of information in there, you know, usually And they're smart people.

443
00:36:49,972 --> 00:36:52,310
Scott: Yeah, they're very smart, intelligent, right?

444
00:36:52,330 --> 00:37:03,170
Scott: They know what's going on And, you know, they get their information, you know Even if their opinions or stances might be wrong Most of their information is correct, you know Their, you know, their core facts.

445
00:37:03,332 --> 00:37:06,410
Rym: I'll argue the technically correct Right, technically correct, right.

446
00:37:06,451 --> 00:37:06,986
Scott: That's what I mean.

447
00:37:08,291 --> 00:37:12,510
Scott: But, you know, what they'll do is then they'll then deliver it in some sort of package.

448
00:37:13,054 --> 00:37:26,429
Scott: You know, that supports basically anything You could take, you know, you could, like, take all the facts out of, say, a Michael Moore movie And make a movie that argues against Michael Moore 100% With the same exact facts just by changing, you know, the other parts.

449
00:37:27,179 --> 00:37:39,190
Rym: And it's like The libertarian thing is the best example Where regardless of the high level rationale The low level pop philosophy meme is the rationale to do whatever you want.

450
00:37:39,291 --> 00:37:40,669
Rym: It's the Hitler rationale.

451
00:37:41,241 --> 00:37:50,689
Scott: Exactly So, and unless people are engaging at the high level If they're down at the low level, they can't really, that's it It's done.

452
00:37:50,852 --> 00:37:52,530
Scott: There's nothing, they can't contribute.

453
00:37:52,631 --> 00:37:57,470
Rym: It's almost like these low level memes At least these philosophy memes that people use to back bad ideas.

454
00:37:58,135 --> 00:38:04,470
Rym: It's like you have a responsible gun owner And, you know, philosophers are all effectively philosophical brain gun owners.

455
00:38:04,912 --> 00:38:08,250
Rym: They all have, they're responsible owners of very powerful guns.

456
00:38:08,852 --> 00:38:13,150
Rym: But if you boil down your philosophy to a meme and you're not extremely careful.

457
00:38:13,712 --> 00:38:23,627
Rym: That's the equivalent of taking your gun and giving it to someone who is blind and stupid And showing them where the trigger is and saying have fun I'll come back in a week.

458
00:38:24,152 --> 00:38:27,310
Scott: Yeah, because, you know, to give, you know, I don't know, I can't come up with any.

459
00:38:27,350 --> 00:38:28,589
Rym: But now look at this, look at what I just did.

460
00:38:28,892 --> 00:38:36,090
Rym: If I take this argument and I boil what I just said down into a meme You could trivially use that to rationalize ivory tower bullshit.

461
00:38:36,520 --> 00:38:38,290
Rym: That's true Keeping knowledge from the masses.

462
00:38:38,290 --> 00:38:46,950
Rym: And it would be trivial to rationalize that with the pop philosophy thing I just spouted Because the high order argument is so long that it won't spread in the memeosphere.

463
00:38:47,373 --> 00:38:49,649
Rym: I'll never use that word again in my life and I apologize for saying it.

464
00:38:51,911 --> 00:38:58,790
Scott: Well, yeah, but yeah, a high level, a high level idea has lots of ifs and ands and buts And this and that, right?

465
00:38:58,870 --> 00:39:02,750
Scott: I mean, look at something like, you know, discussion about like, you know, swine flu.

466
00:39:02,811 --> 00:39:04,430
Scott: It's like, well, it could spread like this.

467
00:39:04,530 --> 00:39:10,930
Scott: And, you know, the actual reality is incredibly complex Ludicrously complex, you know.

468
00:39:11,051 --> 00:39:22,090
Scott: Actually, random aside People boil, you know, that complexity down into, you know, these simple ideas, you know Random aside And they use those simple ideas to make their decisions.

469
00:39:22,291 --> 00:39:30,910
Scott: And really, no, it's very complex And your decision making, you know, is not taking the, you know, your, your is basically effective.

470
00:39:31,131 --> 00:39:34,590
Scott: You might as well be acting randomly the way you're making decisions, you know.

471
00:39:35,012 --> 00:39:37,590
Rym: So I guess there are two immediate questions.

472
00:39:37,810 --> 00:39:53,329
Rym: One, is there a way to foster a society where the either the intellectually large memes can spread Or where the intellectually large memes have more weight regardless of how many people wield them?

473
00:39:54,253 --> 00:40:05,329
Rym: Or where people, where these memes can be boiled down in such a way That people who aren't going to engage on the top level can still engage on a meaningful level?

474
00:40:07,116 --> 00:40:09,990
Rym: Uh, people, uh Can any of these be accomplished?

475
00:40:10,610 --> 00:40:14,124
Scott: Well, I don't know if you can engage at a meaningful level in an area.

476
00:40:14,144 --> 00:40:19,430
Scott: if you are, you know If you haven't just learned all, you know, the things you need to know to get up there.

477
00:40:19,470 --> 00:40:24,269
Scott: It's like if you haven't climbed the stair 10, you're not gonna, you're not involved in the 11th stair building.

478
00:40:24,691 --> 00:40:33,053
Rym: I have run into many people in my life who I know are perfectly capable Of engaging me on a higher level than they do And they just don't Mmm.

479
00:40:33,671 --> 00:40:38,068
Rym: There is definitely a difference between the people, between the will nots and the can nots.

480
00:40:39,095 --> 00:40:42,949
Rym: Mmm, that's very interesting And I don't know what to do about that.

481
00:40:43,333 --> 00:40:47,089
Rym: And then that raises the whole other ethical question of Say there are.

482
00:40:47,171 --> 00:40:48,669
Scott: That's just the issue of, you know, apathy.

483
00:40:48,891 --> 00:40:53,767
Rym: Yes, but even say there are will nots and there are can nots What do you do with the will nots?

484
00:40:54,111 --> 00:40:55,288
Rym: What do you do with the can nots?

485
00:40:55,550 --> 00:40:59,810
Rym: And how do you not make a meme for dealing with them that turns into genocide or eugenics?

486
00:41:03,072 --> 00:41:08,430
Scott: Uh, you know, whenever we do anything like this, you know, it's always like, well, how can we fix the world?

487
00:41:08,530 --> 00:41:10,989
Scott: Well, you know, you do what you can and that's it.

488
00:41:11,070 --> 00:41:11,431
Scott: But it really

489
00:41:11,471 --> 00:41:45,090
Rym: bothers me because it seems like every philosophy, no matter what it is No matter what it really says is boiled down generally and widely into I don't want to say a soundbite, but a meme so small in reference and so wide in scope That any possible course of action that any person could take in the entire world Whether it's good, whether it's bad, genocide, killing babies, whatever Is eminently justifiable if you use only low level memes.

490
00:41:45,170 --> 00:41:47,530
Scott: Yeah, go and look at like, you know, people always.

491
00:41:48,173 --> 00:41:51,190
Scott: One thing that people really like, I really like are like quotes, right?

492
00:41:51,350 --> 00:41:52,550
Scott: You know, aphorisms perhaps?

493
00:41:52,830 --> 00:41:58,570
Scott: Yes, you know, you find some famous person, a Thomas Jefferson or a Benjamin Franklin.

494
00:41:58,751 --> 00:42:02,550
Rym: Those who would give up liberty for security deserve neither.

495
00:42:02,972 --> 00:42:09,410
Scott: You find some quote and you say the quote and then someone else goes, Oh, that is very wise and makes perfect sense.

496
00:42:09,450 --> 00:42:12,910
Scott: And then you say some other quote, Oh, that is very wise and makes perfect sense, right?

497
00:42:13,350 --> 00:42:18,649
Scott: But it's great when you say like two quotes that are both so wise, like, you know, But they completely disagree.

498
00:42:19,571 --> 00:42:23,490
Rym: Or, I mean, look, like those who give up liberty for security deserve neither.

499
00:42:23,931 --> 00:42:29,930
Rym: You could use that to rationalize the taking away of security from people.

500
00:42:30,153 --> 00:42:34,570
Rym: If you really wanted to Yeah You could probably argue for taking away liberty.

501
00:42:36,693 --> 00:42:43,250
Scott: You know, I mean, you could look, Oh, the tree of liberty must, you know, From time to time be refreshed with the blood of patriots.

502
00:42:43,411 --> 00:42:45,450
Scott: Well, you could take that to mean Vampires.

503
00:42:45,831 --> 00:42:50,770
Scott: Yeah, you know, once in a while, you've just got to kill your own people.

504
00:42:51,553 --> 00:42:52,649
Scott: That's just how it's got to be.

505
00:42:52,872 --> 00:43:01,250
Rym: Maybe that is how it's got to be You know, maybe I think the problem is the academics always look for the ivory tower.

506
00:43:01,310 --> 00:43:03,166
Rym: I think we need the crimson tower.

507
00:43:03,951 --> 00:43:08,630
Scott: The crimson tower must be frequently refreshed with the blood of the academics.

508
00:43:09,550 --> 00:43:10,630
Scott: Come here, Roux style.

509
00:43:10,873 --> 00:43:12,288
Rym: No, I think the blood should flow upward.

510
00:43:13,811 --> 00:43:16,510
Scott: So it's like Ganesh, the milk just goes up.

511
00:43:16,650 --> 00:43:20,249
Rym: But that means we got to beat Newton because he's going to fuck us on this one.

512
00:43:21,412 --> 00:43:23,299
Rym: All right I think we've exhausted this topic.

513
00:43:25,110 --> 00:43:29,149
Rym: I think I've said every low level piece of discourse I have.

514
00:43:32,475 --> 00:43:34,609
Rym: And don't forget this weekend, Saturday, we'll be at the mocha.

515
00:43:34,814 --> 00:43:36,329
Rym: You'll find us Saturday, not Sunday.

516
00:43:37,032 --> 00:43:40,190
Rym: Very likely Saturday We will post somewhere if it ends up being Sunday.

517
00:43:46,713 --> 00:43:48,790
Rym: This has been GeekNights with Rym and Scott.

518
00:43:48,991 --> 00:43:51,430
Rym: Special thanks to DJ Pretzel for the opening music.

519
00:43:52,173 --> 00:44:03,290
Scott: Be sure to visit our website at www.frontroadcrew.com Where you'll find show notes, links, our awesome forum, a link to our Frapper map, and links to all the RSS feeds.

520
00:44:03,933 --> 00:44:09,569
Rym: We say feeds plural because GeekNights airs four nights a week covering four different brands of geekery.

521
00:44:10,135 --> 00:44:14,270
Rym: Mondays are science and technology Tuesdays we have video games, board games, and RPGs.

522
00:44:14,814 --> 00:44:20,249
Rym: Wednesdays are anime, manga, comic nights And Thursdays are the catch-alls for various rants and tomfoolery.

523
00:44:20,691 --> 00:44:28,729
Scott: You can send us feedback by email to geeknights@frontroadcrew.com Or you can send audio feedback via Odeo.

524
00:44:29,112 --> 00:44:32,330
Scott: Just click the link that says "send me an Odeo" on the right side of our website.

525
00:44:32,691 --> 00:44:37,790
Rym: If you like what you hear, you can catch the last 100 episodes in iTunes or in your favorite podcatcher.

526
00:44:38,051 --> 00:44:41,150
Rym: For the complete archives, visit the website which has everything.

527
00:44:41,733 --> 00:44:46,663
Scott: GeekNights is distributed under a creative commons attribution non-commercial share alike 2.5 license.

528
00:44:48,254 --> 00:44:54,290
Scott: This means you can do whatever you want with it as long as you give us credit, don't make money, and share it in kind.

529
00:44:55,111 --> 00:45:02,130
Scott: GeekNights is recorded live with no studio and no audience But unlike those other late shows, it's actually recorded at night.

